---
title: 部署ELK日志收集
date: 2025-03-11 18:00:00
---
> <font style="background-color:rgba(255, 255, 255, 0);">以3节点为例，存储使用local pv使用最大io性能，所有节点即是master节点也是data节点。完整内容可参考文档：</font>
>

> [<font style="background-color:rgba(255, 255, 255, 0);">https://www.cuiliangblog.cn/detail/section/162609409</font>](https://www.cuiliangblog.cn/detail/section/162609409)
>

<font style="background-color:rgba(255, 255, 255, 0);"></font>

<h1 id="0b32f354"><font style="background-color:rgba(255, 255, 255, 0);">系统参数调整</font></h1>
---

<h2 id="b27228a9"><font style="background-color:rgba(255, 255, 255, 0);">修改文件描述符数目</font></h2>
---

<font style="background-color:rgba(255, 255, 255, 0);">设置环境变量</font>

```plain
# 修改环境变量文件
vim /etc/profile
ulimit -n 65535
# 使配置生效
source /etc/profile
```

<font style="background-color:rgba(255, 255, 255, 0);"></font>

<font style="background-color:rgba(255, 255, 255, 0);">修改limits.conf配置文件</font>

```plain
# 修改limits.conf配置
vim /etc/security/limits.conf
* soft nofile 65535
* hard nofile 65535
```

<font style="background-color:rgba(255, 255, 255, 0);">验证</font>

```plain
# ulimit -n
65535
```

<font style="background-color:rgba(255, 255, 255, 0);"></font>

<h2 id="651ac674"><font style="background-color:rgba(255, 255, 255, 0);">修改虚拟内存数大小</font></h2>
---

<font style="background-color:rgba(255, 255, 255, 0);">内核设置可以直接在主机上设置，也可以通过具有特权的初始化容器中设置，通常情况下直接在主机上设置。</font>

<font style="background-color:rgba(255, 255, 255, 0);">临时设置</font>

```plain
# sysctl -w vm.max_map_count=262144
vm.max_map_count = 262144
```

<font style="background-color:rgba(255, 255, 255, 0);">永久设置</font>

```plain
cat >> /etc/sysctl.conf << EOF
vm.max_map_count=262144
EOF
# sysctl -p 
vm.max_map_count = 262144
```

<h1 id="6a435bf1"><font style="background-color:rgba(255, 255, 255, 0);">创建local pv资源</font></h1>
---

<h2 id="8115e1c9"><font style="background-color:rgba(255, 255, 255, 0);">创建StorageClass</font></h2>
---

<font style="background-color:rgba(255, 255, 255, 0);">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。  
</font><font style="background-color:rgba(255, 255, 255, 0);">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font>

```plain
[root@tiaoban eck]# cat > storageClass.yaml << EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
EOF
[root@tiaoban eck]# kubectl apply -f storageClass.yaml 
storageclass.storage.k8s.io/local-storage created
[root@tiaoban eck]# kubectl get storageclass
NAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s
```

<h2 id="33e882bc"><font style="background-color:rgba(255, 255, 255, 0);">创建pv</font></h2>
---

<font style="background-color:rgba(255, 255, 255, 0);">pv资源分布如下：</font>

| **<font style="background-color:rgba(255, 255, 255, 0);">pv名称</font>** | **<font style="background-color:rgba(255, 255, 255, 0);">主机</font>** | **<font style="background-color:rgba(255, 255, 255, 0);">路径</font>** | **<font style="background-color:rgba(255, 255, 255, 0);">容量</font>** |
| --- | --- | --- | --- |
| <font style="background-color:rgba(255, 255, 255, 0);">es-data-pv0</font> | <font style="background-color:rgba(255, 255, 255, 0);">k8s-test1</font> | <font style="background-color:rgba(255, 255, 255, 0);">/data/es-data</font> | <font style="background-color:rgba(255, 255, 255, 0);">50G</font> |
| <font style="background-color:rgba(255, 255, 255, 0);">es-data-pv1</font> | <font style="background-color:rgba(255, 255, 255, 0);">k8s-test2</font> | <font style="background-color:rgba(255, 255, 255, 0);">/data/es-data</font> | <font style="background-color:rgba(255, 255, 255, 0);">50G</font> |
| <font style="background-color:rgba(255, 255, 255, 0);">es-data-pv2</font> | <font style="background-color:rgba(255, 255, 255, 0);">k8s-test3</font> | <font style="background-color:rgba(255, 255, 255, 0);">/data/es-data</font> | <font style="background-color:rgba(255, 255, 255, 0);">50G</font> |


<font style="background-color:rgba(255, 255, 255, 0);">我们需要提前在各个节点下创建对应的数据存储目录。</font>

```plain
mkdir -p /data/es-data
```

<font style="background-color:rgba(255, 255, 255, 0);">创建pv资源：</font>

```plain
[root@tiaoban eck]# cat > pv.yaml << EOF
apiVersion: v1
kind: PersistentVolume
metadata:
  name: es-data-pv0
  labels:
    app: es-pv0
spec:
  capacity:
    storage: 50Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain # 删除策略
  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致
  local:
    path: /data/es-data # 本地存储路径
  nodeAffinity: # 调度至k8s-test1节点
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - k8s-test1
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: es-data-pv1
  labels:
    app: es-pv1
spec:
  capacity:
    storage: 50Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain # 删除策略
  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致
  local:
    path: /data/es-data # 本地存储路径
  nodeAffinity: 
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - k8s-test2
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: es-data-pv2
  labels:
    app: es-pv2
spec:
  capacity:
    storage: 50Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain # 删除策略
  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致
  local:
    path: /data/es-data # 本地存储路径
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - k8s-test3
EOF
[root@tiaoban eck]# kubectl apply -f pv.yaml 
persistentvolume/es-data-pv0 created
persistentvolume/es-data-pv1 created
persistentvolume/es-data-pv2 created
[root@tiaoban eck]# kubectl get pv | grep es
es-data-pv0                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s
es-data-pv1                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s
es-data-pv2                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s
```

<h2 id="892d3960"><font style="background-color:rgba(255, 255, 255, 0);">创建pvc</font></h2>
---

<font style="background-color:rgba(255, 255, 255, 0);">创建的时候注意pvc的名字的构成：pvc的名字 = volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font>

```plain
[root@tiaoban eck]# cat > pvc.yaml << EOF
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: elasticsearch-data-elasticsearch-es-all-0
  namespace: elk
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: local-storage
  selector:
    matchLabels:
      app: es-pv0
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: elasticsearch-data-elasticsearch-es-all-1
  namespace: elk
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: local-storage
  selector:
    matchLabels:
      app: es-pv1
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: elasticsearch-data-elasticsearch-es-all-2
  namespace: elk
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: local-storage
  selector:
    matchLabels:
      app: es-pv2
EOF
[root@tiaoban eck]# kubectl create ns elk
namespace/elk created
[root@tiaoban eck]# kubectl apply -f pvc.yaml 
persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-0 created
persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-1 created
persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-2 created
[root@tiaoban eck]# kubectl get pvc -n elk
NAME                                        STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE
elasticsearch-data-elasticsearch-es-all-0   Pending                                      local-storage   <unset>                 53s
elasticsearch-data-elasticsearch-es-all-1   Pending                                      local-storage   <unset>                 53s
elasticsearch-data-elasticsearch-es-all-2   Pending                                      local-storage   <unset>                 53s
```

<h1 id="5df6bac6"><font style="background-color:rgba(255, 255, 255, 0);">ECK部署</font></h1>
---

<h2 id="de76b7b1"><font style="background-color:rgba(255, 255, 255, 0);">部署CRD资源</font></h2>
---

```plain
[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/crds.yaml
[root@tiaoban eck]# kubectl apply -f crds.yaml 
customresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticsearchautoscalers.autoscaling.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/logstashes.logstash.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/stackconfigpolicies.stackconfigpolicy.k8s.elastic.co created
```

<h2 id="95f9c118"><font style="background-color:rgba(255, 255, 255, 0);">部署Operator</font></h2>
---

```plain
[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/operator.yaml
[root@tiaoban eck]# kubectl apply -f operator.yaml 
namespace/elastic-system created
serviceaccount/elastic-operator created
secret/elastic-webhook-server-cert created
configmap/elastic-operator created
clusterrole.rbac.authorization.k8s.io/elastic-operator created
clusterrole.rbac.authorization.k8s.io/elastic-operator-view created
clusterrole.rbac.authorization.k8s.io/elastic-operator-edit created
clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created
service/elastic-webhook-server created
statefulset.apps/elastic-operator created
validatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created
```

<h2 id="cd8992b6"><font style="background-color:rgba(255, 255, 255, 0);">验证</font></h2>
---

```plain
[root@tiaoban eck]# kubectl get pod -n elastic-system 
NAME                 READY   STATUS    RESTARTS   AGE
elastic-operator-0   1/1     Running   0          2s
[root@tiaoban eck]# kubectl get svc -n elastic-system 
NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE
elastic-webhook-server   ClusterIP   10.103.185.159   <none>        443/TCP   5m55s
```

<font style="background-color:rgba(255, 255, 255, 0);">当看到elastic-operator-0状态为Running时，表示eck已成功部署并运行在k8s集群上。</font>

---

<h1 id="e0dd4812"><font style="background-color:rgba(255, 255, 255, 0);">Elasticsearch部署</font></h1>
---

<h2 id="e6087b0d"><font style="background-color:rgba(255, 255, 255, 0);">创建elasticsearch集群</font></h2>
---

```plain
[root@tiaoban eck]# cat > es.yaml << EOF
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  namespace: elk
  name: elasticsearch
spec:
  version: 8.15.3
  image: harbor.local.com/elk/elasticsearch:8.15.3 # 自定义镜像地址，如果不指定则从elastic官方镜像仓库拉取
  nodeSets:
  - name: all # 节点名称
    count: 3  # 节点数量
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 50Gi # 指定master节点存储容量，与pvc容量保持一致。
        storageClassName: local-storage
    podTemplate:
      spec:
        containers:
        - name: elasticsearch
          env:
          - name: ES_JAVA_OPTS           # 指定节点JVM大小
            value: "-Xms1g -Xmx1g"
          resources:
            limits:											# 资源限制值，通常为JVM的2倍
              cpu: 1
              memory: 2Gi
            requests:										# 资源请求值，通常与JVM保持一致
              cpu: 500m
              memory: 1Gi
EOF
[root@tiaoban eck]# kubectl apply -f es.yaml
elasticsearch.elasticsearch.k8s.elastic.co/elasticsearch created
```

<h2 id="9778d05d"><font style="background-color:rgba(255, 255, 255, 0);">查看并验证资源</font></h2>
---

```plain
[root@tiaoban eck]# kubectl get pod -n elk
NAME                     READY   STATUS    RESTARTS   AGE
elasticsearch-es-all-0   1/1     Running   0          3m48s
elasticsearch-es-all-1   1/1     Running   0          3m48s
elasticsearch-es-all-2   1/1     Running   0          3m48s
[root@tiaoban eck]# kubectl get svc -n elk
NAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
elasticsearch-es-all             ClusterIP   None            <none>        9200/TCP   4m7s
elasticsearch-es-http            ClusterIP   10.96.196.197   <none>        9200/TCP   4m9s
elasticsearch-es-internal-http   ClusterIP   10.98.63.89     <none>        9200/TCP   4m9s
elasticsearch-es-transport       ClusterIP   None            <none>        9300/TCP   4m9s
[root@tiaoban eck]# kubectl get es -n elk
NAME            HEALTH   NODES   VERSION   PHASE   AGE
elasticsearch   green    3       8.15.3    Ready   4m22s
```

<font style="background-color:rgba(255, 255, 255, 0);">获取elastic用户密码</font>

```plain
[root@tiaoban eck]# kubectl get secrets -n elk elasticsearch-es-elastic-user -o go-template='{{.data.elastic | base64decode}}'
A1i529P3q783xblCSChV8zY1
```

<font style="background-color:rgba(255, 255, 255, 0);">导出CA证书</font>

```plain
[root@tiaoban eck]# kubectl -n elk get secret elasticsearch-es-http-certs-public -o go-template='{{index .data "ca.crt" | base64decode }}' > ca.crt
```

<font style="background-color:rgba(255, 255, 255, 0);">访问验证</font>

```plain
[root@rockylinux /]# curl -k https://elastic:A1i529P3q783xblCSChV8zY1@elasticsearch-es-http.elk.svc:9200/_cat/nodes?v
ip          heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name
10.244.0.55            8          71   8    0.65    0.69     0.66 cdfhilmrstw -      elasticsearch-es-all-0
10.244.2.32           45          72   9    0.90    0.98     0.82 cdfhilmrstw *      elasticsearch-es-all-2
10.244.1.24           25          70   7    1.04    0.91     0.73 cdfhilmrstw -      elasticsearch-es-all-1
```

<h2 id="3dcf82cf"><font style="background-color:rgba(255, 255, 255, 0);">创建ingress资源</font></h2>
---

<font style="background-color:rgba(255, 255, 255, 0);">自签证书创建secret资源</font>

```plain
[root@tiaoban eck]# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj "/CN=elk-tls"
Generating a RSA private key
writing new private key to 'tls.key'
[root@tiaoban eck]# kubectl create secret tls -n elk elk-tls --cert=tls.crt --key=tls.key
secret/elk-tls created
```

<font style="background-color:rgba(255, 255, 255, 0);">创建IngressRouter规则文件和ServersTransport文件，配置insecureSkipVerify使得traefik代理访问后端服务时跳过证书验证。</font>

```plain
[root@tiaoban eck]# cat > es-ingress.yaml << EOF
apiVersion: traefik.io/v1alpha1
kind: ServersTransport
metadata:
  name: elasticsearch-transport
  namespace: elk
spec:
  serverName: "elasticsearch.local.com"
  insecureSkipVerify: true
---
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: elasticsearch
  namespace: elk
spec:
  entryPoints:
    - websecure                  
  routes:
  - match: Host(`elasticsearch.local.com`)
    kind: Rule
    services:
    - name: elasticsearch-es-http
      port: 9200
      serversTransport: elasticsearch-transport
  tls:
    secretName: elk-tls
EOF
[root@tiaoban eck]# kubectl apply -f es.yaml
serverstransport.traefik.io/elasticsearch-transport created
ingressroute.traefik.io/elasticsearch created
```

<font style="background-color:rgba(255, 255, 255, 0);">添加hosts后访问验证</font>

![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892129822-ebb80e32-5d69-4e48-9c60-e940dd21b19e.jpeg)

<h1 id="e20976d4"><font style="background-color:rgba(255, 255, 255, 0);">Kibana部署</font></h1>
---

<h2 id="c7e46e28"><font style="background-color:rgba(255, 255, 255, 0);">创建kibana资源</font></h2>
---

```plain
[root@tiaoban eck]# cat > kibana.yaml << EOF
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: kibana
  namespace: elk
spec:
  version: 8.15.3
  image: harbor.local.com/elk/kibana:8.15.3
  count: 1
  elasticsearchRef: # 与Elasticsearch资源名称匹配
    name: elasticsearch
  podTemplate:
    spec:
      containers:
      - name: kibana
        env:
          - name: NODE_OPTIONS
            value: "--max-old-space-size=2048"
          - name: SERVER_PUBLICBASEURL
            value: "https://kibana.local.com"
          - name: I18N_LOCALE # 中文配置
            value: "zh-CN"
        resources:
          requests:
            memory: 1Gi
            cpu: 0.5
          limits:
            memory: 2Gi
            cpu: 2
EOF
[root@tiaoban eck]# kubectl apply -f kibana.yaml
kibana.kibana.k8s.elastic.co/kibana created
```

<font style="background-color:rgba(255, 255, 255, 0);">查看验证</font>

```plain
[root@tiaoban eck]# kubectl get pod -n elk | grep kibana
kibana-kb-6698c6c45d-r7jj6   1/1     Running       0          3m39s
[root@tiaoban eck]# kubectl get svc -n elk | grep kibana
kibana-kb-http                   ClusterIP   10.105.217.119   <none>        5601/TCP   3m43s
[root@tiaoban eck]# kubectl get kibana -n elk
NAME     HEALTH   NODES   VERSION   AGE
kibana   green    1       8.15.3     3m50s
```

<h2 id="fd33b243"><font style="background-color:rgba(255, 255, 255, 0);">创建Ingress资源</font></h2>
---

```plain
[root@tiaoban eck]# cat > kibana-ingress.yaml << EOF
apiVersion: traefik.io/v1alpha1
kind: ServersTransport
metadata:
  name: kibana-transport
  namespace: elk
spec:
  serverName: "kibana.local.com"
  insecureSkipVerify: true
---
apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: kibana
  namespace: elk
spec:
  entryPoints:
    - websecure             
  routes:
  - match: Host(`kibana.local.com`)
    kind: Rule
    services:
    - name: kibana-kb-http
      port: 5601
      serversTransport: kibana-transport
  tls:
    secretName: elk-tls
EOF
[root@tiaoban eck]# kubectl apply -f kibana.yaml
serverstransport.traefik.io/kibana-transport created
ingressroute.traefik.io/kibana created
```

<h2 id="046e223e"><font style="background-color:rgba(255, 255, 255, 0);">访问验证</font></h2>
---

<font style="background-color:rgba(255, 255, 255, 0);">客户端添加hosts记录后访问kibana测试</font>

![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892189533-8b40ab8f-903d-4572-a6e5-ed6c0be06c0b.jpeg)


{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"source/wechat-qr/wechat.jpg","path":"wechat-qr/wechat.jpg","modified":1,"renderable":0},{"_id":"node_modules/hexo-theme-butterfly/source/css/index.styl","path":"css/index.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/css/var.styl","path":"css/var.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/404.jpg","path":"img/404.jpg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/R.jpg","path":"img/R.jpg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/butterfly-icon.png","path":"img/butterfly-icon.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/error-page.png","path":"img/error-page.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/fire.jpg","path":"img/fire.jpg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/friend_404.gif","path":"img/friend_404.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/wechat.jpg","path":"img/wechat.jpg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/头像.jpg","path":"img/头像.jpg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/img/小屁股.jpg","path":"img/小屁股.jpg","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/tw_cn.js","path":"js/tw_cn.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/algolia.js","path":"js/search/algolia.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/local-search.js","path":"js/search/local-search.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/_date/index.md","hash":"ad8b033016b9846935124bc2f172f39f504344a4","modified":1743333431137},{"_id":"source/_posts/1.kubeadm高可用部署.md","hash":"df036fab6ce5782a31961430f4d10b0edab24052","modified":1743340150082},{"_id":"source/_posts/1.存储基础 副本.md","hash":"0a3693c7739f6215240db287b30489d50049cc73","modified":1743340766488},{"_id":"source/_posts/1.部署Harbor私有镜像仓库.md","hash":"1f0b045f47c1f6ec5469c674eb0e61a3fc021665","modified":1743340363237},{"_id":"source/_posts/1.配置环境(RHEL).md","hash":"8456a594d611fc6f34f72c45d56425855069b506","modified":1743340146407},{"_id":"source/_posts/10.部署calico网络组件 副本.md","hash":"d02b593cbafdf8a71ebc7e08699b0caf746d4e4b","modified":1743340457221},{"_id":"source/_posts/11.部署metrics监控组件.md","hash":"bece1b256d49c193fcba9b79b41dad88311b644f","modified":1743340476839},{"_id":"source/_posts/12.部署Redis数据库 副本.md","hash":"0bc54909097d881f09a97f389328cdeca514b17d","modified":1743340498013},{"_id":"source/_posts/12部署Prometheus监控.md","hash":"705a92ca92e5565ff3d4adb840efe98fafc70c24","modified":1743340524411},{"_id":"source/_posts/13.部署ELK日志收集.md","hash":"490277c0ebf1d4284f6f1336dd776e12a8fe426d","modified":1743340548542},{"_id":"source/_posts/16.部署Kafka消息队列 副本.md","hash":"fbf9d4bda5cc27a9c95c8fd147ee7c8bdca65a14","modified":1743340572873},{"_id":"source/_posts/17.部署Rabbit MQ消息队列.md","hash":"d14dd3ea31d8472eeeb0720f3866f98ecf9c7aeb","modified":1743340595461},{"_id":"source/_posts/2.ETCD——安装部署.md","hash":"5328652c32858bd177f08c3d50ab47b5319c0b16","modified":1743339849937},{"_id":"source/_posts/2.分布式存储 副本.md","hash":"3a81e3ed76020ad04d7d62b7cd1ddb6b2a9718d7","modified":1743340663838},{"_id":"source/_posts/2.安装容器运行时(Docker).md","hash":"0d4810d07a1f1b3ccb506dd1f1ee9b1939cccb9c","modified":1743340218818},{"_id":"source/_posts/2.部署helm包管理工具.md","hash":"3d2b4500835ffffe32dc5154f9f368f547a1e160","modified":1743340215127},{"_id":"source/_posts/3.ETCD——常用命令.md","hash":"ccbd863c72252c501dcbdca4ffc66d1eaeba3170","modified":1743339866864},{"_id":"source/_posts/3.安装容器运行时(Containerd) 副本.md","hash":"845b62626d6095ce88f8ab5b66bc41649ed4e4c3","modified":1743340255103},{"_id":"source/_posts/4.Containerd进阶使用 副本.md","hash":"31c09de7582b299fa2830d5f190a6e0e3602666c","modified":1743340287640},{"_id":"source/_posts/3.存储类型 副本.md","hash":"4c27d4f2852ca2594a41712e05c5d62d03daa1c1","modified":1743340699079},{"_id":"source/_posts/4.ETCD——confd配置管理.md","hash":"4864254a0c1f18e43a79a44cc7fef128c56c248c","modified":1743339887125},{"_id":"source/_posts/5.安装Kubernets集群.md","hash":"5862cc37cdcdfc69684819d0c5a5cba1e70897f5","modified":1743340316526},{"_id":"source/_posts/4.部署traefik代理.md","hash":"0f81ca313dccf8678cf9c117e5917296c6a161f5","modified":1743340420029},{"_id":"source/_posts/5.部署minIO对象存储 副本.md","hash":"5fcba9ed4b68e1f5af2aac3fe8bb3b7e1163f295","modified":1743340391609},{"_id":"source/_posts/Istio Basic.md","hash":"6a06624876e430a9db1a7d140b99556cede8fab0","modified":1743340778081},{"_id":"source/_posts/Istio.md","hash":"b0dfb55a22b50233a0c767d54dd37434e81cd0a5","modified":1743340781870},{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1743331094437},{"_id":"source/_posts/入门服务注册中心——consul 副本.md","hash":"23489199b0b7fc39dfdcef3d94bd1a66e56d0862","modified":1743340057647},{"_id":"source/tags/index.md","hash":"25ea7ee2342281bf8fec49dae220705efef21fb6","modified":1743332862954},{"_id":"source/wechat-qr/index.md","hash":"4b9948d518d68f0404d5ac3b71faed5bc5edd8cf","modified":1743340859485},{"_id":"source/link/index.md","hash":"00fe21c862e75366891a238242203961a153c615","modified":1743333294465},{"_id":"source/wechat-qr/wechat.jpg","hash":"3e039bf18d78b5d645e526ef4e6436e0280d3b16","modified":1741934916219},{"_id":"node_modules/hexo-theme-butterfly/README.md","hash":"e1b9096ae0c4e5ef0a911aec05dbad4a3aae3173","modified":1743332494392},{"_id":"node_modules/hexo-theme-butterfly/LICENSE","hash":"c8bc7df08db9dd3b39c2c2259a163a36cf2f6808","modified":1743332494147},{"_id":"node_modules/hexo-theme-butterfly/README_CN.md","hash":"92e45255b8725f0a00450c88fcfd51ec61e1db67","modified":1743332494390},{"_id":"node_modules/hexo-theme-butterfly/_config.yml","hash":"275fcf1c23362f740dbed97151d2e95ee39fb9ee","modified":1743339302835},{"_id":"node_modules/hexo-theme-butterfly/package.json","hash":"0f469650107841dc1dc716aa94b3ca2bb0721762","modified":1743332494384},{"_id":"node_modules/hexo-theme-butterfly/plugins.yml","hash":"a2704f0406484fdae3410e9992cf996f9859356e","modified":1743332495148},{"_id":"node_modules/hexo-theme-butterfly/.github/FUNDING.yml","hash":"da5e77f5e0cdb7e11b36546fb6796d10e3dfbe5d","modified":1743332495145},{"_id":"node_modules/hexo-theme-butterfly/languages/default.yml","hash":"a2c938b1ef69195aec10c90dc7d1871953548e01","modified":1743332495142},{"_id":"node_modules/hexo-theme-butterfly/languages/en.yml","hash":"a2c938b1ef69195aec10c90dc7d1871953548e01","modified":1743332495143},{"_id":"node_modules/hexo-theme-butterfly/languages/ja.yml","hash":"a281d3cc3e117e90597b783dc5569dba3976d2eb","modified":1743332495146},{"_id":"node_modules/hexo-theme-butterfly/languages/ko.yml","hash":"c7d861c58f204f47a5b4d6e118e1f1e8fb8a852f","modified":1743332495147},{"_id":"node_modules/hexo-theme-butterfly/languages/zh-CN.yml","hash":"e0bf36edf18cf3380b900be7528b536252990c26","modified":1743332495153},{"_id":"node_modules/hexo-theme-butterfly/languages/zh-HK.yml","hash":"bac3063ad2892be232f7d91361c28585a3cc7eb5","modified":1743332495155},{"_id":"node_modules/hexo-theme-butterfly/languages/zh-TW.yml","hash":"bd7ee35aa30964493d2729ef105bb86331b096c3","modified":1743332495157},{"_id":"node_modules/hexo-theme-butterfly/layout/archive.pug","hash":"bc77220dfc269b8faad0930e1a4142ebf68165e5","modified":1743332494913},{"_id":"node_modules/hexo-theme-butterfly/layout/category.pug","hash":"a7e9805a781e34e38d27462e6ce2a5821c34bb9f","modified":1743332494946},{"_id":"node_modules/hexo-theme-butterfly/layout/index.pug","hash":"a93004cc8ec8050df603d32a6e6e02cd96fd9875","modified":1743332494991},{"_id":"node_modules/hexo-theme-butterfly/layout/page.pug","hash":"7ce2a49c6c41847de4ccea377ade116339984434","modified":1743332495011},{"_id":"node_modules/hexo-theme-butterfly/layout/post.pug","hash":"65c4a49c65c3fc4d9dc88b9791a75710c698c3a1","modified":1743332495020},{"_id":"node_modules/hexo-theme-butterfly/layout/tag.pug","hash":"ca5333bd262cb58c195c844b593a0eed0c721766","modified":1743332495039},{"_id":"node_modules/hexo-theme-butterfly/.github/ISSUE_TEMPLATE/bug_report.yml","hash":"10ce05c8dbde09f53bdabe40b5388de9ccc71a31","modified":1743332495139},{"_id":"node_modules/hexo-theme-butterfly/.github/ISSUE_TEMPLATE/config.yml","hash":"63ad2249ad09fb3fe21bd5ff9adefb304a7ab24a","modified":1743332495140},{"_id":"node_modules/hexo-theme-butterfly/.github/ISSUE_TEMPLATE/feature_request.yml","hash":"6e0f9470b18bd37d4891282ac73d61676b040e8c","modified":1743332495144},{"_id":"node_modules/hexo-theme-butterfly/.github/workflows/publish.yml","hash":"e320b40c051bae1549156cd5ea4a51383cf78598","modified":1743332495149},{"_id":"node_modules/hexo-theme-butterfly/.github/workflows/stale.yml","hash":"4040c76547e270aaf184e9b219a44ca41bbb1b9f","modified":1743332495151},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/additional-js.pug","hash":"f9b02aac0dbbb2b71c037dd215e70c8b7ec7741c","modified":1743332494902},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/footer.pug","hash":"6bd41add3a45e55d5e51eab5285a2d1a909d37f3","modified":1743332494972},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head.pug","hash":"1d11e334b22dbbedcb0f751f9ee9789d4416605e","modified":1743332494980},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/layout.pug","hash":"e5e6c05a621483b3542f2884e8ba45e84b1e973a","modified":1743332494997},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/pagination.pug","hash":"bd45e6fa935ace9cb54499b0491dacfb78ccc354","modified":1743332495014},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/sidebar.pug","hash":"3e65b7bf6bccccbba7e15349f0a44f15c64c5b5e","modified":1743332495033},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/rightside.pug","hash":"43f951b639038f3bc01deea03368d8dcf492cbb0","modified":1743332495031},{"_id":"node_modules/hexo-theme-butterfly/scripts/common/postDesc.js","hash":"272613a71d16f0de6dac883be4839259f774be76","modified":1743332494358},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/404.js","hash":"039fc75f363d79669b0b2177d929cdff6f2ef7a4","modified":1743332494206},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/cdn.js","hash":"7864ba45716c51aef8d8b04fd4bc212e0008ce3b","modified":1743332494219},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/comment.js","hash":"7b1b16e1e8e08245a345764616956be50487eb53","modified":1743332494226},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/init.js","hash":"ce68e84a9ccfcf91100befbaa9afc392a0cd93bb","modified":1743332494237},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/merge_config.js","hash":"10ffed853a935498f1f5da2c5b57200c957874a7","modified":1743332494347},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/stylus.js","hash":"bac639c404588ea62e601ef0bcd368c3bd0119af","modified":1743332494368},{"_id":"node_modules/hexo-theme-butterfly/scripts/events/welcome.js","hash":"f59e10305fef59ea3e62a7395106c0927582879d","modified":1743332494382},{"_id":"node_modules/hexo-theme-butterfly/scripts/filters/post_lazyload.js","hash":"b23108d29fff3e32384d8689c8bcd2ab306a1ae7","modified":1743332494355},{"_id":"node_modules/hexo-theme-butterfly/scripts/filters/random_cover.js","hash":"20a6ebf63439501a4b3fc81e7a2a2ea5d103bace","modified":1743332494361},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/aside_archives.js","hash":"3eb0bbb1288dc7b0ff82cc46ceb53bd666893416","modified":1743332494212},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/aside_categories.js","hash":"0cdf781a8c14d7b50d309e69f282ec7b178804bb","modified":1743332494214},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/getArchiveLength.js","hash":"bf77635e920eaf52bceebc95f87c7c87a7ca8038","modified":1743332494235},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/inject_head_js.js","hash":"00c5742ad1c75b3c5684d02ffc6a1921399e5376","modified":1743332494241},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/page.js","hash":"a07b586b510aa2df953102d998e84207acc34f9b","modified":1743332494353},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/related_post.js","hash":"950b7d0966429bf0f9e6c5e1161e50e545e320b4","modified":1743332494364},{"_id":"node_modules/hexo-theme-butterfly/scripts/helpers/series.js","hash":"45367c4ce827329867dbcc750ec125da9ccb2cfd","modified":1743332494365},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/button.js","hash":"2f44e1b3ccd170b256eae178299d6fa933a8d490","modified":1743332494216},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/chartjs.js","hash":"195ba802d7e8406c155124a9c939a2318f82938b","modified":1743332494224},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/flink.js","hash":"25eefe10189caf3910a0e5d5b2f2043ae9255531","modified":1743332494228},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/gallery.js","hash":"fa3d0a64f7fce4aff7928d4ddd95548978ba001c","modified":1743332494233},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/hide.js","hash":"f02fb085a88a2c0c82aeffacc24e1b71c74bd7c0","modified":1743332494236},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/inlineImg.js","hash":"89c6c78d2db43b190055d5690741a79bab4f3e7e","modified":1743332494242},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/label.js","hash":"cf0bc17d0180231167cc6aa8a00fc64f198cb9f9","modified":1743332494244},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/mermaid.js","hash":"50d8d8fac5c5b6e26317028895d7d82a2cf46606","modified":1743332494348},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/note.js","hash":"e68d8d21f3a86e3646907a3685550ee20e8d4a9f","modified":1743332494350},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/score.js","hash":"f589fb6646bd17cf12d77a9b251dd614e1c8b899","modified":1743332494365},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/series.js","hash":"40bc9a065e3a1423e0e66f4911e00713ca9f5e9e","modified":1743332494367},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/tabs.js","hash":"3c486b149e28edd1a06843f05a5c355000991b82","modified":1743332494370},{"_id":"node_modules/hexo-theme-butterfly/scripts/tag/timeline.js","hash":"176804f07567aa80f1ed95897a968a996b155dec","modified":1743332494372},{"_id":"node_modules/hexo-theme-butterfly/source/css/index.styl","hash":"b13d96924a5534bff91d75566b196ac87b4fac22","modified":1743332495101},{"_id":"node_modules/hexo-theme-butterfly/source/css/var.styl","hash":"d1eec577074ab7b262182885576135bf1896e12c","modified":1743332495131},{"_id":"node_modules/hexo-theme-butterfly/source/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1743332494205},{"_id":"node_modules/hexo-theme-butterfly/source/img/error-page.png","hash":"d2519710498a871ca3e913c57e2ba20a805b6430","modified":1743332494891},{"_id":"node_modules/hexo-theme-butterfly/source/img/favicon.ico","hash":"455ac256580bf31a45813dbbdb87219bfc8bfb04","modified":1743332494197},{"_id":"node_modules/hexo-theme-butterfly/source/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1743332494191},{"_id":"node_modules/hexo-theme-butterfly/source/js/main.js","hash":"5a52047b8520f79864d5a4ee2379a29751aead23","modified":1743332494344},{"_id":"node_modules/hexo-theme-butterfly/source/js/tw_cn.js","hash":"fdb5482d04a75bd79946ad1ed291d281d0e9362d","modified":1743332494377},{"_id":"node_modules/hexo-theme-butterfly/source/js/utils.js","hash":"48637ad8e405306772b93837f33400bde1055819","modified":1743332494381},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/Open_Graph.pug","hash":"e93a36d3c29b5a02c7f26a23f96e1f84b063cbe8","modified":1743332495005},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/analytics.pug","hash":"e792a435afee1f9491095084a00dc77e3522c1fd","modified":1743332494909},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/config_site.pug","hash":"56a3c32de1a15627ff38c67f1131cdd6ec5ac924","modified":1743332494957},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/config.pug","hash":"9ea75b06f19bf356f340f4a3fc1bdc0713cfe445","modified":1743332494958},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/google_adsense.pug","hash":"f29123e603cbbcc6ce277d4e8f600ba67498077c","modified":1743332494979},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/pwa.pug","hash":"83ed05ef1e39f2ee70c3fba2cf96e488d8ffec66","modified":1743332495025},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/preconnect.pug","hash":"1e1a69aa2cbda2e621c741b3802093244b3cc04e","modified":1743332495022},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/site_verification.pug","hash":"5168caadc4cf541f5d6676a9c5e8ae47a948f9ad","modified":1743332495034},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/head/structured_data.pug","hash":"1b83ae33961528f128596753fd05067c672d6bff","modified":1743332495036},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/index.pug","hash":"44331c9db74b281b5c5c41439d3407a9076df1a1","modified":1743332494981},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/menu_item.pug","hash":"733184f88e3a586a5fcc9d193ad500556b6c8eed","modified":1743332495003},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/nav.pug","hash":"18b984ce184ea53d2dff5a03cc2d0d39d2ec3406","modified":1743332495005},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/post-info.pug","hash":"7d799c4694adb6e265e3f4b975d7f7f6a7021a17","modified":1743332495019},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/header/social.pug","hash":"e2d31e0f450ad42c47f7ee96375799342bf2f19b","modified":1743332495035},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/loading/fullpage-loading.pug","hash":"a2f7d69ca7ec58f24fe7d4e04ae21d5b62b01567","modified":1743332494973},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/loading/pace.pug","hash":"9d2d539555bab495959b9df734ed5c43a9f9e5a9","modified":1743332495007},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/loading/index.pug","hash":"d76ce71ba106e350670c021a3dcae57547d01830","modified":1743332494982},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/mixins/article-sort.pug","hash":"ef7afe0df7a3746744ac8185da7163b7406120ca","modified":1743332494923},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/mixins/indexPostUI.pug","hash":"f3389fa9ae4fa32e3c16573286583bc3023e57ad","modified":1743332494993},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/404.pug","hash":"15d32c511e4875066fcbe9cb84c3ada07b5a7c41","modified":1743332494896},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/categories.pug","hash":"5276a8d2835e05bd535fedc9f593a0ce8c3e8437","modified":1743332494945},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/default-page.pug","hash":"efb40388e37cca0b5e7c3c66e811a42f8d32c910","modified":1743332494960},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/flink.pug","hash":"6b0fa5f048aca8e9cbe56978301af918cf7ac34a","modified":1743332494970},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/shuoshuo.pug","hash":"b2423cfc57a5e3a0e1112ff7c18d5c5c720d89d5","modified":1743332495032},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/page/tags.pug","hash":"79ad31eb72a9e14007770b18a426406a25315b38","modified":1743332495039},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/post/outdate-notice.pug","hash":"b7ce9484bc5c97ea6154f0b78fb9b8951fafedbd","modified":1743332495007},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/post/post-copyright.pug","hash":"b96c232e5178d927987791d9ae386dd83679535a","modified":1743332495017},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/post/reward.pug","hash":"db92f25ff3fd061882f81bf74ca560ff66983a0c","modified":1743332495029},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/aplayer.pug","hash":"ed79fef5b5025415ea12eaed970f3fe7f6ef9596","modified":1743332494912},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/effect.pug","hash":"43014bfc63583d3ee8808d526dd165848c0ed52f","modified":1743332494968},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/pjax.pug","hash":"efe4f8019632b51c92c4f7628758538305e06e47","modified":1743332495015},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/prismjs.pug","hash":"88f979a0b1a19eeb0db229247833bf9c6865c3b9","modified":1743332495023},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/subtitle.pug","hash":"236c3ce26dd76e80b04d457789475c42da5ac0c8","modified":1743332495037},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/umami_analytics.pug","hash":"bc35a1552d26ecdeeadbf06300078dbb5128a6e5","modified":1743332495048},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_ad.pug","hash":"a8312b527493dabbadbb1280760168d3bc909a3b","modified":1743332494925},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_announcement.pug","hash":"21e019bdc3b1e796bb00976bb29af2d51f873624","modified":1743332494927},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_archives.pug","hash":"73d33b6930e7944187a4b3403daf25d27077a2dd","modified":1743332494928},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_author.pug","hash":"1aba8aa7cd767dc96879d13a13b4c8ceb9023233","modified":1743332494930},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_bottom_self.pug","hash":"1dba77d250eeebfb6e293d504352c7e9ea31980b","modified":1743332494931},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_categories.pug","hash":"66e383b4ef374951eb87dd1bf4cdb7a667193fb5","modified":1743332494933},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_newest_comment.pug","hash":"d8753772889b5d0f4d15639ed6af5e91e53b1d03","modified":1743332494934},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_post_series.pug","hash":"e0bb72fa0ce15964b11b8fe421cae3432394e35f","modified":1743332494935},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_post_toc.pug","hash":"1dd19a564320d248dbcee7f118a5b96c6466da65","modified":1743332494936},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_recent_post.pug","hash":"bb842d2aa6469d65bf06af1372f0a19a9e4ef44c","modified":1743332494939},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_tags.pug","hash":"842b772a387b576550fa127030e1c2e9bf65716d","modified":1743332494941},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_top_self.pug","hash":"7b5ae404a1205546b7de4be42291315cf918f2b3","modified":1743332494942},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/card_webinfo.pug","hash":"fcddd80cdeb6aa81f342cd9f0102302f6ba087a8","modified":1743332494944},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/widget/index.pug","hash":"45f620cd87b9ef2aa9d1e024e697ed6b4eecff34","modified":1743332494989},{"_id":"node_modules/hexo-theme-butterfly/source/css/_global/function.styl","hash":"d12340a7df4601b9a23f070e16645861aeb3bb0a","modified":1743332495086},{"_id":"node_modules/hexo-theme-butterfly/source/css/_global/index.styl","hash":"4fcb8222b9548e22f7b76f12d33e3698240cbae0","modified":1743332495099},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/highlight.styl","hash":"67062d597408068e4a59e95851e98fed34b745da","modified":1743332495095},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/theme.styl","hash":"a51edfd3e499e7d38c32241c40e8e4d371efca73","modified":1743332495126},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/aside.styl","hash":"ba174889e770ae9f6683379b9eae9d8c94253080","modified":1743332495068},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/chat.styl","hash":"4cc02bcbaa4a1933a82a9ea57a603fe2d059fc77","modified":1743332495070},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/comments.styl","hash":"fbfce4d67cacd1df22fb73d89d008693f59d9d91","modified":1743332495072},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/footer.styl","hash":"d7b988d8588207086670f39aa49fce442c429f7a","modified":1743332495083},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/head.styl","hash":"094108f2a4e351a2fa496d6bd3e2388151416b3f","modified":1743332495090},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/pagination.styl","hash":"7d7554573c005399bc8c2264a85896d2d51be1e1","modified":1743332495111},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/loading.styl","hash":"f0b01bbf321c2c24fdccaee367dd9fd448031a72","modified":1743332495105},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/post.styl","hash":"543eaf9c7df7e0db841e5946ee5f9082c3c46290","modified":1743332495115},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/relatedposts.styl","hash":"ef8e8549fe7ad4b99793844a93b4a89f77f417d5","modified":1743332495116},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/reward.styl","hash":"d9cdf564a822a585e67fd5bac8573ba87eeb3743","modified":1743332495117},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/rightside.styl","hash":"a0f5835f04358122e8b1d38dd3e8da09a1b5b431","modified":1743332495119},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/sidebar.styl","hash":"084dc4dfb41f55e237a9d6cf8c2f5dba729b83be","modified":1743332495123},{"_id":"node_modules/hexo-theme-butterfly/source/css/_layout/third-party.styl","hash":"0af7c8754f04bdd9a02a14d880774753bd2e35ee","modified":1743332495127},{"_id":"node_modules/hexo-theme-butterfly/source/css/_mode/darkmode.styl","hash":"4c9849df9c68d892c7df0ca28123aeb0dc9dc424","modified":1743332495076},{"_id":"node_modules/hexo-theme-butterfly/source/css/_mode/readmode.styl","hash":"ad66212554468b7067590308ed4cf40524fea662","modified":1743332495115},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/404.styl","hash":"205ccc7d0ec6ce1193b46bc0c9ce0385594581fb","modified":1743332495060},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/archives.styl","hash":"5abe5480d83ff8b452a780a484d50a44091475bf","modified":1743332495064},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/categories.styl","hash":"c4cda7b0c99015df29ce00fdfddd2f7679653754","modified":1743332495070},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/common.styl","hash":"dcff804c4c237e1e908481b44c1ac4e39ac0da34","modified":1743332495073},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/flink.styl","hash":"1f8d715faf3b91b53426e38195c0920afb3bfa1c","modified":1743332495082},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/homepage.styl","hash":"992d192db7d1c96e995b85ed11c20c571d33fbad","modified":1743332495098},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/shuoshuo.styl","hash":"79bb1d9a27822ed5675d1e52f5dbd0e2f5d5010a","modified":1743332495121},{"_id":"node_modules/hexo-theme-butterfly/source/css/_page/tags.styl","hash":"7543bb688876a946538d66b991c71b94b5216277","modified":1743332495125},{"_id":"node_modules/hexo-theme-butterfly/source/css/_search/algolia.styl","hash":"d8a8275a68a1421c4c09b604cf78bea16c1d0463","modified":1743332495062},{"_id":"node_modules/hexo-theme-butterfly/source/css/_search/index.styl","hash":"6c4cbdadd9a49029fe0c59e29808d873e5b6b6ee","modified":1743332495100},{"_id":"node_modules/hexo-theme-butterfly/source/css/_search/local-search.styl","hash":"1f2b86df86df81c3a59377b29102314ffc73dfa6","modified":1743332495107},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/button.styl","hash":"de8437a058a315d14d7e7034066f095b7b3ed4b4","modified":1743332495069},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/gallery.styl","hash":"30d1f809efd252ed0233d96d4374efd2b01d2292","modified":1743332495087},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/hexo.styl","hash":"985b183db7b7bfd8f9bdb60494549fb7f850348b","modified":1743332495091},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/hide.styl","hash":"d27dbccaf3de1c9158d19e4fd49a25953cb5778d","modified":1743332495092},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/inlineImg.styl","hash":"3be8d0a75e7cc96548667cae0cb6a474279bd0b5","modified":1743332495101},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/label.styl","hash":"216f52fefc2274b542b549d8470503e6f1a308fb","modified":1743332495102},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/note.styl","hash":"4929382bd60788d34752a66e2fe764ef797a72a0","modified":1743332495109},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/series.styl","hash":"0657169849bc4bf4d93b5492ade040c8f58c1901","modified":1743332495120},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/tabs.styl","hash":"3a88eedcb694da79e92581ce50cb1a430b1fb615","modified":1743332495124},{"_id":"node_modules/hexo-theme-butterfly/source/css/_tags/timeline.styl","hash":"e846ddaef494d46cdfa2379deacfe74fa1cc5264","modified":1743332495129},{"_id":"node_modules/hexo-theme-butterfly/source/css/_third-party/normalize.min.css","hash":"8549829fb7d3c21cd9e119884962e8c463a4a267","modified":1743332494152},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/algolia.js","hash":"7119f2f2943de71999d3dd6ba5c60cde846f114b","modified":1743332494210},{"_id":"node_modules/hexo-theme-butterfly/source/js/search/local-search.js","hash":"a2b783230a9143de69004cfc914d9f55e6fc1660","modified":1743332494246},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/abcjs/index.pug","hash":"f0a90d8e39915a74b16ef22e851f179415cd7eaa","modified":1743332494982},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/artalk.pug","hash":"b03ee8625149191f9d5d057bbc9824b68d8dd0c4","modified":1743332494916},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/disqus.pug","hash":"d6fff5a7f84c8b09f282f9ddc0020a68a8aac9ea","modified":1743332494962},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/fb.pug","hash":"cbfbcf34a24d21ba2b21cf9eedb76f4c3c563c5a","modified":1743332494969},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/index.pug","hash":"846cabae287ae31b3bbfac3da022475713dd5ecc","modified":1743332494984},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/remark42.pug","hash":"716dc463fe4ef5112e7018ed60804125fdfa5cad","modified":1743332495026},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/twikoo.pug","hash":"b5db4203a1392385838c73549ddeae0a4be67eba","modified":1743332495045},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/valine.pug","hash":"7884883ec15792f7e54daacb3c62b851dde2b66a","modified":1743332495050},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/abcjs/abcjs.pug","hash":"febff991595504d8e850ced0b9cc090f02ed97f0","modified":1743332494900},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/chatra.pug","hash":"5b29badecbbe828112c001156023fc0566045cf6","modified":1743332494951},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/card-post-count/waline.pug","hash":"fd2320ee25507bb8ef49f932c2d170586b44ea4d","modified":1743332495053},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/crisp.pug","hash":"24d094fd917947c0ca7492fa094328b1a183b873","modified":1743332494959},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/index.pug","hash":"e8438941085def0591a72fc9b0d705dbf107f54f","modified":1743332494984},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/chat/tidio.pug","hash":"62466b251052cae609b6369d4cb4b6a85320757d","modified":1743332495041},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/artalk.pug","hash":"89c63a5f0c0ab6314de7158fbc8fcbc84997fc55","modified":1743332494918},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/disqus.pug","hash":"f2ea5249b3e6670f6c8c77868f4f42c502e43830","modified":1743332494963},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/disqusjs.pug","hash":"c81fa7d8a5cb96d1ae07bfa8c46b84a58161add1","modified":1743332494964},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/facebook_comments.pug","hash":"8af585e6d6f73ee57114eefad574dc6e8ea9f570","modified":1743332494969},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/giscus.pug","hash":"592b2251db6c1abeb8b0eebe3b2e6d9aa0dec445","modified":1743332494975},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/gitalk.pug","hash":"58914c58a190e3bc0aa37cb581e77e442b563501","modified":1743332494977},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/index.pug","hash":"db6713d2b90eb8183f86ac92c26761a8501c0ddb","modified":1743332494985},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/js.pug","hash":"3abbaaa4ea575c45b3cebffd40bad1acc6ffce84","modified":1743332494994},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/livere.pug","hash":"7a80231fc71822e503879383a2d9611edf1d72dd","modified":1743332494998},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/remark42.pug","hash":"84f7cfde00f929fa3dc40349bcab060ec68f1b9f","modified":1743332495027},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/twikoo.pug","hash":"53d99831f29aeb2e336ed1407d79590041f77002","modified":1743332495046},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/utterances.pug","hash":"30a7d157890de69deab28baa47fb7bb28b040efd","modified":1743332495050},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/valine.pug","hash":"24f18b0c67803210d53abbf9c1d454c000b06eee","modified":1743332495051},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/comments/waline.pug","hash":"e2bf15357485cd502414b3b20f5b1f762a2fd014","modified":1743332495056},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/chartjs.pug","hash":"732eb1118ea1a73aa5c164d639097c614f8e9953","modified":1743332494948},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/index.pug","hash":"af66d13204030d47537b9e31a6173e63589ce7ff","modified":1743332494986},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/katex.pug","hash":"b83db9fa64d42a0bfd97efb660e09be3f166a144","modified":1743332494995},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/mathjax.pug","hash":"db2f4fff80a1166476ea76ae004aa186df11bad3","modified":1743332495001},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/math/mermaid.pug","hash":"ca2fc5928ca292f29fd8333c73733344994096fb","modified":1743332495004},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/artalk.pug","hash":"187302dbc916852ff2fdf47061e272c061611dda","modified":1743332494920},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/common.pug","hash":"27fa75affebc6e84a487c62bceff783bde595256","modified":1743332494956},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/disqus-comment.pug","hash":"fa4b4194749d05f7249f365f2b89c0281057ce54","modified":1743332494961},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/github-issues.pug","hash":"72e2970b23570e308f8af5d8ba8e5e3321d01bbf","modified":1743332494979},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/index.pug","hash":"a7c07dbc1e970a5b247091458e1ee9b144a3366d","modified":1743332494987},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/remark42.pug","hash":"34edfebf0cace0852806be774910ccb0e0914650","modified":1743332495028},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"d2e12a9fc302a4efe52c90d44896fbd73e193a1f","modified":1743332495044},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/valine.pug","hash":"d376ec17fb19fcdcf0d2ad71330190146d3af879","modified":1743332495052},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/newest-comments/waline.pug","hash":"ec6c685080634ac46ffbea1b8f10313388888f43","modified":1743332495058},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/search/algolia.pug","hash":"7f0ede1cd3fed2669c94a8e1b21bc0b183f310b8","modified":1743332494906},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/search/docsearch.pug","hash":"013756ff3363344987cc00fc9bd833baf193c341","modified":1743332494967},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/search/index.pug","hash":"f8557548d2ad8dd149c562193991c6c6cda02415","modified":1743332494988},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/search/local-search.pug","hash":"2622b4cf9189fa23e4a422aaf9ef272e4f2c6137","modified":1743332494999},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/share/addtoany.pug","hash":"f5ee1c9c8ffa4bca972d30f4de69268b8d47f052","modified":1743332494904},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/share/index.pug","hash":"e51e896ccb13900de38dc81cf44dc789e2418a12","modified":1743332494988},{"_id":"node_modules/hexo-theme-butterfly/layout/includes/third-party/share/share-js.pug","hash":"efef352c1d122409575386bf3894dce8e87032e2","modified":1743332495031},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/highlight/diff.styl","hash":"9f02598b5e4296aec6470639d4bac4c9ac46392e","modified":1743332495078},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/highlight/index.styl","hash":"ef52ebf1e8e751a412f9456fdaeee7d88afd9a72","modified":1743332495100},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/prismjs/diff.styl","hash":"077ec530831be1d80e93da380406b9f5abd0918a","modified":1743332495081},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/prismjs/index.styl","hash":"1883c91d43bff10aae55122a21e0b064b6f5c9dd","modified":1743332495100},{"_id":"node_modules/hexo-theme-butterfly/source/css/_highlight/prismjs/line-number.styl","hash":"de4bb5fc2dfca368b35e4c1109c92f7abc9e2245","modified":1743332495105},{"_id":"node_modules/hexo-theme-butterfly/source/img/头像.jpg","hash":"88c4681a842a18e8d0afa1d98d17cac58e97ea74","modified":1741159374455},{"_id":"node_modules/hexo-theme-butterfly/source/img/wechat.jpg","hash":"3e039bf18d78b5d645e526ef4e6436e0280d3b16","modified":1741934916219},{"_id":"node_modules/hexo-theme-butterfly/source/img/butterfly-icon.png","hash":"f5dd732fed5c3bcd4aa76bac3441bac8485fb432","modified":1743332494711},{"_id":"node_modules/hexo-theme-butterfly/source/img/R.jpg","hash":"a20b9d4911248d527aab6197ddea510722837428","modified":1743339165116},{"_id":"node_modules/hexo-theme-butterfly/source/img/fire.jpg","hash":"90b35bdc10fe84c8039d2cf61da7e78ec271b000","modified":1741152826436},{"_id":"node_modules/hexo-theme-butterfly/source/img/小屁股.jpg","hash":"47191da4ef5010db673dd30af4fc21bdf38f8b5c","modified":1741770514489},{"_id":"public/search.xml","hash":"7ae219e510e6d8db0e02b1ebff0dfe302e5ce74d","modified":1743345321103},{"_id":"public/404.html","hash":"4fa5c873a94f8fe05081e004736e061860a8696a","modified":1743345321103},{"_id":"public/link/index.html","hash":"ba68744fddf4d6b52c102abd89c1bfb0cae3ac44","modified":1743345321103},{"_id":"public/tags/index.html","hash":"afe66567752146cc5fb3e82dcebdf8fb475a16c9","modified":1743345321103},{"_id":"public/wechat-qr/index.html","hash":"b884c146c1abdff3ecf6ed515f4116d4271e79ed","modified":1743345321103},{"_id":"public/2025/03/05/2.ETCD——安装部署/index.html","hash":"17848020ff737229d150398674b2a853f102b18d","modified":1743345321103},{"_id":"public/2025/03/05/3.ETCD——常用命令/index.html","hash":"72460ee27f200f49df22d1899e2878214ab25bc2","modified":1743345321103},{"_id":"public/2025/03/05/4.ETCD——confd配置管理/index.html","hash":"637c966f1290db2c02f5fe12f64f6a6814b5fae9","modified":1743345321103},{"_id":"public/2025/03/05/Istio Basic/index.html","hash":"c985ff4c10dc2a6820c48781f8d81e4bb4d607a3","modified":1743345321103},{"_id":"public/2025/03/08/Istio/index.html","hash":"1632921ce1bc195a41bbf30cfb2de4fc5b483b13","modified":1743345321103},{"_id":"public/2025/03/08/入门服务注册中心——consul 副本/index.html","hash":"7827149c1221ba079103c8196e903ece18fc1997","modified":1743345321103},{"_id":"public/2025/03/11/1.kubeadm高可用部署/index.html","hash":"db72b9bafee9e2f04d271b66177f933b82e2347b","modified":1743345321103},{"_id":"public/2025/03/11/1.部署Harbor私有镜像仓库/index.html","hash":"35e0e0dd07c86f3c32cfd8c244ff4be6ba403c4b","modified":1743345321103},{"_id":"public/2025/03/11/1.配置环境(RHEL)/index.html","hash":"51c35b7c78afddce6c6ad44c7e75824f8d633393","modified":1743345321103},{"_id":"public/2025/03/11/10.部署calico网络组件 副本/index.html","hash":"da0d2e56ce7cc7e072f07a37428c07235c480b18","modified":1743345321103},{"_id":"public/2025/03/11/11.部署metrics监控组件/index.html","hash":"b5d21ccba1b4d57b500719ff199da5d776f1e709","modified":1743345321103},{"_id":"public/2025/03/11/12.部署Redis数据库 副本/index.html","hash":"d7ffbc8c43cf6a38c0abe708d03bacf57a19119b","modified":1743345321103},{"_id":"public/2025/03/11/12部署Prometheus监控/index.html","hash":"fc8501d493eb3ea5422d5c4e27800a49465f1cf6","modified":1743345321103},{"_id":"public/2025/03/11/13.部署ELK日志收集/index.html","hash":"a5e4c11e310bd7028bb05bc29c3f25f2ed3cc898","modified":1743345321103},{"_id":"public/2025/03/11/16.部署Kafka消息队列 副本/index.html","hash":"c11f8d566dc1e688202189f3c560682a13097298","modified":1743345321103},{"_id":"public/2025/03/11/17.部署Rabbit MQ消息队列/index.html","hash":"803fb55aad713e30c2de15d4ad3db8aff45af0b3","modified":1743345321103},{"_id":"public/2025/03/11/2.安装容器运行时(Docker)/index.html","hash":"45184313bd63e4c534d57047cd48a2a60ae17d53","modified":1743345321103},{"_id":"public/2025/03/11/2.部署helm包管理工具/index.html","hash":"745a10611cb3c859893d04c238af38f8a021db20","modified":1743345321103},{"_id":"public/2025/03/11/3.安装容器运行时(Containerd) 副本/index.html","hash":"913544a404727eb57cbfa6ef75e00deff3240de7","modified":1743345321103},{"_id":"public/2025/03/11/4.Containerd进阶使用 副本/index.html","hash":"964d7111f6aa999a3de178e6061a2f75481e22ae","modified":1743345321103},{"_id":"public/2025/03/11/5.安装Kubernets集群/index.html","hash":"ffc2e713e24232ebe73f0164bd6aeb781c410622","modified":1743345321103},{"_id":"public/2025/03/11/4.部署traefik代理/index.html","hash":"eef5f20aa11c6e29e3705c543a97429168a29179","modified":1743345321103},{"_id":"public/2025/03/11/5.部署minIO对象存储 副本/index.html","hash":"5baaac792737a886b6af814ae13346fe99a696cf","modified":1743345321103},{"_id":"public/2025/03/17/3.存储类型 副本/index.html","hash":"8eb67ff1fc1edfb6bf1ba2cf5ee3110a23d2058f","modified":1743345321103},{"_id":"public/2025/03/17/1.存储基础 副本/index.html","hash":"704d5892e036572f680701ecd5fdf2f8aa6fdc66","modified":1743345321103},{"_id":"public/2025/03/17/2.分布式存储 副本/index.html","hash":"b4d6a7e7c249587eba0bd17723afdcbfd7275556","modified":1743345321103},{"_id":"public/2025/03/30/hello-world/index.html","hash":"995ba25018d2306281c6b98cf84d6fc3028b9f18","modified":1743345321103},{"_id":"public/archives/index.html","hash":"233fcb2c0e67c5fe4ae378f252137cb703fc8bf8","modified":1743345321103},{"_id":"public/archives/page/2/index.html","hash":"fb4279d3cbe6639d97ba6aed3133b6a25b30329a","modified":1743345321103},{"_id":"public/archives/page/3/index.html","hash":"e37210c860597a07f526c3196448954a5ded96d6","modified":1743345321103},{"_id":"public/archives/2025/index.html","hash":"b2065fc39e59634ce7f09d1ed291681135069ef7","modified":1743345321103},{"_id":"public/archives/2025/page/2/index.html","hash":"3d6c52ee577f4e93cffb5ca637eda3a9eac2c0e3","modified":1743345321103},{"_id":"public/archives/2025/page/3/index.html","hash":"16851f0611bf044f427b785aaf1b4621d19f7785","modified":1743345321103},{"_id":"public/archives/2025/03/index.html","hash":"14d919055695af47c35fa38fcb009c05523cddff","modified":1743345321103},{"_id":"public/archives/2025/03/page/2/index.html","hash":"95b6b985f46af7757d350673b2d56e74fa20a775","modified":1743345321103},{"_id":"public/archives/2025/03/page/3/index.html","hash":"58d534e43ac55be9974069e9a1e485c4bf32de70","modified":1743345321103},{"_id":"public/index.html","hash":"5f613095435eeab1e3f232415318e4b515d3aa98","modified":1743345321103},{"_id":"public/page/2/index.html","hash":"4a9aea804fe4103e8805f7782e1d822d6746c2af","modified":1743345321103},{"_id":"public/page/3/index.html","hash":"678c956572fd164fd52f7520640963404b5ba3b5","modified":1743345321103},{"_id":"public/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1743345321103},{"_id":"public/img/error-page.png","hash":"d2519710498a871ca3e913c57e2ba20a805b6430","modified":1743345321103},{"_id":"public/img/favicon.ico","hash":"455ac256580bf31a45813dbbdb87219bfc8bfb04","modified":1743345321103},{"_id":"public/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1743345321103},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1743345321103},{"_id":"public/img/头像.jpg","hash":"88c4681a842a18e8d0afa1d98d17cac58e97ea74","modified":1743345321103},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1743345321103},{"_id":"public/css/var.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1743345321103},{"_id":"public/js/search/algolia.js","hash":"e5821f78381af9f0f646952a7dd118daab2a79a6","modified":1743345321103},{"_id":"public/js/utils.js","hash":"fd3c26366c78dd82bc87d4ddebe76c582122e1b7","modified":1743345321103},{"_id":"public/js/search/local-search.js","hash":"4e11d033fb58563f5e1b497f1a6f1c62d3501ee6","modified":1743345321103},{"_id":"public/css/index.css","hash":"1e50f21f8b85f7c34a50fa2f0f8935ffaf54c022","modified":1743345321103},{"_id":"public/js/main.js","hash":"fb746a3e67d0373deea8481110dd436fea4ca38c","modified":1743345321103},{"_id":"public/js/tw_cn.js","hash":"7ef59df188ea523da89f4caf69c5c0f14e78da69","modified":1743345321103},{"_id":"public/wechat-qr/wechat.jpg","hash":"3e039bf18d78b5d645e526ef4e6436e0280d3b16","modified":1743345321103},{"_id":"public/img/wechat.jpg","hash":"3e039bf18d78b5d645e526ef4e6436e0280d3b16","modified":1743345321103},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1743345321103},{"_id":"public/img/butterfly-icon.png","hash":"f5dd732fed5c3bcd4aa76bac3441bac8485fb432","modified":1743345321103},{"_id":"public/img/R.jpg","hash":"a20b9d4911248d527aab6197ddea510722837428","modified":1743345321103},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1743345321103},{"_id":"public/img/fire.jpg","hash":"90b35bdc10fe84c8039d2cf61da7e78ec271b000","modified":1743345321103},{"_id":"public/img/小屁股.jpg","hash":"47191da4ef5010db673dd30af4fc21bdf38f8b5c","modified":1743345321103}],"Category":[],"Data":[],"Page":[{"title":"link","date":"2025-03-30T11:08:06.000Z","type":"link","_content":"","source":"link/index.md","raw":"---\ntitle: link\ndate: 2025-03-30 19:08:06\ntype: \"link\"\n---\n","updated":"2025-03-30T11:14:54.465Z","path":"link/index.html","comments":1,"layout":"page","_id":"cm8vqsjl70000tsv17dasf5j1","content":"","excerpt":"","more":""},{"title":"tags","date":"2025-03-30T11:06:39.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2025-03-30 19:06:39\ntype: \"tags\"\n---\n","updated":"2025-03-30T11:07:42.954Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cm8vqsjlc0002tsv1e4uq1w7m","content":"","excerpt":"","more":""},{"title":"我的微信二维码","date":"2025-03-30T12:57:49.000Z","_content":"<div style=\"text-align: center;\">\n  <img src=\"/wechat-qr/wechat.jpg\" alt=\"微信二维码\" style=\"width: 800px; height: 800px;\">\n  <p>扫描二维码添加我的微信</p>\n</div>\n","source":"wechat-qr/index.md","raw":"---\ntitle: 我的微信二维码\ndate: 2025-03-30 20:57:49\n---\n<div style=\"text-align: center;\">\n  <img src=\"/wechat-qr/wechat.jpg\" alt=\"微信二维码\" style=\"width: 800px; height: 800px;\">\n  <p>扫描二维码添加我的微信</p>\n</div>\n","updated":"2025-03-30T13:20:59.485Z","path":"wechat-qr/index.html","comments":1,"layout":"page","_id":"cm8vqsjle0004tsv15q4e3n6e","content":"<div style=\"text-align: center;\">\n  <img src=\"/wechat-qr/wechat.jpg\" alt=\"微信二维码\" style=\"width: 800px; height: 800px;\">\n  <p>扫描二维码添加我的微信</p>\n</div>\n","excerpt":"","more":"<div style=\"text-align: center;\">\n  <img src=\"/wechat-qr/wechat.jpg\" alt=\"微信二维码\" style=\"width: 800px; height: 800px;\">\n  <p>扫描二维码添加我的微信</p>\n</div>\n"}],"Post":[{"title":"kubeadm高可用部署","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"f1b611b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构方案</font></h1>\n---\n\n<h2 id=\"6bdfa137\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构说明</font></h2>\n---\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">核心组件</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">高可用模式</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">高可用实现方式</font>** |\n| --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">集群</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm</font> |\n\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver 通过haproxy+keepalived实现高可用，当某个节点故障时触发keepalived vip 转移；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个controller-manager组件运行；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个scheduler组件运行；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 通过运行kubeadm方式自动创建集群来实现高可用，部署的节点数为奇数。如果剩余可用节点数量超过半数，集群可以几乎没有影响的正常工作(3节点方式最多容忍一台机器宕机)</font>\n\n<h2 id=\"c267defc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HAProxy+</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Keepalived方案</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在以前我们在私有环境下创建 Kubernetes 集群时，我们需要准备一个硬件/软件的负载均衡器来创建多控制面集群，更多的情况下我们会选择使用 HAProxy + Keepalived 来实现这个功能。一般情况下我们会在k8s集群外创建2个负载均衡器的虚拟机，然后分配一个 VIP，然后使用 VIP 为负载均衡器提供服务，通过 VIP 将流量重定向到后端的某个 Kubernetes master节点上。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">或者在所有Kubernetes master节点上部署HAProxy + Keepalived服务，实现故障切换。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940757-19c0d378-d69c-4d9d-bea9-19b988fceb79.jpeg)\n\n<h2 id=\"2540cb93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip方案</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">除了使用传统方式外，我们也可以通过kube-vip实现高可用。kube-vip 可以通过静态 pod 运行在控制平面节点上，这些 pod 通过ARP 对话来识别每个节点上的其他主机，所以需要在 hosts 文件中设置每个节点的 IP 地址，我们可以选择 BGP 或 ARP 来设置负载平衡器，这与 Metal LB 比较类似。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的 Leader，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940896-936a1802-8255-4ae3-b742-b192c9df044c.jpeg)\n\n<h1 id=\"b7a8ae3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 架构</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 有许多功能设计选择提供高可用性或网络功能，作为VIP/负载平衡解决方案的一部分。</font>\n\n<h2 id=\"cluster\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Cluster</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 建立了一个多节点或多模块的集群来提供高可用性。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的领导者，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当使用 ARP 或 layer2 时，它将使用领导者选举，当然也可以使用 raft 集群技术，但这种方法在很大程度上已经被领导者选举所取代，特别是在集群中运行时。</font>\n\n<h2 id=\"15c8be58\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">集群中的领导者将分配 vip，并将其绑定到配置中声明的选定接口上。当领导者改变时，它将首先撤销 vip，或者在失败的情况下，vip 将直接由下一个当选的领导者分配。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当 vip 从一个主机移动到另一个主机时，任何使用 vip 的主机将保留以前的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip <-> MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">地址映射，直到 ARP 过期（通常是30秒）并检索到一个新的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip <-> MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">映射，这可以通过使用无偿的 ARP 广播来优化。</font>\n\n<h2 id=\"arp\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ARP</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip可以被配置为广播一个无偿的 arp（可选），通常会立即通知所有本地主机 vip <-> MAC 地址映射已经改变。当 ARP 广播被接收时，故障转移通常在几秒钟内完成。</font>\n\n<h1 id=\"47b520ed\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群规划</font></h1>\n---\n\n<h2 id=\"2d507904\"><font style=\"background-color:rgba(255, 255, 255, 0);\">软件版本</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">操作系统版本：Rocky Linux release 8.8</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">内核版本：4.18.0-477.21.1.el8_8.x86_64</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes版本：1.27.6</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd版本：1.6.22</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip版本：0.6.0</font>\n\n<h2 id=\"c5b040c2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">主机IP规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">ip</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机配置</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">用途</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.151</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.152</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.153</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.154</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.155</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.156</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">VIP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.150</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP在控制节点上浮动</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端，连接管理K8S集群</font> |\n\n\n<h1 id=\"60fb03bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础环境与软件准备</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有节点都执行</font>\n>\n\n<h2 id=\"d77c61bf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改主机名与hosts文件</font></h2>\n```plain\nhostnamectl set-hostname master1\ncat > /etc/hosts << EOF \n192.168.10.151   master1\n192.168.10.152   master2\n192.168.10.153   master3\n192.168.10.154   work1\n192.168.10.155   work2\n192.168.10.156   work3\nEOF\n```\n\n<h2 id=\"a0b09c93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证mac地址uuid</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">保证各节点mac和uuid唯一，防止克隆主机出现网络异常问题</font>\n\n```plain\ncat /sys/class/net/ens33/address\ncat /sys/class/dmi/id/product_uuid \n```\n\n<h2 id=\"16c50660\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置时间同步</font></h2>\n```plain\ndnf -y install chrony\nsystemctl  start chronyd\nsystemctl  enable chronyd\ntimedatectl set-timezone Asia/Shanghai\nchronyc sourcestats -v \ndate\n```\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">也可以在内网环境其中一台主机启动chronyd服务，其他主机配置chronyd服务地址</font>\n>\n\n<h2 id=\"1663c88c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭防火墙和selinux</font></h2>\n---\n\n```plain\nsystemctl stop firewalld.service\nsystemctl  disable firewalld\nsetenforce  0\nsed  -i 's/enforcing/disabled/g' /etc/selinux/config\ngrep  SELINUX= /etc/selinux/config \n```\n\n<h2 id=\"7c54c7f3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭swap分区</font></h2>\n---\n\n```plain\nswapoff -a \nsed -i '/ swap / s/^(.*)$/#\\1/g' /etc/fstab  \n```\n\n<h2 id=\"825e7bd1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改内核相关参数</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">最大限度使用物理内存，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">bridge 设备在二层转发时也去调用 iptables 配置的三层规则，开启数据包转发。</font>\n\n```plain\ncat > /etc/sysctl.d/kubernetes.conf << EOF\nvm.swappiness = 0\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n\nsysctl -p /etc/sysctl.d/kubernetes.conf\n```\n\n<h2 id=\"927d0791\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置yum源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">配置阿里源</font>\n\n```plain\ncat > /etc/yum.repos.d/kubernetes.repo << EOF \n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果阿里源异常，可切换配置清华源</font>\n\n```plain\ncat > /etc/yum.repos.d/kubernetes.repo << EOF \n[kubernetes]\nname=kubernetes\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/kubernetes/yum/repos/kubernetes-el7-$basearch\nenabled=1\nEOF\n```\n\n<h2 id=\"5e11d2ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置ipvs模块功能</font></h2>\n---\n\n```plain\ndnf -y install ipset ipvsadm \n\ncat > /etc/sysctl.d/ipvs.modules <<EOF \n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\nmodprobe -- br_netfilter\nEOF\n\nchmod 755 /etc/sysctl.d/ipvs.modules && bash \n\n/etc/sysctl.d/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack \nip_vs_sh               20480  0\nip_vs_wrr              16384  0\nip_vs_rr               16384  0\nip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr\nnf_conntrack_netlink    53248  0\nnf_conntrack          176128  5 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE,ip_vs\nnf_defrag_ipv6         24576  2 nf_conntrack,ip_vs\nnf_defrag_ipv4         16384  1 nf_conntrack\nnfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables\nlibcrc32c              16384  5 nf_conntrack,nf_nat,nf_tables,xfs,ip_vs\n\n# 添加开机自动加载模块\necho \"/etc/sysctl.d/ipvs.modules\" >> /etc/rc.local\nchmod +x /etc/rc.local\n# 启用网桥过滤器模块\necho 1 > /proc/sys/net/bridge/bridge-nf-call-iptables\necho 1 > /proc/sys/net/ipv4/ip_forward\n```\n\n<h2 id=\"680cf1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装命令自动补全工具</font></h2>\n---\n\n```plain\ndnf -y install bash-completion \nsource /etc/profile.d/bash_completion.sh \n```\n\n<h2 id=\"752286ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">container</font><font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h2>\n---\n\n<h3 id=\"56f5cf9c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font></h3>\n```plain\n# 安装依赖\ndnf install -y yum-utils device-mapper-persistent-data lvm2\n\n# 添加yum源\ndnf config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n# 查看可安装的containerd版本\ndnf list containerd.io.x86_64 --showduplicates | sort -r\n\n# 安装1.6.22版本containerd\ndnf install -y containerd.io-1.6.22-3.1.el8.x86_64\n\n# 查看版本信息\ncontainerd -v\n```\n\n<h3 id=\"da6011d1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置container</font></h3>\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font>**\n\n```plain\ncontainerd config default > /etc/containerd/config.toml\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font>**\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。把sandbox_image = \"k8s.gcr.io/pause:3.6\"修改为：sandbox_image=“registry.aliyuncs.com/google_containers/pause:3.6”</font>\n\n```plain\nsed -i 's/sandbox_image\\ =.*/sandbox_image\\ =\\ \"registry.aliyuncs.com\\/google_containers\\/pause:3.6\"/g' /etc/containerd/config.toml|grep sandbox_image\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">配置cgroup驱动器</font>**\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 kubelet 和容器运行时需使用相同的 cgroup 驱动并且采用相同的配置。</font>\n\n```plain\nsed -i 's/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g' /etc/containerd/config.toml\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速地址</font>**\n\n```plain\n# 修改container配置，指定registry配置从文件读取\nvim /etc/containerd/config.toml\n    [plugins.\"io.containerd.grpc.v1.cri\".registry]\n      config_path = \"/etc/containerd/certs.d\"\n\n# 创建配置文件目录\nmkdir -p /etc/containerd/certs.d/docker.io\n\n# 新增加速配置\ncat > /etc/containerd/certs.d/docker.io/hosts.toml << EOF\nserver = \"https://docker.io\"\n[host.\"https://o2j0mc5x.mirror.aliyuncs.com\"]\n  capabilities = [\"pull\", \"resolve\"]\nserver = \"https://k8s.gcr.io\"\n[host.\"https://gcr.mirrors.ustc.edu.cn/google-containers/\"]\n  capabilities = [\"pull\", \"resolve\"]\nserver = \"https://quay.io\"\n[host.\"https://mirror.ccs.tencentyun.com\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n```\n\n<h3 id=\"E4Q5q\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 container服务</font></h3>\n```plain\nsystemctl enable containerd --now\n```\n\n<h3 id=\"527bcc5b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：https://github.com/kubernetes-sigs/cri-tools/releases</font>\n\n```plain\n# 下载\nwget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.27.1/crictl-v1.27.1-linux-amd64.tar.gz\n# 解压\ntar -zxvf crictl-v1.27.1-linux-amd64.tar.gz -C /usr/local/bin\n# 配置\ncat > /etc/crictl.yaml << EOF\nruntime-endpoint: \"unix:///run/containerd/containerd.sock\"\nimage-endpoint: \"unix:///run/containerd/containerd.sock\"\ntimeout: 0\ndebug: false\npull-image-on-create: false\ndisable-pull-on-run: false\nEOF\n# 验证\ncrictl version\n```\n\n<h3 id=\"UomHm\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl(建议)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font>\n\n```plain\n# 下载\nwget https://github.com/containerd/nerdctl/releases/download/v1.5.0/nerdctl-1.5.0-linux-amd64.tar.gz\n# 解压\ntar -zxvf nerdctl-1.5.0-linux-amd64.tar.gz \n# 复制文件\ncp nerdctl /usr/bin/\n# 配置 nerdctl 参数自动补齐\necho 'source <(nerdctl completion bash)' >> /etc/profile\nsource /etc/profile\n# 验证\nnerdctl -v\n```\n\n<h2 id=\"8dd46c64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装k8s软件包并配置</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font>\n\n```plain\nyum install -y kubelet kubeadm kubectl \n# 默认安装最新版本，如果需要安装老版本，使用如下命令\nyum list kubeadm --showduplicates | sort -r\nyum install -y kubelet-1.27.6 kubeadm-1.27.6 kubectl-1.27.6\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时并启动。</font>\n\n```plain\ncrictl config runtime-endpoint unix:///run/containerd/containerd.sock\nsystemctl enable kubelet --now\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl命令补全</font>\n\n```plain\necho \"source <(kubectl completion bash)\" >> ~/.bash_profile \nsource ~/.bash_profile \n```\n\n<h1 id=\"6f342ec9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(kube-vip)</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font>\n>\n\n<h2 id=\"88210852\"><font style=\"background-color:rgba(255, 255, 255, 0);\">准备工作</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们使用的vip是192.168.10.150</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">网卡名称是ens160</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip使用arp模式</font>\n\n```plain\n[root@master1 ~]# mkdir -p /etc/kubernetes/manifests\n[root@master1 ~]# export VIP=192.168.10.150\n[root@master1 ~]# export INTERFACE=ens160\n[root@master1 ~]# export KVVERSION=v0.8.2\n```\n\n<h2 id=\"ea49435f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成配置文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取 kube-vip 的 docker 镜像，并在 /etc/kuberentes/manifests 中设置静态 pod 的 yaml 资源清单文件，这样 Kubernetes 就会自动在每个控制平面节点上部署 kube-vip 的 pod 了。</font>\n\n```plain\n[root@master1 ~]# alias kube-vip=\"ctr image pull ghcr.io/kube-vip/kube-vip:$KVVERSION; ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:$KVVERSION vip /kube-vip\"\n[root@master1 ~]# kube-vip manifest pod \\\n    --interface $INTERFACE \\\n    --address $VIP \\\n    --controlplane \\\n    --services \\\n    --arp \\\n    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml\n# 生成文件如下所示：\napiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: null\n  name: kube-vip\n  namespace: kube-system\nspec:\n  containers:\n  - args:\n    - manager\n    env:\n    - name: vip_arp\n      value: \"true\"\n    - name: port\n      value: \"6443\"\n    - name: vip_nodename\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n    - name: vip_interface\n      value: ens160\n    - name: vip_cidr\n      value: \"32\"\n    - name: dns_mode\n      value: first\n    - name: cp_enable\n      value: \"true\"\n    - name: cp_namespace\n      value: kube-system\n    - name: svc_enable\n      value: \"true\"\n    - name: svc_leasename\n      value: plndr-svcs-lock\n    - name: vip_leaderelection\n      value: \"true\"\n    - name: vip_leasename\n      value: plndr-cp-lock\n    - name: vip_leaseduration\n      value: \"5\"\n    - name: vip_renewdeadline\n      value: \"3\"\n    - name: vip_retryperiod\n      value: \"1\"\n    - name: address\n      value: 192.168.10.150\n    - name: prometheus_server\n      value: :2112\n    image: ghcr.io/kube-vip/kube-vip:v0.8.2\n    imagePullPolicy: IfNotPresent\n    name: kube-vip\n    resources: {}\n    securityContext:\n      capabilities:\n        add:\n        - NET_ADMIN\n        - NET_RAW\n    volumeMounts:\n    - mountPath: /etc/kubernetes/admin.conf\n      name: kubeconfig\n  hostAliases:\n  - hostnames:\n    - kubernetes\n    ip: 127.0.0.1\n  hostNetwork: true\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/admin.conf\n    name: kubeconfig\nstatus: {}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当执行完kubeadm init后，kubelet会去加载这里面的yaml创建kube-vip容器。</font>\n\n<h2 id=\"cce0e451\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝至其他master节点</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">所有master节点都需要部署一个kube-vip，我们只需要将yaml文件存放在/etc/kubernetes/manifests/目录下，kubelet启动时会自动加载资源清单并创建pod。</font>\n\n```plain\n[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master2:/etc/kubernetes/manifests/kube-vip.yaml\n[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master3:/etc/kubernetes/manifests/kube-vip.yaml\n```\n\n```plain\nsed -i 's#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#' \\\n          /etc/kubernetes/manifests/kube-vip.yaml\n```\n\n<h1 id=\"9845b730\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(keepalived+haproxy)</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有master节点执行</font>\n\n<h2 id=\"bbd75de9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">haproxy配置</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装haproxy</font>\n\n```plain\n[root@master1 ~]# dnf -y install haproxy\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">编辑配置文件，所有master节点配置一样。</font>\n\n```plain\n[root@master1 ~]# vim /etc/haproxy/haproxy.cfg\nglobal\n    log         127.0.0.1 local2\n    pidfile     /var/run/haproxy.pid\n    maxconn     4000\ndefaults\n    mode                    http\n    log                     global\n    option                  dontlognull\n    option http-server-close\n    option                  redispatch\n    retries                 3\n    timeout http-request    10s\n    timeout queue           1m\n    timeout connect         10s\n    timeout client          1m\n    timeout server          1m\n    timeout http-keep-alive 10s\n    timeout check           10s\n    maxconn                 3000\n\nlisten admin_stats\n    bind    *:8888    #监听的ip端口号\n    stats   enable\n    stats   refresh 30s   #统计页面自动刷新时间\n    stats   uri /admin    #访问的uri   ip:8080/admin\n    stats   realm haproxy\n    stats   auth admin:Miaohua123!  #认证用户名和密码\n    stats   hide-version   #隐藏HAProxy的版本号\n    stats   admin if TRUE   #管理界面，如果认证成功了，可通过webui管理节点  \n\nfrontend  kubernetes-apiserver\n    mode tcp\n    bind *:9443\n    # bind *:443 ssl # To be completed ....\n    default_backend             kubernetes-apiserver\n\nbackend kubernetes-apiserver\n    mode        tcp\n    balance     roundrobin\n# k8s-apiservers backend\n    server master1 192.168.10.151:6443 check\n    server master2 192.168.10.152:6443 check\n    server master3 192.168.10.153:6443 check\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font>\n\n```plain\n[root@master1 ~]# systemctl start haproxy.service \n[root@master1 ~]# systemctl enable haproxy.service \n[root@master1 ~]# ss -tnlp | grep haproxy\nLISTEN    0         3000               0.0.0.0:8888             0.0.0.0:*        users:((\"haproxy\",pid=7062,fd=6))                                              \nLISTEN    0         3000               0.0.0.0:9443             0.0.0.0:*        users:((\"haproxy\",pid=7062,fd=8)) \n```\n\n<h2 id=\"fff6cb90\"><font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived配置</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装keepalived服务</font>\n\n```plain\n[root@master1 ~]# dnf -y install keepalived\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加keepalived配置文件，master1节点内容如下。master2节点state改为BACKUP，priority改为99。master3节点state改为BACKUP，priority改为98。</font>\n\n```plain\n[root@master1 ~]# vim /etc/keepalived/keepalived.conf\nglobal_defs {\n   script_user root\n   enable_script_security\n}\n\nvrrp_script chk_haproxy {\n    script \"/etc/keepalived/check.sh\"\n    interval 1\n    weight -2\n}\n\nvrrp_instance VI_1 {\n  state MASTER # 实例类型\n  interface ens33 # 网卡名称\n  virtual_router_id 201\n  priority 100 # 优先级\n  advert_int 1\n\n  virtual_ipaddress {\n    192.168.10.150/32\n  }\n\n  authentication {\n    auth_type PASS\n    auth_pass 1111\n  }\n\n  track_script {\n      chk_haproxy\n  }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加服务检测脚本，如果containerd进程停止则进行故障切换</font>\n\n```plain\n[root@master1 ~]# vim /etc/keepalived/check.sh\n#!/bin/bash\nif systemctl is-active --quiet containerd; then\n    exit 0\nelse\n    exit 1\nfi\n[root@master1 ~]# chmod +x /etc/keepalived/check.sh\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font>\n\n```plain\n[root@master1 ~]# systemctl start keepalived.service \n[root@master1 ~]# systemctl enable keepalived\n[root@master1 ~]# ip a | grep 192.168.10\n    inet 192.168.10.151/24 brd 192.168.10.255 scope global ens33\n    inet 192.168.10.150/32 scope global ens33\n```\n\n<h1 id=\"ede357c3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化master节点</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font>\n>\n\n<h2 id=\"575087eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置集群参数</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font>\n\n```plain\n[root@master1 ~]# kubeadm config print init-defaults > kubeadm-conf.yaml\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n```plain\n[root@master1 ~]# cat kubeadm-conf.yaml\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.10.151  # 指定当前master1节点IP\n  bindPort: 6443 # 当前master1节点端口\nnodeRegistration:\n  criSocket: unix:///run/containerd/containerd.sock # 使用containerd的socket地址\n  imagePullPolicy: IfNotPresent\n  name: master1 # 节点主机名\n  taints: null\n---\napiServer:\n  extraArgs:\n    authorization-mode: Node,RBAC\n  timeoutForControlPlane: 4m0s\n  certSANs:  # 添加其他master节点的相关信息\n  - 127.0.0.1\n  - master1\n  - master2\n  - master3\n  - 192.168.10.150\n  - 192.168.10.151\n  - 192.168.10.152\n  - 192.168.10.153\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像\nkind: ClusterConfiguration\nkubernetesVersion: 1.27.6 # k8s版本\ncontrolPlaneEndpoint: 192.168.10.150:6443  # 设置控制平面Endpoint地址和端口\nnetworking:\n  dnsDomain: cluster.local\n  serviceSubnet: 10.96.0.0/12\n  podSubnet: 10.244.0.0/16  # 指定 pod 子网\nscheduler: {}\n---\n# 指定kube-proxy基于ipvs模式\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind:  KubeProxyConfiguration\nmode: ipvs\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: systemd   # 指定cgroup驱动器为systemd模式\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nmemorySwap: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\n```\n\n\n\n<h2 id=\"aec284f8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">将master1节点的kubeadm-conf.yaml复制到其他master节点，所有master节点都提前执行</font>\n\n```plain\n[root@master1 ~]# kubeadm config images pull --config kubeadm-conf.yaml\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.9\n[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.7-0\n[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.10.1\n# CRI sandbox(pause) image默认使用registry.k8s.io/pause:3.6，由于网络原因无法拉取，直接改为阿里镜像标签即可。\n[root@master1 ~]# nerdctl -n k8s.io tag registry.aliyuncs.com/google_containers/pause:3.9 registry.k8s.io/pause:3.6\n```\n\n<h2 id=\"5fa25176\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群初始化</font></h2>\n---\n\n```plain\n[root@master1 ~]# kubeadm init --upload-certs --config=kubeadm-conf.yaml \nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of the control-plane node running the following command on each as root:\n\n  kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\\n        --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7\n\nPlease note that the certificate-key gives access to cluster sensitive data, keep it secret!\nAs a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use\n\"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward.\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–upload-certs 标志用来将在所有控制平面实例之间的共享证书上传到集群。然后根据安装提示拷贝 kubeconfig 文件</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果配置问题导致集群初始化失败，可重置集群再次初始化：</font>\n\n```plain\n[root@master1 ~]# kubeadm reset\n[root@master1 ~]# ipvsadm --clear\n[root@master1 ~]# rm -rf $HOME/.kube/config\n```\n\n<h2 id=\"c238630b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示配置环境变量</font></h2>\n---\n\n```plain\n[root@master1 ~]# mkdir -p $HOME/.kube \n[root@master1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config \n[root@master1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config\n[root@master1 ~]# echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" >> ~/.bash_profile\n[root@tiaoban ~]# source ~/.bash_profile\n```\n\n<h2 id=\"154df728\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装flannel网络</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">下载资源清单配置文件</font>\n\n```plain\n[root@master1 ~]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n```plain\n[root@master1 ~]# kubectl apply -f kube-flannel.yml\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果镜像不能正常拉取，所有节点需提前导入镜像，并修改yaml文件镜像拉取策略</font>\n\n```plain\nimagePullPolicy: IfNotPresent\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">镜像导入与查询</font>\n\n```plain\n[root@work3 ~]# ctr -n=k8s.io image import flannel.tar \nunpacking docker.io/flannel/flannel:v0.22.1 (sha256:0b78f714708e837ae667c204cc918649ebcf2441b1d18ebde9a6564254932ee5)...done\n[root@work3 ~]# crictl images\nIMAGE                                                             TAG                 IMAGE ID            SIZE\ndocker.io/flannel/flannel-cni-plugin                              v1.2.0              a55d1bad692b7       8.32MB\n```\n\n<h1 id=\"76ce2493\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他节点加入集群</font></h1>\n---\n\n<h2 id=\"6e7aaa3e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">master节点加入集群</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">另外两个节点 master2 和 master3 都执行上面的 join 命令，上面的命令中的 --control-plane 就是通知 kubeadm join 创建一个新的控制平面，–certificate-key 会从集群中的 kubeadm-certs Secret 下载控制平面证书并使用给定的密钥进行解密。</font>\n\n```plain\n# 以master2节点为例\n[root@master2 ~]#   kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n>         --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\\n>         --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7\n\n# 然后根据提示配置环境变量\n[root@master2 ~]# mkdir -p $HOME/.kube\n[root@master2 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n[root@master2 ~]# chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n<h2 id=\"5eec51f2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">work节点加入集群</font></h2>\n---\n\n```plain\nkubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c\n```\n\n<h2 id=\"ade4c21a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font></h2>\n---\n\n```plain\n# 安装指定版本的kubelet\n[root@tiaoban ~]# yum install -y kubectl-1.27.6\n# 拷贝集群认证文件并配置环境变量\n[root@tiaoban ~]# mkdir -p /etc/kubernetes\n[root@tiaoban ~]# scp master1:/etc/kubernetes/admin.conf /etc/kubernetes/\n[root@tiaoban ~]# echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" >> ~/.bash_profile\n[root@tiaoban ~]# source ~/.bash_profile\n```\n\n<h1 id=\"fb2d3f91\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群验证</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在tiaoban节点执行</font>\n>\n\n<h2 id=\"77b07675\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点信息</font></h2>\n---\n\n```plain\n[root@tiaoban ~]# kubectl get node\nNAME      STATUS   ROLES           AGE    VERSION\nmaster1   Ready    control-plane   18m     v1.27.6\nmaster2   Ready    control-plane   12m7s   v1.27.6\nmaster3   Ready    control-plane   13m6s   v1.27.6\nwork1     Ready    <none>          8m25s   v1.27.6\nwork2     Ready    <none>          8m21s   v1.27.6\nwork3     Ready    <none>          8m17s   v1.27.6\n```\n\n<h2 id=\"86a835fd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod信息</font></h2>\n---\n\n```plain\n[root@master1 ~]# kubectl get pod -A -o wide \nNAMESPACE      NAME                              READY   STATUS    RESTARTS       AGE     IP               NODE      NOMINATED NODE   READINESS GATES\nkube-flannel   kube-flannel-ds-2nqk5             1/1     Running   0              134s   192.168.10.151   master1   <none>           <none>\nkube-flannel   kube-flannel-ds-c87jk             1/1     Running   0              134s   192.168.10.155   work2     <none>           <none>\nkube-flannel   kube-flannel-ds-hnps5             1/1     Running   0              134s   192.168.10.154   work1     <none>           <none>\nkube-flannel   kube-flannel-ds-jphgx             1/1     Running   0              154s   192.168.10.153   master3   <none>           <none>\nkube-flannel   kube-flannel-ds-lxpsp             1/1     Running   0              134s   192.168.10.156   work3     <none>           <none>\nkube-flannel   kube-flannel-ds-rx5kf             1/1     Running   0              134s   192.168.10.152   master2   <none>           <none>\nkube-system    coredns-7bdc4cb885-cjbbx          1/1     Running   0              14m    10.244.5.3       work1     <none>           <none>\nkube-system    coredns-7bdc4cb885-sgsns          1/1     Running   0              14m    10.244.5.2       work1     <none>           <none>\nkube-system    etcd-master1                      1/1     Running   1              14m    192.168.10.151   master1   <none>           <none>\nkube-system    etcd-master2                      1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    etcd-master3                      1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-apiserver-master1            1/1     Running   1              14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-apiserver-master2            1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-apiserver-master3            1/1     Running   2 (154m ago)   14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-controller-manager-master1   1/1     Running   3 (40m ago)    14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-controller-manager-master2   1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-controller-manager-master3   1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-proxy-9jsq7                  1/1     Running   0              18m    192.168.10.155   work2     <none>           <none>\nkube-system    kube-proxy-cpb5n                  1/1     Running   0              14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-proxy-dm2rm                  1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-proxy-g26c4                  1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-proxy-jkhnj                  1/1     Running   0              18m    192.168.10.156   work3     <none>           <none>\nkube-system    kube-proxy-x29d9                  1/1     Running   0              18m    192.168.10.154   work1     <none>           <none>\nkube-system    kube-scheduler-master1            1/1     Running   3 (39m ago)    14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-scheduler-master2            1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-scheduler-master3            1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-vip-master1                  1/1     Running   0              1m     192.168.10.151   master1   <none>           <none>\nkube-system    kube-vip-master2                  1/1     Running   1 (38m ago)    15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-vip-master3                  1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\n```\n\n<h1 id=\"da88e661\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群高可用测试</font></h1>\n---\n\n<h2 id=\"87c533b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件所在节点查看</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看VIP所在节点（当前位于master2）</font>\n\n```plain\n[root@tiaoban ~]# ansible k8s-ha -m shell -a \"ip a | grep 192.168.10.150\"\n[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details\nwork2 | FAILED | rc=1 >>\nnon-zero return code\nmaster2 | CHANGED | rc=0 >>\n    inet 192.168.10.150/32 scope global ens160\nwork1 | FAILED | rc=1 >>\nnon-zero return code\nmaster1 | FAILED | rc=1 >>\nnon-zero return code\nmaster3 | FAILED | rc=1 >>\nnon-zero return code\nwork3 | FAILED | rc=1 >>\nnon-zero return code\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看其他组件所在节点（controller-manager位于master1，scheduler 位于master3）</font>\n\n```plain\n[root@tiaoban ~]# kubectl get leases -n kube-system\nNAME                                   HOLDER                                                                      AGE\napiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   175m\napiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h6m\napiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   176m\nkube-controller-manager                master1_08adefe3-56c0-4c87-94b7-9adda172eaf3                                3h6m\nkube-scheduler                         master3_59611769-b42d-459a-aa45-6ccf535d793f                                3h6m\nplndr-cp-lock                          master3                                                                     176m\nplndr-svcs-lock                        master1                                                                     176m\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建deployment和svc，模拟生产业务</font>\n\n```plain\n# 新建资源清单\n[root@tiaoban k8s]# cat > demo.yaml << EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: ikubernetes/myapp:v1\n        ports:\n        - containerPort: 80\n          name: http\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-svc\nspec:\n  selector:\n    app: myapp\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort:  80\nEOF\n\n# 创建资源\n[root@tiaoban k8s]# kubectl apply -f demo.yaml \ndeployment.apps/myapp created\nservice/myapp-svc created\n\n# 查看资源信息\n[root@tiaoban k8s]# kubectl get pod -o wide\nNAME                     READY   STATUS    RESTARTS   AGE    IP           NODE    NOMINATED NODE   READINESS GATES\nmyapp-64b6b8fbcd-jm5q2   1/1     Running   0          101s   10.244.3.2   work3   <none>           <none>\nmyapp-64b6b8fbcd-qqjsd   1/1     Running   0          101s   10.244.4.2   work2   <none>           <none>\nmyapp-64b6b8fbcd-tsmwx   1/1     Running   0          101s   10.244.5.6   work1   <none>           <none>\n\n[root@tiaoban k8s]# kubectl get svc\nNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nkubernetes   ClusterIP   10.96.0.1        <none>        443/TCP        3h17m\nmyapp-svc    NodePort    10.110.186.236   <none>        80:30380/TCP   5m6s\n\n# 访问测试\n[root@tiaoban k8s]# curl 192.168.10.150:30380\nHello MyApp | Version: v1 | <a href=\"hostname.html\">Pod Name</a>\n```\n\n<h2 id=\"59ab63b0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">宕机一台控制节点</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">将VIP所在的master2节点关机，模拟宕机</font>\n\n```plain\n[root@master3 ~]# init 0\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">各组件信息查看</font>\n\n```plain\n# VIP位于master1\n[root@tiaoban k8s]# ansible k8s-ha -m shell -a \"ip a | grep 192.168.10.150\"\n[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details\n[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details\nmaster2 | UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: ssh: connect to host master2 port 22: Connection refused\",\n    \"unreachable\": true\n}\nwork2 | FAILED | rc=1 >>\nnon-zero return code\nwork3 | FAILED | rc=1 >>\nnon-zero return code\nwork1 | FAILED | rc=1 >>\nnon-zero return code\nmaster3 | FAILED | rc=1 >>\nnon-zero return code\nmaster1 | CHANGED | rc=0 >>\n    inet 192.168.10.150/32 scope global ens160\n\n# controller-manager位于master1 scheduler位于master3\n[root@tiaoban k8s]# kubectl get leases -n kube-system\nNAME                                   HOLDER                                                                      AGE\napiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   3h19m\napiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h30m\napiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   3h20m\nkube-controller-manager                master1_fd5b1081-93e2-4be8-8eb8-8719a70b606a                                3h29m\nkube-scheduler                         master1_2b4c98a1-8d8c-4bb3-a3c4-58793022180a                                3h29m\nplndr-cp-lock                          master3                                                                     3h20m\nplndr-svcs-lock                        master1                                                                     3h20m\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">集群节点信息查看</font>\n\n```plain\n[root@tiaoban k8s]# kubectl get node\nNAME      STATUS     ROLES           AGE     VERSION\nmaster1   Ready      control-plane   3h31m   v1.27.6\nmaster2   NotReady   control-plane   3h22m   v1.27.6\nmaster3   Ready      control-plane   3h21m   v1.27.6\nwork1     Ready      <none>          3h14m   v1.27.6\nwork2     Ready      <none>          3h14m   v1.27.6\nwork3     Ready      <none>          3h14m   v1.27.6\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">业务访问测试</font>\n\n```plain\n[root@tiaoban k8s]# curl 192.168.10.150:30380\nHello MyApp | Version: v1 | <a href=\"hostname.html\">Pod Name</a>\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">结论：当有一个master节点宕机时，VIP会发生漂移，集群各项功能不受影响。</font>\n\n","source":"_posts/1.kubeadm高可用部署.md","raw":"---\ntitle: kubeadm高可用部署\ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"f1b611b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构方案</font></h1>\n---\n\n<h2 id=\"6bdfa137\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构说明</font></h2>\n---\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">核心组件</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">高可用模式</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">高可用实现方式</font>** |\n| --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">集群</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm</font> |\n\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver 通过haproxy+keepalived实现高可用，当某个节点故障时触发keepalived vip 转移；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个controller-manager组件运行；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个scheduler组件运行；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 通过运行kubeadm方式自动创建集群来实现高可用，部署的节点数为奇数。如果剩余可用节点数量超过半数，集群可以几乎没有影响的正常工作(3节点方式最多容忍一台机器宕机)</font>\n\n<h2 id=\"c267defc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HAProxy+</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Keepalived方案</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在以前我们在私有环境下创建 Kubernetes 集群时，我们需要准备一个硬件/软件的负载均衡器来创建多控制面集群，更多的情况下我们会选择使用 HAProxy + Keepalived 来实现这个功能。一般情况下我们会在k8s集群外创建2个负载均衡器的虚拟机，然后分配一个 VIP，然后使用 VIP 为负载均衡器提供服务，通过 VIP 将流量重定向到后端的某个 Kubernetes master节点上。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">或者在所有Kubernetes master节点上部署HAProxy + Keepalived服务，实现故障切换。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940757-19c0d378-d69c-4d9d-bea9-19b988fceb79.jpeg)\n\n<h2 id=\"2540cb93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip方案</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">除了使用传统方式外，我们也可以通过kube-vip实现高可用。kube-vip 可以通过静态 pod 运行在控制平面节点上，这些 pod 通过ARP 对话来识别每个节点上的其他主机，所以需要在 hosts 文件中设置每个节点的 IP 地址，我们可以选择 BGP 或 ARP 来设置负载平衡器，这与 Metal LB 比较类似。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的 Leader，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940896-936a1802-8255-4ae3-b742-b192c9df044c.jpeg)\n\n<h1 id=\"b7a8ae3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 架构</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 有许多功能设计选择提供高可用性或网络功能，作为VIP/负载平衡解决方案的一部分。</font>\n\n<h2 id=\"cluster\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Cluster</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 建立了一个多节点或多模块的集群来提供高可用性。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的领导者，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当使用 ARP 或 layer2 时，它将使用领导者选举，当然也可以使用 raft 集群技术，但这种方法在很大程度上已经被领导者选举所取代，特别是在集群中运行时。</font>\n\n<h2 id=\"15c8be58\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">集群中的领导者将分配 vip，并将其绑定到配置中声明的选定接口上。当领导者改变时，它将首先撤销 vip，或者在失败的情况下，vip 将直接由下一个当选的领导者分配。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当 vip 从一个主机移动到另一个主机时，任何使用 vip 的主机将保留以前的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip <-> MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">地址映射，直到 ARP 过期（通常是30秒）并检索到一个新的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip <-> MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">映射，这可以通过使用无偿的 ARP 广播来优化。</font>\n\n<h2 id=\"arp\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ARP</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip可以被配置为广播一个无偿的 arp（可选），通常会立即通知所有本地主机 vip <-> MAC 地址映射已经改变。当 ARP 广播被接收时，故障转移通常在几秒钟内完成。</font>\n\n<h1 id=\"47b520ed\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群规划</font></h1>\n---\n\n<h2 id=\"2d507904\"><font style=\"background-color:rgba(255, 255, 255, 0);\">软件版本</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">操作系统版本：Rocky Linux release 8.8</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">内核版本：4.18.0-477.21.1.el8_8.x86_64</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes版本：1.27.6</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd版本：1.6.22</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip版本：0.6.0</font>\n\n<h2 id=\"c5b040c2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">主机IP规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">ip</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机配置</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">用途</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.151</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.152</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.153</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.154</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.155</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.156</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">VIP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.150</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP在控制节点上浮动</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端，连接管理K8S集群</font> |\n\n\n<h1 id=\"60fb03bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础环境与软件准备</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有节点都执行</font>\n>\n\n<h2 id=\"d77c61bf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改主机名与hosts文件</font></h2>\n```plain\nhostnamectl set-hostname master1\ncat > /etc/hosts << EOF \n192.168.10.151   master1\n192.168.10.152   master2\n192.168.10.153   master3\n192.168.10.154   work1\n192.168.10.155   work2\n192.168.10.156   work3\nEOF\n```\n\n<h2 id=\"a0b09c93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证mac地址uuid</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">保证各节点mac和uuid唯一，防止克隆主机出现网络异常问题</font>\n\n```plain\ncat /sys/class/net/ens33/address\ncat /sys/class/dmi/id/product_uuid \n```\n\n<h2 id=\"16c50660\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置时间同步</font></h2>\n```plain\ndnf -y install chrony\nsystemctl  start chronyd\nsystemctl  enable chronyd\ntimedatectl set-timezone Asia/Shanghai\nchronyc sourcestats -v \ndate\n```\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">也可以在内网环境其中一台主机启动chronyd服务，其他主机配置chronyd服务地址</font>\n>\n\n<h2 id=\"1663c88c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭防火墙和selinux</font></h2>\n---\n\n```plain\nsystemctl stop firewalld.service\nsystemctl  disable firewalld\nsetenforce  0\nsed  -i 's/enforcing/disabled/g' /etc/selinux/config\ngrep  SELINUX= /etc/selinux/config \n```\n\n<h2 id=\"7c54c7f3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭swap分区</font></h2>\n---\n\n```plain\nswapoff -a \nsed -i '/ swap / s/^(.*)$/#\\1/g' /etc/fstab  \n```\n\n<h2 id=\"825e7bd1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改内核相关参数</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">最大限度使用物理内存，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">bridge 设备在二层转发时也去调用 iptables 配置的三层规则，开启数据包转发。</font>\n\n```plain\ncat > /etc/sysctl.d/kubernetes.conf << EOF\nvm.swappiness = 0\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n\nsysctl -p /etc/sysctl.d/kubernetes.conf\n```\n\n<h2 id=\"927d0791\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置yum源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">配置阿里源</font>\n\n```plain\ncat > /etc/yum.repos.d/kubernetes.repo << EOF \n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果阿里源异常，可切换配置清华源</font>\n\n```plain\ncat > /etc/yum.repos.d/kubernetes.repo << EOF \n[kubernetes]\nname=kubernetes\nbaseurl=https://mirrors.tuna.tsinghua.edu.cn/kubernetes/yum/repos/kubernetes-el7-$basearch\nenabled=1\nEOF\n```\n\n<h2 id=\"5e11d2ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置ipvs模块功能</font></h2>\n---\n\n```plain\ndnf -y install ipset ipvsadm \n\ncat > /etc/sysctl.d/ipvs.modules <<EOF \n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\nmodprobe -- br_netfilter\nEOF\n\nchmod 755 /etc/sysctl.d/ipvs.modules && bash \n\n/etc/sysctl.d/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack \nip_vs_sh               20480  0\nip_vs_wrr              16384  0\nip_vs_rr               16384  0\nip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr\nnf_conntrack_netlink    53248  0\nnf_conntrack          176128  5 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE,ip_vs\nnf_defrag_ipv6         24576  2 nf_conntrack,ip_vs\nnf_defrag_ipv4         16384  1 nf_conntrack\nnfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables\nlibcrc32c              16384  5 nf_conntrack,nf_nat,nf_tables,xfs,ip_vs\n\n# 添加开机自动加载模块\necho \"/etc/sysctl.d/ipvs.modules\" >> /etc/rc.local\nchmod +x /etc/rc.local\n# 启用网桥过滤器模块\necho 1 > /proc/sys/net/bridge/bridge-nf-call-iptables\necho 1 > /proc/sys/net/ipv4/ip_forward\n```\n\n<h2 id=\"680cf1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装命令自动补全工具</font></h2>\n---\n\n```plain\ndnf -y install bash-completion \nsource /etc/profile.d/bash_completion.sh \n```\n\n<h2 id=\"752286ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">container</font><font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h2>\n---\n\n<h3 id=\"56f5cf9c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font></h3>\n```plain\n# 安装依赖\ndnf install -y yum-utils device-mapper-persistent-data lvm2\n\n# 添加yum源\ndnf config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n# 查看可安装的containerd版本\ndnf list containerd.io.x86_64 --showduplicates | sort -r\n\n# 安装1.6.22版本containerd\ndnf install -y containerd.io-1.6.22-3.1.el8.x86_64\n\n# 查看版本信息\ncontainerd -v\n```\n\n<h3 id=\"da6011d1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置container</font></h3>\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font>**\n\n```plain\ncontainerd config default > /etc/containerd/config.toml\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font>**\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。把sandbox_image = \"k8s.gcr.io/pause:3.6\"修改为：sandbox_image=“registry.aliyuncs.com/google_containers/pause:3.6”</font>\n\n```plain\nsed -i 's/sandbox_image\\ =.*/sandbox_image\\ =\\ \"registry.aliyuncs.com\\/google_containers\\/pause:3.6\"/g' /etc/containerd/config.toml|grep sandbox_image\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">配置cgroup驱动器</font>**\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 kubelet 和容器运行时需使用相同的 cgroup 驱动并且采用相同的配置。</font>\n\n```plain\nsed -i 's/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g' /etc/containerd/config.toml\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速地址</font>**\n\n```plain\n# 修改container配置，指定registry配置从文件读取\nvim /etc/containerd/config.toml\n    [plugins.\"io.containerd.grpc.v1.cri\".registry]\n      config_path = \"/etc/containerd/certs.d\"\n\n# 创建配置文件目录\nmkdir -p /etc/containerd/certs.d/docker.io\n\n# 新增加速配置\ncat > /etc/containerd/certs.d/docker.io/hosts.toml << EOF\nserver = \"https://docker.io\"\n[host.\"https://o2j0mc5x.mirror.aliyuncs.com\"]\n  capabilities = [\"pull\", \"resolve\"]\nserver = \"https://k8s.gcr.io\"\n[host.\"https://gcr.mirrors.ustc.edu.cn/google-containers/\"]\n  capabilities = [\"pull\", \"resolve\"]\nserver = \"https://quay.io\"\n[host.\"https://mirror.ccs.tencentyun.com\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n```\n\n<h3 id=\"E4Q5q\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 container服务</font></h3>\n```plain\nsystemctl enable containerd --now\n```\n\n<h3 id=\"527bcc5b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：https://github.com/kubernetes-sigs/cri-tools/releases</font>\n\n```plain\n# 下载\nwget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.27.1/crictl-v1.27.1-linux-amd64.tar.gz\n# 解压\ntar -zxvf crictl-v1.27.1-linux-amd64.tar.gz -C /usr/local/bin\n# 配置\ncat > /etc/crictl.yaml << EOF\nruntime-endpoint: \"unix:///run/containerd/containerd.sock\"\nimage-endpoint: \"unix:///run/containerd/containerd.sock\"\ntimeout: 0\ndebug: false\npull-image-on-create: false\ndisable-pull-on-run: false\nEOF\n# 验证\ncrictl version\n```\n\n<h3 id=\"UomHm\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl(建议)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font>\n\n```plain\n# 下载\nwget https://github.com/containerd/nerdctl/releases/download/v1.5.0/nerdctl-1.5.0-linux-amd64.tar.gz\n# 解压\ntar -zxvf nerdctl-1.5.0-linux-amd64.tar.gz \n# 复制文件\ncp nerdctl /usr/bin/\n# 配置 nerdctl 参数自动补齐\necho 'source <(nerdctl completion bash)' >> /etc/profile\nsource /etc/profile\n# 验证\nnerdctl -v\n```\n\n<h2 id=\"8dd46c64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装k8s软件包并配置</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font>\n\n```plain\nyum install -y kubelet kubeadm kubectl \n# 默认安装最新版本，如果需要安装老版本，使用如下命令\nyum list kubeadm --showduplicates | sort -r\nyum install -y kubelet-1.27.6 kubeadm-1.27.6 kubectl-1.27.6\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时并启动。</font>\n\n```plain\ncrictl config runtime-endpoint unix:///run/containerd/containerd.sock\nsystemctl enable kubelet --now\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl命令补全</font>\n\n```plain\necho \"source <(kubectl completion bash)\" >> ~/.bash_profile \nsource ~/.bash_profile \n```\n\n<h1 id=\"6f342ec9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(kube-vip)</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font>\n>\n\n<h2 id=\"88210852\"><font style=\"background-color:rgba(255, 255, 255, 0);\">准备工作</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们使用的vip是192.168.10.150</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">网卡名称是ens160</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip使用arp模式</font>\n\n```plain\n[root@master1 ~]# mkdir -p /etc/kubernetes/manifests\n[root@master1 ~]# export VIP=192.168.10.150\n[root@master1 ~]# export INTERFACE=ens160\n[root@master1 ~]# export KVVERSION=v0.8.2\n```\n\n<h2 id=\"ea49435f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成配置文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取 kube-vip 的 docker 镜像，并在 /etc/kuberentes/manifests 中设置静态 pod 的 yaml 资源清单文件，这样 Kubernetes 就会自动在每个控制平面节点上部署 kube-vip 的 pod 了。</font>\n\n```plain\n[root@master1 ~]# alias kube-vip=\"ctr image pull ghcr.io/kube-vip/kube-vip:$KVVERSION; ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:$KVVERSION vip /kube-vip\"\n[root@master1 ~]# kube-vip manifest pod \\\n    --interface $INTERFACE \\\n    --address $VIP \\\n    --controlplane \\\n    --services \\\n    --arp \\\n    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml\n# 生成文件如下所示：\napiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: null\n  name: kube-vip\n  namespace: kube-system\nspec:\n  containers:\n  - args:\n    - manager\n    env:\n    - name: vip_arp\n      value: \"true\"\n    - name: port\n      value: \"6443\"\n    - name: vip_nodename\n      valueFrom:\n        fieldRef:\n          fieldPath: spec.nodeName\n    - name: vip_interface\n      value: ens160\n    - name: vip_cidr\n      value: \"32\"\n    - name: dns_mode\n      value: first\n    - name: cp_enable\n      value: \"true\"\n    - name: cp_namespace\n      value: kube-system\n    - name: svc_enable\n      value: \"true\"\n    - name: svc_leasename\n      value: plndr-svcs-lock\n    - name: vip_leaderelection\n      value: \"true\"\n    - name: vip_leasename\n      value: plndr-cp-lock\n    - name: vip_leaseduration\n      value: \"5\"\n    - name: vip_renewdeadline\n      value: \"3\"\n    - name: vip_retryperiod\n      value: \"1\"\n    - name: address\n      value: 192.168.10.150\n    - name: prometheus_server\n      value: :2112\n    image: ghcr.io/kube-vip/kube-vip:v0.8.2\n    imagePullPolicy: IfNotPresent\n    name: kube-vip\n    resources: {}\n    securityContext:\n      capabilities:\n        add:\n        - NET_ADMIN\n        - NET_RAW\n    volumeMounts:\n    - mountPath: /etc/kubernetes/admin.conf\n      name: kubeconfig\n  hostAliases:\n  - hostnames:\n    - kubernetes\n    ip: 127.0.0.1\n  hostNetwork: true\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/admin.conf\n    name: kubeconfig\nstatus: {}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当执行完kubeadm init后，kubelet会去加载这里面的yaml创建kube-vip容器。</font>\n\n<h2 id=\"cce0e451\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝至其他master节点</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">所有master节点都需要部署一个kube-vip，我们只需要将yaml文件存放在/etc/kubernetes/manifests/目录下，kubelet启动时会自动加载资源清单并创建pod。</font>\n\n```plain\n[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master2:/etc/kubernetes/manifests/kube-vip.yaml\n[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master3:/etc/kubernetes/manifests/kube-vip.yaml\n```\n\n```plain\nsed -i 's#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#' \\\n          /etc/kubernetes/manifests/kube-vip.yaml\n```\n\n<h1 id=\"9845b730\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(keepalived+haproxy)</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有master节点执行</font>\n\n<h2 id=\"bbd75de9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">haproxy配置</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装haproxy</font>\n\n```plain\n[root@master1 ~]# dnf -y install haproxy\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">编辑配置文件，所有master节点配置一样。</font>\n\n```plain\n[root@master1 ~]# vim /etc/haproxy/haproxy.cfg\nglobal\n    log         127.0.0.1 local2\n    pidfile     /var/run/haproxy.pid\n    maxconn     4000\ndefaults\n    mode                    http\n    log                     global\n    option                  dontlognull\n    option http-server-close\n    option                  redispatch\n    retries                 3\n    timeout http-request    10s\n    timeout queue           1m\n    timeout connect         10s\n    timeout client          1m\n    timeout server          1m\n    timeout http-keep-alive 10s\n    timeout check           10s\n    maxconn                 3000\n\nlisten admin_stats\n    bind    *:8888    #监听的ip端口号\n    stats   enable\n    stats   refresh 30s   #统计页面自动刷新时间\n    stats   uri /admin    #访问的uri   ip:8080/admin\n    stats   realm haproxy\n    stats   auth admin:Miaohua123!  #认证用户名和密码\n    stats   hide-version   #隐藏HAProxy的版本号\n    stats   admin if TRUE   #管理界面，如果认证成功了，可通过webui管理节点  \n\nfrontend  kubernetes-apiserver\n    mode tcp\n    bind *:9443\n    # bind *:443 ssl # To be completed ....\n    default_backend             kubernetes-apiserver\n\nbackend kubernetes-apiserver\n    mode        tcp\n    balance     roundrobin\n# k8s-apiservers backend\n    server master1 192.168.10.151:6443 check\n    server master2 192.168.10.152:6443 check\n    server master3 192.168.10.153:6443 check\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font>\n\n```plain\n[root@master1 ~]# systemctl start haproxy.service \n[root@master1 ~]# systemctl enable haproxy.service \n[root@master1 ~]# ss -tnlp | grep haproxy\nLISTEN    0         3000               0.0.0.0:8888             0.0.0.0:*        users:((\"haproxy\",pid=7062,fd=6))                                              \nLISTEN    0         3000               0.0.0.0:9443             0.0.0.0:*        users:((\"haproxy\",pid=7062,fd=8)) \n```\n\n<h2 id=\"fff6cb90\"><font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived配置</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装keepalived服务</font>\n\n```plain\n[root@master1 ~]# dnf -y install keepalived\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加keepalived配置文件，master1节点内容如下。master2节点state改为BACKUP，priority改为99。master3节点state改为BACKUP，priority改为98。</font>\n\n```plain\n[root@master1 ~]# vim /etc/keepalived/keepalived.conf\nglobal_defs {\n   script_user root\n   enable_script_security\n}\n\nvrrp_script chk_haproxy {\n    script \"/etc/keepalived/check.sh\"\n    interval 1\n    weight -2\n}\n\nvrrp_instance VI_1 {\n  state MASTER # 实例类型\n  interface ens33 # 网卡名称\n  virtual_router_id 201\n  priority 100 # 优先级\n  advert_int 1\n\n  virtual_ipaddress {\n    192.168.10.150/32\n  }\n\n  authentication {\n    auth_type PASS\n    auth_pass 1111\n  }\n\n  track_script {\n      chk_haproxy\n  }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加服务检测脚本，如果containerd进程停止则进行故障切换</font>\n\n```plain\n[root@master1 ~]# vim /etc/keepalived/check.sh\n#!/bin/bash\nif systemctl is-active --quiet containerd; then\n    exit 0\nelse\n    exit 1\nfi\n[root@master1 ~]# chmod +x /etc/keepalived/check.sh\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font>\n\n```plain\n[root@master1 ~]# systemctl start keepalived.service \n[root@master1 ~]# systemctl enable keepalived\n[root@master1 ~]# ip a | grep 192.168.10\n    inet 192.168.10.151/24 brd 192.168.10.255 scope global ens33\n    inet 192.168.10.150/32 scope global ens33\n```\n\n<h1 id=\"ede357c3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化master节点</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font>\n>\n\n<h2 id=\"575087eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置集群参数</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font>\n\n```plain\n[root@master1 ~]# kubeadm config print init-defaults > kubeadm-conf.yaml\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n```plain\n[root@master1 ~]# cat kubeadm-conf.yaml\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.10.151  # 指定当前master1节点IP\n  bindPort: 6443 # 当前master1节点端口\nnodeRegistration:\n  criSocket: unix:///run/containerd/containerd.sock # 使用containerd的socket地址\n  imagePullPolicy: IfNotPresent\n  name: master1 # 节点主机名\n  taints: null\n---\napiServer:\n  extraArgs:\n    authorization-mode: Node,RBAC\n  timeoutForControlPlane: 4m0s\n  certSANs:  # 添加其他master节点的相关信息\n  - 127.0.0.1\n  - master1\n  - master2\n  - master3\n  - 192.168.10.150\n  - 192.168.10.151\n  - 192.168.10.152\n  - 192.168.10.153\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像\nkind: ClusterConfiguration\nkubernetesVersion: 1.27.6 # k8s版本\ncontrolPlaneEndpoint: 192.168.10.150:6443  # 设置控制平面Endpoint地址和端口\nnetworking:\n  dnsDomain: cluster.local\n  serviceSubnet: 10.96.0.0/12\n  podSubnet: 10.244.0.0/16  # 指定 pod 子网\nscheduler: {}\n---\n# 指定kube-proxy基于ipvs模式\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind:  KubeProxyConfiguration\nmode: ipvs\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: systemd   # 指定cgroup驱动器为systemd模式\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nmemorySwap: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s\n```\n\n\n\n<h2 id=\"aec284f8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">将master1节点的kubeadm-conf.yaml复制到其他master节点，所有master节点都提前执行</font>\n\n```plain\n[root@master1 ~]# kubeadm config images pull --config kubeadm-conf.yaml\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.27.6\n[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.9\n[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.7-0\n[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.10.1\n# CRI sandbox(pause) image默认使用registry.k8s.io/pause:3.6，由于网络原因无法拉取，直接改为阿里镜像标签即可。\n[root@master1 ~]# nerdctl -n k8s.io tag registry.aliyuncs.com/google_containers/pause:3.9 registry.k8s.io/pause:3.6\n```\n\n<h2 id=\"5fa25176\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群初始化</font></h2>\n---\n\n```plain\n[root@master1 ~]# kubeadm init --upload-certs --config=kubeadm-conf.yaml \nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of the control-plane node running the following command on each as root:\n\n  kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\\n        --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7\n\nPlease note that the certificate-key gives access to cluster sensitive data, keep it secret!\nAs a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use\n\"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward.\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–upload-certs 标志用来将在所有控制平面实例之间的共享证书上传到集群。然后根据安装提示拷贝 kubeconfig 文件</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果配置问题导致集群初始化失败，可重置集群再次初始化：</font>\n\n```plain\n[root@master1 ~]# kubeadm reset\n[root@master1 ~]# ipvsadm --clear\n[root@master1 ~]# rm -rf $HOME/.kube/config\n```\n\n<h2 id=\"c238630b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示配置环境变量</font></h2>\n---\n\n```plain\n[root@master1 ~]# mkdir -p $HOME/.kube \n[root@master1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config \n[root@master1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config\n[root@master1 ~]# echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" >> ~/.bash_profile\n[root@tiaoban ~]# source ~/.bash_profile\n```\n\n<h2 id=\"154df728\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装flannel网络</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">下载资源清单配置文件</font>\n\n```plain\n[root@master1 ~]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n```plain\n[root@master1 ~]# kubectl apply -f kube-flannel.yml\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果镜像不能正常拉取，所有节点需提前导入镜像，并修改yaml文件镜像拉取策略</font>\n\n```plain\nimagePullPolicy: IfNotPresent\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">镜像导入与查询</font>\n\n```plain\n[root@work3 ~]# ctr -n=k8s.io image import flannel.tar \nunpacking docker.io/flannel/flannel:v0.22.1 (sha256:0b78f714708e837ae667c204cc918649ebcf2441b1d18ebde9a6564254932ee5)...done\n[root@work3 ~]# crictl images\nIMAGE                                                             TAG                 IMAGE ID            SIZE\ndocker.io/flannel/flannel-cni-plugin                              v1.2.0              a55d1bad692b7       8.32MB\n```\n\n<h1 id=\"76ce2493\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他节点加入集群</font></h1>\n---\n\n<h2 id=\"6e7aaa3e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">master节点加入集群</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">另外两个节点 master2 和 master3 都执行上面的 join 命令，上面的命令中的 --control-plane 就是通知 kubeadm join 创建一个新的控制平面，–certificate-key 会从集群中的 kubeadm-certs Secret 下载控制平面证书并使用给定的密钥进行解密。</font>\n\n```plain\n# 以master2节点为例\n[root@master2 ~]#   kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n>         --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\\n>         --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7\n\n# 然后根据提示配置环境变量\n[root@master2 ~]# mkdir -p $HOME/.kube\n[root@master2 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n[root@master2 ~]# chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n<h2 id=\"5eec51f2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">work节点加入集群</font></h2>\n---\n\n```plain\nkubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\\n        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c\n```\n\n<h2 id=\"ade4c21a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font></h2>\n---\n\n```plain\n# 安装指定版本的kubelet\n[root@tiaoban ~]# yum install -y kubectl-1.27.6\n# 拷贝集群认证文件并配置环境变量\n[root@tiaoban ~]# mkdir -p /etc/kubernetes\n[root@tiaoban ~]# scp master1:/etc/kubernetes/admin.conf /etc/kubernetes/\n[root@tiaoban ~]# echo \"export KUBECONFIG=/etc/kubernetes/admin.conf\" >> ~/.bash_profile\n[root@tiaoban ~]# source ~/.bash_profile\n```\n\n<h1 id=\"fb2d3f91\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群验证</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在tiaoban节点执行</font>\n>\n\n<h2 id=\"77b07675\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点信息</font></h2>\n---\n\n```plain\n[root@tiaoban ~]# kubectl get node\nNAME      STATUS   ROLES           AGE    VERSION\nmaster1   Ready    control-plane   18m     v1.27.6\nmaster2   Ready    control-plane   12m7s   v1.27.6\nmaster3   Ready    control-plane   13m6s   v1.27.6\nwork1     Ready    <none>          8m25s   v1.27.6\nwork2     Ready    <none>          8m21s   v1.27.6\nwork3     Ready    <none>          8m17s   v1.27.6\n```\n\n<h2 id=\"86a835fd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod信息</font></h2>\n---\n\n```plain\n[root@master1 ~]# kubectl get pod -A -o wide \nNAMESPACE      NAME                              READY   STATUS    RESTARTS       AGE     IP               NODE      NOMINATED NODE   READINESS GATES\nkube-flannel   kube-flannel-ds-2nqk5             1/1     Running   0              134s   192.168.10.151   master1   <none>           <none>\nkube-flannel   kube-flannel-ds-c87jk             1/1     Running   0              134s   192.168.10.155   work2     <none>           <none>\nkube-flannel   kube-flannel-ds-hnps5             1/1     Running   0              134s   192.168.10.154   work1     <none>           <none>\nkube-flannel   kube-flannel-ds-jphgx             1/1     Running   0              154s   192.168.10.153   master3   <none>           <none>\nkube-flannel   kube-flannel-ds-lxpsp             1/1     Running   0              134s   192.168.10.156   work3     <none>           <none>\nkube-flannel   kube-flannel-ds-rx5kf             1/1     Running   0              134s   192.168.10.152   master2   <none>           <none>\nkube-system    coredns-7bdc4cb885-cjbbx          1/1     Running   0              14m    10.244.5.3       work1     <none>           <none>\nkube-system    coredns-7bdc4cb885-sgsns          1/1     Running   0              14m    10.244.5.2       work1     <none>           <none>\nkube-system    etcd-master1                      1/1     Running   1              14m    192.168.10.151   master1   <none>           <none>\nkube-system    etcd-master2                      1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    etcd-master3                      1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-apiserver-master1            1/1     Running   1              14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-apiserver-master2            1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-apiserver-master3            1/1     Running   2 (154m ago)   14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-controller-manager-master1   1/1     Running   3 (40m ago)    14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-controller-manager-master2   1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-controller-manager-master3   1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-proxy-9jsq7                  1/1     Running   0              18m    192.168.10.155   work2     <none>           <none>\nkube-system    kube-proxy-cpb5n                  1/1     Running   0              14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-proxy-dm2rm                  1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-proxy-g26c4                  1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-proxy-jkhnj                  1/1     Running   0              18m    192.168.10.156   work3     <none>           <none>\nkube-system    kube-proxy-x29d9                  1/1     Running   0              18m    192.168.10.154   work1     <none>           <none>\nkube-system    kube-scheduler-master1            1/1     Running   3 (39m ago)    14m    192.168.10.151   master1   <none>           <none>\nkube-system    kube-scheduler-master2            1/1     Running   0              15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-scheduler-master3            1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\nkube-system    kube-vip-master1                  1/1     Running   0              1m     192.168.10.151   master1   <none>           <none>\nkube-system    kube-vip-master2                  1/1     Running   1 (38m ago)    15m    192.168.10.152   master2   <none>           <none>\nkube-system    kube-vip-master3                  1/1     Running   0              14m    192.168.10.153   master3   <none>           <none>\n```\n\n<h1 id=\"da88e661\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群高可用测试</font></h1>\n---\n\n<h2 id=\"87c533b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件所在节点查看</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看VIP所在节点（当前位于master2）</font>\n\n```plain\n[root@tiaoban ~]# ansible k8s-ha -m shell -a \"ip a | grep 192.168.10.150\"\n[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details\nwork2 | FAILED | rc=1 >>\nnon-zero return code\nmaster2 | CHANGED | rc=0 >>\n    inet 192.168.10.150/32 scope global ens160\nwork1 | FAILED | rc=1 >>\nnon-zero return code\nmaster1 | FAILED | rc=1 >>\nnon-zero return code\nmaster3 | FAILED | rc=1 >>\nnon-zero return code\nwork3 | FAILED | rc=1 >>\nnon-zero return code\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看其他组件所在节点（controller-manager位于master1，scheduler 位于master3）</font>\n\n```plain\n[root@tiaoban ~]# kubectl get leases -n kube-system\nNAME                                   HOLDER                                                                      AGE\napiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   175m\napiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h6m\napiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   176m\nkube-controller-manager                master1_08adefe3-56c0-4c87-94b7-9adda172eaf3                                3h6m\nkube-scheduler                         master3_59611769-b42d-459a-aa45-6ccf535d793f                                3h6m\nplndr-cp-lock                          master3                                                                     176m\nplndr-svcs-lock                        master1                                                                     176m\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建deployment和svc，模拟生产业务</font>\n\n```plain\n# 新建资源清单\n[root@tiaoban k8s]# cat > demo.yaml << EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: ikubernetes/myapp:v1\n        ports:\n        - containerPort: 80\n          name: http\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-svc\nspec:\n  selector:\n    app: myapp\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort:  80\nEOF\n\n# 创建资源\n[root@tiaoban k8s]# kubectl apply -f demo.yaml \ndeployment.apps/myapp created\nservice/myapp-svc created\n\n# 查看资源信息\n[root@tiaoban k8s]# kubectl get pod -o wide\nNAME                     READY   STATUS    RESTARTS   AGE    IP           NODE    NOMINATED NODE   READINESS GATES\nmyapp-64b6b8fbcd-jm5q2   1/1     Running   0          101s   10.244.3.2   work3   <none>           <none>\nmyapp-64b6b8fbcd-qqjsd   1/1     Running   0          101s   10.244.4.2   work2   <none>           <none>\nmyapp-64b6b8fbcd-tsmwx   1/1     Running   0          101s   10.244.5.6   work1   <none>           <none>\n\n[root@tiaoban k8s]# kubectl get svc\nNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nkubernetes   ClusterIP   10.96.0.1        <none>        443/TCP        3h17m\nmyapp-svc    NodePort    10.110.186.236   <none>        80:30380/TCP   5m6s\n\n# 访问测试\n[root@tiaoban k8s]# curl 192.168.10.150:30380\nHello MyApp | Version: v1 | <a href=\"hostname.html\">Pod Name</a>\n```\n\n<h2 id=\"59ab63b0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">宕机一台控制节点</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">将VIP所在的master2节点关机，模拟宕机</font>\n\n```plain\n[root@master3 ~]# init 0\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">各组件信息查看</font>\n\n```plain\n# VIP位于master1\n[root@tiaoban k8s]# ansible k8s-ha -m shell -a \"ip a | grep 192.168.10.150\"\n[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details\n[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details\nmaster2 | UNREACHABLE! => {\n    \"changed\": false,\n    \"msg\": \"Failed to connect to the host via ssh: ssh: connect to host master2 port 22: Connection refused\",\n    \"unreachable\": true\n}\nwork2 | FAILED | rc=1 >>\nnon-zero return code\nwork3 | FAILED | rc=1 >>\nnon-zero return code\nwork1 | FAILED | rc=1 >>\nnon-zero return code\nmaster3 | FAILED | rc=1 >>\nnon-zero return code\nmaster1 | CHANGED | rc=0 >>\n    inet 192.168.10.150/32 scope global ens160\n\n# controller-manager位于master1 scheduler位于master3\n[root@tiaoban k8s]# kubectl get leases -n kube-system\nNAME                                   HOLDER                                                                      AGE\napiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   3h19m\napiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h30m\napiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   3h20m\nkube-controller-manager                master1_fd5b1081-93e2-4be8-8eb8-8719a70b606a                                3h29m\nkube-scheduler                         master1_2b4c98a1-8d8c-4bb3-a3c4-58793022180a                                3h29m\nplndr-cp-lock                          master3                                                                     3h20m\nplndr-svcs-lock                        master1                                                                     3h20m\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">集群节点信息查看</font>\n\n```plain\n[root@tiaoban k8s]# kubectl get node\nNAME      STATUS     ROLES           AGE     VERSION\nmaster1   Ready      control-plane   3h31m   v1.27.6\nmaster2   NotReady   control-plane   3h22m   v1.27.6\nmaster3   Ready      control-plane   3h21m   v1.27.6\nwork1     Ready      <none>          3h14m   v1.27.6\nwork2     Ready      <none>          3h14m   v1.27.6\nwork3     Ready      <none>          3h14m   v1.27.6\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">业务访问测试</font>\n\n```plain\n[root@tiaoban k8s]# curl 192.168.10.150:30380\nHello MyApp | Version: v1 | <a href=\"hostname.html\">Pod Name</a>\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">结论：当有一个master节点宕机时，VIP会发生漂移，集群各项功能不受影响。</font>\n\n","slug":"1.kubeadm高可用部署","published":1,"updated":"2025-03-30T13:09:10.082Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjl90001tsv1bf1c31bl","content":"<h1 id=\"f1b611b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构方案</font></h1>\n---\n\n<h2 id=\"6bdfa137\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构说明</font></h2>\n---\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">核心组件</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用模式</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用实现方式</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">集群</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm</font></td>\n</tr>\n</tbody></table>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver 通过haproxy+keepalived实现高可用，当某个节点故障时触发keepalived vip 转移；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个controller-manager组件运行；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个scheduler组件运行；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 通过运行kubeadm方式自动创建集群来实现高可用，部署的节点数为奇数。如果剩余可用节点数量超过半数，集群可以几乎没有影响的正常工作(3节点方式最多容忍一台机器宕机)</font></li>\n</ul>\n<h2 id=\"c267defc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HAProxy+</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Keepalived方案</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在以前我们在私有环境下创建 Kubernetes 集群时，我们需要准备一个硬件&#x2F;软件的负载均衡器来创建多控制面集群，更多的情况下我们会选择使用 HAProxy + Keepalived 来实现这个功能。一般情况下我们会在k8s集群外创建2个负载均衡器的虚拟机，然后分配一个 VIP，然后使用 VIP 为负载均衡器提供服务，通过 VIP 将流量重定向到后端的某个 Kubernetes master节点上。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">或者在所有Kubernetes master节点上部署HAProxy + Keepalived服务，实现故障切换。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940757-19c0d378-d69c-4d9d-bea9-19b988fceb79.jpeg\"></p>\n<h2 id=\"2540cb93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip方案</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">除了使用传统方式外，我们也可以通过kube-vip实现高可用。kube-vip 可以通过静态 pod 运行在控制平面节点上，这些 pod 通过ARP 对话来识别每个节点上的其他主机，所以需要在 hosts 文件中设置每个节点的 IP 地址，我们可以选择 BGP 或 ARP 来设置负载平衡器，这与 Metal LB 比较类似。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的 Leader，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940896-936a1802-8255-4ae3-b742-b192c9df044c.jpeg\"></p>\n<h1 id=\"b7a8ae3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 架构</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 有许多功能设计选择提供高可用性或网络功能，作为VIP&#x2F;负载平衡解决方案的一部分。</font></p>\n<h2 id=\"cluster\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Cluster</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 建立了一个多节点或多模块的集群来提供高可用性。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的领导者，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当使用 ARP 或 layer2 时，它将使用领导者选举，当然也可以使用 raft 集群技术，但这种方法在很大程度上已经被领导者选举所取代，特别是在集群中运行时。</font></p>\n<h2 id=\"15c8be58\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">集群中的领导者将分配 vip，并将其绑定到配置中声明的选定接口上。当领导者改变时，它将首先撤销 vip，或者在失败的情况下，vip 将直接由下一个当选的领导者分配。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当 vip 从一个主机移动到另一个主机时，任何使用 vip 的主机将保留以前的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip &lt;-&gt; MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">地址映射，直到 ARP 过期（通常是30秒）并检索到一个新的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip &lt;-&gt; MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">映射，这可以通过使用无偿的 ARP 广播来优化。</font></p>\n<h2 id=\"arp\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ARP</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip可以被配置为广播一个无偿的 arp（可选），通常会立即通知所有本地主机 vip &lt;-&gt; MAC 地址映射已经改变。当 ARP 广播被接收时，故障转移通常在几秒钟内完成。</font></p>\n<h1 id=\"47b520ed\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群规划</font></h1>\n---\n\n<h2 id=\"2d507904\"><font style=\"background-color:rgba(255, 255, 255, 0);\">软件版本</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">操作系统版本：Rocky Linux release 8.8</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">内核版本：4.18.0-477.21.1.el8_8.x86_64</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes版本：1.27.6</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">containerd版本：1.6.22</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip版本：0.6.0</font></p>\n<h2 id=\"c5b040c2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">主机IP规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">ip</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机配置</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">用途</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.151</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.152</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.153</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.154</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.155</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.156</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">VIP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.150</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP在控制节点上浮动</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端，连接管理K8S集群</font> |\n\n\n<h1 id=\"60fb03bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础环境与软件准备</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有节点都执行</font></p>\n</blockquote>\n<h2 id=\"d77c61bf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改主机名与hosts文件</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl set-hostname master1</span><br><span class=\"line\">cat &gt; /etc/hosts &lt;&lt; EOF </span><br><span class=\"line\">192.168.10.151   master1</span><br><span class=\"line\">192.168.10.152   master2</span><br><span class=\"line\">192.168.10.153   master3</span><br><span class=\"line\">192.168.10.154   work1</span><br><span class=\"line\">192.168.10.155   work2</span><br><span class=\"line\">192.168.10.156   work3</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"a0b09c93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证mac地址uuid</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">保证各节点mac和uuid唯一，防止克隆主机出现网络异常问题</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /sys/class/net/ens33/address</span><br><span class=\"line\">cat /sys/class/dmi/id/product_uuid </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"16c50660\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置时间同步</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf -y install chrony</span><br><span class=\"line\">systemctl  start chronyd</span><br><span class=\"line\">systemctl  enable chronyd</span><br><span class=\"line\">timedatectl set-timezone Asia/Shanghai</span><br><span class=\"line\">chronyc sourcestats -v </span><br><span class=\"line\">date</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">也可以在内网环境其中一台主机启动chronyd服务，其他主机配置chronyd服务地址</font></p>\n</blockquote>\n<h2 id=\"1663c88c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭防火墙和selinux</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop firewalld.service</span><br><span class=\"line\">systemctl  disable firewalld</span><br><span class=\"line\">setenforce  0</span><br><span class=\"line\">sed  -i &#x27;s/enforcing/disabled/g&#x27; /etc/selinux/config</span><br><span class=\"line\">grep  SELINUX= /etc/selinux/config </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7c54c7f3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭swap分区</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">swapoff -a </span><br><span class=\"line\">sed -i &#x27;/ swap / s/^(.*)$/#\\1/g&#x27; /etc/fstab  </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"825e7bd1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改内核相关参数</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">最大限度使用物理内存，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">bridge 设备在二层转发时也去调用 iptables 配置的三层规则，开启数据包转发。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF</span><br><span class=\"line\">vm.swappiness = 0</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">net.ipv4.ip_forward = 1</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">sysctl -p /etc/sysctl.d/kubernetes.conf</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"927d0791\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置yum源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">配置阿里源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF </span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果阿里源异常，可切换配置清华源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF </span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.tuna.tsinghua.edu.cn/kubernetes/yum/repos/kubernetes-el7-$basearch</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5e11d2ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置ipvs模块功能</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf -y install ipset ipvsadm </span><br><span class=\"line\"></span><br><span class=\"line\">cat &gt; /etc/sysctl.d/ipvs.modules &lt;&lt;EOF </span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">modprobe -- ip_vs</span><br><span class=\"line\">modprobe -- ip_vs_rr</span><br><span class=\"line\">modprobe -- ip_vs_wrr</span><br><span class=\"line\">modprobe -- ip_vs_sh</span><br><span class=\"line\">modprobe -- nf_conntrack</span><br><span class=\"line\">modprobe -- br_netfilter</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">chmod 755 /etc/sysctl.d/ipvs.modules &amp;&amp; bash </span><br><span class=\"line\"></span><br><span class=\"line\">/etc/sysctl.d/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack </span><br><span class=\"line\">ip_vs_sh               20480  0</span><br><span class=\"line\">ip_vs_wrr              16384  0</span><br><span class=\"line\">ip_vs_rr               16384  0</span><br><span class=\"line\">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class=\"line\">nf_conntrack_netlink    53248  0</span><br><span class=\"line\">nf_conntrack          176128  5 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE,ip_vs</span><br><span class=\"line\">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class=\"line\">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class=\"line\">nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables</span><br><span class=\"line\">libcrc32c              16384  5 nf_conntrack,nf_nat,nf_tables,xfs,ip_vs</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加开机自动加载模块</span><br><span class=\"line\">echo &quot;/etc/sysctl.d/ipvs.modules&quot; &gt;&gt; /etc/rc.local</span><br><span class=\"line\">chmod +x /etc/rc.local</span><br><span class=\"line\"># 启用网桥过滤器模块</span><br><span class=\"line\">echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</span><br><span class=\"line\">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"680cf1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装命令自动补全工具</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf -y install bash-completion </span><br><span class=\"line\">source /etc/profile.d/bash_completion.sh </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"752286ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">container</font><font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h2>\n---\n\n<h3 id=\"56f5cf9c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装依赖</span><br><span class=\"line\">dnf install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加yum源</span><br><span class=\"line\">dnf config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看可安装的containerd版本</span><br><span class=\"line\">dnf list containerd.io.x86_64 --showduplicates | sort -r</span><br><span class=\"line\"></span><br><span class=\"line\"># 安装1.6.22版本containerd</span><br><span class=\"line\">dnf install -y containerd.io-1.6.22-3.1.el8.x86_64</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看版本信息</span><br><span class=\"line\">containerd -v</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"da6011d1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置container</font></h3>\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font>**\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">containerd config default &gt; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font></strong></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。把sandbox_image &#x3D; “k8s.gcr.io&#x2F;pause:3.6”修改为：sandbox_image&#x3D;“registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.6”</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &#x27;s/sandbox_image\\ =.*/sandbox_image\\ =\\ &quot;registry.aliyuncs.com\\/google_containers\\/pause:3.6&quot;/g&#x27; /etc/containerd/config.toml|grep sandbox_image</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">配置cgroup驱动器</font></strong></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 kubelet 和容器运行时需使用相同的 cgroup 驱动并且采用相同的配置。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &#x27;s/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g&#x27; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速地址</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改container配置，指定registry配置从文件读取</span><br><span class=\"line\">vim /etc/containerd/config.toml</span><br><span class=\"line\">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]</span><br><span class=\"line\">      config_path = &quot;/etc/containerd/certs.d&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建配置文件目录</span><br><span class=\"line\">mkdir -p /etc/containerd/certs.d/docker.io</span><br><span class=\"line\"></span><br><span class=\"line\"># 新增加速配置</span><br><span class=\"line\">cat &gt; /etc/containerd/certs.d/docker.io/hosts.toml &lt;&lt; EOF</span><br><span class=\"line\">server = &quot;https://docker.io&quot;</span><br><span class=\"line\">[host.&quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">server = &quot;https://k8s.gcr.io&quot;</span><br><span class=\"line\">[host.&quot;https://gcr.mirrors.ustc.edu.cn/google-containers/&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">server = &quot;https://quay.io&quot;</span><br><span class=\"line\">[host.&quot;https://mirror.ccs.tencentyun.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"E4Q5q\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 container服务</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable containerd --now</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"527bcc5b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：<a href=\"https://github.com/kubernetes-sigs/cri-tools/releases\">https://github.com/kubernetes-sigs/cri-tools/releases</a></font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载</span><br><span class=\"line\">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.27.1/crictl-v1.27.1-linux-amd64.tar.gz</span><br><span class=\"line\"># 解压</span><br><span class=\"line\">tar -zxvf crictl-v1.27.1-linux-amd64.tar.gz -C /usr/local/bin</span><br><span class=\"line\"># 配置</span><br><span class=\"line\">cat &gt; /etc/crictl.yaml &lt;&lt; EOF</span><br><span class=\"line\">runtime-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">image-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">timeout: 0</span><br><span class=\"line\">debug: false</span><br><span class=\"line\">pull-image-on-create: false</span><br><span class=\"line\">disable-pull-on-run: false</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 验证</span><br><span class=\"line\">crictl version</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"UomHm\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl(建议)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载</span><br><span class=\"line\">wget https://github.com/containerd/nerdctl/releases/download/v1.5.0/nerdctl-1.5.0-linux-amd64.tar.gz</span><br><span class=\"line\"># 解压</span><br><span class=\"line\">tar -zxvf nerdctl-1.5.0-linux-amd64.tar.gz </span><br><span class=\"line\"># 复制文件</span><br><span class=\"line\">cp nerdctl /usr/bin/</span><br><span class=\"line\"># 配置 nerdctl 参数自动补齐</span><br><span class=\"line\">echo &#x27;source &lt;(nerdctl completion bash)&#x27; &gt;&gt; /etc/profile</span><br><span class=\"line\">source /etc/profile</span><br><span class=\"line\"># 验证</span><br><span class=\"line\">nerdctl -v</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"8dd46c64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装k8s软件包并配置</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y kubelet kubeadm kubectl </span><br><span class=\"line\"># 默认安装最新版本，如果需要安装老版本，使用如下命令</span><br><span class=\"line\">yum list kubeadm --showduplicates | sort -r</span><br><span class=\"line\">yum install -y kubelet-1.27.6 kubeadm-1.27.6 kubectl-1.27.6</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时并启动。</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crictl config runtime-endpoint unix:///run/containerd/containerd.sock</span><br><span class=\"line\">systemctl enable kubelet --now</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl命令补全</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profile </span><br><span class=\"line\">source ~/.bash_profile </span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6f342ec9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(kube-vip)</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font></p>\n</blockquote>\n<h2 id=\"88210852\"><font style=\"background-color:rgba(255, 255, 255, 0);\">准备工作</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们使用的vip是192.168.10.150</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">网卡名称是ens160</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip使用arp模式</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# mkdir -p /etc/kubernetes/manifests</span><br><span class=\"line\">[root@master1 ~]# export VIP=192.168.10.150</span><br><span class=\"line\">[root@master1 ~]# export INTERFACE=ens160</span><br><span class=\"line\">[root@master1 ~]# export KVVERSION=v0.8.2</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"ea49435f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成配置文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取 kube-vip 的 docker 镜像，并在 &#x2F;etc&#x2F;kuberentes&#x2F;manifests 中设置静态 pod 的 yaml 资源清单文件，这样 Kubernetes 就会自动在每个控制平面节点上部署 kube-vip 的 pod 了。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# alias kube-vip=&quot;ctr image pull ghcr.io/kube-vip/kube-vip:$KVVERSION; ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:$KVVERSION vip /kube-vip&quot;</span><br><span class=\"line\">[root@master1 ~]# kube-vip manifest pod \\</span><br><span class=\"line\">    --interface $INTERFACE \\</span><br><span class=\"line\">    --address $VIP \\</span><br><span class=\"line\">    --controlplane \\</span><br><span class=\"line\">    --services \\</span><br><span class=\"line\">    --arp \\</span><br><span class=\"line\">    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml</span><br><span class=\"line\"># 生成文件如下所示：</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  name: kube-vip</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - args:</span><br><span class=\"line\">    - manager</span><br><span class=\"line\">    env:</span><br><span class=\"line\">    - name: vip_arp</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: port</span><br><span class=\"line\">      value: &quot;6443&quot;</span><br><span class=\"line\">    - name: vip_nodename</span><br><span class=\"line\">      valueFrom:</span><br><span class=\"line\">        fieldRef:</span><br><span class=\"line\">          fieldPath: spec.nodeName</span><br><span class=\"line\">    - name: vip_interface</span><br><span class=\"line\">      value: ens160</span><br><span class=\"line\">    - name: vip_cidr</span><br><span class=\"line\">      value: &quot;32&quot;</span><br><span class=\"line\">    - name: dns_mode</span><br><span class=\"line\">      value: first</span><br><span class=\"line\">    - name: cp_enable</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: cp_namespace</span><br><span class=\"line\">      value: kube-system</span><br><span class=\"line\">    - name: svc_enable</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: svc_leasename</span><br><span class=\"line\">      value: plndr-svcs-lock</span><br><span class=\"line\">    - name: vip_leaderelection</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: vip_leasename</span><br><span class=\"line\">      value: plndr-cp-lock</span><br><span class=\"line\">    - name: vip_leaseduration</span><br><span class=\"line\">      value: &quot;5&quot;</span><br><span class=\"line\">    - name: vip_renewdeadline</span><br><span class=\"line\">      value: &quot;3&quot;</span><br><span class=\"line\">    - name: vip_retryperiod</span><br><span class=\"line\">      value: &quot;1&quot;</span><br><span class=\"line\">    - name: address</span><br><span class=\"line\">      value: 192.168.10.150</span><br><span class=\"line\">    - name: prometheus_server</span><br><span class=\"line\">      value: :2112</span><br><span class=\"line\">    image: ghcr.io/kube-vip/kube-vip:v0.8.2</span><br><span class=\"line\">    imagePullPolicy: IfNotPresent</span><br><span class=\"line\">    name: kube-vip</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">    securityContext:</span><br><span class=\"line\">      capabilities:</span><br><span class=\"line\">        add:</span><br><span class=\"line\">        - NET_ADMIN</span><br><span class=\"line\">        - NET_RAW</span><br><span class=\"line\">    volumeMounts:</span><br><span class=\"line\">    - mountPath: /etc/kubernetes/admin.conf</span><br><span class=\"line\">      name: kubeconfig</span><br><span class=\"line\">  hostAliases:</span><br><span class=\"line\">  - hostnames:</span><br><span class=\"line\">    - kubernetes</span><br><span class=\"line\">    ip: 127.0.0.1</span><br><span class=\"line\">  hostNetwork: true</span><br><span class=\"line\">  volumes:</span><br><span class=\"line\">  - hostPath:</span><br><span class=\"line\">      path: /etc/kubernetes/admin.conf</span><br><span class=\"line\">    name: kubeconfig</span><br><span class=\"line\">status: &#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当执行完kubeadm init后，kubelet会去加载这里面的yaml创建kube-vip容器。</font></p>\n<h2 id=\"cce0e451\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝至其他master节点</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">所有master节点都需要部署一个kube-vip，我们只需要将yaml文件存放在&#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;目录下，kubelet启动时会自动加载资源清单并创建pod。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master2:/etc/kubernetes/manifests/kube-vip.yaml</span><br><span class=\"line\">[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master3:/etc/kubernetes/manifests/kube-vip.yaml</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &#x27;s#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#&#x27; \\</span><br><span class=\"line\">          /etc/kubernetes/manifests/kube-vip.yaml</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"9845b730\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(keepalived+haproxy)</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有master节点执行</font></p>\n<h2 id=\"bbd75de9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">haproxy配置</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装haproxy</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# dnf -y install haproxy</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">编辑配置文件，所有master节点配置一样。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# vim /etc/haproxy/haproxy.cfg</span><br><span class=\"line\">global</span><br><span class=\"line\">    log         127.0.0.1 local2</span><br><span class=\"line\">    pidfile     /var/run/haproxy.pid</span><br><span class=\"line\">    maxconn     4000</span><br><span class=\"line\">defaults</span><br><span class=\"line\">    mode                    http</span><br><span class=\"line\">    log                     global</span><br><span class=\"line\">    option                  dontlognull</span><br><span class=\"line\">    option http-server-close</span><br><span class=\"line\">    option                  redispatch</span><br><span class=\"line\">    retries                 3</span><br><span class=\"line\">    timeout http-request    10s</span><br><span class=\"line\">    timeout queue           1m</span><br><span class=\"line\">    timeout connect         10s</span><br><span class=\"line\">    timeout client          1m</span><br><span class=\"line\">    timeout server          1m</span><br><span class=\"line\">    timeout http-keep-alive 10s</span><br><span class=\"line\">    timeout check           10s</span><br><span class=\"line\">    maxconn                 3000</span><br><span class=\"line\"></span><br><span class=\"line\">listen admin_stats</span><br><span class=\"line\">    bind    *:8888    #监听的ip端口号</span><br><span class=\"line\">    stats   enable</span><br><span class=\"line\">    stats   refresh 30s   #统计页面自动刷新时间</span><br><span class=\"line\">    stats   uri /admin    #访问的uri   ip:8080/admin</span><br><span class=\"line\">    stats   realm haproxy</span><br><span class=\"line\">    stats   auth admin:Miaohua123!  #认证用户名和密码</span><br><span class=\"line\">    stats   hide-version   #隐藏HAProxy的版本号</span><br><span class=\"line\">    stats   admin if TRUE   #管理界面，如果认证成功了，可通过webui管理节点  </span><br><span class=\"line\"></span><br><span class=\"line\">frontend  kubernetes-apiserver</span><br><span class=\"line\">    mode tcp</span><br><span class=\"line\">    bind *:9443</span><br><span class=\"line\">    # bind *:443 ssl # To be completed ....</span><br><span class=\"line\">    default_backend             kubernetes-apiserver</span><br><span class=\"line\"></span><br><span class=\"line\">backend kubernetes-apiserver</span><br><span class=\"line\">    mode        tcp</span><br><span class=\"line\">    balance     roundrobin</span><br><span class=\"line\"># k8s-apiservers backend</span><br><span class=\"line\">    server master1 192.168.10.151:6443 check</span><br><span class=\"line\">    server master2 192.168.10.152:6443 check</span><br><span class=\"line\">    server master3 192.168.10.153:6443 check</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# systemctl start haproxy.service </span><br><span class=\"line\">[root@master1 ~]# systemctl enable haproxy.service </span><br><span class=\"line\">[root@master1 ~]# ss -tnlp | grep haproxy</span><br><span class=\"line\">LISTEN    0         3000               0.0.0.0:8888             0.0.0.0:*        users:((&quot;haproxy&quot;,pid=7062,fd=6))                                              </span><br><span class=\"line\">LISTEN    0         3000               0.0.0.0:9443             0.0.0.0:*        users:((&quot;haproxy&quot;,pid=7062,fd=8)) </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fff6cb90\"><font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived配置</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装keepalived服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# dnf -y install keepalived</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加keepalived配置文件，master1节点内容如下。master2节点state改为BACKUP，priority改为99。master3节点state改为BACKUP，priority改为98。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# vim /etc/keepalived/keepalived.conf</span><br><span class=\"line\">global_defs &#123;</span><br><span class=\"line\">   script_user root</span><br><span class=\"line\">   enable_script_security</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vrrp_script chk_haproxy &#123;</span><br><span class=\"line\">    script &quot;/etc/keepalived/check.sh&quot;</span><br><span class=\"line\">    interval 1</span><br><span class=\"line\">    weight -2</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vrrp_instance VI_1 &#123;</span><br><span class=\"line\">  state MASTER # 实例类型</span><br><span class=\"line\">  interface ens33 # 网卡名称</span><br><span class=\"line\">  virtual_router_id 201</span><br><span class=\"line\">  priority 100 # 优先级</span><br><span class=\"line\">  advert_int 1</span><br><span class=\"line\"></span><br><span class=\"line\">  virtual_ipaddress &#123;</span><br><span class=\"line\">    192.168.10.150/32</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  authentication &#123;</span><br><span class=\"line\">    auth_type PASS</span><br><span class=\"line\">    auth_pass 1111</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  track_script &#123;</span><br><span class=\"line\">      chk_haproxy</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加服务检测脚本，如果containerd进程停止则进行故障切换</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# vim /etc/keepalived/check.sh</span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">if systemctl is-active --quiet containerd; then</span><br><span class=\"line\">    exit 0</span><br><span class=\"line\">else</span><br><span class=\"line\">    exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\">[root@master1 ~]# chmod +x /etc/keepalived/check.sh</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# systemctl start keepalived.service </span><br><span class=\"line\">[root@master1 ~]# systemctl enable keepalived</span><br><span class=\"line\">[root@master1 ~]# ip a | grep 192.168.10</span><br><span class=\"line\">    inet 192.168.10.151/24 brd 192.168.10.255 scope global ens33</span><br><span class=\"line\">    inet 192.168.10.150/32 scope global ens33</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"ede357c3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化master节点</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font></p>\n</blockquote>\n<h2 id=\"575087eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置集群参数</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm config print init-defaults &gt; kubeadm-conf.yaml</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# cat kubeadm-conf.yaml</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 192.168.10.151  # 指定当前master1节点IP</span><br><span class=\"line\">  bindPort: 6443 # 当前master1节点端口</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: unix:///run/containerd/containerd.sock # 使用containerd的socket地址</span><br><span class=\"line\">  imagePullPolicy: IfNotPresent</span><br><span class=\"line\">  name: master1 # 节点主机名</span><br><span class=\"line\">  taints: null</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  extraArgs:</span><br><span class=\"line\">    authorization-mode: Node,RBAC</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">  certSANs:  # 添加其他master节点的相关信息</span><br><span class=\"line\">  - 127.0.0.1</span><br><span class=\"line\">  - master1</span><br><span class=\"line\">  - master2</span><br><span class=\"line\">  - master3</span><br><span class=\"line\">  - 192.168.10.150</span><br><span class=\"line\">  - 192.168.10.151</span><br><span class=\"line\">  - 192.168.10.152</span><br><span class=\"line\">  - 192.168.10.153</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns: &#123;&#125;</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: 1.27.6 # k8s版本</span><br><span class=\"line\">controlPlaneEndpoint: 192.168.10.150:6443  # 设置控制平面Endpoint地址和端口</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12</span><br><span class=\"line\">  podSubnet: 10.244.0.0/16  # 指定 pod 子网</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br><span class=\"line\">---</span><br><span class=\"line\"># 指定kube-proxy基于ipvs模式</span><br><span class=\"line\">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class=\"line\">kind:  KubeProxyConfiguration</span><br><span class=\"line\">mode: ipvs</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class=\"line\">authentication:</span><br><span class=\"line\">  anonymous:</span><br><span class=\"line\">    enabled: false</span><br><span class=\"line\">  webhook:</span><br><span class=\"line\">    cacheTTL: 0s</span><br><span class=\"line\">    enabled: true</span><br><span class=\"line\">  x509:</span><br><span class=\"line\">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br><span class=\"line\">authorization:</span><br><span class=\"line\">  mode: Webhook</span><br><span class=\"line\">  webhook:</span><br><span class=\"line\">    cacheAuthorizedTTL: 0s</span><br><span class=\"line\">    cacheUnauthorizedTTL: 0s</span><br><span class=\"line\">cgroupDriver: systemd   # 指定cgroup驱动器为systemd模式</span><br><span class=\"line\">clusterDNS:</span><br><span class=\"line\">- 10.96.0.10</span><br><span class=\"line\">clusterDomain: cluster.local</span><br><span class=\"line\">cpuManagerReconcilePeriod: 0s</span><br><span class=\"line\">evictionPressureTransitionPeriod: 0s</span><br><span class=\"line\">fileCheckFrequency: 0s</span><br><span class=\"line\">healthzBindAddress: 127.0.0.1</span><br><span class=\"line\">healthzPort: 10248</span><br><span class=\"line\">httpCheckFrequency: 0s</span><br><span class=\"line\">imageMinimumGCAge: 0s</span><br><span class=\"line\">kind: KubeletConfiguration</span><br><span class=\"line\">logging: &#123;&#125;</span><br><span class=\"line\">memorySwap: &#123;&#125;</span><br><span class=\"line\">nodeStatusReportFrequency: 0s</span><br><span class=\"line\">nodeStatusUpdateFrequency: 0s</span><br><span class=\"line\">rotateCertificates: true</span><br><span class=\"line\">runtimeRequestTimeout: 0s</span><br><span class=\"line\">shutdownGracePeriod: 0s</span><br><span class=\"line\">shutdownGracePeriodCriticalPods: 0s</span><br><span class=\"line\">staticPodPath: /etc/kubernetes/manifests</span><br><span class=\"line\">streamingConnectionIdleTimeout: 0s</span><br><span class=\"line\">syncFrequency: 0s</span><br><span class=\"line\">volumeStatsAggPeriod: 0s</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"aec284f8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">将master1节点的kubeadm-conf.yaml复制到其他master节点，所有master节点都提前执行</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm config images pull --config kubeadm-conf.yaml</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.9</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.7-0</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.10.1</span><br><span class=\"line\"># CRI sandbox(pause) image默认使用registry.k8s.io/pause:3.6，由于网络原因无法拉取，直接改为阿里镜像标签即可。</span><br><span class=\"line\">[root@master1 ~]# nerdctl -n k8s.io tag registry.aliyuncs.com/google_containers/pause:3.9 registry.k8s.io/pause:3.6</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5fa25176\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群初始化</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm init --upload-certs --config=kubeadm-conf.yaml </span><br><span class=\"line\">Your Kubernetes control-plane has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">Alternatively, if you are the root user, you can run:</span><br><span class=\"line\"></span><br><span class=\"line\">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\</span><br><span class=\"line\">        --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7</span><br><span class=\"line\"></span><br><span class=\"line\">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class=\"line\">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class=\"line\">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class=\"line\"></span><br><span class=\"line\">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–upload-certs 标志用来将在所有控制平面实例之间的共享证书上传到集群。然后根据安装提示拷贝 kubeconfig 文件</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果配置问题导致集群初始化失败，可重置集群再次初始化：</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm reset</span><br><span class=\"line\">[root@master1 ~]# ipvsadm --clear</span><br><span class=\"line\">[root@master1 ~]# rm -rf $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c238630b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示配置环境变量</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# mkdir -p $HOME/.kube </span><br><span class=\"line\">[root@master1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config </span><br><span class=\"line\">[root@master1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\">[root@master1 ~]# echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class=\"line\">[root@tiaoban ~]# source ~/.bash_profile</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"154df728\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装flannel网络</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">下载资源清单配置文件</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubectl apply -f kube-flannel.yml</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果镜像不能正常拉取，所有节点需提前导入镜像，并修改yaml文件镜像拉取策略</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">imagePullPolicy: IfNotPresent</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像导入与查询</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr -n=k8s.io image import flannel.tar </span><br><span class=\"line\">unpacking docker.io/flannel/flannel:v0.22.1 (sha256:0b78f714708e837ae667c204cc918649ebcf2441b1d18ebde9a6564254932ee5)...done</span><br><span class=\"line\">[root@work3 ~]# crictl images</span><br><span class=\"line\">IMAGE                                                             TAG                 IMAGE ID            SIZE</span><br><span class=\"line\">docker.io/flannel/flannel-cni-plugin                              v1.2.0              a55d1bad692b7       8.32MB</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"76ce2493\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他节点加入集群</font></h1>\n---\n\n<h2 id=\"6e7aaa3e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">master节点加入集群</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">另外两个节点 master2 和 master3 都执行上面的 join 命令，上面的命令中的 –control-plane 就是通知 kubeadm join 创建一个新的控制平面，–certificate-key 会从集群中的 kubeadm-certs Secret 下载控制平面证书并使用给定的密钥进行解密。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 以master2节点为例</span><br><span class=\"line\">[root@master2 ~]#   kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">&gt;         --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\</span><br><span class=\"line\">&gt;         --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7</span><br><span class=\"line\"></span><br><span class=\"line\"># 然后根据提示配置环境变量</span><br><span class=\"line\">[root@master2 ~]# mkdir -p $HOME/.kube</span><br><span class=\"line\">[root@master2 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">[root@master2 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5eec51f2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">work节点加入集群</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"ade4c21a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装指定版本的kubelet</span><br><span class=\"line\">[root@tiaoban ~]# yum install -y kubectl-1.27.6</span><br><span class=\"line\"># 拷贝集群认证文件并配置环境变量</span><br><span class=\"line\">[root@tiaoban ~]# mkdir -p /etc/kubernetes</span><br><span class=\"line\">[root@tiaoban ~]# scp master1:/etc/kubernetes/admin.conf /etc/kubernetes/</span><br><span class=\"line\">[root@tiaoban ~]# echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class=\"line\">[root@tiaoban ~]# source ~/.bash_profile</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"fb2d3f91\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群验证</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在tiaoban节点执行</font></p>\n</blockquote>\n<h2 id=\"77b07675\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# kubectl get node</span><br><span class=\"line\">NAME      STATUS   ROLES           AGE    VERSION</span><br><span class=\"line\">master1   Ready    control-plane   18m     v1.27.6</span><br><span class=\"line\">master2   Ready    control-plane   12m7s   v1.27.6</span><br><span class=\"line\">master3   Ready    control-plane   13m6s   v1.27.6</span><br><span class=\"line\">work1     Ready    &lt;none&gt;          8m25s   v1.27.6</span><br><span class=\"line\">work2     Ready    &lt;none&gt;          8m21s   v1.27.6</span><br><span class=\"line\">work3     Ready    &lt;none&gt;          8m17s   v1.27.6</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"86a835fd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubectl get pod -A -o wide </span><br><span class=\"line\">NAMESPACE      NAME                              READY   STATUS    RESTARTS       AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-2nqk5             1/1     Running   0              134s   192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-c87jk             1/1     Running   0              134s   192.168.10.155   work2     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-hnps5             1/1     Running   0              134s   192.168.10.154   work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-jphgx             1/1     Running   0              154s   192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-lxpsp             1/1     Running   0              134s   192.168.10.156   work3     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-rx5kf             1/1     Running   0              134s   192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    coredns-7bdc4cb885-cjbbx          1/1     Running   0              14m    10.244.5.3       work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    coredns-7bdc4cb885-sgsns          1/1     Running   0              14m    10.244.5.2       work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    etcd-master1                      1/1     Running   1              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    etcd-master2                      1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    etcd-master3                      1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-apiserver-master1            1/1     Running   1              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-apiserver-master2            1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-apiserver-master3            1/1     Running   2 (154m ago)   14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-controller-manager-master1   1/1     Running   3 (40m ago)    14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-controller-manager-master2   1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-controller-manager-master3   1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-9jsq7                  1/1     Running   0              18m    192.168.10.155   work2     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-cpb5n                  1/1     Running   0              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-dm2rm                  1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-g26c4                  1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-jkhnj                  1/1     Running   0              18m    192.168.10.156   work3     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-x29d9                  1/1     Running   0              18m    192.168.10.154   work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-scheduler-master1            1/1     Running   3 (39m ago)    14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-scheduler-master2            1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-scheduler-master3            1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-vip-master1                  1/1     Running   0              1m     192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-vip-master2                  1/1     Running   1 (38m ago)    15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-vip-master3                  1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"da88e661\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群高可用测试</font></h1>\n---\n\n<h2 id=\"87c533b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件所在节点查看</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看VIP所在节点（当前位于master2）</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# ansible k8s-ha -m shell -a &quot;ip a | grep 192.168.10.150&quot;</span><br><span class=\"line\">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class=\"line\">work2 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master2 | CHANGED | rc=0 &gt;&gt;</span><br><span class=\"line\">    inet 192.168.10.150/32 scope global ens160</span><br><span class=\"line\">work1 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master1 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">work3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看其他组件所在节点（controller-manager位于master1，scheduler 位于master3）</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# kubectl get leases -n kube-system</span><br><span class=\"line\">NAME                                   HOLDER                                                                      AGE</span><br><span class=\"line\">apiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   175m</span><br><span class=\"line\">apiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h6m</span><br><span class=\"line\">apiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   176m</span><br><span class=\"line\">kube-controller-manager                master1_08adefe3-56c0-4c87-94b7-9adda172eaf3                                3h6m</span><br><span class=\"line\">kube-scheduler                         master3_59611769-b42d-459a-aa45-6ccf535d793f                                3h6m</span><br><span class=\"line\">plndr-cp-lock                          master3                                                                     176m</span><br><span class=\"line\">plndr-svcs-lock                        master1                                                                     176m</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建deployment和svc，模拟生产业务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 新建资源清单</span><br><span class=\"line\">[root@tiaoban k8s]# cat &gt; demo.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: myapp</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: myapp</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: myapp</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: myapp</span><br><span class=\"line\">        image: ikubernetes/myapp:v1</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">          name: http</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: myapp-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app: myapp</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 80</span><br><span class=\"line\">    targetPort:  80</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建资源</span><br><span class=\"line\">[root@tiaoban k8s]# kubectl apply -f demo.yaml </span><br><span class=\"line\">deployment.apps/myapp created</span><br><span class=\"line\">service/myapp-svc created</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看资源信息</span><br><span class=\"line\">[root@tiaoban k8s]# kubectl get pod -o wide</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE    IP           NODE    NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">myapp-64b6b8fbcd-jm5q2   1/1     Running   0          101s   10.244.3.2   work3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">myapp-64b6b8fbcd-qqjsd   1/1     Running   0          101s   10.244.4.2   work2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">myapp-64b6b8fbcd-tsmwx   1/1     Running   0          101s   10.244.5.6   work1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@tiaoban k8s]# kubectl get svc</span><br><span class=\"line\">NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        3h17m</span><br><span class=\"line\">myapp-svc    NodePort    10.110.186.236   &lt;none&gt;        80:30380/TCP   5m6s</span><br><span class=\"line\"></span><br><span class=\"line\"># 访问测试</span><br><span class=\"line\">[root@tiaoban k8s]# curl 192.168.10.150:30380</span><br><span class=\"line\">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"59ab63b0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">宕机一台控制节点</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">将VIP所在的master2节点关机，模拟宕机</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master3 ~]# init 0</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">各组件信息查看</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># VIP位于master1</span><br><span class=\"line\">[root@tiaoban k8s]# ansible k8s-ha -m shell -a &quot;ip a | grep 192.168.10.150&quot;</span><br><span class=\"line\">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class=\"line\">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class=\"line\">master2 | UNREACHABLE! =&gt; &#123;</span><br><span class=\"line\">    &quot;changed&quot;: false,</span><br><span class=\"line\">    &quot;msg&quot;: &quot;Failed to connect to the host via ssh: ssh: connect to host master2 port 22: Connection refused&quot;,</span><br><span class=\"line\">    &quot;unreachable&quot;: true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">work2 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">work3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">work1 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master1 | CHANGED | rc=0 &gt;&gt;</span><br><span class=\"line\">    inet 192.168.10.150/32 scope global ens160</span><br><span class=\"line\"></span><br><span class=\"line\"># controller-manager位于master1 scheduler位于master3</span><br><span class=\"line\">[root@tiaoban k8s]# kubectl get leases -n kube-system</span><br><span class=\"line\">NAME                                   HOLDER                                                                      AGE</span><br><span class=\"line\">apiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   3h19m</span><br><span class=\"line\">apiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h30m</span><br><span class=\"line\">apiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   3h20m</span><br><span class=\"line\">kube-controller-manager                master1_fd5b1081-93e2-4be8-8eb8-8719a70b606a                                3h29m</span><br><span class=\"line\">kube-scheduler                         master1_2b4c98a1-8d8c-4bb3-a3c4-58793022180a                                3h29m</span><br><span class=\"line\">plndr-cp-lock                          master3                                                                     3h20m</span><br><span class=\"line\">plndr-svcs-lock                        master1                                                                     3h20m</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">集群节点信息查看</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban k8s]# kubectl get node</span><br><span class=\"line\">NAME      STATUS     ROLES           AGE     VERSION</span><br><span class=\"line\">master1   Ready      control-plane   3h31m   v1.27.6</span><br><span class=\"line\">master2   NotReady   control-plane   3h22m   v1.27.6</span><br><span class=\"line\">master3   Ready      control-plane   3h21m   v1.27.6</span><br><span class=\"line\">work1     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br><span class=\"line\">work2     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br><span class=\"line\">work3     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">业务访问测试</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban k8s]# curl 192.168.10.150:30380</span><br><span class=\"line\">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">结论：当有一个master节点宕机时，VIP会发生漂移，集群各项功能不受影响。</font></p>\n","excerpt":"","more":"<h1 id=\"f1b611b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构方案</font></h1>\n---\n\n<h2 id=\"6bdfa137\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用架构说明</font></h2>\n---\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">核心组件</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用模式</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用实现方式</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主备</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">leader election</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">集群</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm</font></td>\n</tr>\n</tbody></table>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">apiserver 通过haproxy+keepalived实现高可用，当某个节点故障时触发keepalived vip 转移；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">controller-manager k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个controller-manager组件运行；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">scheduler k8s内部通过选举方式产生领导者(由–leader-elect 选型控制，默认为true)，同一时刻集群内只有一个scheduler组件运行；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 通过运行kubeadm方式自动创建集群来实现高可用，部署的节点数为奇数。如果剩余可用节点数量超过半数，集群可以几乎没有影响的正常工作(3节点方式最多容忍一台机器宕机)</font></li>\n</ul>\n<h2 id=\"c267defc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HAProxy+</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Keepalived方案</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在以前我们在私有环境下创建 Kubernetes 集群时，我们需要准备一个硬件&#x2F;软件的负载均衡器来创建多控制面集群，更多的情况下我们会选择使用 HAProxy + Keepalived 来实现这个功能。一般情况下我们会在k8s集群外创建2个负载均衡器的虚拟机，然后分配一个 VIP，然后使用 VIP 为负载均衡器提供服务，通过 VIP 将流量重定向到后端的某个 Kubernetes master节点上。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">或者在所有Kubernetes master节点上部署HAProxy + Keepalived服务，实现故障切换。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940757-19c0d378-d69c-4d9d-bea9-19b988fceb79.jpeg\"></p>\n<h2 id=\"2540cb93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip方案</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">除了使用传统方式外，我们也可以通过kube-vip实现高可用。kube-vip 可以通过静态 pod 运行在控制平面节点上，这些 pod 通过ARP 对话来识别每个节点上的其他主机，所以需要在 hosts 文件中设置每个节点的 IP 地址，我们可以选择 BGP 或 ARP 来设置负载平衡器，这与 Metal LB 比较类似。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的 Leader，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738317940896-936a1802-8255-4ae3-b742-b192c9df044c.jpeg\"></p>\n<h1 id=\"b7a8ae3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 架构</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 有许多功能设计选择提供高可用性或网络功能，作为VIP&#x2F;负载平衡解决方案的一部分。</font></p>\n<h2 id=\"cluster\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Cluster</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip 建立了一个多节点或多模块的集群来提供高可用性。在 ARP 模式下，会选出一个领导者，这个节点将继承虚拟 IP 并成为集群内负载均衡的领导者，而在 BGP 模式下，所有节点都会通知 VIP 地址。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当使用 ARP 或 layer2 时，它将使用领导者选举，当然也可以使用 raft 集群技术，但这种方法在很大程度上已经被领导者选举所取代，特别是在集群中运行时。</font></p>\n<h2 id=\"15c8be58\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">集群中的领导者将分配 vip，并将其绑定到配置中声明的选定接口上。当领导者改变时，它将首先撤销 vip，或者在失败的情况下，vip 将直接由下一个当选的领导者分配。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当 vip 从一个主机移动到另一个主机时，任何使用 vip 的主机将保留以前的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip &lt;-&gt; MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">地址映射，直到 ARP 过期（通常是30秒）并检索到一个新的</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">vip &lt;-&gt; MAC</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><font style=\"background-color:rgba(255, 255, 255, 0);\">映射，这可以通过使用无偿的 ARP 广播来优化。</font></p>\n<h2 id=\"arp\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ARP</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip可以被配置为广播一个无偿的 arp（可选），通常会立即通知所有本地主机 vip &lt;-&gt; MAC 地址映射已经改变。当 ARP 广播被接收时，故障转移通常在几秒钟内完成。</font></p>\n<h1 id=\"47b520ed\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群规划</font></h1>\n---\n\n<h2 id=\"2d507904\"><font style=\"background-color:rgba(255, 255, 255, 0);\">软件版本</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">操作系统版本：Rocky Linux release 8.8</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">内核版本：4.18.0-477.21.1.el8_8.x86_64</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes版本：1.27.6</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">containerd版本：1.6.22</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip版本：0.6.0</font></p>\n<h2 id=\"c5b040c2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">主机IP规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">ip</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机配置</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">用途</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.151</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.152</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">master3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.153</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">control-plane</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.154</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.155</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">work3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.156</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">VIP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.150</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟IP在控制节点上浮动</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">2C2G</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端，连接管理K8S集群</font> |\n\n\n<h1 id=\"60fb03bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础环境与软件准备</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有节点都执行</font></p>\n</blockquote>\n<h2 id=\"d77c61bf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改主机名与hosts文件</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hostnamectl set-hostname master1</span><br><span class=\"line\">cat &gt; /etc/hosts &lt;&lt; EOF </span><br><span class=\"line\">192.168.10.151   master1</span><br><span class=\"line\">192.168.10.152   master2</span><br><span class=\"line\">192.168.10.153   master3</span><br><span class=\"line\">192.168.10.154   work1</span><br><span class=\"line\">192.168.10.155   work2</span><br><span class=\"line\">192.168.10.156   work3</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"a0b09c93\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证mac地址uuid</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">保证各节点mac和uuid唯一，防止克隆主机出现网络异常问题</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat /sys/class/net/ens33/address</span><br><span class=\"line\">cat /sys/class/dmi/id/product_uuid </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"16c50660\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置时间同步</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf -y install chrony</span><br><span class=\"line\">systemctl  start chronyd</span><br><span class=\"line\">systemctl  enable chronyd</span><br><span class=\"line\">timedatectl set-timezone Asia/Shanghai</span><br><span class=\"line\">chronyc sourcestats -v </span><br><span class=\"line\">date</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">也可以在内网环境其中一台主机启动chronyd服务，其他主机配置chronyd服务地址</font></p>\n</blockquote>\n<h2 id=\"1663c88c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭防火墙和selinux</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl stop firewalld.service</span><br><span class=\"line\">systemctl  disable firewalld</span><br><span class=\"line\">setenforce  0</span><br><span class=\"line\">sed  -i &#x27;s/enforcing/disabled/g&#x27; /etc/selinux/config</span><br><span class=\"line\">grep  SELINUX= /etc/selinux/config </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7c54c7f3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭swap分区</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">swapoff -a </span><br><span class=\"line\">sed -i &#x27;/ swap / s/^(.*)$/#\\1/g&#x27; /etc/fstab  </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"825e7bd1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改内核相关参数</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">最大限度使用物理内存，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">bridge 设备在二层转发时也去调用 iptables 配置的三层规则，开启数据包转发。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF</span><br><span class=\"line\">vm.swappiness = 0</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">net.ipv4.ip_forward = 1</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">sysctl -p /etc/sysctl.d/kubernetes.conf</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"927d0791\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置yum源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">配置阿里源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF </span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果阿里源异常，可切换配置清华源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF </span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.tuna.tsinghua.edu.cn/kubernetes/yum/repos/kubernetes-el7-$basearch</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5e11d2ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置ipvs模块功能</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf -y install ipset ipvsadm </span><br><span class=\"line\"></span><br><span class=\"line\">cat &gt; /etc/sysctl.d/ipvs.modules &lt;&lt;EOF </span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">modprobe -- ip_vs</span><br><span class=\"line\">modprobe -- ip_vs_rr</span><br><span class=\"line\">modprobe -- ip_vs_wrr</span><br><span class=\"line\">modprobe -- ip_vs_sh</span><br><span class=\"line\">modprobe -- nf_conntrack</span><br><span class=\"line\">modprobe -- br_netfilter</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">chmod 755 /etc/sysctl.d/ipvs.modules &amp;&amp; bash </span><br><span class=\"line\"></span><br><span class=\"line\">/etc/sysctl.d/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack </span><br><span class=\"line\">ip_vs_sh               20480  0</span><br><span class=\"line\">ip_vs_wrr              16384  0</span><br><span class=\"line\">ip_vs_rr               16384  0</span><br><span class=\"line\">ip_vs                 180224  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class=\"line\">nf_conntrack_netlink    53248  0</span><br><span class=\"line\">nf_conntrack          176128  5 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE,ip_vs</span><br><span class=\"line\">nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs</span><br><span class=\"line\">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class=\"line\">nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables</span><br><span class=\"line\">libcrc32c              16384  5 nf_conntrack,nf_nat,nf_tables,xfs,ip_vs</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加开机自动加载模块</span><br><span class=\"line\">echo &quot;/etc/sysctl.d/ipvs.modules&quot; &gt;&gt; /etc/rc.local</span><br><span class=\"line\">chmod +x /etc/rc.local</span><br><span class=\"line\"># 启用网桥过滤器模块</span><br><span class=\"line\">echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</span><br><span class=\"line\">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"680cf1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装命令自动补全工具</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnf -y install bash-completion </span><br><span class=\"line\">source /etc/profile.d/bash_completion.sh </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"752286ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">container</font><font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h2>\n---\n\n<h3 id=\"56f5cf9c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装依赖</span><br><span class=\"line\">dnf install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加yum源</span><br><span class=\"line\">dnf config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看可安装的containerd版本</span><br><span class=\"line\">dnf list containerd.io.x86_64 --showduplicates | sort -r</span><br><span class=\"line\"></span><br><span class=\"line\"># 安装1.6.22版本containerd</span><br><span class=\"line\">dnf install -y containerd.io-1.6.22-3.1.el8.x86_64</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看版本信息</span><br><span class=\"line\">containerd -v</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"da6011d1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置container</font></h3>\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font>**\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">containerd config default &gt; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font></strong></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。把sandbox_image &#x3D; “k8s.gcr.io&#x2F;pause:3.6”修改为：sandbox_image&#x3D;“registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.6”</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &#x27;s/sandbox_image\\ =.*/sandbox_image\\ =\\ &quot;registry.aliyuncs.com\\/google_containers\\/pause:3.6&quot;/g&#x27; /etc/containerd/config.toml|grep sandbox_image</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">配置cgroup驱动器</font></strong></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 kubelet 和容器运行时需使用相同的 cgroup 驱动并且采用相同的配置。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &#x27;s/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g&#x27; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速地址</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改container配置，指定registry配置从文件读取</span><br><span class=\"line\">vim /etc/containerd/config.toml</span><br><span class=\"line\">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]</span><br><span class=\"line\">      config_path = &quot;/etc/containerd/certs.d&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建配置文件目录</span><br><span class=\"line\">mkdir -p /etc/containerd/certs.d/docker.io</span><br><span class=\"line\"></span><br><span class=\"line\"># 新增加速配置</span><br><span class=\"line\">cat &gt; /etc/containerd/certs.d/docker.io/hosts.toml &lt;&lt; EOF</span><br><span class=\"line\">server = &quot;https://docker.io&quot;</span><br><span class=\"line\">[host.&quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">server = &quot;https://k8s.gcr.io&quot;</span><br><span class=\"line\">[host.&quot;https://gcr.mirrors.ustc.edu.cn/google-containers/&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">server = &quot;https://quay.io&quot;</span><br><span class=\"line\">[host.&quot;https://mirror.ccs.tencentyun.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"E4Q5q\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 container服务</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl enable containerd --now</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"527bcc5b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：<a href=\"https://github.com/kubernetes-sigs/cri-tools/releases\">https://github.com/kubernetes-sigs/cri-tools/releases</a></font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载</span><br><span class=\"line\">wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.27.1/crictl-v1.27.1-linux-amd64.tar.gz</span><br><span class=\"line\"># 解压</span><br><span class=\"line\">tar -zxvf crictl-v1.27.1-linux-amd64.tar.gz -C /usr/local/bin</span><br><span class=\"line\"># 配置</span><br><span class=\"line\">cat &gt; /etc/crictl.yaml &lt;&lt; EOF</span><br><span class=\"line\">runtime-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">image-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">timeout: 0</span><br><span class=\"line\">debug: false</span><br><span class=\"line\">pull-image-on-create: false</span><br><span class=\"line\">disable-pull-on-run: false</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 验证</span><br><span class=\"line\">crictl version</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"UomHm\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl(建议)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载</span><br><span class=\"line\">wget https://github.com/containerd/nerdctl/releases/download/v1.5.0/nerdctl-1.5.0-linux-amd64.tar.gz</span><br><span class=\"line\"># 解压</span><br><span class=\"line\">tar -zxvf nerdctl-1.5.0-linux-amd64.tar.gz </span><br><span class=\"line\"># 复制文件</span><br><span class=\"line\">cp nerdctl /usr/bin/</span><br><span class=\"line\"># 配置 nerdctl 参数自动补齐</span><br><span class=\"line\">echo &#x27;source &lt;(nerdctl completion bash)&#x27; &gt;&gt; /etc/profile</span><br><span class=\"line\">source /etc/profile</span><br><span class=\"line\"># 验证</span><br><span class=\"line\">nerdctl -v</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"8dd46c64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装k8s软件包并配置</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y kubelet kubeadm kubectl </span><br><span class=\"line\"># 默认安装最新版本，如果需要安装老版本，使用如下命令</span><br><span class=\"line\">yum list kubeadm --showduplicates | sort -r</span><br><span class=\"line\">yum install -y kubelet-1.27.6 kubeadm-1.27.6 kubectl-1.27.6</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时并启动。</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crictl config runtime-endpoint unix:///run/containerd/containerd.sock</span><br><span class=\"line\">systemctl enable kubelet --now</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl命令补全</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profile </span><br><span class=\"line\">source ~/.bash_profile </span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6f342ec9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(kube-vip)</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font></p>\n</blockquote>\n<h2 id=\"88210852\"><font style=\"background-color:rgba(255, 255, 255, 0);\">准备工作</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们使用的vip是192.168.10.150</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">网卡名称是ens160</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-vip使用arp模式</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# mkdir -p /etc/kubernetes/manifests</span><br><span class=\"line\">[root@master1 ~]# export VIP=192.168.10.150</span><br><span class=\"line\">[root@master1 ~]# export INTERFACE=ens160</span><br><span class=\"line\">[root@master1 ~]# export KVVERSION=v0.8.2</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"ea49435f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成配置文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取 kube-vip 的 docker 镜像，并在 &#x2F;etc&#x2F;kuberentes&#x2F;manifests 中设置静态 pod 的 yaml 资源清单文件，这样 Kubernetes 就会自动在每个控制平面节点上部署 kube-vip 的 pod 了。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# alias kube-vip=&quot;ctr image pull ghcr.io/kube-vip/kube-vip:$KVVERSION; ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:$KVVERSION vip /kube-vip&quot;</span><br><span class=\"line\">[root@master1 ~]# kube-vip manifest pod \\</span><br><span class=\"line\">    --interface $INTERFACE \\</span><br><span class=\"line\">    --address $VIP \\</span><br><span class=\"line\">    --controlplane \\</span><br><span class=\"line\">    --services \\</span><br><span class=\"line\">    --arp \\</span><br><span class=\"line\">    --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml</span><br><span class=\"line\"># 生成文件如下所示：</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  name: kube-vip</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - args:</span><br><span class=\"line\">    - manager</span><br><span class=\"line\">    env:</span><br><span class=\"line\">    - name: vip_arp</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: port</span><br><span class=\"line\">      value: &quot;6443&quot;</span><br><span class=\"line\">    - name: vip_nodename</span><br><span class=\"line\">      valueFrom:</span><br><span class=\"line\">        fieldRef:</span><br><span class=\"line\">          fieldPath: spec.nodeName</span><br><span class=\"line\">    - name: vip_interface</span><br><span class=\"line\">      value: ens160</span><br><span class=\"line\">    - name: vip_cidr</span><br><span class=\"line\">      value: &quot;32&quot;</span><br><span class=\"line\">    - name: dns_mode</span><br><span class=\"line\">      value: first</span><br><span class=\"line\">    - name: cp_enable</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: cp_namespace</span><br><span class=\"line\">      value: kube-system</span><br><span class=\"line\">    - name: svc_enable</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: svc_leasename</span><br><span class=\"line\">      value: plndr-svcs-lock</span><br><span class=\"line\">    - name: vip_leaderelection</span><br><span class=\"line\">      value: &quot;true&quot;</span><br><span class=\"line\">    - name: vip_leasename</span><br><span class=\"line\">      value: plndr-cp-lock</span><br><span class=\"line\">    - name: vip_leaseduration</span><br><span class=\"line\">      value: &quot;5&quot;</span><br><span class=\"line\">    - name: vip_renewdeadline</span><br><span class=\"line\">      value: &quot;3&quot;</span><br><span class=\"line\">    - name: vip_retryperiod</span><br><span class=\"line\">      value: &quot;1&quot;</span><br><span class=\"line\">    - name: address</span><br><span class=\"line\">      value: 192.168.10.150</span><br><span class=\"line\">    - name: prometheus_server</span><br><span class=\"line\">      value: :2112</span><br><span class=\"line\">    image: ghcr.io/kube-vip/kube-vip:v0.8.2</span><br><span class=\"line\">    imagePullPolicy: IfNotPresent</span><br><span class=\"line\">    name: kube-vip</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">    securityContext:</span><br><span class=\"line\">      capabilities:</span><br><span class=\"line\">        add:</span><br><span class=\"line\">        - NET_ADMIN</span><br><span class=\"line\">        - NET_RAW</span><br><span class=\"line\">    volumeMounts:</span><br><span class=\"line\">    - mountPath: /etc/kubernetes/admin.conf</span><br><span class=\"line\">      name: kubeconfig</span><br><span class=\"line\">  hostAliases:</span><br><span class=\"line\">  - hostnames:</span><br><span class=\"line\">    - kubernetes</span><br><span class=\"line\">    ip: 127.0.0.1</span><br><span class=\"line\">  hostNetwork: true</span><br><span class=\"line\">  volumes:</span><br><span class=\"line\">  - hostPath:</span><br><span class=\"line\">      path: /etc/kubernetes/admin.conf</span><br><span class=\"line\">    name: kubeconfig</span><br><span class=\"line\">status: &#123;&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当执行完kubeadm init后，kubelet会去加载这里面的yaml创建kube-vip容器。</font></p>\n<h2 id=\"cce0e451\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝至其他master节点</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">所有master节点都需要部署一个kube-vip，我们只需要将yaml文件存放在&#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;目录下，kubelet启动时会自动加载资源清单并创建pod。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master2:/etc/kubernetes/manifests/kube-vip.yaml</span><br><span class=\"line\">[root@master1 ~]# scp /etc/kubernetes/manifests/kube-vip.yaml master3:/etc/kubernetes/manifests/kube-vip.yaml</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &#x27;s#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#&#x27; \\</span><br><span class=\"line\">          /etc/kubernetes/manifests/kube-vip.yaml</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"9845b730\"><font style=\"background-color:rgba(255, 255, 255, 0);\">VIP配置(keepalived+haproxy)</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在所有master节点执行</font></p>\n<h2 id=\"bbd75de9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">haproxy配置</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装haproxy</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# dnf -y install haproxy</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">编辑配置文件，所有master节点配置一样。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# vim /etc/haproxy/haproxy.cfg</span><br><span class=\"line\">global</span><br><span class=\"line\">    log         127.0.0.1 local2</span><br><span class=\"line\">    pidfile     /var/run/haproxy.pid</span><br><span class=\"line\">    maxconn     4000</span><br><span class=\"line\">defaults</span><br><span class=\"line\">    mode                    http</span><br><span class=\"line\">    log                     global</span><br><span class=\"line\">    option                  dontlognull</span><br><span class=\"line\">    option http-server-close</span><br><span class=\"line\">    option                  redispatch</span><br><span class=\"line\">    retries                 3</span><br><span class=\"line\">    timeout http-request    10s</span><br><span class=\"line\">    timeout queue           1m</span><br><span class=\"line\">    timeout connect         10s</span><br><span class=\"line\">    timeout client          1m</span><br><span class=\"line\">    timeout server          1m</span><br><span class=\"line\">    timeout http-keep-alive 10s</span><br><span class=\"line\">    timeout check           10s</span><br><span class=\"line\">    maxconn                 3000</span><br><span class=\"line\"></span><br><span class=\"line\">listen admin_stats</span><br><span class=\"line\">    bind    *:8888    #监听的ip端口号</span><br><span class=\"line\">    stats   enable</span><br><span class=\"line\">    stats   refresh 30s   #统计页面自动刷新时间</span><br><span class=\"line\">    stats   uri /admin    #访问的uri   ip:8080/admin</span><br><span class=\"line\">    stats   realm haproxy</span><br><span class=\"line\">    stats   auth admin:Miaohua123!  #认证用户名和密码</span><br><span class=\"line\">    stats   hide-version   #隐藏HAProxy的版本号</span><br><span class=\"line\">    stats   admin if TRUE   #管理界面，如果认证成功了，可通过webui管理节点  </span><br><span class=\"line\"></span><br><span class=\"line\">frontend  kubernetes-apiserver</span><br><span class=\"line\">    mode tcp</span><br><span class=\"line\">    bind *:9443</span><br><span class=\"line\">    # bind *:443 ssl # To be completed ....</span><br><span class=\"line\">    default_backend             kubernetes-apiserver</span><br><span class=\"line\"></span><br><span class=\"line\">backend kubernetes-apiserver</span><br><span class=\"line\">    mode        tcp</span><br><span class=\"line\">    balance     roundrobin</span><br><span class=\"line\"># k8s-apiservers backend</span><br><span class=\"line\">    server master1 192.168.10.151:6443 check</span><br><span class=\"line\">    server master2 192.168.10.152:6443 check</span><br><span class=\"line\">    server master3 192.168.10.153:6443 check</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# systemctl start haproxy.service </span><br><span class=\"line\">[root@master1 ~]# systemctl enable haproxy.service </span><br><span class=\"line\">[root@master1 ~]# ss -tnlp | grep haproxy</span><br><span class=\"line\">LISTEN    0         3000               0.0.0.0:8888             0.0.0.0:*        users:((&quot;haproxy&quot;,pid=7062,fd=6))                                              </span><br><span class=\"line\">LISTEN    0         3000               0.0.0.0:9443             0.0.0.0:*        users:((&quot;haproxy&quot;,pid=7062,fd=8)) </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fff6cb90\"><font style=\"background-color:rgba(255, 255, 255, 0);\">keepalived配置</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装keepalived服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# dnf -y install keepalived</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加keepalived配置文件，master1节点内容如下。master2节点state改为BACKUP，priority改为99。master3节点state改为BACKUP，priority改为98。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# vim /etc/keepalived/keepalived.conf</span><br><span class=\"line\">global_defs &#123;</span><br><span class=\"line\">   script_user root</span><br><span class=\"line\">   enable_script_security</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vrrp_script chk_haproxy &#123;</span><br><span class=\"line\">    script &quot;/etc/keepalived/check.sh&quot;</span><br><span class=\"line\">    interval 1</span><br><span class=\"line\">    weight -2</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vrrp_instance VI_1 &#123;</span><br><span class=\"line\">  state MASTER # 实例类型</span><br><span class=\"line\">  interface ens33 # 网卡名称</span><br><span class=\"line\">  virtual_router_id 201</span><br><span class=\"line\">  priority 100 # 优先级</span><br><span class=\"line\">  advert_int 1</span><br><span class=\"line\"></span><br><span class=\"line\">  virtual_ipaddress &#123;</span><br><span class=\"line\">    192.168.10.150/32</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  authentication &#123;</span><br><span class=\"line\">    auth_type PASS</span><br><span class=\"line\">    auth_pass 1111</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  track_script &#123;</span><br><span class=\"line\">      chk_haproxy</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加服务检测脚本，如果containerd进程停止则进行故障切换</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# vim /etc/keepalived/check.sh</span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">if systemctl is-active --quiet containerd; then</span><br><span class=\"line\">    exit 0</span><br><span class=\"line\">else</span><br><span class=\"line\">    exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\">[root@master1 ~]# chmod +x /etc/keepalived/check.sh</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# systemctl start keepalived.service </span><br><span class=\"line\">[root@master1 ~]# systemctl enable keepalived</span><br><span class=\"line\">[root@master1 ~]# ip a | grep 192.168.10</span><br><span class=\"line\">    inet 192.168.10.151/24 brd 192.168.10.255 scope global ens33</span><br><span class=\"line\">    inet 192.168.10.150/32 scope global ens33</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"ede357c3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化master节点</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master1节点执行</font></p>\n</blockquote>\n<h2 id=\"575087eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置集群参数</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm config print init-defaults &gt; kubeadm-conf.yaml</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# cat kubeadm-conf.yaml</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 192.168.10.151  # 指定当前master1节点IP</span><br><span class=\"line\">  bindPort: 6443 # 当前master1节点端口</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: unix:///run/containerd/containerd.sock # 使用containerd的socket地址</span><br><span class=\"line\">  imagePullPolicy: IfNotPresent</span><br><span class=\"line\">  name: master1 # 节点主机名</span><br><span class=\"line\">  taints: null</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  extraArgs:</span><br><span class=\"line\">    authorization-mode: Node,RBAC</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">  certSANs:  # 添加其他master节点的相关信息</span><br><span class=\"line\">  - 127.0.0.1</span><br><span class=\"line\">  - master1</span><br><span class=\"line\">  - master2</span><br><span class=\"line\">  - master3</span><br><span class=\"line\">  - 192.168.10.150</span><br><span class=\"line\">  - 192.168.10.151</span><br><span class=\"line\">  - 192.168.10.152</span><br><span class=\"line\">  - 192.168.10.153</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns: &#123;&#125;</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers # 阿里云镜像</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: 1.27.6 # k8s版本</span><br><span class=\"line\">controlPlaneEndpoint: 192.168.10.150:6443  # 设置控制平面Endpoint地址和端口</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12</span><br><span class=\"line\">  podSubnet: 10.244.0.0/16  # 指定 pod 子网</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br><span class=\"line\">---</span><br><span class=\"line\"># 指定kube-proxy基于ipvs模式</span><br><span class=\"line\">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class=\"line\">kind:  KubeProxyConfiguration</span><br><span class=\"line\">mode: ipvs</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class=\"line\">authentication:</span><br><span class=\"line\">  anonymous:</span><br><span class=\"line\">    enabled: false</span><br><span class=\"line\">  webhook:</span><br><span class=\"line\">    cacheTTL: 0s</span><br><span class=\"line\">    enabled: true</span><br><span class=\"line\">  x509:</span><br><span class=\"line\">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br><span class=\"line\">authorization:</span><br><span class=\"line\">  mode: Webhook</span><br><span class=\"line\">  webhook:</span><br><span class=\"line\">    cacheAuthorizedTTL: 0s</span><br><span class=\"line\">    cacheUnauthorizedTTL: 0s</span><br><span class=\"line\">cgroupDriver: systemd   # 指定cgroup驱动器为systemd模式</span><br><span class=\"line\">clusterDNS:</span><br><span class=\"line\">- 10.96.0.10</span><br><span class=\"line\">clusterDomain: cluster.local</span><br><span class=\"line\">cpuManagerReconcilePeriod: 0s</span><br><span class=\"line\">evictionPressureTransitionPeriod: 0s</span><br><span class=\"line\">fileCheckFrequency: 0s</span><br><span class=\"line\">healthzBindAddress: 127.0.0.1</span><br><span class=\"line\">healthzPort: 10248</span><br><span class=\"line\">httpCheckFrequency: 0s</span><br><span class=\"line\">imageMinimumGCAge: 0s</span><br><span class=\"line\">kind: KubeletConfiguration</span><br><span class=\"line\">logging: &#123;&#125;</span><br><span class=\"line\">memorySwap: &#123;&#125;</span><br><span class=\"line\">nodeStatusReportFrequency: 0s</span><br><span class=\"line\">nodeStatusUpdateFrequency: 0s</span><br><span class=\"line\">rotateCertificates: true</span><br><span class=\"line\">runtimeRequestTimeout: 0s</span><br><span class=\"line\">shutdownGracePeriod: 0s</span><br><span class=\"line\">shutdownGracePeriodCriticalPods: 0s</span><br><span class=\"line\">staticPodPath: /etc/kubernetes/manifests</span><br><span class=\"line\">streamingConnectionIdleTimeout: 0s</span><br><span class=\"line\">syncFrequency: 0s</span><br><span class=\"line\">volumeStatsAggPeriod: 0s</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"aec284f8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">将master1节点的kubeadm-conf.yaml复制到其他master节点，所有master节点都提前执行</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm config images pull --config kubeadm-conf.yaml</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.27.6</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/pause:3.9</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/etcd:3.5.7-0</span><br><span class=\"line\">[config/images] Pulled registry.aliyuncs.com/google_containers/coredns:v1.10.1</span><br><span class=\"line\"># CRI sandbox(pause) image默认使用registry.k8s.io/pause:3.6，由于网络原因无法拉取，直接改为阿里镜像标签即可。</span><br><span class=\"line\">[root@master1 ~]# nerdctl -n k8s.io tag registry.aliyuncs.com/google_containers/pause:3.9 registry.k8s.io/pause:3.6</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5fa25176\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群初始化</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm init --upload-certs --config=kubeadm-conf.yaml </span><br><span class=\"line\">Your Kubernetes control-plane has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">Alternatively, if you are the root user, you can run:</span><br><span class=\"line\"></span><br><span class=\"line\">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\</span><br><span class=\"line\">        --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7</span><br><span class=\"line\"></span><br><span class=\"line\">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class=\"line\">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class=\"line\">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class=\"line\"></span><br><span class=\"line\">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–upload-certs 标志用来将在所有控制平面实例之间的共享证书上传到集群。然后根据安装提示拷贝 kubeconfig 文件</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果配置问题导致集群初始化失败，可重置集群再次初始化：</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubeadm reset</span><br><span class=\"line\">[root@master1 ~]# ipvsadm --clear</span><br><span class=\"line\">[root@master1 ~]# rm -rf $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c238630b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示配置环境变量</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# mkdir -p $HOME/.kube </span><br><span class=\"line\">[root@master1 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config </span><br><span class=\"line\">[root@master1 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\">[root@master1 ~]# echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class=\"line\">[root@tiaoban ~]# source ~/.bash_profile</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"154df728\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装flannel网络</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">下载资源清单配置文件</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubectl apply -f kube-flannel.yml</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果镜像不能正常拉取，所有节点需提前导入镜像，并修改yaml文件镜像拉取策略</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">imagePullPolicy: IfNotPresent</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像导入与查询</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr -n=k8s.io image import flannel.tar </span><br><span class=\"line\">unpacking docker.io/flannel/flannel:v0.22.1 (sha256:0b78f714708e837ae667c204cc918649ebcf2441b1d18ebde9a6564254932ee5)...done</span><br><span class=\"line\">[root@work3 ~]# crictl images</span><br><span class=\"line\">IMAGE                                                             TAG                 IMAGE ID            SIZE</span><br><span class=\"line\">docker.io/flannel/flannel-cni-plugin                              v1.2.0              a55d1bad692b7       8.32MB</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"76ce2493\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他节点加入集群</font></h1>\n---\n\n<h2 id=\"6e7aaa3e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">master节点加入集群</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">另外两个节点 master2 和 master3 都执行上面的 join 命令，上面的命令中的 –control-plane 就是通知 kubeadm join 创建一个新的控制平面，–certificate-key 会从集群中的 kubeadm-certs Secret 下载控制平面证书并使用给定的密钥进行解密。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 以master2节点为例</span><br><span class=\"line\">[root@master2 ~]#   kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">&gt;         --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c \\</span><br><span class=\"line\">&gt;         --control-plane --certificate-key efde545c8ea984be7ce9449ea1e77eb44659f1708001be512b7e01f70cf568b7</span><br><span class=\"line\"></span><br><span class=\"line\"># 然后根据提示配置环境变量</span><br><span class=\"line\">[root@master2 ~]# mkdir -p $HOME/.kube</span><br><span class=\"line\">[root@master2 ~]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">[root@master2 ~]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5eec51f2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">work节点加入集群</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubeadm join 192.168.10.150:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">        --discovery-token-ca-cert-hash sha256:4f8a53db87e99a4f3e8512169b7269ef2e28779e4602c0c3df898c645973c88c</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"ade4c21a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 安装指定版本的kubelet</span><br><span class=\"line\">[root@tiaoban ~]# yum install -y kubectl-1.27.6</span><br><span class=\"line\"># 拷贝集群认证文件并配置环境变量</span><br><span class=\"line\">[root@tiaoban ~]# mkdir -p /etc/kubernetes</span><br><span class=\"line\">[root@tiaoban ~]# scp master1:/etc/kubernetes/admin.conf /etc/kubernetes/</span><br><span class=\"line\">[root@tiaoban ~]# echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class=\"line\">[root@tiaoban ~]# source ~/.bash_profile</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"fb2d3f91\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群验证</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在tiaoban节点执行</font></p>\n</blockquote>\n<h2 id=\"77b07675\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# kubectl get node</span><br><span class=\"line\">NAME      STATUS   ROLES           AGE    VERSION</span><br><span class=\"line\">master1   Ready    control-plane   18m     v1.27.6</span><br><span class=\"line\">master2   Ready    control-plane   12m7s   v1.27.6</span><br><span class=\"line\">master3   Ready    control-plane   13m6s   v1.27.6</span><br><span class=\"line\">work1     Ready    &lt;none&gt;          8m25s   v1.27.6</span><br><span class=\"line\">work2     Ready    &lt;none&gt;          8m21s   v1.27.6</span><br><span class=\"line\">work3     Ready    &lt;none&gt;          8m17s   v1.27.6</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"86a835fd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# kubectl get pod -A -o wide </span><br><span class=\"line\">NAMESPACE      NAME                              READY   STATUS    RESTARTS       AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-2nqk5             1/1     Running   0              134s   192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-c87jk             1/1     Running   0              134s   192.168.10.155   work2     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-hnps5             1/1     Running   0              134s   192.168.10.154   work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-jphgx             1/1     Running   0              154s   192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-lxpsp             1/1     Running   0              134s   192.168.10.156   work3     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-rx5kf             1/1     Running   0              134s   192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    coredns-7bdc4cb885-cjbbx          1/1     Running   0              14m    10.244.5.3       work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    coredns-7bdc4cb885-sgsns          1/1     Running   0              14m    10.244.5.2       work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    etcd-master1                      1/1     Running   1              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    etcd-master2                      1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    etcd-master3                      1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-apiserver-master1            1/1     Running   1              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-apiserver-master2            1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-apiserver-master3            1/1     Running   2 (154m ago)   14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-controller-manager-master1   1/1     Running   3 (40m ago)    14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-controller-manager-master2   1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-controller-manager-master3   1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-9jsq7                  1/1     Running   0              18m    192.168.10.155   work2     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-cpb5n                  1/1     Running   0              14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-dm2rm                  1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-g26c4                  1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-jkhnj                  1/1     Running   0              18m    192.168.10.156   work3     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-proxy-x29d9                  1/1     Running   0              18m    192.168.10.154   work1     &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-scheduler-master1            1/1     Running   3 (39m ago)    14m    192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-scheduler-master2            1/1     Running   0              15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-scheduler-master3            1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-vip-master1                  1/1     Running   0              1m     192.168.10.151   master1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-vip-master2                  1/1     Running   1 (38m ago)    15m    192.168.10.152   master2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">kube-system    kube-vip-master3                  1/1     Running   0              14m    192.168.10.153   master3   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"da88e661\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群高可用测试</font></h1>\n---\n\n<h2 id=\"87c533b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件所在节点查看</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看VIP所在节点（当前位于master2）</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# ansible k8s-ha -m shell -a &quot;ip a | grep 192.168.10.150&quot;</span><br><span class=\"line\">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class=\"line\">work2 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master2 | CHANGED | rc=0 &gt;&gt;</span><br><span class=\"line\">    inet 192.168.10.150/32 scope global ens160</span><br><span class=\"line\">work1 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master1 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">work3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看其他组件所在节点（controller-manager位于master1，scheduler 位于master3）</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# kubectl get leases -n kube-system</span><br><span class=\"line\">NAME                                   HOLDER                                                                      AGE</span><br><span class=\"line\">apiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   175m</span><br><span class=\"line\">apiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h6m</span><br><span class=\"line\">apiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   176m</span><br><span class=\"line\">kube-controller-manager                master1_08adefe3-56c0-4c87-94b7-9adda172eaf3                                3h6m</span><br><span class=\"line\">kube-scheduler                         master3_59611769-b42d-459a-aa45-6ccf535d793f                                3h6m</span><br><span class=\"line\">plndr-cp-lock                          master3                                                                     176m</span><br><span class=\"line\">plndr-svcs-lock                        master1                                                                     176m</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建deployment和svc，模拟生产业务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 新建资源清单</span><br><span class=\"line\">[root@tiaoban k8s]# cat &gt; demo.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: myapp</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: myapp</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: myapp</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: myapp</span><br><span class=\"line\">        image: ikubernetes/myapp:v1</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 80</span><br><span class=\"line\">          name: http</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: myapp-svc</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app: myapp</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 80</span><br><span class=\"line\">    targetPort:  80</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建资源</span><br><span class=\"line\">[root@tiaoban k8s]# kubectl apply -f demo.yaml </span><br><span class=\"line\">deployment.apps/myapp created</span><br><span class=\"line\">service/myapp-svc created</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看资源信息</span><br><span class=\"line\">[root@tiaoban k8s]# kubectl get pod -o wide</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE    IP           NODE    NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">myapp-64b6b8fbcd-jm5q2   1/1     Running   0          101s   10.244.3.2   work3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">myapp-64b6b8fbcd-qqjsd   1/1     Running   0          101s   10.244.4.2   work2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">myapp-64b6b8fbcd-tsmwx   1/1     Running   0          101s   10.244.5.6   work1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">[root@tiaoban k8s]# kubectl get svc</span><br><span class=\"line\">NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        3h17m</span><br><span class=\"line\">myapp-svc    NodePort    10.110.186.236   &lt;none&gt;        80:30380/TCP   5m6s</span><br><span class=\"line\"></span><br><span class=\"line\"># 访问测试</span><br><span class=\"line\">[root@tiaoban k8s]# curl 192.168.10.150:30380</span><br><span class=\"line\">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"59ab63b0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">宕机一台控制节点</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">将VIP所在的master2节点关机，模拟宕机</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master3 ~]# init 0</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">各组件信息查看</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># VIP位于master1</span><br><span class=\"line\">[root@tiaoban k8s]# ansible k8s-ha -m shell -a &quot;ip a | grep 192.168.10.150&quot;</span><br><span class=\"line\">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class=\"line\">[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details</span><br><span class=\"line\">master2 | UNREACHABLE! =&gt; &#123;</span><br><span class=\"line\">    &quot;changed&quot;: false,</span><br><span class=\"line\">    &quot;msg&quot;: &quot;Failed to connect to the host via ssh: ssh: connect to host master2 port 22: Connection refused&quot;,</span><br><span class=\"line\">    &quot;unreachable&quot;: true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">work2 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">work3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">work1 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master3 | FAILED | rc=1 &gt;&gt;</span><br><span class=\"line\">non-zero return code</span><br><span class=\"line\">master1 | CHANGED | rc=0 &gt;&gt;</span><br><span class=\"line\">    inet 192.168.10.150/32 scope global ens160</span><br><span class=\"line\"></span><br><span class=\"line\"># controller-manager位于master1 scheduler位于master3</span><br><span class=\"line\">[root@tiaoban k8s]# kubectl get leases -n kube-system</span><br><span class=\"line\">NAME                                   HOLDER                                                                      AGE</span><br><span class=\"line\">apiserver-bqv2ezepcsovu7bfu7lvbrdg2m   apiserver-bqv2ezepcsovu7bfu7lvbrdg2m_c3892ab2-71ee-40f4-be66-4f65c664f568   3h19m</span><br><span class=\"line\">apiserver-bskcrn2i4gf5c5gco6huepssle   apiserver-bskcrn2i4gf5c5gco6huepssle_00e69eb5-4df9-4c3d-87e0-2eb54d7d93c4   3h30m</span><br><span class=\"line\">apiserver-s5dbgrswajhxxnkoaowmosesjm   apiserver-s5dbgrswajhxxnkoaowmosesjm_3665e3ce-dc72-440d-ba7a-ff08f9c71b6a   3h20m</span><br><span class=\"line\">kube-controller-manager                master1_fd5b1081-93e2-4be8-8eb8-8719a70b606a                                3h29m</span><br><span class=\"line\">kube-scheduler                         master1_2b4c98a1-8d8c-4bb3-a3c4-58793022180a                                3h29m</span><br><span class=\"line\">plndr-cp-lock                          master3                                                                     3h20m</span><br><span class=\"line\">plndr-svcs-lock                        master1                                                                     3h20m</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">集群节点信息查看</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban k8s]# kubectl get node</span><br><span class=\"line\">NAME      STATUS     ROLES           AGE     VERSION</span><br><span class=\"line\">master1   Ready      control-plane   3h31m   v1.27.6</span><br><span class=\"line\">master2   NotReady   control-plane   3h22m   v1.27.6</span><br><span class=\"line\">master3   Ready      control-plane   3h21m   v1.27.6</span><br><span class=\"line\">work1     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br><span class=\"line\">work2     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br><span class=\"line\">work3     Ready      &lt;none&gt;          3h14m   v1.27.6</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">业务访问测试</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban k8s]# curl 192.168.10.150:30380</span><br><span class=\"line\">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">结论：当有一个master节点宕机时，VIP会发生漂移，集群各项功能不受影响。</font></p>\n"},{"title":"存储基础","date":"2025-03-17T11:30:00.000Z","_content":"<h1 id=\"8453e91e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础知识</font></h1>\n---\n\n<h2 id=\"d7f3f1a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式介绍</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814481-02fe756f-42d3-4ea5-840b-5b97d2b0cee1.jpeg)\n\n<h3 id=\"a798c497\"><font style=\"background-color:rgba(255, 255, 255, 0);\">直连附加存储(DAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：DAS 指Direct Attached Storage，即直连附加存储，可以理解为本地文件系统。这种设备直接连接到计算机主板总线上，计算机将其识别为一个块设备，例如常见的硬盘，U盘等，这种设备很难做到共享。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">特点：DAS 购置成本低，配置简单，使用过程和使用本机硬盘并无太大差别，对于服务器的要求仅仅是一个外接的</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SCSI</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">口，因此对于小型企业很有吸引力。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 数据备份操作复杂。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 服务器本身容易成为系统瓶颈。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 服务器发生故障，数据不可访问。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(4) 对于存在多个服务器的系统来说，设备分散，不便管理。</font>\n\n<h3 id=\"7934385c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">网络附加存储(NAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：NAS指Network Area Storage，即网络附加存储。它一般是将本地的存储空间共享给其他主机使用，一般通过C/S架构实现通信。它实现的是文件级别的共享，计算机通常将共享的设别识别为一个文件系统，其文件服务器会管理锁以实现并发访问。网络文件系统，以文件模块的形式进行共享，工作在应用层上，常见的NAS有NFS和CIFS(FTP)。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">特点：NAS实际是一种带有瘦服务器的存储设备，这个瘦服务器实际是一台网络文件服务器。NAS设备直接连接到TCP/IP网络上，网络服务器通过TCP/IP网络存取管理数据。NAS作为一种瘦服务器系统，易于安装和部署，管理使用也很方便。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 存储数据通过网络传输，因此容易产生数据泄漏等安全问题。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 存储数据通过网络传输，因此易受网络上其它流量的影响，当网络上有其它大数据流量时会严重影响系统性能。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 存储只能以文件方式访问，而不能像普通文件系统一样直接访问物理数据块，因此会在某些情况下严重影响系统效率，比如大型数据库就不能使用 NAS 这种存储方案。</font>\n\n<h3 id=\"929d65ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网(SAN)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SAN</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">指Storage Area Network，即</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网络</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，工作于内核层。它将传输网络模拟成</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SCSI</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">总线来使用，每一个主机的网卡相当于SCSI总线中的initiator，服务器相当于一个或多个target，它需要借助客户端和服务端的SCSI驱动，通过FC或TCP/IP协议封装SCSI报文。它实现的是</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">块级别</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">的共享，通常被识别为一个块设备，但是需要借助专门的锁管理软件才能实现多主机并发访问。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">特点：SAN实际是一种专门为存储建立的独立于TCP/IP网络之外的专用网络。目前一般的SAN提供2Gb/S到4Gb/S的传输数率，同时SAN网络独立于数据网络存在，因此存取速度很快，另外SAN一般采用高端的RAID阵列，使SAN的性能在几种专业网络存储技术中傲视群雄。SAN由于其基础是一个专用网络，因此扩展性很强，不管是在一个SAN系统中增加一定的存储空间还是增加几台使用存储空间的服务器都非常方便。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 需要单独建立光纤网络，异地扩展比较困难。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 不论是SAN阵列柜还是SAN必须的光纤通道交换机价格都是十分昂贵的。</font>\n\n<h2 id=\"432769e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式对比</font></h2>\n---\n\n| <font style=\"background-color:rgba(255, 255, 255, 0);\"></font> | **<font style=\"background-color:rgba(255, 255, 255, 0);\">DAS</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">NAS</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">IP-SAN</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">FC-SAN</font>** |\n| --- | --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">成本</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">数据传输速度</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">快</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">慢</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较快</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">极快</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">扩展性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">无扩展性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">最易扩展</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">易于扩展</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器访问存储方式</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">以文件方式访问</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器系统性能开销</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">安全性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">是否集中管理存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">否</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">是</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">是</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">是</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">备份效率</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">网络传输协议</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">无</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">TCP/IP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">TCP/IP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">Fibre Channel</font> |\n\n\n<h1 id=\"8dc8bbbc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font></h1>\n---\n\n<h2 id=\"b776d636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本组成</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统是操作系统中负责管理持久数据的子系统，负责把用户的文件存到磁盘硬件中。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本数据单位是文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。</font>\n\n<h3 id=\"e9bef67a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。</font>\n\n<h3 id=\"2d0ecc68\"><font style=\"background-color:rgba(255, 255, 255, 0);\">目录项</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。</font>\n\n<h2 id=\"86797e74\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储过程</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。所以，文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘想要呗文件系统使用，需要进行格式化，在格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。</font>\n\n<h3 id=\"0f7ddcc2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">超级块</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。</font>\n\n<h3 id=\"75db212d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储索引节点，也就是记录文件的属性等元信息。</font>\n\n<h3 id=\"beb4e218\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据块区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件或目录数据。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814409-ab155d66-8769-4847-ae65-a7065b59d56d.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">超级块：当文件系统挂载时进入内存；</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区：当文件被访问时进入内存；</font>\n\n<h2 id=\"85c5a550\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟文件系统</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（Virtual File System，VFS）。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 文件系统中，用户空间、系统调用、虚拟机文件系统、缓存、文件系统以及存储之间的关系如下图：</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814564-d0f169dc-eb48-4032-852a-f7a20acc9a10.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">根据存储位置的不同，可以把文件系统分为三类：</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘的文件系统，它是直接把数据存储在磁盘中，比如 Ext 2/3/4、XFS 等都是这类文件系统。</font>\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">内存的文件系统，这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 /proc 和 /sys 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据数据。</font>\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">网络的文件系统，用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。</font>\n\n<h2 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」。</font>\n\n<h3 id=\"13825d64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式顾名思义，文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">所以，文件头里需要指定「起始块的位置」和「长度」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意，此处说的文件头，就类似于 Linux 的 inode。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814475-675c761e-6690-41b9-98bf-1fb6c130be11.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如下图，如果文件 B 被删除，磁盘上就留下一块空缺，这时，如果新来的文件小于其中的一个空缺，我们就可以将其放在相应空缺里。但如果该文件的大小大于所有的空缺，但却小于空缺大小之和，则虽然磁盘上有足够的空缺，但该文件还是不能存放。当然了，我们可以通过将现有文件进行挪动来腾出空间以容纳新的文件，但是这个在磁盘挪动文件是非常耗时，所以这种方式不太现实。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814540-c25844ec-e4af-42f5-a9c2-59eb74916570.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">另外一个缺陷是文件长度扩展不方便，例如上图中的文件 A 要想扩大一下，需要更多的磁盘空间，唯一的办法就只能是挪动的方式，前面也说了，这种方式效率是非常低的。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">那么有没有更好的方式来解决上面的问题呢？答案当然有，既然连续空间存放的方式不太行，那么我们就改变存放的方式，使用非连续空间存放方式来解决这些缺陷。</font>\n\n<h3 id=\"b6fde348\"><font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式分为「链表方式」和「索引方式」。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件要以「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开是就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814984-2b1f126f-378c-47da-bfa1-2a118faa1deb.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表的存放方式的缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「显式链接」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">对于显式链接的工作方式，我们举个例子，文件 A 依次使用了磁盘块 4、7、2、10 和 12 ，文件 B 依次使用了磁盘块 6、3、11 和 14 。利用下图中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找出文件 B 的全部磁盘块。最后，这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1 ）结束。内存中的这样一个表格称为文件分配表（File Allocation Table，FAT）。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815067-e7cdcc51-5419-439c-ab92-a06788cf4c25.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">显式链接</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">比如，对于 200GB 的磁盘和 1KB 大小的块，这张表需要有 2 亿项，每一项对应于这 2 亿个磁盘块中的一个块，每项如果需要 4 个字节，那这张表要占用 800MB 内存，很显然 FAT 方案对于大磁盘而言不太合适。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">接下来，我们来看看索引的方式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">另外，文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815034-85216709-0194-49c0-8a20-f0f0597c431b.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式优点在于：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件的创建、增大、缩小很方便；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">不会有碎片的问题；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">支持顺序读写和随机读写；</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">先来看看链表 + 索引的组合，这种组合称为「链式索引块」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815051-92b925d5-a884-4619-8245-61a56aab760f.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">链式索引块</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引，像极了俄罗斯套娃。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815742-d7933567-1ef6-4eba-96d7-42bdc76211fc.jpeg)\n\n","source":"_posts/1.存储基础 副本.md","raw":"---\ntitle: 存储基础 \ndate: 2025-03-17 19:30:00\n---\n<h1 id=\"8453e91e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础知识</font></h1>\n---\n\n<h2 id=\"d7f3f1a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式介绍</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814481-02fe756f-42d3-4ea5-840b-5b97d2b0cee1.jpeg)\n\n<h3 id=\"a798c497\"><font style=\"background-color:rgba(255, 255, 255, 0);\">直连附加存储(DAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：DAS 指Direct Attached Storage，即直连附加存储，可以理解为本地文件系统。这种设备直接连接到计算机主板总线上，计算机将其识别为一个块设备，例如常见的硬盘，U盘等，这种设备很难做到共享。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">特点：DAS 购置成本低，配置简单，使用过程和使用本机硬盘并无太大差别，对于服务器的要求仅仅是一个外接的</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SCSI</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">口，因此对于小型企业很有吸引力。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 数据备份操作复杂。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 服务器本身容易成为系统瓶颈。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 服务器发生故障，数据不可访问。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(4) 对于存在多个服务器的系统来说，设备分散，不便管理。</font>\n\n<h3 id=\"7934385c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">网络附加存储(NAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：NAS指Network Area Storage，即网络附加存储。它一般是将本地的存储空间共享给其他主机使用，一般通过C/S架构实现通信。它实现的是文件级别的共享，计算机通常将共享的设别识别为一个文件系统，其文件服务器会管理锁以实现并发访问。网络文件系统，以文件模块的形式进行共享，工作在应用层上，常见的NAS有NFS和CIFS(FTP)。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">特点：NAS实际是一种带有瘦服务器的存储设备，这个瘦服务器实际是一台网络文件服务器。NAS设备直接连接到TCP/IP网络上，网络服务器通过TCP/IP网络存取管理数据。NAS作为一种瘦服务器系统，易于安装和部署，管理使用也很方便。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 存储数据通过网络传输，因此容易产生数据泄漏等安全问题。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 存储数据通过网络传输，因此易受网络上其它流量的影响，当网络上有其它大数据流量时会严重影响系统性能。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 存储只能以文件方式访问，而不能像普通文件系统一样直接访问物理数据块，因此会在某些情况下严重影响系统效率，比如大型数据库就不能使用 NAS 这种存储方案。</font>\n\n<h3 id=\"929d65ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网(SAN)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SAN</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">指Storage Area Network，即</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网络</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，工作于内核层。它将传输网络模拟成</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SCSI</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">总线来使用，每一个主机的网卡相当于SCSI总线中的initiator，服务器相当于一个或多个target，它需要借助客户端和服务端的SCSI驱动，通过FC或TCP/IP协议封装SCSI报文。它实现的是</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">块级别</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">的共享，通常被识别为一个块设备，但是需要借助专门的锁管理软件才能实现多主机并发访问。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">特点：SAN实际是一种专门为存储建立的独立于TCP/IP网络之外的专用网络。目前一般的SAN提供2Gb/S到4Gb/S的传输数率，同时SAN网络独立于数据网络存在，因此存取速度很快，另外SAN一般采用高端的RAID阵列，使SAN的性能在几种专业网络存储技术中傲视群雄。SAN由于其基础是一个专用网络，因此扩展性很强，不管是在一个SAN系统中增加一定的存储空间还是增加几台使用存储空间的服务器都非常方便。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 需要单独建立光纤网络，异地扩展比较困难。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 不论是SAN阵列柜还是SAN必须的光纤通道交换机价格都是十分昂贵的。</font>\n\n<h2 id=\"432769e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式对比</font></h2>\n---\n\n| <font style=\"background-color:rgba(255, 255, 255, 0);\"></font> | **<font style=\"background-color:rgba(255, 255, 255, 0);\">DAS</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">NAS</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">IP-SAN</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">FC-SAN</font>** |\n| --- | --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">成本</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">数据传输速度</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">快</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">慢</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较快</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">极快</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">扩展性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">无扩展性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">最易扩展</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">易于扩展</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器访问存储方式</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">以文件方式访问</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器系统性能开销</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">安全性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">是否集中管理存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">否</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">是</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">是</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">是</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">备份效率</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">网络传输协议</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">无</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">TCP/IP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">TCP/IP</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">Fibre Channel</font> |\n\n\n<h1 id=\"8dc8bbbc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font></h1>\n---\n\n<h2 id=\"b776d636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本组成</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统是操作系统中负责管理持久数据的子系统，负责把用户的文件存到磁盘硬件中。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本数据单位是文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。</font>\n\n<h3 id=\"e9bef67a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。</font>\n\n<h3 id=\"2d0ecc68\"><font style=\"background-color:rgba(255, 255, 255, 0);\">目录项</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。</font>\n\n<h2 id=\"86797e74\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储过程</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。所以，文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘想要呗文件系统使用，需要进行格式化，在格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。</font>\n\n<h3 id=\"0f7ddcc2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">超级块</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。</font>\n\n<h3 id=\"75db212d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储索引节点，也就是记录文件的属性等元信息。</font>\n\n<h3 id=\"beb4e218\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据块区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件或目录数据。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814409-ab155d66-8769-4847-ae65-a7065b59d56d.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">超级块：当文件系统挂载时进入内存；</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区：当文件被访问时进入内存；</font>\n\n<h2 id=\"85c5a550\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟文件系统</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（Virtual File System，VFS）。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 文件系统中，用户空间、系统调用、虚拟机文件系统、缓存、文件系统以及存储之间的关系如下图：</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814564-d0f169dc-eb48-4032-852a-f7a20acc9a10.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">根据存储位置的不同，可以把文件系统分为三类：</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘的文件系统，它是直接把数据存储在磁盘中，比如 Ext 2/3/4、XFS 等都是这类文件系统。</font>\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">内存的文件系统，这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 /proc 和 /sys 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据数据。</font>\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">网络的文件系统，用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。</font>\n\n<h2 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」。</font>\n\n<h3 id=\"13825d64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式顾名思义，文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">所以，文件头里需要指定「起始块的位置」和「长度」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意，此处说的文件头，就类似于 Linux 的 inode。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814475-675c761e-6690-41b9-98bf-1fb6c130be11.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如下图，如果文件 B 被删除，磁盘上就留下一块空缺，这时，如果新来的文件小于其中的一个空缺，我们就可以将其放在相应空缺里。但如果该文件的大小大于所有的空缺，但却小于空缺大小之和，则虽然磁盘上有足够的空缺，但该文件还是不能存放。当然了，我们可以通过将现有文件进行挪动来腾出空间以容纳新的文件，但是这个在磁盘挪动文件是非常耗时，所以这种方式不太现实。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814540-c25844ec-e4af-42f5-a9c2-59eb74916570.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">另外一个缺陷是文件长度扩展不方便，例如上图中的文件 A 要想扩大一下，需要更多的磁盘空间，唯一的办法就只能是挪动的方式，前面也说了，这种方式效率是非常低的。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">那么有没有更好的方式来解决上面的问题呢？答案当然有，既然连续空间存放的方式不太行，那么我们就改变存放的方式，使用非连续空间存放方式来解决这些缺陷。</font>\n\n<h3 id=\"b6fde348\"><font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式分为「链表方式」和「索引方式」。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件要以「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开是就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814984-2b1f126f-378c-47da-bfa1-2a118faa1deb.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表的存放方式的缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「显式链接」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">对于显式链接的工作方式，我们举个例子，文件 A 依次使用了磁盘块 4、7、2、10 和 12 ，文件 B 依次使用了磁盘块 6、3、11 和 14 。利用下图中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找出文件 B 的全部磁盘块。最后，这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1 ）结束。内存中的这样一个表格称为文件分配表（File Allocation Table，FAT）。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815067-e7cdcc51-5419-439c-ab92-a06788cf4c25.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">显式链接</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">比如，对于 200GB 的磁盘和 1KB 大小的块，这张表需要有 2 亿项，每一项对应于这 2 亿个磁盘块中的一个块，每项如果需要 4 个字节，那这张表要占用 800MB 内存，很显然 FAT 方案对于大磁盘而言不太合适。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">接下来，我们来看看索引的方式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">另外，文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815034-85216709-0194-49c0-8a20-f0f0597c431b.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式优点在于：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件的创建、增大、缩小很方便；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">不会有碎片的问题；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">支持顺序读写和随机读写；</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">先来看看链表 + 索引的组合，这种组合称为「链式索引块」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815051-92b925d5-a884-4619-8245-61a56aab760f.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">链式索引块</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引，像极了俄罗斯套娃。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815742-d7933567-1ef6-4eba-96d7-42bdc76211fc.jpeg)\n\n","slug":"1.存储基础 副本","published":1,"updated":"2025-03-30T13:19:26.488Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlc0003tsv11d113grc","content":"<h1 id=\"8453e91e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础知识</font></h1>\n---\n\n<h2 id=\"d7f3f1a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式介绍</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814481-02fe756f-42d3-4ea5-840b-5b97d2b0cee1.jpeg\"></p>\n<h3 id=\"a798c497\"><font style=\"background-color:rgba(255, 255, 255, 0);\">直连附加存储(DAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：DAS 指Direct Attached Storage，即直连附加存储，可以理解为本地文件系统。这种设备直接连接到计算机主板总线上，计算机将其识别为一个块设备，例如常见的硬盘，U盘等，这种设备很难做到共享。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">特点：DAS 购置成本低，配置简单，使用过程和使用本机硬盘并无太大差别，对于服务器的要求仅仅是一个外接的</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;SCSI&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">口，因此对于小型企业很有吸引力。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 数据备份操作复杂。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 服务器本身容易成为系统瓶颈。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 服务器发生故障，数据不可访问。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(4) 对于存在多个服务器的系统来说，设备分散，不便管理。</font></p>\n<h3 id=\"7934385c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">网络附加存储(NAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：NAS指Network Area Storage，即网络附加存储。它一般是将本地的存储空间共享给其他主机使用，一般通过C/S架构实现通信。它实现的是文件级别的共享，计算机通常将共享的设别识别为一个文件系统，其文件服务器会管理锁以实现并发访问。网络文件系统，以文件模块的形式进行共享，工作在应用层上，常见的NAS有NFS和CIFS(FTP)。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">特点：NAS实际是一种带有瘦服务器的存储设备，这个瘦服务器实际是一台网络文件服务器。NAS设备直接连接到TCP&#x2F;IP网络上，网络服务器通过TCP&#x2F;IP网络存取管理数据。NAS作为一种瘦服务器系统，易于安装和部署，管理使用也很方便。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 存储数据通过网络传输，因此容易产生数据泄漏等安全问题。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 存储数据通过网络传输，因此易受网络上其它流量的影响，当网络上有其它大数据流量时会严重影响系统性能。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 存储只能以文件方式访问，而不能像普通文件系统一样直接访问物理数据块，因此会在某些情况下严重影响系统效率，比如大型数据库就不能使用 NAS 这种存储方案。</font></p>\n<h3 id=\"929d65ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网(SAN)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SAN</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">指Storage Area Network，即</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网络</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，工作于内核层。它将传输网络模拟成</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SCSI</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">总线来使用，每一个主机的网卡相当于SCSI总线中的initiator，服务器相当于一个或多个target，它需要借助客户端和服务端的SCSI驱动，通过FC或TCP/IP协议封装SCSI报文。它实现的是</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">块级别</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">的共享，通常被识别为一个块设备，但是需要借助专门的锁管理软件才能实现多主机并发访问。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">特点：SAN实际是一种专门为存储建立的独立于TCP&#x2F;IP网络之外的专用网络。目前一般的SAN提供2Gb&#x2F;S到4Gb&#x2F;S的传输数率，同时SAN网络独立于数据网络存在，因此存取速度很快，另外SAN一般采用高端的RAID阵列，使SAN的性能在几种专业网络存储技术中傲视群雄。SAN由于其基础是一个专用网络，因此扩展性很强，不管是在一个SAN系统中增加一定的存储空间还是增加几台使用存储空间的服务器都非常方便。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 需要单独建立光纤网络，异地扩展比较困难。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 不论是SAN阵列柜还是SAN必须的光纤通道交换机价格都是十分昂贵的。</font></p>\n<h2 id=\"432769e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式对比</font></h2>\n---\n\n<table>\n<thead>\n<tr>\n<th><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">DAS</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">NAS</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">IP-SAN</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">FC-SAN</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">成本</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">数据传输速度</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">快</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">慢</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较快</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">极快</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">扩展性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">无扩展性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">最易扩展</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">易于扩展</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务器访问存储方式</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">以文件方式访问</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务器系统性能开销</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">安全性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是否集中管理存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">否</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">备份效率</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">网络传输协议</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">无</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">TCP&#x2F;IP</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">TCP&#x2F;IP</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">Fibre Channel</font></td>\n</tr>\n</tbody></table>\n<h1 id=\"8dc8bbbc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font></h1>\n---\n\n<h2 id=\"b776d636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本组成</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统是操作系统中负责管理持久数据的子系统，负责把用户的文件存到磁盘硬件中。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本数据单位是文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。</font></p>\n<h3 id=\"e9bef67a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。</font>\n\n<h3 id=\"2d0ecc68\"><font style=\"background-color:rgba(255, 255, 255, 0);\">目录项</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。</font></p>\n<h2 id=\"86797e74\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储过程</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。所以，文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘想要呗文件系统使用，需要进行格式化，在格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。</font></p>\n<h3 id=\"0f7ddcc2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">超级块</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。</font>\n\n<h3 id=\"75db212d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储索引节点，也就是记录文件的属性等元信息。</font>\n\n<h3 id=\"beb4e218\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据块区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件或目录数据。</font>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814409-ab155d66-8769-4847-ae65-a7065b59d56d.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">超级块：当文件系统挂载时进入内存；</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区：当文件被访问时进入内存；</font></p>\n<h2 id=\"85c5a550\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟文件系统</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（Virtual File System，VFS）。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 文件系统中，用户空间、系统调用、虚拟机文件系统、缓存、文件系统以及存储之间的关系如下图：</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814564-d0f169dc-eb48-4032-852a-f7a20acc9a10.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">根据存储位置的不同，可以把文件系统分为三类：</font></p>\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘的文件系统，它是直接把数据存储在磁盘中，比如 Ext 2&#x2F;3&#x2F;4、XFS 等都是这类文件系统。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">内存的文件系统，这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 &#x2F;proc 和 &#x2F;sys 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据数据。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">网络的文件系统，用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。</font></li>\n</ol>\n<h2 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」。</font></p>\n<h3 id=\"13825d64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式顾名思义，文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">所以，文件头里需要指定「起始块的位置」和「长度」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">注意，此处说的文件头，就类似于 Linux 的 inode。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814475-675c761e-6690-41b9-98bf-1fb6c130be11.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如下图，如果文件 B 被删除，磁盘上就留下一块空缺，这时，如果新来的文件小于其中的一个空缺，我们就可以将其放在相应空缺里。但如果该文件的大小大于所有的空缺，但却小于空缺大小之和，则虽然磁盘上有足够的空缺，但该文件还是不能存放。当然了，我们可以通过将现有文件进行挪动来腾出空间以容纳新的文件，但是这个在磁盘挪动文件是非常耗时，所以这种方式不太现实。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814540-c25844ec-e4af-42f5-a9c2-59eb74916570.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">另外一个缺陷是文件长度扩展不方便，例如上图中的文件 A 要想扩大一下，需要更多的磁盘空间，唯一的办法就只能是挪动的方式，前面也说了，这种方式效率是非常低的。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">那么有没有更好的方式来解决上面的问题呢？答案当然有，既然连续空间存放的方式不太行，那么我们就改变存放的方式，使用非连续空间存放方式来解决这些缺陷。</font></p>\n<h3 id=\"b6fde348\"><font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式分为「链表方式」和「索引方式」。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件要以「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开是就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814984-2b1f126f-378c-47da-bfa1-2a118faa1deb.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表的存放方式的缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「显式链接」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">对于显式链接的工作方式，我们举个例子，文件 A 依次使用了磁盘块 4、7、2、10 和 12 ，文件 B 依次使用了磁盘块 6、3、11 和 14 。利用下图中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找出文件 B 的全部磁盘块。最后，这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1 ）结束。内存中的这样一个表格称为文件分配表（File Allocation Table，FAT）。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815067-e7cdcc51-5419-439c-ab92-a06788cf4c25.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">显式链接</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">比如，对于 200GB 的磁盘和 1KB 大小的块，这张表需要有 2 亿项，每一项对应于这 2 亿个磁盘块中的一个块，每项如果需要 4 个字节，那这张表要占用 800MB 内存，很显然 FAT 方案对于大磁盘而言不太合适。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">接下来，我们来看看索引的方式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">另外，文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815034-85216709-0194-49c0-8a20-f0f0597c431b.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式优点在于：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">文件的创建、增大、缩小很方便；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">不会有碎片的问题；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">支持顺序读写和随机读写；</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">先来看看链表 + 索引的组合，这种组合称为「链式索引块」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815051-92b925d5-a884-4619-8245-61a56aab760f.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">链式索引块</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引，像极了俄罗斯套娃。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815742-d7933567-1ef6-4eba-96d7-42bdc76211fc.jpeg\"></p>\n","excerpt":"","more":"<h1 id=\"8453e91e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础知识</font></h1>\n---\n\n<h2 id=\"d7f3f1a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式介绍</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814481-02fe756f-42d3-4ea5-840b-5b97d2b0cee1.jpeg\"></p>\n<h3 id=\"a798c497\"><font style=\"background-color:rgba(255, 255, 255, 0);\">直连附加存储(DAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：DAS 指Direct Attached Storage，即直连附加存储，可以理解为本地文件系统。这种设备直接连接到计算机主板总线上，计算机将其识别为一个块设备，例如常见的硬盘，U盘等，这种设备很难做到共享。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">特点：DAS 购置成本低，配置简单，使用过程和使用本机硬盘并无太大差别，对于服务器的要求仅仅是一个外接的</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;SCSI&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">口，因此对于小型企业很有吸引力。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 数据备份操作复杂。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 服务器本身容易成为系统瓶颈。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 服务器发生故障，数据不可访问。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(4) 对于存在多个服务器的系统来说，设备分散，不便管理。</font></p>\n<h3 id=\"7934385c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">网络附加存储(NAS)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：NAS指Network Area Storage，即网络附加存储。它一般是将本地的存储空间共享给其他主机使用，一般通过C/S架构实现通信。它实现的是文件级别的共享，计算机通常将共享的设别识别为一个文件系统，其文件服务器会管理锁以实现并发访问。网络文件系统，以文件模块的形式进行共享，工作在应用层上，常见的NAS有NFS和CIFS(FTP)。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">特点：NAS实际是一种带有瘦服务器的存储设备，这个瘦服务器实际是一台网络文件服务器。NAS设备直接连接到TCP&#x2F;IP网络上，网络服务器通过TCP&#x2F;IP网络存取管理数据。NAS作为一种瘦服务器系统，易于安装和部署，管理使用也很方便。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 存储数据通过网络传输，因此容易产生数据泄漏等安全问题。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 存储数据通过网络传输，因此易受网络上其它流量的影响，当网络上有其它大数据流量时会严重影响系统性能。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(3) 存储只能以文件方式访问，而不能像普通文件系统一样直接访问物理数据块，因此会在某些情况下严重影响系统效率，比如大型数据库就不能使用 NAS 这种存储方案。</font></p>\n<h3 id=\"929d65ce\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网(SAN)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">定义：</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SAN</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">指Storage Area Network，即</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">存储区域网络</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，工作于内核层。它将传输网络模拟成</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">SCSI</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">总线来使用，每一个主机的网卡相当于SCSI总线中的initiator，服务器相当于一个或多个target，它需要借助客户端和服务端的SCSI驱动，通过FC或TCP/IP协议封装SCSI报文。它实现的是</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">块级别</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">的共享，通常被识别为一个块设备，但是需要借助专门的锁管理软件才能实现多主机并发访问。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">特点：SAN实际是一种专门为存储建立的独立于TCP&#x2F;IP网络之外的专用网络。目前一般的SAN提供2Gb&#x2F;S到4Gb&#x2F;S的传输数率，同时SAN网络独立于数据网络存在，因此存取速度很快，另外SAN一般采用高端的RAID阵列，使SAN的性能在几种专业网络存储技术中傲视群雄。SAN由于其基础是一个专用网络，因此扩展性很强，不管是在一个SAN系统中增加一定的存储空间还是增加几台使用存储空间的服务器都非常方便。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(1) 需要单独建立光纤网络，异地扩展比较困难。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">(2) 不论是SAN阵列柜还是SAN必须的光纤通道交换机价格都是十分昂贵的。</font></p>\n<h2 id=\"432769e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储方式对比</font></h2>\n---\n\n<table>\n<thead>\n<tr>\n<th><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">DAS</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">NAS</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">IP-SAN</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">FC-SAN</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">成本</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">数据传输速度</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">快</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">慢</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较快</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">极快</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">扩展性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">无扩展性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">最易扩展</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">易于扩展</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务器访问存储方式</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">以文件方式访问</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">直接访问存储数据块</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务器系统性能开销</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">安全性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是否集中管理存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">否</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">是</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">备份效率</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较低</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">较高</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">网络传输协议</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">无</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">TCP&#x2F;IP</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">TCP&#x2F;IP</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">Fibre Channel</font></td>\n</tr>\n</tbody></table>\n<h1 id=\"8dc8bbbc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font></h1>\n---\n\n<h2 id=\"b776d636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本组成</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统是操作系统中负责管理持久数据的子系统，负责把用户的文件存到磁盘硬件中。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的基本数据单位是文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。</font></p>\n<h3 id=\"e9bef67a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。</font>\n\n<h3 id=\"2d0ecc68\"><font style=\"background-color:rgba(255, 255, 255, 0);\">目录项</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引节点唯一标识一个文件，而目录项记录着文件的名，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别字。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。</font></p>\n<h2 id=\"86797e74\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储过程</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。所以，文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘想要呗文件系统使用，需要进行格式化，在格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。</font></p>\n<h3 id=\"0f7ddcc2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">超级块</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。</font>\n\n<h3 id=\"75db212d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储索引节点，也就是记录文件的属性等元信息。</font>\n\n<h3 id=\"beb4e218\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据块区</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用来存储文件或目录数据。</font>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814409-ab155d66-8769-4847-ae65-a7065b59d56d.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">超级块：当文件系统挂载时进入内存；</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引节点区：当文件被访问时进入内存；</font></p>\n<h2 id=\"85c5a550\"><font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟文件系统</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统的种类众多，而操作系统希望对用户提供一个统一的接口，于是在用户层与文件系统层引入了中间层，这个中间层就称为虚拟文件系统（Virtual File System，VFS）。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 文件系统中，用户空间、系统调用、虚拟机文件系统、缓存、文件系统以及存储之间的关系如下图：</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814564-d0f169dc-eb48-4032-852a-f7a20acc9a10.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">根据存储位置的不同，可以把文件系统分为三类：</font></p>\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">磁盘的文件系统，它是直接把数据存储在磁盘中，比如 Ext 2&#x2F;3&#x2F;4、XFS 等都是这类文件系统。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">内存的文件系统，这类文件系统的数据不是存储在硬盘的，而是占用内存空间，我们经常用到的 &#x2F;proc 和 &#x2F;sys 文件系统都属于这一类，读写这类文件，实际上是读写内核中相关的数据数据。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">网络的文件系统，用来访问其他计算机主机数据的文件系统，比如 NFS、SMB 等等。</font></li>\n</ol>\n<h2 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其中，非连续空间存放方式又可以分为「链表方式」和「索引方式」。</font></p>\n<h3 id=\"13825d64\"><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放方式顾名思义，文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">所以，文件头里需要指定「起始块的位置」和「长度」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">注意，此处说的文件头，就类似于 Linux 的 inode。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814475-675c761e-6690-41b9-98bf-1fb6c130be11.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">连续空间存放的方式虽然读写效率高，但是有「磁盘空间碎片」和「文件长度不易扩展」的缺陷。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如下图，如果文件 B 被删除，磁盘上就留下一块空缺，这时，如果新来的文件小于其中的一个空缺，我们就可以将其放在相应空缺里。但如果该文件的大小大于所有的空缺，但却小于空缺大小之和，则虽然磁盘上有足够的空缺，但该文件还是不能存放。当然了，我们可以通过将现有文件进行挪动来腾出空间以容纳新的文件，但是这个在磁盘挪动文件是非常耗时，所以这种方式不太现实。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814540-c25844ec-e4af-42f5-a9c2-59eb74916570.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">另外一个缺陷是文件长度扩展不方便，例如上图中的文件 A 要想扩大一下，需要更多的磁盘空间，唯一的办法就只能是挪动的方式，前面也说了，这种方式效率是非常低的。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">那么有没有更好的方式来解决上面的问题呢？答案当然有，既然连续空间存放的方式不太行，那么我们就改变存放的方式，使用非连续空间存放方式来解决这些缺陷。</font></p>\n<h3 id=\"b6fde348\"><font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">非连续空间存放方式分为「链表方式」和「索引方式」。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式存放是离散的，不用连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件要以「隐式链表」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开是就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851814984-2b1f126f-378c-47da-bfa1-2a118faa1deb.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">隐式链表的存放方式的缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。那么，这种实现方式是「显式链接」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">对于显式链接的工作方式，我们举个例子，文件 A 依次使用了磁盘块 4、7、2、10 和 12 ，文件 B 依次使用了磁盘块 6、3、11 和 14 。利用下图中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找出文件 B 的全部磁盘块。最后，这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1 ）结束。内存中的这样一个表格称为文件分配表（File Allocation Table，FAT）。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815067-e7cdcc51-5419-439c-ab92-a06788cf4c25.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">显式链接</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">比如，对于 200GB 的磁盘和 1KB 大小的块，这张表需要有 2 亿项，每一项对应于这 2 亿个磁盘块中的一个块，每项如果需要 4 个字节，那这张表要占用 800MB 内存，很显然 FAT 方案对于大磁盘而言不太合适。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">接下来，我们来看看索引的方式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">另外，文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815034-85216709-0194-49c0-8a20-f0f0597c431b.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">索引的方式优点在于：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">文件的创建、增大、缩小很方便；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">不会有碎片的问题；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">支持顺序读写和随机读写；</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">先来看看链表 + 索引的组合，这种组合称为「链式索引块」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815051-92b925d5-a884-4619-8245-61a56aab760f.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">链式索引块</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引，像极了俄罗斯套娃。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851815742-d7933567-1ef6-4eba-96d7-42bdc76211fc.jpeg\"></p>\n"},{"title":"部署Harbor私有镜像仓库","date":"2025-03-11T10:00:00.000Z","_content":"\n<h1 id=\"fc12ee52\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署harbor</font></h1>\n---\n\n<h2 id=\"8ee50e07\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载软件包</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker</font>\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker-compose</font>\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">下载harbor离线安装包  \n</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">github仓库软件包下载地址</font>](https://github.com/goharbor/harbor/releases)\n\n```plain\n[root@opt ~]# wget https://github.com/goharbor/harbor/releases/download/v2.11.1/harbor-offline-installer-v2.11.1.tgz\n[root@opt ~]# tar -xvf harbor-offline-installer-v2.11.1.tgz \n```\n\n<h2 id=\"faaccfba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http方式</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">复制配置文件并修改</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n```plain\n[root@harbor ~]# cp harbor.yml.tmpl harbor.yml\n[root@harbor ~]# vim harbor.yml\n# 设置域名\nhostname: harbor.local.com\n# 注释https相关配置\n# http related config\nhttp:\n  # port for http, default is 80. If https enabled, this port will redirect to https port\n  port: 80\n\n# https related config\n#https:\n  # https port for harbor, default is 443\n  #port: 443\n  # The path of cert and key files for nginx\n  #certificate: /your/certificate/path\n  #private_key: /your/private/key/path\n```\n\n<h2 id=\"f1a7433c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https方式(建议)</font></h2>\n---\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">生成自签名证书</font>**\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这里我们使用</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/Fishdrowned/ssl</font>](https://github.com/Fishdrowned/ssl)<font style=\"background-color:rgba(255, 255, 255, 0);\">提供的shell脚本生成ssl证书，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">证书有效期是 2 年，可以修改 ca.cnf 来修改这个年限。</font>\n\n```plain\n# 克隆项目\n[root@tiaoban opt]# git clone https://github.com/Fishdrowned/ssl.git\n# 一键生成证书\n[root@tiaoban opt]# cd ssl\n[root@tiaoban ssl]# ./gen.cert.sh harbor.local.com # 生成harbor.local.com域名的证书\nRemoving dir out\nCreating output structure\nDone\nGenerating a RSA private key\n...................................+++++\n....+++++\nwriting new private key to 'out/root.key.pem'\n-----\nGenerating RSA private key, 2048 bit long modulus (2 primes)\n.............+++++\n....................................+++++\ne is 65537 (0x010001)\nUsing configuration from ./ca.cnf\nCheck that the request matches the signature\nSignature ok\nThe Subject's Distinguished Name is as follows\ncountryName           :PRINTABLE:'CN'\nstateOrProvinceName   :ASN.1 12:'Guangdong'\nlocalityName          :ASN.1 12:'Guangzhou'\norganizationName      :ASN.1 12:'Fishdrowned'\norganizationalUnitName:ASN.1 12:'harbor.local.com'\ncommonName            :ASN.1 12:'*.harbor.local.com\nCertificate is to be certified until Aug 12 10:49:02 2025 GMT (730 days)\n\nWrite out database with 1 new entries\nData Base Updated\n\nCertificates are located in:\nlrwxrwxrwx 1 root root 43 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.bundle.crt -> ./20230813-1849/harbor.local.com.bundle.crt\nlrwxrwxrwx 1 root root 36 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.crt -> ./20230813-1849/harbor.local.com.crt\nlrwxrwxrwx 1 root root 15 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.key.pem -> ../cert.key.pem\nlrwxrwxrwx 1 root root 11 8月  13 18:49 /opt/ssl/out/harbor.local.com/root.crt -> ../root.crt\n\n# 查看证书文件\n[root@tiaoban ssl]# cd out/harbor.local.com/\n[root@tiaoban harbor.local.com]# ll\n总用量 0\ndrwxr-xr-x 2 root root 101 8月  13 18:49 20230813-1849\nlrwxrwxrwx 1 root root  43 8月  13 18:49 harbor.local.com.bundle.crt -> ./20230813-1849/harbor.local.com.bundle.crt\nlrwxrwxrwx 1 root root  36 8月  13 18:49 harbor.local.com.crt -> ./20230813-1849/harbor.local.com.crt\nlrwxrwxrwx 1 root root  15 8月  13 18:49 harbor.local.com.key.pem -> ../cert.key.pem\nlrwxrwxrwx 1 root root  11 8月  13 18:49 root.crt -> ../root.crt\n\n# 拷贝证书至harbor目录\n[root@tiaoban harbor.local.com]# cp harbor.local.com.crt /opt/harbor/\n[root@tiaoban harbor.local.com]# cp harbor.local.com.key.pem /opt/harbor/\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>**\n\n```plain\n[root@harbor ~]# cp harbor.yml.tmpl harbor.yml\n[root@harbor ~]# vim harbor.yml\n# 设置域名\nhostname: harbor.local.com\n# 注释http相关配置\n# http related config\n# http:\n  # port for http, default is 80. If https enabled, this port will redirect to https port\n  # port: 80\n\n# https related config\nhttps:\n  # https port for harbor, default is 443\n  port: 443\n  # The path of cert and key files for nginx\n  certificate: /opt/harbor/harbor.local.com.crt \n  private_key: /opt/harbor/harbor.local.com.key.pem\ndata_volume: /data/harbor\n```\n\n<h2 id=\"2ee20074\"><font style=\"background-color:rgba(255, 255, 255, 0);\">执行安装脚本</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">运行install.sh脚本</font>\n\n```plain\n[root@harbor  harbor]# ./install.sh \n[Step 5]: starting Harbor ...\n[+] Building 0.0s (0/0)                                                                                                                                            \n[+] Running 10/10\n ✔ Network harbor_harbor        Created                                                                                                                       0.3s \n ✔ Container harbor-log         Started                                                                                                                       1.8s \n ✔ Container harbor-portal      Started                                                                                                                      12.8s \n ✔ Container registry           Started                                                                                                                      13.1s \n ✔ Container redis              Started                                                                                                                      13.2s \n ✔ Container registryctl        Started                                                                                                                      11.4s \n ✔ Container harbor-db          Started                                                                                                                      12.0s \n ✔ Container harbor-core        Started                                                                                                                      14.3s \n ✔ Container nginx              Started                                                                                                                      18.2s \n ✔ Container harbor-jobservice  Started                                                                                                                      18.1s \n✔ ----Harbor has been installed and started successfully.----\n```\n\n<h2 id=\"aeb9bb00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问Harbor并登录</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737809926767-7b8f9ce6-e59e-46ea-b7b0-2f4e7dc81375.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">初始用户名admin</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">初始密码Harbor12345</font>\n\n<h2 id=\"a4c4a61c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建systemd服务管理脚本</font></h2>\n---\n\n+ `<font style=\"background-color:rgba(255, 255, 255, 0);\">vim /lib/systemd/system/harbor.service</font>`\n\n```plain\n[Unit]\nDescription=Harbor\nAfter=docker.service systemd-networkd.service systemd-resolved.service\nRequires=docker.service\nDocumentation=http://github.com/vmware/harbor\n\n[Service]\nType=simple\nRestart=on-failure\nRestartSec=5\nExecStart=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml up\nExecReload=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml restart\nExecStop=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml down\n\n[Install]\nWantedBy=multi-user.target\n```\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">systemctl enable harbor --now</font>`\n\n<h1 id=\"a3c8ccc3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">授权访问</font></h1>\n---\n\n<h2 id=\"6cf19b66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker授权访问</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">docker配置文件私有仓库设置  \n</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@master ~]# vim /etc/docker/daemon.json</font>`\n\n```plain\n{\n    \"registry-mirrors\": [\n        \"https://mirror.ccs.tencentyun.com\",\n        \"https://o2j0mc5x.mirror.aliyuncs.com\"\n    ],\n    \"insecure-registries\": [\n        \"https://harbor.local.com\"\n    ]\n}\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">重启docker  \n</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">systemctl daemon-reload</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">   \n</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">systemctl restart docker</font>`\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">master节点登陆测试</font>\n\n```plain\n[root@tiaoban ~]# docker login harbor.local.com -u admin\nPassword: \nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n```\n\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font>\n\n```plain\n[root@tiaoban ~]# docker pull busybox\nUsing default tag: latest\nlatest: Pulling from library/busybox\n5cc84ad355aa: Pull complete \nDigest: sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678\nStatus: Downloaded newer image for busybox:latest\ndocker.io/library/busybox:latest\n[root@tiaoban ~]# docker tag busybox:latest harbor.local.com/library/busybox:latest\n[root@tiaoban ~]# docker push harbor.local.com/library/busybox:latest\nThe push refers to repository [harbor.local.com/library/busybox]\n01fd6df81c8e: Pushed \nlatest: digest: sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee size: 527\n```\n\n<h2 id=\"8731a2b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd授权访问</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n```plain\n[root@master1 ~]# mkdir -p /etc/containerd/certs.d/harbor.local.com\n[root@master1 ~]# cat > /etc/containerd/certs.d/harbor.local.com/hosts.toml << EOF\nserver = \"https://harbor.local.com\"\n[host.\"https://harbor.local.com\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\n  skip_verify = true\nEOF\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">重启containerd</font>\n\n```plain\n[root@master1 ~]# systemctl restart containerd \n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">登录测试</font>\n\n```plain\n[root@master1 ~]# nerdctl login -u admin -p Harbor12345 --insecure-registry harbor.local.com\nWARN[0000] WARNING! Using --password via the CLI is insecure. Use --password-stdin. \nWARN[0000] skipping verifying HTTPS certs for \"harbor.local.com\" \nWARNING: Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n```\n\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font>\n\n```plain\n[root@master1 ~]# nerdctl pull busybox\n[root@master1 ~]# nerdctl tag busybox:latest harbor.local.com/library/busybox:latest\n[root@master1 ~]# nerdctl push --insecure-registry harbor.local.com/library/busybox:latest\n```\n\n<h2 id=\"bd90f437\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernets授权访问</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于harbor采用了用户名密码认证，所以在镜像下载时，如果仓库类型为私有，则需要配置sercet才可以拉取镜像。</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">创建认证secret</font>\n\n```plain\nkubectl create secret docker-registry registry-secret --namespace=default --docker-server=harbor.local.com --docker-username=admin --docker-password=Harbor12345\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">查看secret</font>\n\n```plain\n# kubectl get secrets \nNAME              TYPE                             DATA   AGE\nregistry-secret   kubernetes.io/dockerconfigjson   1      9s\n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">使用相应的私有registry中镜像的Pod资源的定义，即可通过imagePullSecrets字段使用此Secret对象</font>\n\n```plain\n\tapiVersion: v1\n\tkind: Pod \n\tmetadata:\n\t  name: secret-imagepull-demo\n\t  namespace: default\n\tspec:\n\t  imagePullSecrets:\n\t  - name: registry-secret\n\t  containers:\n\t  - image: 192.168.10.14/k8s/nginx:v1\n\t    name: myapp\n```\n\n","source":"_posts/1.部署Harbor私有镜像仓库.md","raw":"---\ntitle: 部署Harbor私有镜像仓库\ndate: 2025-03-11 18:00:00\n---\n\n<h1 id=\"fc12ee52\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署harbor</font></h1>\n---\n\n<h2 id=\"8ee50e07\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载软件包</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker</font>\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker-compose</font>\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">下载harbor离线安装包  \n</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">github仓库软件包下载地址</font>](https://github.com/goharbor/harbor/releases)\n\n```plain\n[root@opt ~]# wget https://github.com/goharbor/harbor/releases/download/v2.11.1/harbor-offline-installer-v2.11.1.tgz\n[root@opt ~]# tar -xvf harbor-offline-installer-v2.11.1.tgz \n```\n\n<h2 id=\"faaccfba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http方式</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">复制配置文件并修改</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n```plain\n[root@harbor ~]# cp harbor.yml.tmpl harbor.yml\n[root@harbor ~]# vim harbor.yml\n# 设置域名\nhostname: harbor.local.com\n# 注释https相关配置\n# http related config\nhttp:\n  # port for http, default is 80. If https enabled, this port will redirect to https port\n  port: 80\n\n# https related config\n#https:\n  # https port for harbor, default is 443\n  #port: 443\n  # The path of cert and key files for nginx\n  #certificate: /your/certificate/path\n  #private_key: /your/private/key/path\n```\n\n<h2 id=\"f1a7433c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https方式(建议)</font></h2>\n---\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">生成自签名证书</font>**\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这里我们使用</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/Fishdrowned/ssl</font>](https://github.com/Fishdrowned/ssl)<font style=\"background-color:rgba(255, 255, 255, 0);\">提供的shell脚本生成ssl证书，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">证书有效期是 2 年，可以修改 ca.cnf 来修改这个年限。</font>\n\n```plain\n# 克隆项目\n[root@tiaoban opt]# git clone https://github.com/Fishdrowned/ssl.git\n# 一键生成证书\n[root@tiaoban opt]# cd ssl\n[root@tiaoban ssl]# ./gen.cert.sh harbor.local.com # 生成harbor.local.com域名的证书\nRemoving dir out\nCreating output structure\nDone\nGenerating a RSA private key\n...................................+++++\n....+++++\nwriting new private key to 'out/root.key.pem'\n-----\nGenerating RSA private key, 2048 bit long modulus (2 primes)\n.............+++++\n....................................+++++\ne is 65537 (0x010001)\nUsing configuration from ./ca.cnf\nCheck that the request matches the signature\nSignature ok\nThe Subject's Distinguished Name is as follows\ncountryName           :PRINTABLE:'CN'\nstateOrProvinceName   :ASN.1 12:'Guangdong'\nlocalityName          :ASN.1 12:'Guangzhou'\norganizationName      :ASN.1 12:'Fishdrowned'\norganizationalUnitName:ASN.1 12:'harbor.local.com'\ncommonName            :ASN.1 12:'*.harbor.local.com\nCertificate is to be certified until Aug 12 10:49:02 2025 GMT (730 days)\n\nWrite out database with 1 new entries\nData Base Updated\n\nCertificates are located in:\nlrwxrwxrwx 1 root root 43 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.bundle.crt -> ./20230813-1849/harbor.local.com.bundle.crt\nlrwxrwxrwx 1 root root 36 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.crt -> ./20230813-1849/harbor.local.com.crt\nlrwxrwxrwx 1 root root 15 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.key.pem -> ../cert.key.pem\nlrwxrwxrwx 1 root root 11 8月  13 18:49 /opt/ssl/out/harbor.local.com/root.crt -> ../root.crt\n\n# 查看证书文件\n[root@tiaoban ssl]# cd out/harbor.local.com/\n[root@tiaoban harbor.local.com]# ll\n总用量 0\ndrwxr-xr-x 2 root root 101 8月  13 18:49 20230813-1849\nlrwxrwxrwx 1 root root  43 8月  13 18:49 harbor.local.com.bundle.crt -> ./20230813-1849/harbor.local.com.bundle.crt\nlrwxrwxrwx 1 root root  36 8月  13 18:49 harbor.local.com.crt -> ./20230813-1849/harbor.local.com.crt\nlrwxrwxrwx 1 root root  15 8月  13 18:49 harbor.local.com.key.pem -> ../cert.key.pem\nlrwxrwxrwx 1 root root  11 8月  13 18:49 root.crt -> ../root.crt\n\n# 拷贝证书至harbor目录\n[root@tiaoban harbor.local.com]# cp harbor.local.com.crt /opt/harbor/\n[root@tiaoban harbor.local.com]# cp harbor.local.com.key.pem /opt/harbor/\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>**\n\n```plain\n[root@harbor ~]# cp harbor.yml.tmpl harbor.yml\n[root@harbor ~]# vim harbor.yml\n# 设置域名\nhostname: harbor.local.com\n# 注释http相关配置\n# http related config\n# http:\n  # port for http, default is 80. If https enabled, this port will redirect to https port\n  # port: 80\n\n# https related config\nhttps:\n  # https port for harbor, default is 443\n  port: 443\n  # The path of cert and key files for nginx\n  certificate: /opt/harbor/harbor.local.com.crt \n  private_key: /opt/harbor/harbor.local.com.key.pem\ndata_volume: /data/harbor\n```\n\n<h2 id=\"2ee20074\"><font style=\"background-color:rgba(255, 255, 255, 0);\">执行安装脚本</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">运行install.sh脚本</font>\n\n```plain\n[root@harbor  harbor]# ./install.sh \n[Step 5]: starting Harbor ...\n[+] Building 0.0s (0/0)                                                                                                                                            \n[+] Running 10/10\n ✔ Network harbor_harbor        Created                                                                                                                       0.3s \n ✔ Container harbor-log         Started                                                                                                                       1.8s \n ✔ Container harbor-portal      Started                                                                                                                      12.8s \n ✔ Container registry           Started                                                                                                                      13.1s \n ✔ Container redis              Started                                                                                                                      13.2s \n ✔ Container registryctl        Started                                                                                                                      11.4s \n ✔ Container harbor-db          Started                                                                                                                      12.0s \n ✔ Container harbor-core        Started                                                                                                                      14.3s \n ✔ Container nginx              Started                                                                                                                      18.2s \n ✔ Container harbor-jobservice  Started                                                                                                                      18.1s \n✔ ----Harbor has been installed and started successfully.----\n```\n\n<h2 id=\"aeb9bb00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问Harbor并登录</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737809926767-7b8f9ce6-e59e-46ea-b7b0-2f4e7dc81375.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">初始用户名admin</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">初始密码Harbor12345</font>\n\n<h2 id=\"a4c4a61c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建systemd服务管理脚本</font></h2>\n---\n\n+ `<font style=\"background-color:rgba(255, 255, 255, 0);\">vim /lib/systemd/system/harbor.service</font>`\n\n```plain\n[Unit]\nDescription=Harbor\nAfter=docker.service systemd-networkd.service systemd-resolved.service\nRequires=docker.service\nDocumentation=http://github.com/vmware/harbor\n\n[Service]\nType=simple\nRestart=on-failure\nRestartSec=5\nExecStart=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml up\nExecReload=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml restart\nExecStop=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml down\n\n[Install]\nWantedBy=multi-user.target\n```\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">systemctl enable harbor --now</font>`\n\n<h1 id=\"a3c8ccc3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">授权访问</font></h1>\n---\n\n<h2 id=\"6cf19b66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker授权访问</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">docker配置文件私有仓库设置  \n</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@master ~]# vim /etc/docker/daemon.json</font>`\n\n```plain\n{\n    \"registry-mirrors\": [\n        \"https://mirror.ccs.tencentyun.com\",\n        \"https://o2j0mc5x.mirror.aliyuncs.com\"\n    ],\n    \"insecure-registries\": [\n        \"https://harbor.local.com\"\n    ]\n}\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">重启docker  \n</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">systemctl daemon-reload</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">   \n</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">systemctl restart docker</font>`\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">master节点登陆测试</font>\n\n```plain\n[root@tiaoban ~]# docker login harbor.local.com -u admin\nPassword: \nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n```\n\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font>\n\n```plain\n[root@tiaoban ~]# docker pull busybox\nUsing default tag: latest\nlatest: Pulling from library/busybox\n5cc84ad355aa: Pull complete \nDigest: sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678\nStatus: Downloaded newer image for busybox:latest\ndocker.io/library/busybox:latest\n[root@tiaoban ~]# docker tag busybox:latest harbor.local.com/library/busybox:latest\n[root@tiaoban ~]# docker push harbor.local.com/library/busybox:latest\nThe push refers to repository [harbor.local.com/library/busybox]\n01fd6df81c8e: Pushed \nlatest: digest: sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee size: 527\n```\n\n<h2 id=\"8731a2b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd授权访问</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n```plain\n[root@master1 ~]# mkdir -p /etc/containerd/certs.d/harbor.local.com\n[root@master1 ~]# cat > /etc/containerd/certs.d/harbor.local.com/hosts.toml << EOF\nserver = \"https://harbor.local.com\"\n[host.\"https://harbor.local.com\"]\n  capabilities = [\"pull\", \"resolve\", \"push\"]\n  skip_verify = true\nEOF\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">重启containerd</font>\n\n```plain\n[root@master1 ~]# systemctl restart containerd \n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">登录测试</font>\n\n```plain\n[root@master1 ~]# nerdctl login -u admin -p Harbor12345 --insecure-registry harbor.local.com\nWARN[0000] WARNING! Using --password via the CLI is insecure. Use --password-stdin. \nWARN[0000] skipping verifying HTTPS certs for \"harbor.local.com\" \nWARNING: Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n```\n\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font>\n\n```plain\n[root@master1 ~]# nerdctl pull busybox\n[root@master1 ~]# nerdctl tag busybox:latest harbor.local.com/library/busybox:latest\n[root@master1 ~]# nerdctl push --insecure-registry harbor.local.com/library/busybox:latest\n```\n\n<h2 id=\"bd90f437\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernets授权访问</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于harbor采用了用户名密码认证，所以在镜像下载时，如果仓库类型为私有，则需要配置sercet才可以拉取镜像。</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">创建认证secret</font>\n\n```plain\nkubectl create secret docker-registry registry-secret --namespace=default --docker-server=harbor.local.com --docker-username=admin --docker-password=Harbor12345\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">查看secret</font>\n\n```plain\n# kubectl get secrets \nNAME              TYPE                             DATA   AGE\nregistry-secret   kubernetes.io/dockerconfigjson   1      9s\n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">使用相应的私有registry中镜像的Pod资源的定义，即可通过imagePullSecrets字段使用此Secret对象</font>\n\n```plain\n\tapiVersion: v1\n\tkind: Pod \n\tmetadata:\n\t  name: secret-imagepull-demo\n\t  namespace: default\n\tspec:\n\t  imagePullSecrets:\n\t  - name: registry-secret\n\t  containers:\n\t  - image: 192.168.10.14/k8s/nginx:v1\n\t    name: myapp\n```\n\n","slug":"1.部署Harbor私有镜像仓库","published":1,"updated":"2025-03-30T13:12:43.237Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjle0005tsv1avhf70xs","content":"<h1 id=\"fc12ee52\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署harbor</font></h1>\n---\n\n<h2 id=\"8ee50e07\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载软件包</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker-compose</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">下载harbor离线安装包<br></font><a href=\"https://github.com/goharbor/harbor/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">github仓库软件包下载地址</font></a></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@opt ~]# wget https://github.com/goharbor/harbor/releases/download/v2.11.1/harbor-offline-installer-v2.11.1.tgz</span><br><span class=\"line\">[root@opt ~]# tar -xvf harbor-offline-installer-v2.11.1.tgz </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"faaccfba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http方式</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">复制配置文件并修改</font></li>\n</ol>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@harbor ~]# cp harbor.yml.tmpl harbor.yml</span><br><span class=\"line\">[root@harbor ~]# vim harbor.yml</span><br><span class=\"line\"># 设置域名</span><br><span class=\"line\">hostname: harbor.local.com</span><br><span class=\"line\"># 注释https相关配置</span><br><span class=\"line\"># http related config</span><br><span class=\"line\">http:</span><br><span class=\"line\">  # port for http, default is 80. If https enabled, this port will redirect to https port</span><br><span class=\"line\">  port: 80</span><br><span class=\"line\"></span><br><span class=\"line\"># https related config</span><br><span class=\"line\">#https:</span><br><span class=\"line\">  # https port for harbor, default is 443</span><br><span class=\"line\">  #port: 443</span><br><span class=\"line\">  # The path of cert and key files for nginx</span><br><span class=\"line\">  #certificate: /your/certificate/path</span><br><span class=\"line\">  #private_key: /your/private/key/path</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f1a7433c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https方式(建议)</font></h2>\n---\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">生成自签名证书</font></strong></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这里我们使用</font><a href=\"https://github.com/Fishdrowned/ssl\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/Fishdrowned/ssl</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">提供的shell脚本生成ssl证书，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">证书有效期是 2 年，可以修改 ca.cnf 来修改这个年限。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 克隆项目</span><br><span class=\"line\">[root@tiaoban opt]# git clone https://github.com/Fishdrowned/ssl.git</span><br><span class=\"line\"># 一键生成证书</span><br><span class=\"line\">[root@tiaoban opt]# cd ssl</span><br><span class=\"line\">[root@tiaoban ssl]# ./gen.cert.sh harbor.local.com # 生成harbor.local.com域名的证书</span><br><span class=\"line\">Removing dir out</span><br><span class=\"line\">Creating output structure</span><br><span class=\"line\">Done</span><br><span class=\"line\">Generating a RSA private key</span><br><span class=\"line\">...................................+++++</span><br><span class=\"line\">....+++++</span><br><span class=\"line\">writing new private key to &#x27;out/root.key.pem&#x27;</span><br><span class=\"line\">-----</span><br><span class=\"line\">Generating RSA private key, 2048 bit long modulus (2 primes)</span><br><span class=\"line\">.............+++++</span><br><span class=\"line\">....................................+++++</span><br><span class=\"line\">e is 65537 (0x010001)</span><br><span class=\"line\">Using configuration from ./ca.cnf</span><br><span class=\"line\">Check that the request matches the signature</span><br><span class=\"line\">Signature ok</span><br><span class=\"line\">The Subject&#x27;s Distinguished Name is as follows</span><br><span class=\"line\">countryName           :PRINTABLE:&#x27;CN&#x27;</span><br><span class=\"line\">stateOrProvinceName   :ASN.1 12:&#x27;Guangdong&#x27;</span><br><span class=\"line\">localityName          :ASN.1 12:&#x27;Guangzhou&#x27;</span><br><span class=\"line\">organizationName      :ASN.1 12:&#x27;Fishdrowned&#x27;</span><br><span class=\"line\">organizationalUnitName:ASN.1 12:&#x27;harbor.local.com&#x27;</span><br><span class=\"line\">commonName            :ASN.1 12:&#x27;*.harbor.local.com</span><br><span class=\"line\">Certificate is to be certified until Aug 12 10:49:02 2025 GMT (730 days)</span><br><span class=\"line\"></span><br><span class=\"line\">Write out database with 1 new entries</span><br><span class=\"line\">Data Base Updated</span><br><span class=\"line\"></span><br><span class=\"line\">Certificates are located in:</span><br><span class=\"line\">lrwxrwxrwx 1 root root 43 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.bundle.crt -&gt; ./20230813-1849/harbor.local.com.bundle.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root 36 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.crt -&gt; ./20230813-1849/harbor.local.com.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root 15 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.key.pem -&gt; ../cert.key.pem</span><br><span class=\"line\">lrwxrwxrwx 1 root root 11 8月  13 18:49 /opt/ssl/out/harbor.local.com/root.crt -&gt; ../root.crt</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看证书文件</span><br><span class=\"line\">[root@tiaoban ssl]# cd out/harbor.local.com/</span><br><span class=\"line\">[root@tiaoban harbor.local.com]# ll</span><br><span class=\"line\">总用量 0</span><br><span class=\"line\">drwxr-xr-x 2 root root 101 8月  13 18:49 20230813-1849</span><br><span class=\"line\">lrwxrwxrwx 1 root root  43 8月  13 18:49 harbor.local.com.bundle.crt -&gt; ./20230813-1849/harbor.local.com.bundle.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root  36 8月  13 18:49 harbor.local.com.crt -&gt; ./20230813-1849/harbor.local.com.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root  15 8月  13 18:49 harbor.local.com.key.pem -&gt; ../cert.key.pem</span><br><span class=\"line\">lrwxrwxrwx 1 root root  11 8月  13 18:49 root.crt -&gt; ../root.crt</span><br><span class=\"line\"></span><br><span class=\"line\"># 拷贝证书至harbor目录</span><br><span class=\"line\">[root@tiaoban harbor.local.com]# cp harbor.local.com.crt /opt/harbor/</span><br><span class=\"line\">[root@tiaoban harbor.local.com]# cp harbor.local.com.key.pem /opt/harbor/</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@harbor ~]# cp harbor.yml.tmpl harbor.yml</span><br><span class=\"line\">[root@harbor ~]# vim harbor.yml</span><br><span class=\"line\"># 设置域名</span><br><span class=\"line\">hostname: harbor.local.com</span><br><span class=\"line\"># 注释http相关配置</span><br><span class=\"line\"># http related config</span><br><span class=\"line\"># http:</span><br><span class=\"line\">  # port for http, default is 80. If https enabled, this port will redirect to https port</span><br><span class=\"line\">  # port: 80</span><br><span class=\"line\"></span><br><span class=\"line\"># https related config</span><br><span class=\"line\">https:</span><br><span class=\"line\">  # https port for harbor, default is 443</span><br><span class=\"line\">  port: 443</span><br><span class=\"line\">  # The path of cert and key files for nginx</span><br><span class=\"line\">  certificate: /opt/harbor/harbor.local.com.crt </span><br><span class=\"line\">  private_key: /opt/harbor/harbor.local.com.key.pem</span><br><span class=\"line\">data_volume: /data/harbor</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2ee20074\"><font style=\"background-color:rgba(255, 255, 255, 0);\">执行安装脚本</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">运行install.sh脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@harbor  harbor]# ./install.sh </span><br><span class=\"line\">[Step 5]: starting Harbor ...</span><br><span class=\"line\">[+] Building 0.0s (0/0)                                                                                                                                            </span><br><span class=\"line\">[+] Running 10/10</span><br><span class=\"line\"> ✔ Network harbor_harbor        Created                                                                                                                       0.3s </span><br><span class=\"line\"> ✔ Container harbor-log         Started                                                                                                                       1.8s </span><br><span class=\"line\"> ✔ Container harbor-portal      Started                                                                                                                      12.8s </span><br><span class=\"line\"> ✔ Container registry           Started                                                                                                                      13.1s </span><br><span class=\"line\"> ✔ Container redis              Started                                                                                                                      13.2s </span><br><span class=\"line\"> ✔ Container registryctl        Started                                                                                                                      11.4s </span><br><span class=\"line\"> ✔ Container harbor-db          Started                                                                                                                      12.0s </span><br><span class=\"line\"> ✔ Container harbor-core        Started                                                                                                                      14.3s </span><br><span class=\"line\"> ✔ Container nginx              Started                                                                                                                      18.2s </span><br><span class=\"line\"> ✔ Container harbor-jobservice  Started                                                                                                                      18.1s </span><br><span class=\"line\">✔ ----Harbor has been installed and started successfully.----</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"aeb9bb00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问Harbor并登录</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737809926767-7b8f9ce6-e59e-46ea-b7b0-2f4e7dc81375.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">初始用户名admin</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">初始密码Harbor12345</font></li>\n</ul>\n<h2 id=\"a4c4a61c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建systemd服务管理脚本</font></h2>\n---\n\n<ul>\n<li><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;vim /lib/systemd/system/harbor.service&lt;/font&gt;</code></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=Harbor</span><br><span class=\"line\">After=docker.service systemd-networkd.service systemd-resolved.service</span><br><span class=\"line\">Requires=docker.service</span><br><span class=\"line\">Documentation=http://github.com/vmware/harbor</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Type=simple</span><br><span class=\"line\">Restart=on-failure</span><br><span class=\"line\">RestartSec=5</span><br><span class=\"line\">ExecStart=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml up</span><br><span class=\"line\">ExecReload=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml restart</span><br><span class=\"line\">ExecStop=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml down</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;systemctl enable harbor --now&lt;/font&gt;</code></p>\n<h1 id=\"a3c8ccc3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">授权访问</font></h1>\n---\n\n<h2 id=\"6cf19b66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker授权访问</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">docker配置文件私有仓库设置<br></font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;[root@master ~]# vim /etc/docker/daemon.json&lt;/font&gt;</code></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;: [</span><br><span class=\"line\">        &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class=\"line\">        &quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;insecure-registries&quot;: [</span><br><span class=\"line\">        &quot;https://harbor.local.com&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">重启docker<br></font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;systemctl daemon-reload&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;systemctl restart docker&lt;/font&gt;</code></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">master节点登陆测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# docker login harbor.local.com -u admin</span><br><span class=\"line\">Password: </span><br><span class=\"line\">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class=\"line\">Configure a credential helper to remove this warning. See</span><br><span class=\"line\">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# docker pull busybox</span><br><span class=\"line\">Using default tag: latest</span><br><span class=\"line\">latest: Pulling from library/busybox</span><br><span class=\"line\">5cc84ad355aa: Pull complete </span><br><span class=\"line\">Digest: sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678</span><br><span class=\"line\">Status: Downloaded newer image for busybox:latest</span><br><span class=\"line\">docker.io/library/busybox:latest</span><br><span class=\"line\">[root@tiaoban ~]# docker tag busybox:latest harbor.local.com/library/busybox:latest</span><br><span class=\"line\">[root@tiaoban ~]# docker push harbor.local.com/library/busybox:latest</span><br><span class=\"line\">The push refers to repository [harbor.local.com/library/busybox]</span><br><span class=\"line\">01fd6df81c8e: Pushed </span><br><span class=\"line\">latest: digest: sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee size: 527</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"8731a2b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd授权访问</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# mkdir -p /etc/containerd/certs.d/harbor.local.com</span><br><span class=\"line\">[root@master1 ~]# cat &gt; /etc/containerd/certs.d/harbor.local.com/hosts.toml &lt;&lt; EOF</span><br><span class=\"line\">server = &quot;https://harbor.local.com&quot;</span><br><span class=\"line\">[host.&quot;https://harbor.local.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;, &quot;push&quot;]</span><br><span class=\"line\">  skip_verify = true</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">重启containerd</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# systemctl restart containerd </span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">登录测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# nerdctl login -u admin -p Harbor12345 --insecure-registry harbor.local.com</span><br><span class=\"line\">WARN[0000] WARNING! Using --password via the CLI is insecure. Use --password-stdin. </span><br><span class=\"line\">WARN[0000] skipping verifying HTTPS certs for &quot;harbor.local.com&quot; </span><br><span class=\"line\">WARNING: Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class=\"line\">Configure a credential helper to remove this warning. See</span><br><span class=\"line\">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# nerdctl pull busybox</span><br><span class=\"line\">[root@master1 ~]# nerdctl tag busybox:latest harbor.local.com/library/busybox:latest</span><br><span class=\"line\">[root@master1 ~]# nerdctl push --insecure-registry harbor.local.com/library/busybox:latest</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"bd90f437\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernets授权访问</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于harbor采用了用户名密码认证，所以在镜像下载时，如果仓库类型为私有，则需要配置sercet才可以拉取镜像。</font></p>\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建认证secret</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create secret docker-registry registry-secret --namespace=default --docker-server=harbor.local.com --docker-username=admin --docker-password=Harbor12345</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看secret</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl get secrets </span><br><span class=\"line\">NAME              TYPE                             DATA   AGE</span><br><span class=\"line\">registry-secret   kubernetes.io/dockerconfigjson   1      9s</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">使用相应的私有registry中镜像的Pod资源的定义，即可通过imagePullSecrets字段使用此Secret对象</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod </span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: secret-imagepull-demo</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  imagePullSecrets:</span><br><span class=\"line\">  - name: registry-secret</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: 192.168.10.14/k8s/nginx:v1</span><br><span class=\"line\">    name: myapp</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<h1 id=\"fc12ee52\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署harbor</font></h1>\n---\n\n<h2 id=\"8ee50e07\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载软件包</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安装docker-compose</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">下载harbor离线安装包<br></font><a href=\"https://github.com/goharbor/harbor/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">github仓库软件包下载地址</font></a></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@opt ~]# wget https://github.com/goharbor/harbor/releases/download/v2.11.1/harbor-offline-installer-v2.11.1.tgz</span><br><span class=\"line\">[root@opt ~]# tar -xvf harbor-offline-installer-v2.11.1.tgz </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"faaccfba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http方式</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">复制配置文件并修改</font></li>\n</ol>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@harbor ~]# cp harbor.yml.tmpl harbor.yml</span><br><span class=\"line\">[root@harbor ~]# vim harbor.yml</span><br><span class=\"line\"># 设置域名</span><br><span class=\"line\">hostname: harbor.local.com</span><br><span class=\"line\"># 注释https相关配置</span><br><span class=\"line\"># http related config</span><br><span class=\"line\">http:</span><br><span class=\"line\">  # port for http, default is 80. If https enabled, this port will redirect to https port</span><br><span class=\"line\">  port: 80</span><br><span class=\"line\"></span><br><span class=\"line\"># https related config</span><br><span class=\"line\">#https:</span><br><span class=\"line\">  # https port for harbor, default is 443</span><br><span class=\"line\">  #port: 443</span><br><span class=\"line\">  # The path of cert and key files for nginx</span><br><span class=\"line\">  #certificate: /your/certificate/path</span><br><span class=\"line\">  #private_key: /your/private/key/path</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f1a7433c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https方式(建议)</font></h2>\n---\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">生成自签名证书</font></strong></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这里我们使用</font><a href=\"https://github.com/Fishdrowned/ssl\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/Fishdrowned/ssl</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">提供的shell脚本生成ssl证书，</font><font style=\"background-color:rgba(255, 255, 255, 0);\">证书有效期是 2 年，可以修改 ca.cnf 来修改这个年限。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 克隆项目</span><br><span class=\"line\">[root@tiaoban opt]# git clone https://github.com/Fishdrowned/ssl.git</span><br><span class=\"line\"># 一键生成证书</span><br><span class=\"line\">[root@tiaoban opt]# cd ssl</span><br><span class=\"line\">[root@tiaoban ssl]# ./gen.cert.sh harbor.local.com # 生成harbor.local.com域名的证书</span><br><span class=\"line\">Removing dir out</span><br><span class=\"line\">Creating output structure</span><br><span class=\"line\">Done</span><br><span class=\"line\">Generating a RSA private key</span><br><span class=\"line\">...................................+++++</span><br><span class=\"line\">....+++++</span><br><span class=\"line\">writing new private key to &#x27;out/root.key.pem&#x27;</span><br><span class=\"line\">-----</span><br><span class=\"line\">Generating RSA private key, 2048 bit long modulus (2 primes)</span><br><span class=\"line\">.............+++++</span><br><span class=\"line\">....................................+++++</span><br><span class=\"line\">e is 65537 (0x010001)</span><br><span class=\"line\">Using configuration from ./ca.cnf</span><br><span class=\"line\">Check that the request matches the signature</span><br><span class=\"line\">Signature ok</span><br><span class=\"line\">The Subject&#x27;s Distinguished Name is as follows</span><br><span class=\"line\">countryName           :PRINTABLE:&#x27;CN&#x27;</span><br><span class=\"line\">stateOrProvinceName   :ASN.1 12:&#x27;Guangdong&#x27;</span><br><span class=\"line\">localityName          :ASN.1 12:&#x27;Guangzhou&#x27;</span><br><span class=\"line\">organizationName      :ASN.1 12:&#x27;Fishdrowned&#x27;</span><br><span class=\"line\">organizationalUnitName:ASN.1 12:&#x27;harbor.local.com&#x27;</span><br><span class=\"line\">commonName            :ASN.1 12:&#x27;*.harbor.local.com</span><br><span class=\"line\">Certificate is to be certified until Aug 12 10:49:02 2025 GMT (730 days)</span><br><span class=\"line\"></span><br><span class=\"line\">Write out database with 1 new entries</span><br><span class=\"line\">Data Base Updated</span><br><span class=\"line\"></span><br><span class=\"line\">Certificates are located in:</span><br><span class=\"line\">lrwxrwxrwx 1 root root 43 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.bundle.crt -&gt; ./20230813-1849/harbor.local.com.bundle.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root 36 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.crt -&gt; ./20230813-1849/harbor.local.com.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root 15 8月  13 18:49 /opt/ssl/out/harbor.local.com/harbor.local.com.key.pem -&gt; ../cert.key.pem</span><br><span class=\"line\">lrwxrwxrwx 1 root root 11 8月  13 18:49 /opt/ssl/out/harbor.local.com/root.crt -&gt; ../root.crt</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看证书文件</span><br><span class=\"line\">[root@tiaoban ssl]# cd out/harbor.local.com/</span><br><span class=\"line\">[root@tiaoban harbor.local.com]# ll</span><br><span class=\"line\">总用量 0</span><br><span class=\"line\">drwxr-xr-x 2 root root 101 8月  13 18:49 20230813-1849</span><br><span class=\"line\">lrwxrwxrwx 1 root root  43 8月  13 18:49 harbor.local.com.bundle.crt -&gt; ./20230813-1849/harbor.local.com.bundle.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root  36 8月  13 18:49 harbor.local.com.crt -&gt; ./20230813-1849/harbor.local.com.crt</span><br><span class=\"line\">lrwxrwxrwx 1 root root  15 8月  13 18:49 harbor.local.com.key.pem -&gt; ../cert.key.pem</span><br><span class=\"line\">lrwxrwxrwx 1 root root  11 8月  13 18:49 root.crt -&gt; ../root.crt</span><br><span class=\"line\"></span><br><span class=\"line\"># 拷贝证书至harbor目录</span><br><span class=\"line\">[root@tiaoban harbor.local.com]# cp harbor.local.com.crt /opt/harbor/</span><br><span class=\"line\">[root@tiaoban harbor.local.com]# cp harbor.local.com.key.pem /opt/harbor/</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@harbor ~]# cp harbor.yml.tmpl harbor.yml</span><br><span class=\"line\">[root@harbor ~]# vim harbor.yml</span><br><span class=\"line\"># 设置域名</span><br><span class=\"line\">hostname: harbor.local.com</span><br><span class=\"line\"># 注释http相关配置</span><br><span class=\"line\"># http related config</span><br><span class=\"line\"># http:</span><br><span class=\"line\">  # port for http, default is 80. If https enabled, this port will redirect to https port</span><br><span class=\"line\">  # port: 80</span><br><span class=\"line\"></span><br><span class=\"line\"># https related config</span><br><span class=\"line\">https:</span><br><span class=\"line\">  # https port for harbor, default is 443</span><br><span class=\"line\">  port: 443</span><br><span class=\"line\">  # The path of cert and key files for nginx</span><br><span class=\"line\">  certificate: /opt/harbor/harbor.local.com.crt </span><br><span class=\"line\">  private_key: /opt/harbor/harbor.local.com.key.pem</span><br><span class=\"line\">data_volume: /data/harbor</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2ee20074\"><font style=\"background-color:rgba(255, 255, 255, 0);\">执行安装脚本</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">运行install.sh脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@harbor  harbor]# ./install.sh </span><br><span class=\"line\">[Step 5]: starting Harbor ...</span><br><span class=\"line\">[+] Building 0.0s (0/0)                                                                                                                                            </span><br><span class=\"line\">[+] Running 10/10</span><br><span class=\"line\"> ✔ Network harbor_harbor        Created                                                                                                                       0.3s </span><br><span class=\"line\"> ✔ Container harbor-log         Started                                                                                                                       1.8s </span><br><span class=\"line\"> ✔ Container harbor-portal      Started                                                                                                                      12.8s </span><br><span class=\"line\"> ✔ Container registry           Started                                                                                                                      13.1s </span><br><span class=\"line\"> ✔ Container redis              Started                                                                                                                      13.2s </span><br><span class=\"line\"> ✔ Container registryctl        Started                                                                                                                      11.4s </span><br><span class=\"line\"> ✔ Container harbor-db          Started                                                                                                                      12.0s </span><br><span class=\"line\"> ✔ Container harbor-core        Started                                                                                                                      14.3s </span><br><span class=\"line\"> ✔ Container nginx              Started                                                                                                                      18.2s </span><br><span class=\"line\"> ✔ Container harbor-jobservice  Started                                                                                                                      18.1s </span><br><span class=\"line\">✔ ----Harbor has been installed and started successfully.----</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"aeb9bb00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问Harbor并登录</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737809926767-7b8f9ce6-e59e-46ea-b7b0-2f4e7dc81375.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">初始用户名admin</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">初始密码Harbor12345</font></li>\n</ul>\n<h2 id=\"a4c4a61c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建systemd服务管理脚本</font></h2>\n---\n\n<ul>\n<li><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;vim /lib/systemd/system/harbor.service&lt;/font&gt;</code></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=Harbor</span><br><span class=\"line\">After=docker.service systemd-networkd.service systemd-resolved.service</span><br><span class=\"line\">Requires=docker.service</span><br><span class=\"line\">Documentation=http://github.com/vmware/harbor</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Type=simple</span><br><span class=\"line\">Restart=on-failure</span><br><span class=\"line\">RestartSec=5</span><br><span class=\"line\">ExecStart=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml up</span><br><span class=\"line\">ExecReload=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml restart</span><br><span class=\"line\">ExecStop=/usr/local/bin/docker-compose -f /opt/harbor/docker-compose.yml down</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;systemctl enable harbor --now&lt;/font&gt;</code></p>\n<h1 id=\"a3c8ccc3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">授权访问</font></h1>\n---\n\n<h2 id=\"6cf19b66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker授权访问</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">docker配置文件私有仓库设置<br></font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;[root@master ~]# vim /etc/docker/daemon.json&lt;/font&gt;</code></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;: [</span><br><span class=\"line\">        &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class=\"line\">        &quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;insecure-registries&quot;: [</span><br><span class=\"line\">        &quot;https://harbor.local.com&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">重启docker<br></font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;systemctl daemon-reload&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;systemctl restart docker&lt;/font&gt;</code></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">master节点登陆测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# docker login harbor.local.com -u admin</span><br><span class=\"line\">Password: </span><br><span class=\"line\">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class=\"line\">Configure a credential helper to remove this warning. See</span><br><span class=\"line\">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# docker pull busybox</span><br><span class=\"line\">Using default tag: latest</span><br><span class=\"line\">latest: Pulling from library/busybox</span><br><span class=\"line\">5cc84ad355aa: Pull complete </span><br><span class=\"line\">Digest: sha256:5acba83a746c7608ed544dc1533b87c737a0b0fb730301639a0179f9344b1678</span><br><span class=\"line\">Status: Downloaded newer image for busybox:latest</span><br><span class=\"line\">docker.io/library/busybox:latest</span><br><span class=\"line\">[root@tiaoban ~]# docker tag busybox:latest harbor.local.com/library/busybox:latest</span><br><span class=\"line\">[root@tiaoban ~]# docker push harbor.local.com/library/busybox:latest</span><br><span class=\"line\">The push refers to repository [harbor.local.com/library/busybox]</span><br><span class=\"line\">01fd6df81c8e: Pushed </span><br><span class=\"line\">latest: digest: sha256:62ffc2ed7554e4c6d360bce40bbcf196573dd27c4ce080641a2c59867e732dee size: 527</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"8731a2b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd授权访问</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# mkdir -p /etc/containerd/certs.d/harbor.local.com</span><br><span class=\"line\">[root@master1 ~]# cat &gt; /etc/containerd/certs.d/harbor.local.com/hosts.toml &lt;&lt; EOF</span><br><span class=\"line\">server = &quot;https://harbor.local.com&quot;</span><br><span class=\"line\">[host.&quot;https://harbor.local.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;, &quot;push&quot;]</span><br><span class=\"line\">  skip_verify = true</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">重启containerd</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# systemctl restart containerd </span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">登录测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# nerdctl login -u admin -p Harbor12345 --insecure-registry harbor.local.com</span><br><span class=\"line\">WARN[0000] WARNING! Using --password via the CLI is insecure. Use --password-stdin. </span><br><span class=\"line\">WARN[0000] skipping verifying HTTPS certs for &quot;harbor.local.com&quot; </span><br><span class=\"line\">WARNING: Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class=\"line\">Configure a credential helper to remove this warning. See</span><br><span class=\"line\">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">推送镜像测试</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# nerdctl pull busybox</span><br><span class=\"line\">[root@master1 ~]# nerdctl tag busybox:latest harbor.local.com/library/busybox:latest</span><br><span class=\"line\">[root@master1 ~]# nerdctl push --insecure-registry harbor.local.com/library/busybox:latest</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"bd90f437\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernets授权访问</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于harbor采用了用户名密码认证，所以在镜像下载时，如果仓库类型为私有，则需要配置sercet才可以拉取镜像。</font></p>\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建认证secret</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl create secret docker-registry registry-secret --namespace=default --docker-server=harbor.local.com --docker-username=admin --docker-password=Harbor12345</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看secret</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl get secrets </span><br><span class=\"line\">NAME              TYPE                             DATA   AGE</span><br><span class=\"line\">registry-secret   kubernetes.io/dockerconfigjson   1      9s</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">使用相应的私有registry中镜像的Pod资源的定义，即可通过imagePullSecrets字段使用此Secret对象</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod </span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: secret-imagepull-demo</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  imagePullSecrets:</span><br><span class=\"line\">  - name: registry-secret</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: 192.168.10.14/k8s/nginx:v1</span><br><span class=\"line\">    name: myapp</span><br></pre></td></tr></table></figure>\n\n"},{"title":"配置环境(RHEL)","date":"2025-03-11T10:00:00.000Z","_content":"> 如果操作系统环境为CentOS、Red Hat、Rocky Linux、Alma Linux、Fedora等RHEL系列操作系统，使用以下步骤操作。\n>\n\n\n\n<h1 id=\"pDB2G\">基础环境配置（所有节点）</h1>\n---\n\n<h2 id=\"Rd2qp\">修改主机名与hosts文件</h2>\n---\n\n```shell\n[root@k8s-master ~]# hostnamectl set-hostname k8s-master\n\n[root@k8s-master ~]# vim /etc/hosts\n192.168.10.10   k8s-master\n192.168.10.11   k8s-work1\n192.168.10.12   k8s-work2\n192.168.10.15   k8s-harbor\n```\n\n\n\n<h2 id=\"cl7ee\">验证mac地址uuid</h2>\n---\n\n保证各节点mac和uuid唯一，避免克隆虚拟机后uuid一致导致加入集群异常。\n\n\n\n```shell\n[root@k8s-master ~]# cat /sys/class/net/ens160/address \n[root@k8s-master ~]# cat /sys/class/dmi/id/product_uuid \n```\n\n\n\n<h2 id=\"AjRJW\">时间同步</h2>\n---\n\n+ master节点设置\n\n```shell\n[root@k8s-master ~]# dnf -y install chrony\n[root@k8s-master ~]# vim /etc/chrony.conf\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver ntp.aliyun.com iburst\n\n# Allow NTP client access from local network.\n#allow 192.168.10.0/24\n\n[root@k8s-master ~]# systemctl start chronyd\n[root@k8s-master ~]# systemctl enable chronyd\n[root@k8s-master ~]# timedatectl set-timezone Asia/Shanghai\n[root@k8s-master ~]# chronyc sources\n210 Number of sources = 4\nMS Name/IP address         Stratum Poll Reach LastRx Last sample               \n===============================================================================\n^* 202.118.1.81                  1   6   357   100   +124us[ +205us] +/- 7213us\n^? 2a01:4f8:120:9224::2          0   6     0     -     +0ns[   +0ns] +/-    0ns\n^+ 202.118.1.130                 1   6   316   184    -29us[  +33us] +/- 7479us\n^- 119.28.206.193                2   6   316   192    +13ms[  +13ms] +/-   44ms\n[root@k8s-master ~]#\n```\n\n\n\n+ node节点配置\n\n```shell\n[root@node1  ~]# yum -y install chrony  \n[root@node1  ~]# vim /etc/chrony.conf\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver 192.168.10.100\n\n[root@node1  ~]# systemctl start chronyd  \n[root@node1  ~]# systemctl enable chronyd  \n[root@node1  ~]# chronyc sources\n```\n\n\n\n<h2 id=\"wLAgk\">设置防火墙规则</h2>\n---\n\n```shell\n[root@master  ~]# systemctl stop firewalld  \n[root@master  ~]# systemctl disable firewalld  \n[root@master  ~]# yum -y install iptables-services  \n[root@master  ~]# systemctl start iptables  \n[root@master  ~]# systemctl enable iptables  \n[root@master  ~]# iptables -F \n[root@master  ~]# service iptables save \n```\n\n\n\n<h2 id=\"KUlJ1\">关闭selinux</h2>\n---\n\n```shell\n[root@master  ~]# setenforce 0  \n[root@master  ~]# sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config \n```\n\n\n\n<h2 id=\"wyG8q\">关闭swap分区</h2>\n---\n\n```shell\n[root@master  ~]# swapoff -a  \n[root@master  ~]# sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab  \n```\n\n\n\n<h1 id=\"MXkxb\">其他配置（所有节点）</h1>\n---\n\n<h2 id=\"wMId3\">修改内核相关参数</h2>\n---\n\nvm.swappiness = 0 # 最大限度避免使用 swap\n\nnet.bridge.bridge-nf-call-ip6tables = 1 # 内核在桥接设备上让IPv6流量经过 Netfilter（iptables）过滤。\n\nnet.bridge.bridge-nf-call-iptables = 1 # 内核在桥接设备上让IPv4流量经过 Netfilter（iptables）过滤。\n\nnet.ipv4.ip_forward = 1 # 允许 IPv4 数据包从一个网络接口转发到另一个网络接口。\n\n```shell\n[root@master  ~]# cat > /etc/sysctl.d/kubernetes.conf << EOF\nvm.swappiness = 0 \nnet.bridge.bridge-nf-call-ip6tables = 1  \nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1 \nEOF\n[root@master  ~]# sysctl -p /etc/sysctl.d/kubernetes.conf \n```\n\n\n\n    - centos8会有如下报错\n\n```shell\nvm.swappiness = 0\nsysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: 没有那个文件或目录\nsysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: 没有那个文件或目录\nnet.ipv4.ip_forward = 1\n```\n\n+ 临时解决，重启失效  \nmodprobe br_netfilter\n+ 开机加载上面这个模块\n\n```shell\n[root@master  ~]# cat > /etc/rc.sysinit << EOF\n#!/bin/bash\nfor file in /etc/sysconfig/modules/*.modules ; do\n[ -x $file ] && $file\ndone\nEOF\n[root@master  ~]# cat > /etc/sysconfig/modules/br_netfilter.modules << EOF\nmodprobe br_netfilter # 通过 br_netfilter，内核能够让网络包在经过桥接设备时被 iptables 规则处理\nEOF\n[root@master  ~]# chmod 755 /etc/sysconfig/modules/br_netfilter.modules \n[root@master  ~]# lsmod |grep br_netfilter\nbr_netfilter           24576  0\nbridge                290816  1 br_netfilter\n```\n\n<h2 id=\"e6VbR\">kube-proxy开启ipvs的前置条件</h2>\n---\n\n```shell\n[root@k8s-master ~]# yum -y install ipset ipvsadm\n[root@k8s-master ~]# cat > /etc/sysconfig/modules/ipvs.modules <<EOF \n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\nEOF\n[root@k8s-master ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules && bash  \n[root@k8s-master ~]# /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack \nip_vs_sh               16384  0\nip_vs_wrr              16384  0\nip_vs_rr               16384  0\nip_vs                 172032  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr\nnf_conntrack          172032  1 ip_vs\nnf_defrag_ipv6         20480  2 nf_conntrack,ip_vs\nnf_defrag_ipv4         16384  1 nf_conntrack\nlibcrc32c              16384  4 nf_conntrack,nf_tables,xfs,ip_vs\n# 添加开机自动加载模块\n[root@k8s-master ~]# echo \"/etc/sysconfig/modules/ipvs.modules\" >> /etc/rc.local\n[root@k8s-master ~]# chmod +x /etc/rc.local\n# 启用网桥过滤器模块\n[root@k8s-master ~]# echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables\n[root@k8s-master ~]# echo 1 > /proc/sys/net/ipv4/ip_forward\n```\n\n\n\n+ linux kernel 4.19版本已经将nf_conntrack_ipv4 更新为 nf_conntrack\n\n\n\n<h2 id=\"oQzak\">升级内核</h2>\n---\n\n可选，建议4.18及+以上即可\n\n```shell\n载入公钥\n[root@master  ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org \n升级安装ELRepo\n[root@master  ~]# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm \n如果是centos8使用如下命令\n[root@master  ~]#yum install https://www.elrepo.org/elrepo-release-8.0-2.el8.elrepo.noarch.rpm \n载入elrepo-kernel元数据\n[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel repolist \n安装最新版本的kernel\n[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml.x86_64 -y \n删除旧版本工具包\n[root@master  ~]# yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 -y \n安装新版本工具包\n[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml-tools.x86_64 -y \n查看内核插入顺序\n[root@server-1  ~]# awk -F \\' '$1==\"menuentry \" {print i++ \" : \" $2}'  /etc/grub2.cfg \n设置默认启动\n[root@server-1  ~]# grub2-set-default 0 // 0代表当前第一行，也就是5.3版本  \n[root@server-1  ~]# grub2-editenv list  \n重启验证\n```\n\n\n\n<h2 id=\"ArqRC\">配置阿里云yum源</h2>\n---\n\nk8s版本1.28前，使用如下命令配置yum源。\n\n```shell\n[root@k8s-master ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\nk8s版本1.28以后，例如安装1.30，则修改对应的版本号即可。\n\n```shell\n[root@k8s-master ~]# cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/repodata/repomd.xml.key\nEOF\n```\n\n<h2 id=\"VaLKH\">安装kubeadm、kubectl、kubelet</h2>\n---\n\n```shell\nyum install -y kubelet kubeadm kubectl\nsystemctl enable kubelet\nsystemctl start kubelet\n```\n\nkubelet 运行在集群所有节点上，用于启动Pod和容器等对象的工具  \nkubeadm 用于初始化集群，启动集群的命令工具  \nkubectl 用于和集群通信的命令行，通过kubectl可以部署和管理应用，查看各种资源，创建、删除和更新各种组件\n\n+ 默认安装最新版，也可以指定老版本安装\n\n```shell\nyum list kubeadm --showduplicates | sort -r\nyum install -y kubelet-1.24.13 kubeadm-1.24.13 kubectl-1.24.13\n```\n\n\n\n","source":"_posts/1.配置环境(RHEL).md","raw":"---\ntitle: 配置环境(RHEL)\ndate: 2025-03-11 18:00:00\n---\n> 如果操作系统环境为CentOS、Red Hat、Rocky Linux、Alma Linux、Fedora等RHEL系列操作系统，使用以下步骤操作。\n>\n\n\n\n<h1 id=\"pDB2G\">基础环境配置（所有节点）</h1>\n---\n\n<h2 id=\"Rd2qp\">修改主机名与hosts文件</h2>\n---\n\n```shell\n[root@k8s-master ~]# hostnamectl set-hostname k8s-master\n\n[root@k8s-master ~]# vim /etc/hosts\n192.168.10.10   k8s-master\n192.168.10.11   k8s-work1\n192.168.10.12   k8s-work2\n192.168.10.15   k8s-harbor\n```\n\n\n\n<h2 id=\"cl7ee\">验证mac地址uuid</h2>\n---\n\n保证各节点mac和uuid唯一，避免克隆虚拟机后uuid一致导致加入集群异常。\n\n\n\n```shell\n[root@k8s-master ~]# cat /sys/class/net/ens160/address \n[root@k8s-master ~]# cat /sys/class/dmi/id/product_uuid \n```\n\n\n\n<h2 id=\"AjRJW\">时间同步</h2>\n---\n\n+ master节点设置\n\n```shell\n[root@k8s-master ~]# dnf -y install chrony\n[root@k8s-master ~]# vim /etc/chrony.conf\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver ntp.aliyun.com iburst\n\n# Allow NTP client access from local network.\n#allow 192.168.10.0/24\n\n[root@k8s-master ~]# systemctl start chronyd\n[root@k8s-master ~]# systemctl enable chronyd\n[root@k8s-master ~]# timedatectl set-timezone Asia/Shanghai\n[root@k8s-master ~]# chronyc sources\n210 Number of sources = 4\nMS Name/IP address         Stratum Poll Reach LastRx Last sample               \n===============================================================================\n^* 202.118.1.81                  1   6   357   100   +124us[ +205us] +/- 7213us\n^? 2a01:4f8:120:9224::2          0   6     0     -     +0ns[   +0ns] +/-    0ns\n^+ 202.118.1.130                 1   6   316   184    -29us[  +33us] +/- 7479us\n^- 119.28.206.193                2   6   316   192    +13ms[  +13ms] +/-   44ms\n[root@k8s-master ~]#\n```\n\n\n\n+ node节点配置\n\n```shell\n[root@node1  ~]# yum -y install chrony  \n[root@node1  ~]# vim /etc/chrony.conf\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver 192.168.10.100\n\n[root@node1  ~]# systemctl start chronyd  \n[root@node1  ~]# systemctl enable chronyd  \n[root@node1  ~]# chronyc sources\n```\n\n\n\n<h2 id=\"wLAgk\">设置防火墙规则</h2>\n---\n\n```shell\n[root@master  ~]# systemctl stop firewalld  \n[root@master  ~]# systemctl disable firewalld  \n[root@master  ~]# yum -y install iptables-services  \n[root@master  ~]# systemctl start iptables  \n[root@master  ~]# systemctl enable iptables  \n[root@master  ~]# iptables -F \n[root@master  ~]# service iptables save \n```\n\n\n\n<h2 id=\"KUlJ1\">关闭selinux</h2>\n---\n\n```shell\n[root@master  ~]# setenforce 0  \n[root@master  ~]# sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config \n```\n\n\n\n<h2 id=\"wyG8q\">关闭swap分区</h2>\n---\n\n```shell\n[root@master  ~]# swapoff -a  \n[root@master  ~]# sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab  \n```\n\n\n\n<h1 id=\"MXkxb\">其他配置（所有节点）</h1>\n---\n\n<h2 id=\"wMId3\">修改内核相关参数</h2>\n---\n\nvm.swappiness = 0 # 最大限度避免使用 swap\n\nnet.bridge.bridge-nf-call-ip6tables = 1 # 内核在桥接设备上让IPv6流量经过 Netfilter（iptables）过滤。\n\nnet.bridge.bridge-nf-call-iptables = 1 # 内核在桥接设备上让IPv4流量经过 Netfilter（iptables）过滤。\n\nnet.ipv4.ip_forward = 1 # 允许 IPv4 数据包从一个网络接口转发到另一个网络接口。\n\n```shell\n[root@master  ~]# cat > /etc/sysctl.d/kubernetes.conf << EOF\nvm.swappiness = 0 \nnet.bridge.bridge-nf-call-ip6tables = 1  \nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1 \nEOF\n[root@master  ~]# sysctl -p /etc/sysctl.d/kubernetes.conf \n```\n\n\n\n    - centos8会有如下报错\n\n```shell\nvm.swappiness = 0\nsysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: 没有那个文件或目录\nsysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: 没有那个文件或目录\nnet.ipv4.ip_forward = 1\n```\n\n+ 临时解决，重启失效  \nmodprobe br_netfilter\n+ 开机加载上面这个模块\n\n```shell\n[root@master  ~]# cat > /etc/rc.sysinit << EOF\n#!/bin/bash\nfor file in /etc/sysconfig/modules/*.modules ; do\n[ -x $file ] && $file\ndone\nEOF\n[root@master  ~]# cat > /etc/sysconfig/modules/br_netfilter.modules << EOF\nmodprobe br_netfilter # 通过 br_netfilter，内核能够让网络包在经过桥接设备时被 iptables 规则处理\nEOF\n[root@master  ~]# chmod 755 /etc/sysconfig/modules/br_netfilter.modules \n[root@master  ~]# lsmod |grep br_netfilter\nbr_netfilter           24576  0\nbridge                290816  1 br_netfilter\n```\n\n<h2 id=\"e6VbR\">kube-proxy开启ipvs的前置条件</h2>\n---\n\n```shell\n[root@k8s-master ~]# yum -y install ipset ipvsadm\n[root@k8s-master ~]# cat > /etc/sysconfig/modules/ipvs.modules <<EOF \n#!/bin/bash\nmodprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\nEOF\n[root@k8s-master ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules && bash  \n[root@k8s-master ~]# /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack \nip_vs_sh               16384  0\nip_vs_wrr              16384  0\nip_vs_rr               16384  0\nip_vs                 172032  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr\nnf_conntrack          172032  1 ip_vs\nnf_defrag_ipv6         20480  2 nf_conntrack,ip_vs\nnf_defrag_ipv4         16384  1 nf_conntrack\nlibcrc32c              16384  4 nf_conntrack,nf_tables,xfs,ip_vs\n# 添加开机自动加载模块\n[root@k8s-master ~]# echo \"/etc/sysconfig/modules/ipvs.modules\" >> /etc/rc.local\n[root@k8s-master ~]# chmod +x /etc/rc.local\n# 启用网桥过滤器模块\n[root@k8s-master ~]# echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables\n[root@k8s-master ~]# echo 1 > /proc/sys/net/ipv4/ip_forward\n```\n\n\n\n+ linux kernel 4.19版本已经将nf_conntrack_ipv4 更新为 nf_conntrack\n\n\n\n<h2 id=\"oQzak\">升级内核</h2>\n---\n\n可选，建议4.18及+以上即可\n\n```shell\n载入公钥\n[root@master  ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org \n升级安装ELRepo\n[root@master  ~]# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm \n如果是centos8使用如下命令\n[root@master  ~]#yum install https://www.elrepo.org/elrepo-release-8.0-2.el8.elrepo.noarch.rpm \n载入elrepo-kernel元数据\n[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel repolist \n安装最新版本的kernel\n[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml.x86_64 -y \n删除旧版本工具包\n[root@master  ~]# yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 -y \n安装新版本工具包\n[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml-tools.x86_64 -y \n查看内核插入顺序\n[root@server-1  ~]# awk -F \\' '$1==\"menuentry \" {print i++ \" : \" $2}'  /etc/grub2.cfg \n设置默认启动\n[root@server-1  ~]# grub2-set-default 0 // 0代表当前第一行，也就是5.3版本  \n[root@server-1  ~]# grub2-editenv list  \n重启验证\n```\n\n\n\n<h2 id=\"ArqRC\">配置阿里云yum源</h2>\n---\n\nk8s版本1.28前，使用如下命令配置yum源。\n\n```shell\n[root@k8s-master ~]# cat <<EOF > /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\nk8s版本1.28以后，例如安装1.30，则修改对应的版本号即可。\n\n```shell\n[root@k8s-master ~]# cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/repodata/repomd.xml.key\nEOF\n```\n\n<h2 id=\"VaLKH\">安装kubeadm、kubectl、kubelet</h2>\n---\n\n```shell\nyum install -y kubelet kubeadm kubectl\nsystemctl enable kubelet\nsystemctl start kubelet\n```\n\nkubelet 运行在集群所有节点上，用于启动Pod和容器等对象的工具  \nkubeadm 用于初始化集群，启动集群的命令工具  \nkubectl 用于和集群通信的命令行，通过kubectl可以部署和管理应用，查看各种资源，创建、删除和更新各种组件\n\n+ 默认安装最新版，也可以指定老版本安装\n\n```shell\nyum list kubeadm --showduplicates | sort -r\nyum install -y kubelet-1.24.13 kubeadm-1.24.13 kubectl-1.24.13\n```\n\n\n\n","slug":"1.配置环境(RHEL)","published":1,"updated":"2025-03-30T13:09:06.407Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlf0006tsv1dcl3fb6f","content":"<blockquote>\n<p>如果操作系统环境为CentOS、Red Hat、Rocky Linux、Alma Linux、Fedora等RHEL系列操作系统，使用以下步骤操作。</p>\n</blockquote>\n<h1 id=\"pDB2G\">基础环境配置（所有节点）</h1>\n---\n\n<h2 id=\"Rd2qp\">修改主机名与hosts文件</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# hostnamectl set-hostname k8s-master</span><br><span class=\"line\"></span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/hosts</span><br><span class=\"line\">192.168.10.10   k8s-master</span><br><span class=\"line\">192.168.10.11   k8s-work1</span><br><span class=\"line\">192.168.10.12   k8s-work2</span><br><span class=\"line\">192.168.10.15   k8s-harbor</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"cl7ee\">验证mac地址uuid</h2>\n---\n\n<p>保证各节点mac和uuid唯一，避免克隆虚拟机后uuid一致导致加入集群异常。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# cat /sys/class/net/ens160/address </span><br><span class=\"line\">[root@k8s-master ~]# cat /sys/class/dmi/id/product_uuid </span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"AjRJW\">时间同步</h2>\n---\n\n<ul>\n<li>master节点设置</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# dnf -y install chrony</span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/chrony.conf</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Use public servers from the pool.ntp.org project.</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class=\"line\">server ntp.aliyun.com iburst</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Allow NTP client access from <span class=\"built_in\">local</span> network.</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">allow 192.168.10.0/24</span></span><br><span class=\"line\"></span><br><span class=\"line\">[root@k8s-master ~]# systemctl start chronyd</span><br><span class=\"line\">[root@k8s-master ~]# systemctl enable chronyd</span><br><span class=\"line\">[root@k8s-master ~]# timedatectl set-timezone Asia/Shanghai</span><br><span class=\"line\">[root@k8s-master ~]# chronyc sources</span><br><span class=\"line\">210 Number of sources = 4</span><br><span class=\"line\">MS Name/IP address         Stratum Poll Reach LastRx Last sample               </span><br><span class=\"line\">===============================================================================</span><br><span class=\"line\">^* 202.118.1.81                  1   6   357   100   +124us[ +205us] +/- 7213us</span><br><span class=\"line\">^? 2a01:4f8:120:9224::2          0   6     0     -     +0ns[   +0ns] +/-    0ns</span><br><span class=\"line\">^+ 202.118.1.130                 1   6   316   184    -29us[  +33us] +/- 7479us</span><br><span class=\"line\">^- 119.28.206.193                2   6   316   192    +13ms[  +13ms] +/-   44ms</span><br><span class=\"line\">[root@k8s-master ~]#</span><br></pre></td></tr></table></figure>\n\n\n\n<ul>\n<li>node节点配置</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@node1  ~]# yum -y install chrony  </span><br><span class=\"line\">[root@node1  ~]# vim /etc/chrony.conf</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Use public servers from the pool.ntp.org project.</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class=\"line\">server 192.168.10.100</span><br><span class=\"line\"></span><br><span class=\"line\">[root@node1  ~]# systemctl start chronyd  </span><br><span class=\"line\">[root@node1  ~]# systemctl enable chronyd  </span><br><span class=\"line\">[root@node1  ~]# chronyc sources</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"wLAgk\">设置防火墙规则</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# systemctl stop firewalld  </span><br><span class=\"line\">[root@master  ~]# systemctl disable firewalld  </span><br><span class=\"line\">[root@master  ~]# yum -y install iptables-services  </span><br><span class=\"line\">[root@master  ~]# systemctl start iptables  </span><br><span class=\"line\">[root@master  ~]# systemctl enable iptables  </span><br><span class=\"line\">[root@master  ~]# iptables -F </span><br><span class=\"line\">[root@master  ~]# service iptables save </span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"KUlJ1\">关闭selinux</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# setenforce 0  </span><br><span class=\"line\">[root@master  ~]# sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27; /etc/selinux/config </span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"wyG8q\">关闭swap分区</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# swapoff -a  </span><br><span class=\"line\">[root@master  ~]# sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab  </span><br></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"MXkxb\">其他配置（所有节点）</h1>\n---\n\n<h2 id=\"wMId3\">修改内核相关参数</h2>\n---\n\n<p>vm.swappiness &#x3D; 0 # 最大限度避免使用 swap</p>\n<p>net.bridge.bridge-nf-call-ip6tables &#x3D; 1 # 内核在桥接设备上让IPv6流量经过 Netfilter（iptables）过滤。</p>\n<p>net.bridge.bridge-nf-call-iptables &#x3D; 1 # 内核在桥接设备上让IPv4流量经过 Netfilter（iptables）过滤。</p>\n<p>net.ipv4.ip_forward &#x3D; 1 # 允许 IPv4 数据包从一个网络接口转发到另一个网络接口。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF</span><br><span class=\"line\">vm.swappiness = 0 </span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1  </span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">net.ipv4.ip_forward = 1 </span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master  ~]# sysctl -p /etc/sysctl.d/kubernetes.conf </span><br></pre></td></tr></table></figure>\n\n\n\n<pre><code>- centos8会有如下报错\n</code></pre>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vm.swappiness = 0</span><br><span class=\"line\">sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: 没有那个文件或目录</span><br><span class=\"line\">sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: 没有那个文件或目录</span><br><span class=\"line\">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>临时解决，重启失效<br>modprobe br_netfilter</li>\n<li>开机加载上面这个模块</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# cat &gt; /etc/rc.sysinit &lt;&lt; EOF</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">!/bin/bash</span></span><br><span class=\"line\">for file in /etc/sysconfig/modules/*.modules ; do</span><br><span class=\"line\">[ -x $file ] &amp;&amp; $file</span><br><span class=\"line\">done</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master  ~]# cat &gt; /etc/sysconfig/modules/br_netfilter.modules &lt;&lt; EOF</span><br><span class=\"line\">modprobe br_netfilter # 通过 br_netfilter，内核能够让网络包在经过桥接设备时被 iptables 规则处理</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master  ~]# chmod 755 /etc/sysconfig/modules/br_netfilter.modules </span><br><span class=\"line\">[root@master  ~]# lsmod |grep br_netfilter</span><br><span class=\"line\">br_netfilter           24576  0</span><br><span class=\"line\">bridge                290816  1 br_netfilter</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e6VbR\">kube-proxy开启ipvs的前置条件</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# yum -y install ipset ipvsadm</span><br><span class=\"line\">[root@k8s-master ~]# cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF </span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">!/bin/bash</span></span><br><span class=\"line\">modprobe -- ip_vs</span><br><span class=\"line\">modprobe -- ip_vs_rr</span><br><span class=\"line\">modprobe -- ip_vs_wrr</span><br><span class=\"line\">modprobe -- ip_vs_sh</span><br><span class=\"line\">modprobe -- nf_conntrack</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash  </span><br><span class=\"line\">[root@k8s-master ~]# /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack </span><br><span class=\"line\">ip_vs_sh               16384  0</span><br><span class=\"line\">ip_vs_wrr              16384  0</span><br><span class=\"line\">ip_vs_rr               16384  0</span><br><span class=\"line\">ip_vs                 172032  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class=\"line\">nf_conntrack          172032  1 ip_vs</span><br><span class=\"line\">nf_defrag_ipv6         20480  2 nf_conntrack,ip_vs</span><br><span class=\"line\">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class=\"line\">libcrc32c              16384  4 nf_conntrack,nf_tables,xfs,ip_vs</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">添加开机自动加载模块</span></span><br><span class=\"line\">[root@k8s-master ~]# echo &quot;/etc/sysconfig/modules/ipvs.modules&quot; &gt;&gt; /etc/rc.local</span><br><span class=\"line\">[root@k8s-master ~]# chmod +x /etc/rc.local</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">启用网桥过滤器模块</span></span><br><span class=\"line\">[root@k8s-master ~]# echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</span><br><span class=\"line\">[root@k8s-master ~]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure>\n\n\n\n<ul>\n<li>linux kernel 4.19版本已经将nf_conntrack_ipv4 更新为 nf_conntrack</li>\n</ul>\n<h2 id=\"oQzak\">升级内核</h2>\n---\n\n<p>可选，建议4.18及+以上即可</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">载入公钥</span><br><span class=\"line\">[root@master  ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org </span><br><span class=\"line\">升级安装ELRepo</span><br><span class=\"line\">[root@master  ~]# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm </span><br><span class=\"line\">如果是centos8使用如下命令</span><br><span class=\"line\">[root@master  ~]#yum install https://www.elrepo.org/elrepo-release-8.0-2.el8.elrepo.noarch.rpm </span><br><span class=\"line\">载入elrepo-kernel元数据</span><br><span class=\"line\">[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel repolist </span><br><span class=\"line\">安装最新版本的kernel</span><br><span class=\"line\">[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml.x86_64 -y </span><br><span class=\"line\">删除旧版本工具包</span><br><span class=\"line\">[root@master  ~]# yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 -y </span><br><span class=\"line\">安装新版本工具包</span><br><span class=\"line\">[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml-tools.x86_64 -y </span><br><span class=\"line\">查看内核插入顺序</span><br><span class=\"line\">[root@server-1  ~]# awk -F \\&#x27; &#x27;$1==&quot;menuentry &quot; &#123;print i++ &quot; : &quot; $2&#125;&#x27;  /etc/grub2.cfg </span><br><span class=\"line\">设置默认启动</span><br><span class=\"line\">[root@server-1  ~]# grub2-set-default 0 // 0代表当前第一行，也就是5.3版本  </span><br><span class=\"line\">[root@server-1  ~]# grub2-editenv list  </span><br><span class=\"line\">重启验证</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"ArqRC\">配置阿里云yum源</h2>\n---\n\n<p>k8s版本1.28前，使用如下命令配置yum源。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p>k8s版本1.28以后，例如安装1.30，则修改对应的版本号即可。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# cat &lt;&lt;EOF | tee /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/repodata/repomd.xml.key</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"VaLKH\">安装kubeadm、kubectl、kubelet</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y kubelet kubeadm kubectl</span><br><span class=\"line\">systemctl enable kubelet</span><br><span class=\"line\">systemctl start kubelet</span><br></pre></td></tr></table></figure>\n\n<p>kubelet 运行在集群所有节点上，用于启动Pod和容器等对象的工具<br>kubeadm 用于初始化集群，启动集群的命令工具<br>kubectl 用于和集群通信的命令行，通过kubectl可以部署和管理应用，查看各种资源，创建、删除和更新各种组件</p>\n<ul>\n<li>默认安装最新版，也可以指定老版本安装</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum list kubeadm --showduplicates | sort -r</span><br><span class=\"line\">yum install -y kubelet-1.24.13 kubeadm-1.24.13 kubectl-1.24.13</span><br></pre></td></tr></table></figure>\n\n\n\n","excerpt":"","more":"<blockquote>\n<p>如果操作系统环境为CentOS、Red Hat、Rocky Linux、Alma Linux、Fedora等RHEL系列操作系统，使用以下步骤操作。</p>\n</blockquote>\n<h1 id=\"pDB2G\">基础环境配置（所有节点）</h1>\n---\n\n<h2 id=\"Rd2qp\">修改主机名与hosts文件</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# hostnamectl set-hostname k8s-master</span><br><span class=\"line\"></span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/hosts</span><br><span class=\"line\">192.168.10.10   k8s-master</span><br><span class=\"line\">192.168.10.11   k8s-work1</span><br><span class=\"line\">192.168.10.12   k8s-work2</span><br><span class=\"line\">192.168.10.15   k8s-harbor</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"cl7ee\">验证mac地址uuid</h2>\n---\n\n<p>保证各节点mac和uuid唯一，避免克隆虚拟机后uuid一致导致加入集群异常。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# cat /sys/class/net/ens160/address </span><br><span class=\"line\">[root@k8s-master ~]# cat /sys/class/dmi/id/product_uuid </span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"AjRJW\">时间同步</h2>\n---\n\n<ul>\n<li>master节点设置</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# dnf -y install chrony</span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/chrony.conf</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Use public servers from the pool.ntp.org project.</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class=\"line\">server ntp.aliyun.com iburst</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Allow NTP client access from <span class=\"built_in\">local</span> network.</span></span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">allow 192.168.10.0/24</span></span><br><span class=\"line\"></span><br><span class=\"line\">[root@k8s-master ~]# systemctl start chronyd</span><br><span class=\"line\">[root@k8s-master ~]# systemctl enable chronyd</span><br><span class=\"line\">[root@k8s-master ~]# timedatectl set-timezone Asia/Shanghai</span><br><span class=\"line\">[root@k8s-master ~]# chronyc sources</span><br><span class=\"line\">210 Number of sources = 4</span><br><span class=\"line\">MS Name/IP address         Stratum Poll Reach LastRx Last sample               </span><br><span class=\"line\">===============================================================================</span><br><span class=\"line\">^* 202.118.1.81                  1   6   357   100   +124us[ +205us] +/- 7213us</span><br><span class=\"line\">^? 2a01:4f8:120:9224::2          0   6     0     -     +0ns[   +0ns] +/-    0ns</span><br><span class=\"line\">^+ 202.118.1.130                 1   6   316   184    -29us[  +33us] +/- 7479us</span><br><span class=\"line\">^- 119.28.206.193                2   6   316   192    +13ms[  +13ms] +/-   44ms</span><br><span class=\"line\">[root@k8s-master ~]#</span><br></pre></td></tr></table></figure>\n\n\n\n<ul>\n<li>node节点配置</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@node1  ~]# yum -y install chrony  </span><br><span class=\"line\">[root@node1  ~]# vim /etc/chrony.conf</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Use public servers from the pool.ntp.org project.</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class=\"line\">server 192.168.10.100</span><br><span class=\"line\"></span><br><span class=\"line\">[root@node1  ~]# systemctl start chronyd  </span><br><span class=\"line\">[root@node1  ~]# systemctl enable chronyd  </span><br><span class=\"line\">[root@node1  ~]# chronyc sources</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"wLAgk\">设置防火墙规则</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# systemctl stop firewalld  </span><br><span class=\"line\">[root@master  ~]# systemctl disable firewalld  </span><br><span class=\"line\">[root@master  ~]# yum -y install iptables-services  </span><br><span class=\"line\">[root@master  ~]# systemctl start iptables  </span><br><span class=\"line\">[root@master  ~]# systemctl enable iptables  </span><br><span class=\"line\">[root@master  ~]# iptables -F </span><br><span class=\"line\">[root@master  ~]# service iptables save </span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"KUlJ1\">关闭selinux</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# setenforce 0  </span><br><span class=\"line\">[root@master  ~]# sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27; /etc/selinux/config </span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"wyG8q\">关闭swap分区</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# swapoff -a  </span><br><span class=\"line\">[root@master  ~]# sed -i &#x27;/ swap / s/^\\(.*\\)$/#\\1/g&#x27; /etc/fstab  </span><br></pre></td></tr></table></figure>\n\n\n\n<h1 id=\"MXkxb\">其他配置（所有节点）</h1>\n---\n\n<h2 id=\"wMId3\">修改内核相关参数</h2>\n---\n\n<p>vm.swappiness &#x3D; 0 # 最大限度避免使用 swap</p>\n<p>net.bridge.bridge-nf-call-ip6tables &#x3D; 1 # 内核在桥接设备上让IPv6流量经过 Netfilter（iptables）过滤。</p>\n<p>net.bridge.bridge-nf-call-iptables &#x3D; 1 # 内核在桥接设备上让IPv4流量经过 Netfilter（iptables）过滤。</p>\n<p>net.ipv4.ip_forward &#x3D; 1 # 允许 IPv4 数据包从一个网络接口转发到另一个网络接口。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt; EOF</span><br><span class=\"line\">vm.swappiness = 0 </span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1  </span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">net.ipv4.ip_forward = 1 </span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master  ~]# sysctl -p /etc/sysctl.d/kubernetes.conf </span><br></pre></td></tr></table></figure>\n\n\n\n<pre><code>- centos8会有如下报错\n</code></pre>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vm.swappiness = 0</span><br><span class=\"line\">sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-ip6tables: 没有那个文件或目录</span><br><span class=\"line\">sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: 没有那个文件或目录</span><br><span class=\"line\">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>临时解决，重启失效<br>modprobe br_netfilter</li>\n<li>开机加载上面这个模块</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master  ~]# cat &gt; /etc/rc.sysinit &lt;&lt; EOF</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">!/bin/bash</span></span><br><span class=\"line\">for file in /etc/sysconfig/modules/*.modules ; do</span><br><span class=\"line\">[ -x $file ] &amp;&amp; $file</span><br><span class=\"line\">done</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master  ~]# cat &gt; /etc/sysconfig/modules/br_netfilter.modules &lt;&lt; EOF</span><br><span class=\"line\">modprobe br_netfilter # 通过 br_netfilter，内核能够让网络包在经过桥接设备时被 iptables 规则处理</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master  ~]# chmod 755 /etc/sysconfig/modules/br_netfilter.modules </span><br><span class=\"line\">[root@master  ~]# lsmod |grep br_netfilter</span><br><span class=\"line\">br_netfilter           24576  0</span><br><span class=\"line\">bridge                290816  1 br_netfilter</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e6VbR\">kube-proxy开启ipvs的前置条件</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# yum -y install ipset ipvsadm</span><br><span class=\"line\">[root@k8s-master ~]# cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF </span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">!/bin/bash</span></span><br><span class=\"line\">modprobe -- ip_vs</span><br><span class=\"line\">modprobe -- ip_vs_rr</span><br><span class=\"line\">modprobe -- ip_vs_wrr</span><br><span class=\"line\">modprobe -- ip_vs_sh</span><br><span class=\"line\">modprobe -- nf_conntrack</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash  </span><br><span class=\"line\">[root@k8s-master ~]# /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack </span><br><span class=\"line\">ip_vs_sh               16384  0</span><br><span class=\"line\">ip_vs_wrr              16384  0</span><br><span class=\"line\">ip_vs_rr               16384  0</span><br><span class=\"line\">ip_vs                 172032  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr</span><br><span class=\"line\">nf_conntrack          172032  1 ip_vs</span><br><span class=\"line\">nf_defrag_ipv6         20480  2 nf_conntrack,ip_vs</span><br><span class=\"line\">nf_defrag_ipv4         16384  1 nf_conntrack</span><br><span class=\"line\">libcrc32c              16384  4 nf_conntrack,nf_tables,xfs,ip_vs</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">添加开机自动加载模块</span></span><br><span class=\"line\">[root@k8s-master ~]# echo &quot;/etc/sysconfig/modules/ipvs.modules&quot; &gt;&gt; /etc/rc.local</span><br><span class=\"line\">[root@k8s-master ~]# chmod +x /etc/rc.local</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">启用网桥过滤器模块</span></span><br><span class=\"line\">[root@k8s-master ~]# echo 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables</span><br><span class=\"line\">[root@k8s-master ~]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure>\n\n\n\n<ul>\n<li>linux kernel 4.19版本已经将nf_conntrack_ipv4 更新为 nf_conntrack</li>\n</ul>\n<h2 id=\"oQzak\">升级内核</h2>\n---\n\n<p>可选，建议4.18及+以上即可</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">载入公钥</span><br><span class=\"line\">[root@master  ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org </span><br><span class=\"line\">升级安装ELRepo</span><br><span class=\"line\">[root@master  ~]# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm </span><br><span class=\"line\">如果是centos8使用如下命令</span><br><span class=\"line\">[root@master  ~]#yum install https://www.elrepo.org/elrepo-release-8.0-2.el8.elrepo.noarch.rpm </span><br><span class=\"line\">载入elrepo-kernel元数据</span><br><span class=\"line\">[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel repolist </span><br><span class=\"line\">安装最新版本的kernel</span><br><span class=\"line\">[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml.x86_64 -y </span><br><span class=\"line\">删除旧版本工具包</span><br><span class=\"line\">[root@master  ~]# yum remove kernel-tools-libs.x86_64 kernel-tools.x86_64 -y </span><br><span class=\"line\">安装新版本工具包</span><br><span class=\"line\">[root@master  ~]# yum --disablerepo=\\* --enablerepo=elrepo-kernel install kernel-ml-tools.x86_64 -y </span><br><span class=\"line\">查看内核插入顺序</span><br><span class=\"line\">[root@server-1  ~]# awk -F \\&#x27; &#x27;$1==&quot;menuentry &quot; &#123;print i++ &quot; : &quot; $2&#125;&#x27;  /etc/grub2.cfg </span><br><span class=\"line\">设置默认启动</span><br><span class=\"line\">[root@server-1  ~]# grub2-set-default 0 // 0代表当前第一行，也就是5.3版本  </span><br><span class=\"line\">[root@server-1  ~]# grub2-editenv list  </span><br><span class=\"line\">重启验证</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"ArqRC\">配置阿里云yum源</h2>\n---\n\n<p>k8s版本1.28前，使用如下命令配置yum源。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">repo_gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p>k8s版本1.28以后，例如安装1.30，则修改对应的版本号即可。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# cat &lt;&lt;EOF | tee /etc/yum.repos.d/kubernetes.repo</span><br><span class=\"line\">[kubernetes]</span><br><span class=\"line\">name=Kubernetes</span><br><span class=\"line\">baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/</span><br><span class=\"line\">enabled=1</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/repodata/repomd.xml.key</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"VaLKH\">安装kubeadm、kubectl、kubelet</h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install -y kubelet kubeadm kubectl</span><br><span class=\"line\">systemctl enable kubelet</span><br><span class=\"line\">systemctl start kubelet</span><br></pre></td></tr></table></figure>\n\n<p>kubelet 运行在集群所有节点上，用于启动Pod和容器等对象的工具<br>kubeadm 用于初始化集群，启动集群的命令工具<br>kubectl 用于和集群通信的命令行，通过kubectl可以部署和管理应用，查看各种资源，创建、删除和更新各种组件</p>\n<ul>\n<li>默认安装最新版，也可以指定老版本安装</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum list kubeadm --showduplicates | sort -r</span><br><span class=\"line\">yum install -y kubelet-1.24.13 kubeadm-1.24.13 kubectl-1.24.13</span><br></pre></td></tr></table></figure>\n\n\n\n"},{"title":"部署calico网络组件","date":"2025-03-11T10:00:00.000Z","_content":"> <font style=\"background-color:rgba(255, 255, 255, 0);\">flannel和calico部署其中一个即可，如果要部署calico的话，先卸载flannel。</font>\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"JE6KQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、Calico官网：</font></h1>\n---\n\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel</font>](https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">不同的k8s版本对应不同的calico版本，详情查看文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements</font>](https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements)\n\n<h1 id=\"tbIPR\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、安装部署</font></h1>\n---\n\n<h2 id=\"AUfkL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 下载calico的canal插件：</font></h2>\n---\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># wget https://docs.projectcalico.org/manifests/canal.yaml</font>`\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用的是pod cidr 10.244.0.0/16，请跳到下一步。如果您使用的是不同的pod cidr，请使用以下命令来设置包含pod cidr的环境变量pod cidr，并将清单中的10.244.0.0/16替换为pod cidr。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">POD_CIDR=“<your-pod-cidr>”</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">sed -i -e \"s?10.244.0.0/16?$POD_CIDR?g\" canal.yaml</font>`\n\n<h2 id=\"zEtIg\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. 部署canal插件：</font></h2>\n---\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl apply -f canal.yaml</font>`\n\n<h2 id=\"P8aQ3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 使用kubectl get pods -n kube-system中查看安装进程。</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813234495-78e06fc0-df64-4915-aef3-2f3c8ca21fa9.jpeg)\n\n","source":"_posts/10.部署calico网络组件 副本.md","raw":"---\ntitle: 部署calico网络组件\ndate: 2025-03-11 18:00:00\n---\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">flannel和calico部署其中一个即可，如果要部署calico的话，先卸载flannel。</font>\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"JE6KQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、Calico官网：</font></h1>\n---\n\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel</font>](https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">不同的k8s版本对应不同的calico版本，详情查看文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements</font>](https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements)\n\n<h1 id=\"tbIPR\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、安装部署</font></h1>\n---\n\n<h2 id=\"AUfkL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 下载calico的canal插件：</font></h2>\n---\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># wget https://docs.projectcalico.org/manifests/canal.yaml</font>`\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用的是pod cidr 10.244.0.0/16，请跳到下一步。如果您使用的是不同的pod cidr，请使用以下命令来设置包含pod cidr的环境变量pod cidr，并将清单中的10.244.0.0/16替换为pod cidr。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">POD_CIDR=“<your-pod-cidr>”</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">sed -i -e \"s?10.244.0.0/16?$POD_CIDR?g\" canal.yaml</font>`\n\n<h2 id=\"zEtIg\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. 部署canal插件：</font></h2>\n---\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl apply -f canal.yaml</font>`\n\n<h2 id=\"P8aQ3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 使用kubectl get pods -n kube-system中查看安装进程。</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813234495-78e06fc0-df64-4915-aef3-2f3c8ca21fa9.jpeg)\n\n","slug":"10.部署calico网络组件 副本","published":1,"updated":"2025-03-30T13:14:17.221Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlg0007tsv13bsr2sjm","content":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">flannel和calico部署其中一个即可，如果要部署calico的话，先卸载flannel。</font></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"JE6KQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、Calico官网：</font></h1>\n---\n\n<p><a href=\"https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">不同的k8s版本对应不同的calico版本，详情查看文档：</font><a href=\"https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements</font></a></p>\n<h1 id=\"tbIPR\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、安装部署</font></h1>\n---\n\n<h2 id=\"AUfkL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 下载calico的canal插件：</font></h2>\n---\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# wget https://docs.projectcalico.org/manifests/canal.yaml&lt;/font&gt;</code></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用的是pod cidr 10.244.0.0&#x2F;16，请跳到下一步。如果您使用的是不同的pod cidr，请使用以下命令来设置包含pod cidr的环境变量pod cidr，并将清单中的10.244.0.0&#x2F;16替换为pod cidr。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">POD_CIDR&#x3D;“<your-pod-cidr>”</font></p>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;sed -i -e &quot;s?10.244.0.0/16?$POD_CIDR?g&quot; canal.yaml&lt;/font&gt;</code></p>\n<h2 id=\"zEtIg\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. 部署canal插件：</font></h2>\n---\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubectl apply -f canal.yaml&lt;/font&gt;</code></p>\n<h2 id=\"P8aQ3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 使用kubectl get pods -n kube-system中查看安装进程。</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813234495-78e06fc0-df64-4915-aef3-2f3c8ca21fa9.jpeg\"></p>\n","excerpt":"","more":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">flannel和calico部署其中一个即可，如果要部署calico的话，先卸载flannel。</font></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"JE6KQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、Calico官网：</font></h1>\n---\n\n<p><a href=\"https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/flannel</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">不同的k8s版本对应不同的calico版本，详情查看文档：</font><a href=\"https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://projectcalico.docs.tigera.io/archive/v3.23/getting-started/kubernetes/requirements</font></a></p>\n<h1 id=\"tbIPR\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、安装部署</font></h1>\n---\n\n<h2 id=\"AUfkL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 下载calico的canal插件：</font></h2>\n---\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# wget https://docs.projectcalico.org/manifests/canal.yaml&lt;/font&gt;</code></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用的是pod cidr 10.244.0.0&#x2F;16，请跳到下一步。如果您使用的是不同的pod cidr，请使用以下命令来设置包含pod cidr的环境变量pod cidr，并将清单中的10.244.0.0&#x2F;16替换为pod cidr。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">POD_CIDR&#x3D;“<your-pod-cidr>”</font></p>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;sed -i -e &quot;s?10.244.0.0/16?$POD_CIDR?g&quot; canal.yaml&lt;/font&gt;</code></p>\n<h2 id=\"zEtIg\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. 部署canal插件：</font></h2>\n---\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubectl apply -f canal.yaml&lt;/font&gt;</code></p>\n<h2 id=\"P8aQ3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 使用kubectl get pods -n kube-system中查看安装进程。</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813234495-78e06fc0-df64-4915-aef3-2f3c8ca21fa9.jpeg\"></p>\n"},{"title":"部署metrics监控组件","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"1878abb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、metrics-server(HPA使用)</font></h1>\n---\n\n<h2 id=\"e9a93a8e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 版本说明</font></h2>\n---\n\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">github地址</font>](https://github.com/kubernetes-sigs/metrics-server)\n\n<h2 id=\"24f31c48\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. Aggregator开启</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这个是k8s在1.7的新特性，如果是1.16版本的可以不用添加，1.17以后要添加。这个参数的作用是Aggregation允许在不修改Kubernetes核心代码的同时扩展Kubernetes API。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查询是否开启：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">master机器：ps -ef |grep apiserver|grep ‘enable-aggregator-routing=true’</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">开启方法：要在master机器上执行</font>**\n\n```plain\nvim /etc/kubernetes/manifests/kube-apiserver.yaml\n\n- command:\n    - kube-apiserver\n    …………\n    - --enable-aggregator-routing=true  //加入这一行\n# 保存后apiserver会自动重启\n```\n\n<h2 id=\"df5bec15\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 部署</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">下载yaml文件</font>\n\n```plain\nwget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font>\n\n```plain\n# vim components.yaml\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: metrics-server\n    spec:\n      containers:\n      - args:\n        - --kubelet-insecure-tls # 跳过 TLS 认证，否则会出现 x509 的认证问题\n        - --kubelet-preferred-address-types=InternalIP # 使用 Node IP 进行通信。\n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl apply -f components.yaml</font>`\n\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">检验相应的API群组metrics.k8s.io是否出现在Kubernetes集群的API群组列表中</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># kubectl api-versions | grep metrics</font>`\n\n5. <font style=\"background-color:rgba(255, 255, 255, 0);\">确认相关的Pod对象运行正常</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># kubectl get pods -n kube-system -l k8s-app=metrics-server</font>`\n\n6. <font style=\"background-color:rgba(255, 255, 255, 0);\">使用kubectl top node查看结果</font>\n\n```plain\n[root@tiaoban ~]# kubectl top node\nNAME         CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \nk8s-master   422m         10%    1471Mi          40%       \nk8s-work1    268m         6%     1197Mi          33%       \nk8s-work2    239m         5%     1286Mi          35%       \nk8s-work3    320m         8%     1091Mi          30% \n```\n\n<h1 id=\"dadc99f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、kube-state-metrics部署(prometheus采集数据使用)</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">仓库地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes/kube-state-metrics: Add-on agent to generate and expose cluster-level metrics. (github.com)</font>](https://github.com/kubernetes/kube-state-metrics)\n\n<h2 id=\"092d2f88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本说明</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">版本依赖</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-state-metrics</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes client-go Version</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.9.2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.26</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.10.1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.27</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.11.0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.28</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.12.0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.29</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.13.0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">main</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font> |\n\n\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font>\n\n```plain\n# git clone https://github.com/kubernetes/kube-state-metrics.git\n# cd kube-state-metrics/examples/standard/\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">修改service，允许prometheus自动发现</font>\n\n```plain\n# vim service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.2.0\n  name: kube-state-metrics\n  namespace: kube-system\n  annotations:  \n    prometheus.io/scrape: \"true\"       ##添加此参数，允许prometheus自动发现\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n```plain\nkubectl apply -f .\n[root@tiaoban standard]# kubectl get pod -n kube-system -l app.kubernetes.io/name=kube-state-metrics\nNAME                                 READY   STATUS    RESTARTS   AGE\nkube-state-metrics-bb59558c8-cx9pz   1/1     Running   0          1m\n```\n\n","source":"_posts/11.部署metrics监控组件.md","raw":"---\ntitle: 部署metrics监控组件\ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"1878abb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、metrics-server(HPA使用)</font></h1>\n---\n\n<h2 id=\"e9a93a8e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 版本说明</font></h2>\n---\n\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">github地址</font>](https://github.com/kubernetes-sigs/metrics-server)\n\n<h2 id=\"24f31c48\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. Aggregator开启</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这个是k8s在1.7的新特性，如果是1.16版本的可以不用添加，1.17以后要添加。这个参数的作用是Aggregation允许在不修改Kubernetes核心代码的同时扩展Kubernetes API。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查询是否开启：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">master机器：ps -ef |grep apiserver|grep ‘enable-aggregator-routing=true’</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">开启方法：要在master机器上执行</font>**\n\n```plain\nvim /etc/kubernetes/manifests/kube-apiserver.yaml\n\n- command:\n    - kube-apiserver\n    …………\n    - --enable-aggregator-routing=true  //加入这一行\n# 保存后apiserver会自动重启\n```\n\n<h2 id=\"df5bec15\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 部署</font></h2>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">下载yaml文件</font>\n\n```plain\nwget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font>\n\n```plain\n# vim components.yaml\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: metrics-server\n    spec:\n      containers:\n      - args:\n        - --kubelet-insecure-tls # 跳过 TLS 认证，否则会出现 x509 的认证问题\n        - --kubelet-preferred-address-types=InternalIP # 使用 Node IP 进行通信。\n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl apply -f components.yaml</font>`\n\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">检验相应的API群组metrics.k8s.io是否出现在Kubernetes集群的API群组列表中</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># kubectl api-versions | grep metrics</font>`\n\n5. <font style=\"background-color:rgba(255, 255, 255, 0);\">确认相关的Pod对象运行正常</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># kubectl get pods -n kube-system -l k8s-app=metrics-server</font>`\n\n6. <font style=\"background-color:rgba(255, 255, 255, 0);\">使用kubectl top node查看结果</font>\n\n```plain\n[root@tiaoban ~]# kubectl top node\nNAME         CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \nk8s-master   422m         10%    1471Mi          40%       \nk8s-work1    268m         6%     1197Mi          33%       \nk8s-work2    239m         5%     1286Mi          35%       \nk8s-work3    320m         8%     1091Mi          30% \n```\n\n<h1 id=\"dadc99f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、kube-state-metrics部署(prometheus采集数据使用)</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">仓库地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes/kube-state-metrics: Add-on agent to generate and expose cluster-level metrics. (github.com)</font>](https://github.com/kubernetes/kube-state-metrics)\n\n<h2 id=\"092d2f88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本说明</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">版本依赖</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">kube-state-metrics</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes client-go Version</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.9.2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.26</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.10.1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.27</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.11.0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.28</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.12.0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.29</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">v2.13.0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">main</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font> |\n\n\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font>\n\n```plain\n# git clone https://github.com/kubernetes/kube-state-metrics.git\n# cd kube-state-metrics/examples/standard/\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">修改service，允许prometheus自动发现</font>\n\n```plain\n# vim service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/name: kube-state-metrics\n    app.kubernetes.io/version: 2.2.0\n  name: kube-state-metrics\n  namespace: kube-system\n  annotations:  \n    prometheus.io/scrape: \"true\"       ##添加此参数，允许prometheus自动发现\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n```plain\nkubectl apply -f .\n[root@tiaoban standard]# kubectl get pod -n kube-system -l app.kubernetes.io/name=kube-state-metrics\nNAME                                 READY   STATUS    RESTARTS   AGE\nkube-state-metrics-bb59558c8-cx9pz   1/1     Running   0          1m\n```\n\n","slug":"11.部署metrics监控组件","published":1,"updated":"2025-03-30T13:14:36.839Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlg0008tsv1cc6bg4eo","content":"<h1 id=\"1878abb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、metrics-server(HPA使用)</font></h1>\n---\n\n<h2 id=\"e9a93a8e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 版本说明</font></h2>\n---\n\n<p><a href=\"https://github.com/kubernetes-sigs/metrics-server\"><font style=\"background-color:rgba(255, 255, 255, 0);\">github地址</font></a></p>\n<h2 id=\"24f31c48\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. Aggregator开启</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这个是k8s在1.7的新特性，如果是1.16版本的可以不用添加，1.17以后要添加。这个参数的作用是Aggregation允许在不修改Kubernetes核心代码的同时扩展Kubernetes API。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查询是否开启：</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">master机器：ps -ef |grep apiserver|grep ‘enable-aggregator-routing&#x3D;true’</font></p>\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">开启方法：要在master机器上执行</font></strong></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/kubernetes/manifests/kube-apiserver.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">- command:</span><br><span class=\"line\">    - kube-apiserver</span><br><span class=\"line\">    …………</span><br><span class=\"line\">    - --enable-aggregator-routing=true  //加入这一行</span><br><span class=\"line\"># 保存后apiserver会自动重启</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"df5bec15\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 部署</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">下载yaml文件</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># vim components.yaml</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: metrics-server</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - args:</span><br><span class=\"line\">        - --kubelet-insecure-tls # 跳过 TLS 认证，否则会出现 x509 的认证问题</span><br><span class=\"line\">        - --kubelet-preferred-address-types=InternalIP # 使用 Node IP 进行通信。</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></li>\n</ol>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubectl apply -f components.yaml&lt;/font&gt;</code></p>\n<ol start=\"4\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">检验相应的API群组metrics.k8s.io是否出现在Kubernetes集群的API群组列表中</font></li>\n</ol>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# kubectl api-versions | grep metrics&lt;/font&gt;</code></p>\n<ol start=\"5\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">确认相关的Pod对象运行正常</font></li>\n</ol>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# kubectl get pods -n kube-system -l k8s-app=metrics-server&lt;/font&gt;</code></p>\n<ol start=\"6\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">使用kubectl top node查看结果</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# kubectl top node</span><br><span class=\"line\">NAME         CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class=\"line\">k8s-master   422m         10%    1471Mi          40%       </span><br><span class=\"line\">k8s-work1    268m         6%     1197Mi          33%       </span><br><span class=\"line\">k8s-work2    239m         5%     1286Mi          35%       </span><br><span class=\"line\">k8s-work3    320m         8%     1091Mi          30% </span><br></pre></td></tr></table></figure>\n\n<h1 id=\"dadc99f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、kube-state-metrics部署(prometheus采集数据使用)</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">仓库地址：</font><a href=\"https://github.com/kubernetes/kube-state-metrics\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes&#x2F;kube-state-metrics: Add-on agent to generate and expose cluster-level metrics. (github.com)</font></a></p>\n<h2 id=\"092d2f88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本说明</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">版本依赖</font></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-state-metrics</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes client-go Version</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.9.2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.26</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.10.1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.27</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.11.0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.28</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.12.0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.29</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.13.0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">main</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font></td>\n</tr>\n</tbody></table>\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># git clone https://github.com/kubernetes/kube-state-metrics.git</span><br><span class=\"line\"># cd kube-state-metrics/examples/standard/</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">修改service，允许prometheus自动发现</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># vim service.yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: kube-state-metrics</span><br><span class=\"line\">    app.kubernetes.io/version: 2.2.0</span><br><span class=\"line\">  name: kube-state-metrics</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  annotations:  </span><br><span class=\"line\">    prometheus.io/scrape: &quot;true&quot;       ##添加此参数，允许prometheus自动发现</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f .</span><br><span class=\"line\">[root@tiaoban standard]# kubectl get pod -n kube-system -l app.kubernetes.io/name=kube-state-metrics</span><br><span class=\"line\">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-state-metrics-bb59558c8-cx9pz   1/1     Running   0          1m</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<h1 id=\"1878abb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">一、metrics-server(HPA使用)</font></h1>\n---\n\n<h2 id=\"e9a93a8e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">1. 版本说明</font></h2>\n---\n\n<p><a href=\"https://github.com/kubernetes-sigs/metrics-server\"><font style=\"background-color:rgba(255, 255, 255, 0);\">github地址</font></a></p>\n<h2 id=\"24f31c48\"><font style=\"background-color:rgba(255, 255, 255, 0);\">2. Aggregator开启</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这个是k8s在1.7的新特性，如果是1.16版本的可以不用添加，1.17以后要添加。这个参数的作用是Aggregation允许在不修改Kubernetes核心代码的同时扩展Kubernetes API。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查询是否开启：</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">master机器：ps -ef |grep apiserver|grep ‘enable-aggregator-routing&#x3D;true’</font></p>\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">开启方法：要在master机器上执行</font></strong></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim /etc/kubernetes/manifests/kube-apiserver.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">- command:</span><br><span class=\"line\">    - kube-apiserver</span><br><span class=\"line\">    …………</span><br><span class=\"line\">    - --enable-aggregator-routing=true  //加入这一行</span><br><span class=\"line\"># 保存后apiserver会自动重启</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"df5bec15\"><font style=\"background-color:rgba(255, 255, 255, 0);\">3. 部署</font></h2>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">下载yaml文件</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># vim components.yaml</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: metrics-server</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - args:</span><br><span class=\"line\">        - --kubelet-insecure-tls # 跳过 TLS 认证，否则会出现 x509 的认证问题</span><br><span class=\"line\">        - --kubelet-preferred-address-types=InternalIP # 使用 Node IP 进行通信。</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></li>\n</ol>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubectl apply -f components.yaml&lt;/font&gt;</code></p>\n<ol start=\"4\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">检验相应的API群组metrics.k8s.io是否出现在Kubernetes集群的API群组列表中</font></li>\n</ol>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# kubectl api-versions | grep metrics&lt;/font&gt;</code></p>\n<ol start=\"5\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">确认相关的Pod对象运行正常</font></li>\n</ol>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# kubectl get pods -n kube-system -l k8s-app=metrics-server&lt;/font&gt;</code></p>\n<ol start=\"6\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">使用kubectl top node查看结果</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# kubectl top node</span><br><span class=\"line\">NAME         CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class=\"line\">k8s-master   422m         10%    1471Mi          40%       </span><br><span class=\"line\">k8s-work1    268m         6%     1197Mi          33%       </span><br><span class=\"line\">k8s-work2    239m         5%     1286Mi          35%       </span><br><span class=\"line\">k8s-work3    320m         8%     1091Mi          30% </span><br></pre></td></tr></table></figure>\n\n<h1 id=\"dadc99f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二、kube-state-metrics部署(prometheus采集数据使用)</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">仓库地址：</font><a href=\"https://github.com/kubernetes/kube-state-metrics\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubernetes&#x2F;kube-state-metrics: Add-on agent to generate and expose cluster-level metrics. (github.com)</font></a></p>\n<h2 id=\"092d2f88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本说明</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">版本依赖</font></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">kube-state-metrics</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes client-go Version</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.9.2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.26</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.10.1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.27</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.11.0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.28</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.12.0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.29</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v2.13.0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">main</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">v1.30</font></td>\n</tr>\n</tbody></table>\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># git clone https://github.com/kubernetes/kube-state-metrics.git</span><br><span class=\"line\"># cd kube-state-metrics/examples/standard/</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">修改service，允许prometheus自动发现</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># vim service.yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/name: kube-state-metrics</span><br><span class=\"line\">    app.kubernetes.io/version: 2.2.0</span><br><span class=\"line\">  name: kube-state-metrics</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  annotations:  </span><br><span class=\"line\">    prometheus.io/scrape: &quot;true&quot;       ##添加此参数，允许prometheus自动发现</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f .</span><br><span class=\"line\">[root@tiaoban standard]# kubectl get pod -n kube-system -l app.kubernetes.io/name=kube-state-metrics</span><br><span class=\"line\">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-state-metrics-bb59558c8-cx9pz   1/1     Running   0          1m</span><br></pre></td></tr></table></figure>\n\n"},{"title":"部署Redis数据库","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"863728e1\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">安装Redis</font></h1>\n---\n\n```plain\n# 添加repo\n[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami\n# 更新repo仓库资源\n[root@k8s-master ~]# helm repo update\n# 拉取helm包\n[root@k8s-master ~]# helm pull bitnami/redis-cluster --untar\n# 修改配置\n[root@k8s-master ~]# cd redis-cluster/\n[root@k8s-master redis-cluster]# vim values.yaml \nglobal:\n  storageClass: \"nfs\"\n  redis:\n    password: \"password\"\ncluster:\n  init: true # nodes：是包括副本在内的节点总数。这意味着将有 3 个主节点和 3 个副本节点\n  nodes: 6\n  replicas: 1\nmetrics:\n  enabled: true # 启用prometheus监控\n  \n# 安装\n[root@k8s-master redis-cluster]# helm install redis -n redis . -f values.yaml --create-namespace         \nNAME: redis\nLAST DEPLOYED: Tue Oct 15 14:22:35 2024\nNAMESPACE: redis\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCHART NAME: redis-cluster\nCHART VERSION: 11.0.6\nAPP VERSION: 7.4.1** Please be patient while the chart is being deployed **\n\n\nTo get your password run:\n    export REDIS_PASSWORD=$(kubectl get secret --namespace \"redis\" redis-redis-cluster -o jsonpath=\"{.data.redis-password}\" | base64 -d)\n\nYou have deployed a Redis&reg; Cluster accessible only from within you Kubernetes Cluster.INFO: The Job to create the cluster will be created.To connect to your Redis&reg; cluster:\n\n1. Run a Redis&reg; pod that you can use as a client:\nkubectl run --namespace redis redis-redis-cluster-client --rm --tty -i --restart='Never' \\\n --env REDIS_PASSWORD=$REDIS_PASSWORD \\\n--image docker.io/bitnami/redis-cluster:7.4.1-debian-12-r0 -- bash\n\n2. Connect using the Redis&reg; CLI:\n\nredis-cli -c -h redis-redis-cluster -a $REDIS_PASSWORD\n\n\n\nWARNING: There are \"resources\" sections in the chart not set. Using \"resourcesPreset\" is not recommended for production. For production installations, please set the following values according to your workload needs:\n  - redis.resources\n  - updateJob.resources\n+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n# 查看验证\nkubectl get pod -n redis          \nNAME                            READY   STATUS    RESTARTS    AGE\nredis-redis-cluster-0           1/1     Running   0           3m\nredis-redis-cluster-1           1/1     Running   0           3m\nredis-redis-cluster-2           1/1     Running   0           3m\nredis-redis-cluster-3           1/1     Running   0           3m\nredis-redis-cluster-4           1/1     Running   0           3m\nredis-redis-cluster-5           1/1     Running   0           3m\n```\n\n<h1 id=\"7777419e\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">部署redisinsight服务</font></h1>\n---\n\n```plain\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redisinsight-pvc\n  namespace: redis\n  labels:\n    app: redisinsight  \nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 500Mi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redisinsight\n  namespace: redis\n  labels:\n    app: redisinsight\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redisinsight\n  template:\n    metadata:\n      labels:\n        app: redisinsight\n    spec:\n      containers:\n      - name:  redisinsight\n        image: redisinsight:2.58\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n        volumeMounts:\n        - name: db\n          mountPath: /db\n        ports:\n        - containerPort: 5540\n          protocol: TCP\n        resources:\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n      volumes:\n      - name: db\n        persistentVolumeClaim:\n          claimName: redisinsight-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redisinsight\n  namespace: redis\nspec:\n  selector:\n    app: redisinsight\n  ports:\n  - port: 5540\n    targetPort: 5540\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: redisinsight\n  namespace: redis\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`redisinsight.maka.sensetime.com`)\n    kind: Rule\n    services:\n      - name: redisinsight\n        port: 5540\n```\n\n<font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">添加域名解析后访问验证</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892708154-57944998-4ad6-4ca2-a699-21840f640217.jpeg)\n\n\n\n","source":"_posts/12.部署Redis数据库 副本.md","raw":"---\ntitle: 部署Redis数据库 \ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"863728e1\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">安装Redis</font></h1>\n---\n\n```plain\n# 添加repo\n[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami\n# 更新repo仓库资源\n[root@k8s-master ~]# helm repo update\n# 拉取helm包\n[root@k8s-master ~]# helm pull bitnami/redis-cluster --untar\n# 修改配置\n[root@k8s-master ~]# cd redis-cluster/\n[root@k8s-master redis-cluster]# vim values.yaml \nglobal:\n  storageClass: \"nfs\"\n  redis:\n    password: \"password\"\ncluster:\n  init: true # nodes：是包括副本在内的节点总数。这意味着将有 3 个主节点和 3 个副本节点\n  nodes: 6\n  replicas: 1\nmetrics:\n  enabled: true # 启用prometheus监控\n  \n# 安装\n[root@k8s-master redis-cluster]# helm install redis -n redis . -f values.yaml --create-namespace         \nNAME: redis\nLAST DEPLOYED: Tue Oct 15 14:22:35 2024\nNAMESPACE: redis\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCHART NAME: redis-cluster\nCHART VERSION: 11.0.6\nAPP VERSION: 7.4.1** Please be patient while the chart is being deployed **\n\n\nTo get your password run:\n    export REDIS_PASSWORD=$(kubectl get secret --namespace \"redis\" redis-redis-cluster -o jsonpath=\"{.data.redis-password}\" | base64 -d)\n\nYou have deployed a Redis&reg; Cluster accessible only from within you Kubernetes Cluster.INFO: The Job to create the cluster will be created.To connect to your Redis&reg; cluster:\n\n1. Run a Redis&reg; pod that you can use as a client:\nkubectl run --namespace redis redis-redis-cluster-client --rm --tty -i --restart='Never' \\\n --env REDIS_PASSWORD=$REDIS_PASSWORD \\\n--image docker.io/bitnami/redis-cluster:7.4.1-debian-12-r0 -- bash\n\n2. Connect using the Redis&reg; CLI:\n\nredis-cli -c -h redis-redis-cluster -a $REDIS_PASSWORD\n\n\n\nWARNING: There are \"resources\" sections in the chart not set. Using \"resourcesPreset\" is not recommended for production. For production installations, please set the following values according to your workload needs:\n  - redis.resources\n  - updateJob.resources\n+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n# 查看验证\nkubectl get pod -n redis          \nNAME                            READY   STATUS    RESTARTS    AGE\nredis-redis-cluster-0           1/1     Running   0           3m\nredis-redis-cluster-1           1/1     Running   0           3m\nredis-redis-cluster-2           1/1     Running   0           3m\nredis-redis-cluster-3           1/1     Running   0           3m\nredis-redis-cluster-4           1/1     Running   0           3m\nredis-redis-cluster-5           1/1     Running   0           3m\n```\n\n<h1 id=\"7777419e\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">部署redisinsight服务</font></h1>\n---\n\n```plain\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: redisinsight-pvc\n  namespace: redis\n  labels:\n    app: redisinsight  \nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 500Mi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redisinsight\n  namespace: redis\n  labels:\n    app: redisinsight\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redisinsight\n  template:\n    metadata:\n      labels:\n        app: redisinsight\n    spec:\n      containers:\n      - name:  redisinsight\n        image: redisinsight:2.58\n        imagePullPolicy: IfNotPresent\n        securityContext:\n          runAsUser: 0\n        volumeMounts:\n        - name: db\n          mountPath: /db\n        ports:\n        - containerPort: 5540\n          protocol: TCP\n        resources:\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n      volumes:\n      - name: db\n        persistentVolumeClaim:\n          claimName: redisinsight-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: redisinsight\n  namespace: redis\nspec:\n  selector:\n    app: redisinsight\n  ports:\n  - port: 5540\n    targetPort: 5540\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: redisinsight\n  namespace: redis\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`redisinsight.maka.sensetime.com`)\n    kind: Rule\n    services:\n      - name: redisinsight\n        port: 5540\n```\n\n<font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">添加域名解析后访问验证</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892708154-57944998-4ad6-4ca2-a699-21840f640217.jpeg)\n\n\n\n","slug":"12.部署Redis数据库 副本","published":1,"updated":"2025-03-30T13:14:58.013Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlh0009tsv183800ty1","content":"<h1 id=\"863728e1\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">安装Redis</font></h1>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加repo</span><br><span class=\"line\">[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class=\"line\"># 更新repo仓库资源</span><br><span class=\"line\">[root@k8s-master ~]# helm repo update</span><br><span class=\"line\"># 拉取helm包</span><br><span class=\"line\">[root@k8s-master ~]# helm pull bitnami/redis-cluster --untar</span><br><span class=\"line\"># 修改配置</span><br><span class=\"line\">[root@k8s-master ~]# cd redis-cluster/</span><br><span class=\"line\">[root@k8s-master redis-cluster]# vim values.yaml </span><br><span class=\"line\">global:</span><br><span class=\"line\">  storageClass: &quot;nfs&quot;</span><br><span class=\"line\">  redis:</span><br><span class=\"line\">    password: &quot;password&quot;</span><br><span class=\"line\">cluster:</span><br><span class=\"line\">  init: true # nodes：是包括副本在内的节点总数。这意味着将有 3 个主节点和 3 个副本节点</span><br><span class=\"line\">  nodes: 6</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">metrics:</span><br><span class=\"line\">  enabled: true # 启用prometheus监控</span><br><span class=\"line\">  </span><br><span class=\"line\"># 安装</span><br><span class=\"line\">[root@k8s-master redis-cluster]# helm install redis -n redis . -f values.yaml --create-namespace         </span><br><span class=\"line\">NAME: redis</span><br><span class=\"line\">LAST DEPLOYED: Tue Oct 15 14:22:35 2024</span><br><span class=\"line\">NAMESPACE: redis</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">CHART NAME: redis-cluster</span><br><span class=\"line\">CHART VERSION: 11.0.6</span><br><span class=\"line\">APP VERSION: 7.4.1** Please be patient while the chart is being deployed **</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">To get your password run:</span><br><span class=\"line\">    export REDIS_PASSWORD=$(kubectl get secret --namespace &quot;redis&quot; redis-redis-cluster -o jsonpath=&quot;&#123;.data.redis-password&#125;&quot; | base64 -d)</span><br><span class=\"line\"></span><br><span class=\"line\">You have deployed a Redis&amp;reg; Cluster accessible only from within you Kubernetes Cluster.INFO: The Job to create the cluster will be created.To connect to your Redis&amp;reg; cluster:</span><br><span class=\"line\"></span><br><span class=\"line\">1. Run a Redis&amp;reg; pod that you can use as a client:</span><br><span class=\"line\">kubectl run --namespace redis redis-redis-cluster-client --rm --tty -i --restart=&#x27;Never&#x27; \\</span><br><span class=\"line\"> --env REDIS_PASSWORD=$REDIS_PASSWORD \\</span><br><span class=\"line\">--image docker.io/bitnami/redis-cluster:7.4.1-debian-12-r0 -- bash</span><br><span class=\"line\"></span><br><span class=\"line\">2. Connect using the Redis&amp;reg; CLI:</span><br><span class=\"line\"></span><br><span class=\"line\">redis-cli -c -h redis-redis-cluster -a $REDIS_PASSWORD</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">WARNING: There are &quot;resources&quot; sections in the chart not set. Using &quot;resourcesPreset&quot; is not recommended for production. For production installations, please set the following values according to your workload needs:</span><br><span class=\"line\">  - redis.resources</span><br><span class=\"line\">  - updateJob.resources</span><br><span class=\"line\">+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</span><br><span class=\"line\"># 查看验证</span><br><span class=\"line\">kubectl get pod -n redis          </span><br><span class=\"line\">NAME                            READY   STATUS    RESTARTS    AGE</span><br><span class=\"line\">redis-redis-cluster-0           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-1           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-2           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-3           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-4           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-5           1/1     Running   0           3m</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"7777419e\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">部署redisinsight服务</font></h1>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight-pvc</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: redisinsight  </span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 500Mi</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: redisinsight</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: redisinsight</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: redisinsight</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name:  redisinsight</span><br><span class=\"line\">        image: redisinsight:2.58</span><br><span class=\"line\">        imagePullPolicy: IfNotPresent</span><br><span class=\"line\">        securityContext:</span><br><span class=\"line\">          runAsUser: 0</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: db</span><br><span class=\"line\">          mountPath: /db</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 5540</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            memory: &quot;1Gi&quot;</span><br><span class=\"line\">            cpu: &quot;500m&quot;</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: db</span><br><span class=\"line\">        persistentVolumeClaim:</span><br><span class=\"line\">          claimName: redisinsight-pvc</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app: redisinsight</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 5540</span><br><span class=\"line\">    targetPort: 5540</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`redisinsight.maka.sensetime.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: redisinsight</span><br><span class=\"line\">        port: 5540</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">添加域名解析后访问验证</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892708154-57944998-4ad6-4ca2-a699-21840f640217.jpeg\"></p>\n","excerpt":"","more":"<h1 id=\"863728e1\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">安装Redis</font></h1>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加repo</span><br><span class=\"line\">[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class=\"line\"># 更新repo仓库资源</span><br><span class=\"line\">[root@k8s-master ~]# helm repo update</span><br><span class=\"line\"># 拉取helm包</span><br><span class=\"line\">[root@k8s-master ~]# helm pull bitnami/redis-cluster --untar</span><br><span class=\"line\"># 修改配置</span><br><span class=\"line\">[root@k8s-master ~]# cd redis-cluster/</span><br><span class=\"line\">[root@k8s-master redis-cluster]# vim values.yaml </span><br><span class=\"line\">global:</span><br><span class=\"line\">  storageClass: &quot;nfs&quot;</span><br><span class=\"line\">  redis:</span><br><span class=\"line\">    password: &quot;password&quot;</span><br><span class=\"line\">cluster:</span><br><span class=\"line\">  init: true # nodes：是包括副本在内的节点总数。这意味着将有 3 个主节点和 3 个副本节点</span><br><span class=\"line\">  nodes: 6</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">metrics:</span><br><span class=\"line\">  enabled: true # 启用prometheus监控</span><br><span class=\"line\">  </span><br><span class=\"line\"># 安装</span><br><span class=\"line\">[root@k8s-master redis-cluster]# helm install redis -n redis . -f values.yaml --create-namespace         </span><br><span class=\"line\">NAME: redis</span><br><span class=\"line\">LAST DEPLOYED: Tue Oct 15 14:22:35 2024</span><br><span class=\"line\">NAMESPACE: redis</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">CHART NAME: redis-cluster</span><br><span class=\"line\">CHART VERSION: 11.0.6</span><br><span class=\"line\">APP VERSION: 7.4.1** Please be patient while the chart is being deployed **</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">To get your password run:</span><br><span class=\"line\">    export REDIS_PASSWORD=$(kubectl get secret --namespace &quot;redis&quot; redis-redis-cluster -o jsonpath=&quot;&#123;.data.redis-password&#125;&quot; | base64 -d)</span><br><span class=\"line\"></span><br><span class=\"line\">You have deployed a Redis&amp;reg; Cluster accessible only from within you Kubernetes Cluster.INFO: The Job to create the cluster will be created.To connect to your Redis&amp;reg; cluster:</span><br><span class=\"line\"></span><br><span class=\"line\">1. Run a Redis&amp;reg; pod that you can use as a client:</span><br><span class=\"line\">kubectl run --namespace redis redis-redis-cluster-client --rm --tty -i --restart=&#x27;Never&#x27; \\</span><br><span class=\"line\"> --env REDIS_PASSWORD=$REDIS_PASSWORD \\</span><br><span class=\"line\">--image docker.io/bitnami/redis-cluster:7.4.1-debian-12-r0 -- bash</span><br><span class=\"line\"></span><br><span class=\"line\">2. Connect using the Redis&amp;reg; CLI:</span><br><span class=\"line\"></span><br><span class=\"line\">redis-cli -c -h redis-redis-cluster -a $REDIS_PASSWORD</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">WARNING: There are &quot;resources&quot; sections in the chart not set. Using &quot;resourcesPreset&quot; is not recommended for production. For production installations, please set the following values according to your workload needs:</span><br><span class=\"line\">  - redis.resources</span><br><span class=\"line\">  - updateJob.resources</span><br><span class=\"line\">+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</span><br><span class=\"line\"># 查看验证</span><br><span class=\"line\">kubectl get pod -n redis          </span><br><span class=\"line\">NAME                            READY   STATUS    RESTARTS    AGE</span><br><span class=\"line\">redis-redis-cluster-0           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-1           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-2           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-3           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-4           1/1     Running   0           3m</span><br><span class=\"line\">redis-redis-cluster-5           1/1     Running   0           3m</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"7777419e\"><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">部署redisinsight服务</font></h1>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight-pvc</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: redisinsight  </span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 500Mi</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: redisinsight</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: redisinsight</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: redisinsight</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name:  redisinsight</span><br><span class=\"line\">        image: redisinsight:2.58</span><br><span class=\"line\">        imagePullPolicy: IfNotPresent</span><br><span class=\"line\">        securityContext:</span><br><span class=\"line\">          runAsUser: 0</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: db</span><br><span class=\"line\">          mountPath: /db</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 5540</span><br><span class=\"line\">          protocol: TCP</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            memory: &quot;1Gi&quot;</span><br><span class=\"line\">            cpu: &quot;500m&quot;</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: db</span><br><span class=\"line\">        persistentVolumeClaim:</span><br><span class=\"line\">          claimName: redisinsight-pvc</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app: redisinsight</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - port: 5540</span><br><span class=\"line\">    targetPort: 5540</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: redisinsight</span><br><span class=\"line\">  namespace: redis</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`redisinsight.maka.sensetime.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: redisinsight</span><br><span class=\"line\">        port: 5540</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"color:rgb(202, 216, 230);background-color:rgb(23, 24, 25);\">添加域名解析后访问验证</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892708154-57944998-4ad6-4ca2-a699-21840f640217.jpeg\"></p>\n"},{"title":"部署Prometheus监控","date":"2025-03-11T10:00:00.000Z","_content":"> <font style=\"background-color:rgba(255, 255, 255, 0);\">如果已安装metrics-server需要先卸载，否则冲突</font>\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"adfb3ce8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件说明</font></h1>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如kubectl,hpa,scheduler等。</font>\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。</font>\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">NodeExporter：用于各node的关键度量指标状态数据。</font>\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">KubeStateMetrics：收集kubernetes集群内资源对象数据，制定告警规则。</font>\n5. <font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数据，通过http协议传输。</font>\n6. <font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana：是可视化数据统计和监控平台。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/prometheus-operator/kube-prometheus</font>](https://github.com/prometheus-operator/kube-prometheus)\n\n<h2 id=\"6a6cc2b2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font></h2>\n---\n\n```plain\ngit clone https://github.com/prometheus-operator/kube-prometheus.git\n```\n\n<h2 id=\"1dcabd41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源对象</font></h2>\n---\n\n```plain\n[root@master1 k8s-install]# kubectl create namespace monitoring \n[root@master1 k8s-install]# cd kube-prometheus/\n[root@master1 kube-prometheus]# kubectl apply --server-side -f manifests/setup\n[root@master1 kube-prometheus]# kubectl wait \\\n\t--for condition=Established \\\n\t--all CustomResourceDefinition \\\n\t--namespace=monitoring\n[root@master1 kube-prometheus]# kubectl apply -f manifests/\n```\n\n<h2 id=\"fea33636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证查看</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod状态</font>\n\n```plain\n[root@master1 kube-prometheus]# kubectl get pod -n monitoring \nNAME                                   READY   STATUS    RESTARTS   AGE\nalertmanager-main-0                    2/2     Running   0          61s\nalertmanager-main-1                    2/2     Running   0          61s\nalertmanager-main-2                    2/2     Running   0          61s\nblackbox-exporter-576df9484f-lr6xd     3/3     Running   0          107s\ngrafana-795ddfd4bd-jxlrw               1/1     Running   0          105s\nkube-state-metrics-bdfdcd5cd-7dgwl     3/3     Running   0          104s\nnode-exporter-4qnrz                    2/2     Running   0          104s\nnode-exporter-8hjr7                    2/2     Running   0          104s\nnode-exporter-8s5hp                    2/2     Running   0          103s\nnode-exporter-kgb48                    2/2     Running   0          104s\nnode-exporter-p8b7q                    2/2     Running   0          103s\nnode-exporter-v4nz7                    2/2     Running   0          103s\nprometheus-adapter-65b6bd474c-qvdb8    1/1     Running   0          102s\nprometheus-adapter-65b6bd474c-vlxhn    1/1     Running   0          102s\nprometheus-k8s-0                       1/2     Running   0          58s\nprometheus-k8s-1                       2/2     Running   0          58s\nprometheus-operator-6565b7b5f5-mgclf   2/2     Running   0          101s\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看top信息</font>\n\n```plain\n[root@master1 kube-prometheus]# kubectl top node\nNAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \nmaster1   579m         14%    2357Mi          66%       \nmaster2   383m         9%     1697Mi          48%       \nmaster3   482m         12%    2069Mi          58%       \nwork1     131m         3%     1327Mi          37%       \nwork2     132m         3%     1134Mi          32%       \nwork3     176m         4%     1100Mi          31%       \n[root@master1 kube-prometheus]# kubectl top pod\nNAME                     CPU(cores)   MEMORY(bytes)   \nmyapp-58bbc79c4f-cc9g5   0m           1Mi             \nmyapp-58bbc79c4f-txnp5   0m           1Mi             \nmyapp-58bbc79c4f-zvlcr   0m           1Mi\n```\n\n<h2 id=\"200078c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ingress资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以ingress-nginx为例：</font>\n\n```plain\n[root@master1 manifests]# cat ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: alertmanager\n  namespace: monitoring\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: alertmanager.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: alertmanager-main\n            port:\n              number: 9093 \n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana\n  namespace: monitoring\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: grafana.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: grafana\n            port:\n              number: 3000\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: prometheus\n  namespace: monitoring\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: prometheus.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: prometheus-k8s\n            port:\n              number: 9090\n```\n\n<h2 id=\"10b4cf9a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web访问验证</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">新增hosts解析记录</font>\n\n```plain\n192.168.10.10 alertmanager.local.com grafana.local.com prometheus.local.com\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://alertmanager.local.com/</font>](http://alertmanager.local.com/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，查看当前激活的告警</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813858882-40dfbb97-749d-4cf4-b79b-02dfa018a3fa.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://prometheus.local.com/targets</font>](http://prometheus.local.com/targets)<font style=\"background-color:rgba(255, 255, 255, 0);\">，查看targets已全部up</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813870278-f52a4a68-aca7-4ea7-8964-0be9efccd42e.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://grafana.local.com/login</font>](http://grafana.local.com/login)<font style=\"background-color:rgba(255, 255, 255, 0);\">，默认用户名和密码是admin/admin</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813882935-61131e36-ed0a-41fd-9c20-ea4e8a71edc2.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看数据源，以为我们自动配置Prometheus数据源</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813895510-86a615e8-c0a0-4c36-bb6b-b9b40d22ed5d.jpeg)\n\n<h2 id=\"8094d557\"><font style=\"background-color:rgba(255, 255, 255, 0);\">targets异常处理</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看targets可发现有两个监控任务没有对应的instance，这和serviceMonitor资源对象有关</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813909963-bdc64819-89b3-4ed4-9071-a8e3fcd6c7e6.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于prometheus-serviceMonitorKubeScheduler文件中，selector匹配的是service的标签，但是namespace中并没有app.kubernetes.io/name的service</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeSchedulerService.yaml并apply创建资源</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n    namespace: kube-system\n    name: kube-scheduler\n    labels:\n      app.kubernetes.io/name: kube-scheduler\nspec:\n    selector:\n      component: kube-scheduler\n    type: ClusterIP\n    ports:\n    - name: https-metrics\n      port: 10259\n      targetPort: 10259\n      protocol: TCP\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeControllerManagerService.yaml并apply创建资源</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n    namespace: kube-system\n    name: kube-controller-manager\n    labels:\n      app.kubernetes.io/name: kube-controller-manager\nspec:\n    selector:\n      component: kube-controller-manager\n    type: ClusterIP\n    ports:\n    - name: https-metrics\n      port: 10257\n      targetPort: 10257\n      protocol: TCP\n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">再次查看targets信息</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813969703-36af3983-6b25-42e6-afaf-b85b13f7855e.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">发现虽然加载了targets，但是无法访问该端口。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">需要请修改master节点的/etc/kubernetes/manifests/kube-controller-manager.yaml 文件和 /etc/kubernetes/manifests/kube-scheduler.yaml 文件，将其中的 - --bind-address=127.0.0.1 修改为 - --bind-address=0.0.0.0</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改完保存文件，pod会自动重启。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"48a6122b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署pushgateway(可选)</font></h1>\n---\n\n<h2 id=\"5e69a94c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源清单</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pushgateway目录下，创建这三个yaml文件。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayServiceMonitor.yaml</font>\n\n```plain\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    prometheus: k8s\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  endpoints:\n  - honorLabels: true\n    port: http\n  jobLabel: pushgateway\n  selector:\n    matchLabels:\n      app: prometheus-pushgateway\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayService.yaml</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: prometheus-pushgateway\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  type: NodePort\n  ports:\n  - name: http\n    port: 9091\n    nodePort: 30400\n    targetPort: metrics\n  selector:\n    app: prometheus-pushgateway\n#  type: ClusterIP\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayDeployment.yaml</font>\n\n```plain\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: prometheus-pushgateway\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prometheus-pushgateway\n  template:\n    metadata:\n      labels:\n        app: prometheus-pushgateway\n    spec:\n      containers:\n      - image: prom/pushgateway:v1.10.0\n        livenessProbe:\n          httpGet:\n            path: /#/status\n            port: 9091\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n        name: prometheus-pushgateway\n        ports:\n        - containerPort: 9091\n          name: metrics\n        readinessProbe:\n          httpGet:\n            path: /#/status\n            port: 9091\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 50m\n            memory: 100Mi\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-ingress.yaml</font>\n\n```plain\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`prometheus-pushgateway.local.com`)\n    kind: Rule\n    services:\n      - name: prometheus-pushgateway\n        port: 9091\n```\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n```plain\nkubectl apply -f .\n```\n\n<h2 id=\"eca8abf0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737814086186-b0c70632-a294-474f-8d17-9514ff77cd90.jpeg)\n\n<h1 id=\"1f318234\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高级配置</font></h1>\n---\n\n<h2 id=\"3b5e4f43\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana配置修改</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">默认grafana使用UTC时区和sqllite数据库，可按需调整</font>\n\n```plain\n# pwd\n/opt/k8s/kube-prometheus/manifests\n# cat grafana-config.yaml                \napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    app.kubernetes.io/component: grafana\n    app.kubernetes.io/name: grafana\n    app.kubernetes.io/part-of: kube-prometheus\n    app.kubernetes.io/version: 11.2.1\n  name: grafana-config\n  namespace: monitoring\nstringData:\n  grafana.ini: |\n    [date_formats] # 时区设置\n    default_timezone = Asia/Shanghai\n    [database] # 数据库设置\n    type = mysql\n    host = cluster-mysql-master.mysql.svc:3306\n    name = grafana\n    user = grafana\n    password = password\ntype: Opaque\n```\n\n<h2 id=\"e80a0cad\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据持久化存储</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">默认的的存储为</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">emptyDir</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，生产环境建议更换为</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">persistentVolumeClaim</font>`\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建grafana-pvc</font>\n\n```plain\n# cat grafana-pvc.yaml      \nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: grafana-pvc\n  namespace: monitoring\nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 500Mi\n# kubectl apply -f grafana-pvc.yaml   \npersistentvolumeclaim/grafana-pvc created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改grafana</font>\n\n```plain\n# cp /opt/k8s/kube-prometheus/manifests/grafana-deployment.yaml .\n# vim grafana-deployment.yaml \nvolumes:\n- name: grafana-storage\n  persistentVolumeClaim:\n    claimName: grafana-pvc\n# kubectl apply -f grafana-deployment.yaml \ndeployment.apps/grafana configured\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改prometheus</font>\n\n```plain\n# cp /opt/k8s/kube-prometheus/manifests/prometheus-prometheus.yaml .\n# vim prometheus-prometheus.yaml \nspec:\n  image: quay.io/prometheus/prometheus:v2.54.1\n  retention: 30d # 数据保留天数\n  storage: # 持久化配置\n    volumeClaimTemplate:\n      spec:\n        storageClassName: nfs   \n        accessModes: [\"ReadWriteOnce\"]\n        resources:\n          requests:\n            storage: 500Gi\n# kubectl apply -f prometheus-prometheus.yaml          \nprometheus.monitoring.coreos.com/k8s configured\n```\n\n<h2 id=\"f28d5761\"><font style=\"background-color:rgba(255, 255, 255, 0);\">node exporter新增ip标签</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">默认情况下node exporter指标只有主机名没有ip标签，可添加全局IP标签。</font>\n\n```plain\n# cp ../kube-prometheus/manifests/nodeExporter-serviceMonitor.yaml .\n# vim nodeExporter-serviceMonitor.yaml \napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    app.kubernetes.io/component: exporter\n    app.kubernetes.io/name: node-exporter\n    app.kubernetes.io/part-of: kube-prometheus\n    app.kubernetes.io/version: 1.8.2\n  name: node-exporter\n  namespace: monitoring\nspec:\n  endpoints:\n  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token\n    interval: 15s\n    port: https\n    relabelings:\n    - action: replace\n      regex: (.*)\n      replacement: $1\n      sourceLabels:\n      - __meta_kubernetes_pod_node_name\n      targetLabel: instance\n    - action: replace\n      sourceLabels: \n      - __meta_kubernetes_pod_host_ip\n      targetLabel: ip\n    scheme: https\n    tlsConfig:\n      insecureSkipVerify: true\n  jobLabel: app.kubernetes.io/name\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: exporter\n      app.kubernetes.io/name: node-exporter\n      app.kubernetes.io/part-of: kube-prometheus\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n","source":"_posts/12部署Prometheus监控.md","raw":"---\ntitle: 部署Prometheus监控\ndate: 2025-03-11 18:00:00\n---\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">如果已安装metrics-server需要先卸载，否则冲突</font>\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"adfb3ce8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件说明</font></h1>\n---\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如kubectl,hpa,scheduler等。</font>\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。</font>\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">NodeExporter：用于各node的关键度量指标状态数据。</font>\n4. <font style=\"background-color:rgba(255, 255, 255, 0);\">KubeStateMetrics：收集kubernetes集群内资源对象数据，制定告警规则。</font>\n5. <font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数据，通过http协议传输。</font>\n6. <font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana：是可视化数据统计和监控平台。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/prometheus-operator/kube-prometheus</font>](https://github.com/prometheus-operator/kube-prometheus)\n\n<h2 id=\"6a6cc2b2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font></h2>\n---\n\n```plain\ngit clone https://github.com/prometheus-operator/kube-prometheus.git\n```\n\n<h2 id=\"1dcabd41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源对象</font></h2>\n---\n\n```plain\n[root@master1 k8s-install]# kubectl create namespace monitoring \n[root@master1 k8s-install]# cd kube-prometheus/\n[root@master1 kube-prometheus]# kubectl apply --server-side -f manifests/setup\n[root@master1 kube-prometheus]# kubectl wait \\\n\t--for condition=Established \\\n\t--all CustomResourceDefinition \\\n\t--namespace=monitoring\n[root@master1 kube-prometheus]# kubectl apply -f manifests/\n```\n\n<h2 id=\"fea33636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证查看</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod状态</font>\n\n```plain\n[root@master1 kube-prometheus]# kubectl get pod -n monitoring \nNAME                                   READY   STATUS    RESTARTS   AGE\nalertmanager-main-0                    2/2     Running   0          61s\nalertmanager-main-1                    2/2     Running   0          61s\nalertmanager-main-2                    2/2     Running   0          61s\nblackbox-exporter-576df9484f-lr6xd     3/3     Running   0          107s\ngrafana-795ddfd4bd-jxlrw               1/1     Running   0          105s\nkube-state-metrics-bdfdcd5cd-7dgwl     3/3     Running   0          104s\nnode-exporter-4qnrz                    2/2     Running   0          104s\nnode-exporter-8hjr7                    2/2     Running   0          104s\nnode-exporter-8s5hp                    2/2     Running   0          103s\nnode-exporter-kgb48                    2/2     Running   0          104s\nnode-exporter-p8b7q                    2/2     Running   0          103s\nnode-exporter-v4nz7                    2/2     Running   0          103s\nprometheus-adapter-65b6bd474c-qvdb8    1/1     Running   0          102s\nprometheus-adapter-65b6bd474c-vlxhn    1/1     Running   0          102s\nprometheus-k8s-0                       1/2     Running   0          58s\nprometheus-k8s-1                       2/2     Running   0          58s\nprometheus-operator-6565b7b5f5-mgclf   2/2     Running   0          101s\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看top信息</font>\n\n```plain\n[root@master1 kube-prometheus]# kubectl top node\nNAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \nmaster1   579m         14%    2357Mi          66%       \nmaster2   383m         9%     1697Mi          48%       \nmaster3   482m         12%    2069Mi          58%       \nwork1     131m         3%     1327Mi          37%       \nwork2     132m         3%     1134Mi          32%       \nwork3     176m         4%     1100Mi          31%       \n[root@master1 kube-prometheus]# kubectl top pod\nNAME                     CPU(cores)   MEMORY(bytes)   \nmyapp-58bbc79c4f-cc9g5   0m           1Mi             \nmyapp-58bbc79c4f-txnp5   0m           1Mi             \nmyapp-58bbc79c4f-zvlcr   0m           1Mi\n```\n\n<h2 id=\"200078c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ingress资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以ingress-nginx为例：</font>\n\n```plain\n[root@master1 manifests]# cat ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: alertmanager\n  namespace: monitoring\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: alertmanager.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: alertmanager-main\n            port:\n              number: 9093 \n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana\n  namespace: monitoring\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: grafana.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: grafana\n            port:\n              number: 3000\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: prometheus\n  namespace: monitoring\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: prometheus.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: prometheus-k8s\n            port:\n              number: 9090\n```\n\n<h2 id=\"10b4cf9a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web访问验证</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">新增hosts解析记录</font>\n\n```plain\n192.168.10.10 alertmanager.local.com grafana.local.com prometheus.local.com\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://alertmanager.local.com/</font>](http://alertmanager.local.com/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，查看当前激活的告警</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813858882-40dfbb97-749d-4cf4-b79b-02dfa018a3fa.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://prometheus.local.com/targets</font>](http://prometheus.local.com/targets)<font style=\"background-color:rgba(255, 255, 255, 0);\">，查看targets已全部up</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813870278-f52a4a68-aca7-4ea7-8964-0be9efccd42e.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://grafana.local.com/login</font>](http://grafana.local.com/login)<font style=\"background-color:rgba(255, 255, 255, 0);\">，默认用户名和密码是admin/admin</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813882935-61131e36-ed0a-41fd-9c20-ea4e8a71edc2.jpeg)\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看数据源，以为我们自动配置Prometheus数据源</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813895510-86a615e8-c0a0-4c36-bb6b-b9b40d22ed5d.jpeg)\n\n<h2 id=\"8094d557\"><font style=\"background-color:rgba(255, 255, 255, 0);\">targets异常处理</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看targets可发现有两个监控任务没有对应的instance，这和serviceMonitor资源对象有关</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813909963-bdc64819-89b3-4ed4-9071-a8e3fcd6c7e6.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于prometheus-serviceMonitorKubeScheduler文件中，selector匹配的是service的标签，但是namespace中并没有app.kubernetes.io/name的service</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeSchedulerService.yaml并apply创建资源</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n    namespace: kube-system\n    name: kube-scheduler\n    labels:\n      app.kubernetes.io/name: kube-scheduler\nspec:\n    selector:\n      component: kube-scheduler\n    type: ClusterIP\n    ports:\n    - name: https-metrics\n      port: 10259\n      targetPort: 10259\n      protocol: TCP\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeControllerManagerService.yaml并apply创建资源</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n    namespace: kube-system\n    name: kube-controller-manager\n    labels:\n      app.kubernetes.io/name: kube-controller-manager\nspec:\n    selector:\n      component: kube-controller-manager\n    type: ClusterIP\n    ports:\n    - name: https-metrics\n      port: 10257\n      targetPort: 10257\n      protocol: TCP\n```\n\n3. <font style=\"background-color:rgba(255, 255, 255, 0);\">再次查看targets信息</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813969703-36af3983-6b25-42e6-afaf-b85b13f7855e.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">发现虽然加载了targets，但是无法访问该端口。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">需要请修改master节点的/etc/kubernetes/manifests/kube-controller-manager.yaml 文件和 /etc/kubernetes/manifests/kube-scheduler.yaml 文件，将其中的 - --bind-address=127.0.0.1 修改为 - --bind-address=0.0.0.0</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改完保存文件，pod会自动重启。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"48a6122b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署pushgateway(可选)</font></h1>\n---\n\n<h2 id=\"5e69a94c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源清单</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pushgateway目录下，创建这三个yaml文件。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayServiceMonitor.yaml</font>\n\n```plain\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    prometheus: k8s\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  endpoints:\n  - honorLabels: true\n    port: http\n  jobLabel: pushgateway\n  selector:\n    matchLabels:\n      app: prometheus-pushgateway\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayService.yaml</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: prometheus-pushgateway\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  type: NodePort\n  ports:\n  - name: http\n    port: 9091\n    nodePort: 30400\n    targetPort: metrics\n  selector:\n    app: prometheus-pushgateway\n#  type: ClusterIP\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayDeployment.yaml</font>\n\n```plain\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: prometheus-pushgateway\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: prometheus-pushgateway\n  template:\n    metadata:\n      labels:\n        app: prometheus-pushgateway\n    spec:\n      containers:\n      - image: prom/pushgateway:v1.10.0\n        livenessProbe:\n          httpGet:\n            path: /#/status\n            port: 9091\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n        name: prometheus-pushgateway\n        ports:\n        - containerPort: 9091\n          name: metrics\n        readinessProbe:\n          httpGet:\n            path: /#/status\n            port: 9091\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n        resources:\n          limits:\n            cpu: 50m\n            memory: 100Mi\n          requests:\n            cpu: 50m\n            memory: 100Mi\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-ingress.yaml</font>\n\n```plain\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: prometheus-pushgateway\n  namespace: monitoring\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`prometheus-pushgateway.local.com`)\n    kind: Rule\n    services:\n      - name: prometheus-pushgateway\n        port: 9091\n```\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n```plain\nkubectl apply -f .\n```\n\n<h2 id=\"eca8abf0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737814086186-b0c70632-a294-474f-8d17-9514ff77cd90.jpeg)\n\n<h1 id=\"1f318234\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高级配置</font></h1>\n---\n\n<h2 id=\"3b5e4f43\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana配置修改</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">默认grafana使用UTC时区和sqllite数据库，可按需调整</font>\n\n```plain\n# pwd\n/opt/k8s/kube-prometheus/manifests\n# cat grafana-config.yaml                \napiVersion: v1\nkind: Secret\nmetadata:\n  labels:\n    app.kubernetes.io/component: grafana\n    app.kubernetes.io/name: grafana\n    app.kubernetes.io/part-of: kube-prometheus\n    app.kubernetes.io/version: 11.2.1\n  name: grafana-config\n  namespace: monitoring\nstringData:\n  grafana.ini: |\n    [date_formats] # 时区设置\n    default_timezone = Asia/Shanghai\n    [database] # 数据库设置\n    type = mysql\n    host = cluster-mysql-master.mysql.svc:3306\n    name = grafana\n    user = grafana\n    password = password\ntype: Opaque\n```\n\n<h2 id=\"e80a0cad\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据持久化存储</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">默认的的存储为</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">emptyDir</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，生产环境建议更换为</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">persistentVolumeClaim</font>`\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建grafana-pvc</font>\n\n```plain\n# cat grafana-pvc.yaml      \nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: grafana-pvc\n  namespace: monitoring\nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 500Mi\n# kubectl apply -f grafana-pvc.yaml   \npersistentvolumeclaim/grafana-pvc created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改grafana</font>\n\n```plain\n# cp /opt/k8s/kube-prometheus/manifests/grafana-deployment.yaml .\n# vim grafana-deployment.yaml \nvolumes:\n- name: grafana-storage\n  persistentVolumeClaim:\n    claimName: grafana-pvc\n# kubectl apply -f grafana-deployment.yaml \ndeployment.apps/grafana configured\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改prometheus</font>\n\n```plain\n# cp /opt/k8s/kube-prometheus/manifests/prometheus-prometheus.yaml .\n# vim prometheus-prometheus.yaml \nspec:\n  image: quay.io/prometheus/prometheus:v2.54.1\n  retention: 30d # 数据保留天数\n  storage: # 持久化配置\n    volumeClaimTemplate:\n      spec:\n        storageClassName: nfs   \n        accessModes: [\"ReadWriteOnce\"]\n        resources:\n          requests:\n            storage: 500Gi\n# kubectl apply -f prometheus-prometheus.yaml          \nprometheus.monitoring.coreos.com/k8s configured\n```\n\n<h2 id=\"f28d5761\"><font style=\"background-color:rgba(255, 255, 255, 0);\">node exporter新增ip标签</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">默认情况下node exporter指标只有主机名没有ip标签，可添加全局IP标签。</font>\n\n```plain\n# cp ../kube-prometheus/manifests/nodeExporter-serviceMonitor.yaml .\n# vim nodeExporter-serviceMonitor.yaml \napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  labels:\n    app.kubernetes.io/component: exporter\n    app.kubernetes.io/name: node-exporter\n    app.kubernetes.io/part-of: kube-prometheus\n    app.kubernetes.io/version: 1.8.2\n  name: node-exporter\n  namespace: monitoring\nspec:\n  endpoints:\n  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token\n    interval: 15s\n    port: https\n    relabelings:\n    - action: replace\n      regex: (.*)\n      replacement: $1\n      sourceLabels:\n      - __meta_kubernetes_pod_node_name\n      targetLabel: instance\n    - action: replace\n      sourceLabels: \n      - __meta_kubernetes_pod_host_ip\n      targetLabel: ip\n    scheme: https\n    tlsConfig:\n      insecureSkipVerify: true\n  jobLabel: app.kubernetes.io/name\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: exporter\n      app.kubernetes.io/name: node-exporter\n      app.kubernetes.io/part-of: kube-prometheus\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n","slug":"12部署Prometheus监控","published":1,"updated":"2025-03-30T13:15:24.411Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjli000atsv19szcb6xd","content":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果已安装metrics-server需要先卸载，否则冲突</font></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"adfb3ce8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件说明</font></h1>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如kubectl,hpa,scheduler等。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">NodeExporter：用于各node的关键度量指标状态数据。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">KubeStateMetrics：收集kubernetes集群内资源对象数据，制定告警规则。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数据，通过http协议传输。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana：是可视化数据统计和监控平台。</font></li>\n</ol>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font><a href=\"https://github.com/prometheus-operator/kube-prometheus\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/prometheus-operator/kube-prometheus</font></a></p>\n<h2 id=\"6a6cc2b2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/prometheus-operator/kube-prometheus.git</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1dcabd41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源对象</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 k8s-install]# kubectl create namespace monitoring </span><br><span class=\"line\">[root@master1 k8s-install]# cd kube-prometheus/</span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl apply --server-side -f manifests/setup</span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl wait \\</span><br><span class=\"line\">\t--for condition=Established \\</span><br><span class=\"line\">\t--all CustomResourceDefinition \\</span><br><span class=\"line\">\t--namespace=monitoring</span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl apply -f manifests/</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fea33636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证查看</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod状态</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 kube-prometheus]# kubectl get pod -n monitoring </span><br><span class=\"line\">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">alertmanager-main-0                    2/2     Running   0          61s</span><br><span class=\"line\">alertmanager-main-1                    2/2     Running   0          61s</span><br><span class=\"line\">alertmanager-main-2                    2/2     Running   0          61s</span><br><span class=\"line\">blackbox-exporter-576df9484f-lr6xd     3/3     Running   0          107s</span><br><span class=\"line\">grafana-795ddfd4bd-jxlrw               1/1     Running   0          105s</span><br><span class=\"line\">kube-state-metrics-bdfdcd5cd-7dgwl     3/3     Running   0          104s</span><br><span class=\"line\">node-exporter-4qnrz                    2/2     Running   0          104s</span><br><span class=\"line\">node-exporter-8hjr7                    2/2     Running   0          104s</span><br><span class=\"line\">node-exporter-8s5hp                    2/2     Running   0          103s</span><br><span class=\"line\">node-exporter-kgb48                    2/2     Running   0          104s</span><br><span class=\"line\">node-exporter-p8b7q                    2/2     Running   0          103s</span><br><span class=\"line\">node-exporter-v4nz7                    2/2     Running   0          103s</span><br><span class=\"line\">prometheus-adapter-65b6bd474c-qvdb8    1/1     Running   0          102s</span><br><span class=\"line\">prometheus-adapter-65b6bd474c-vlxhn    1/1     Running   0          102s</span><br><span class=\"line\">prometheus-k8s-0                       1/2     Running   0          58s</span><br><span class=\"line\">prometheus-k8s-1                       2/2     Running   0          58s</span><br><span class=\"line\">prometheus-operator-6565b7b5f5-mgclf   2/2     Running   0          101s</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看top信息</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 kube-prometheus]# kubectl top node</span><br><span class=\"line\">NAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class=\"line\">master1   579m         14%    2357Mi          66%       </span><br><span class=\"line\">master2   383m         9%     1697Mi          48%       </span><br><span class=\"line\">master3   482m         12%    2069Mi          58%       </span><br><span class=\"line\">work1     131m         3%     1327Mi          37%       </span><br><span class=\"line\">work2     132m         3%     1134Mi          32%       </span><br><span class=\"line\">work3     176m         4%     1100Mi          31%       </span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl top pod</span><br><span class=\"line\">NAME                     CPU(cores)   MEMORY(bytes)   </span><br><span class=\"line\">myapp-58bbc79c4f-cc9g5   0m           1Mi             </span><br><span class=\"line\">myapp-58bbc79c4f-txnp5   0m           1Mi             </span><br><span class=\"line\">myapp-58bbc79c4f-zvlcr   0m           1Mi</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"200078c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ingress资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以ingress-nginx为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 manifests]# cat ingress.yaml</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: alertmanager</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: alertmanager.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: alertmanager-main</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 9093 </span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: grafana</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: grafana.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: grafana</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 3000</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: prometheus</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: prometheus.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: prometheus-k8s</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 9090</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10b4cf9a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web访问验证</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">新增hosts解析记录</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">192.168.10.10 alertmanager.local.com grafana.local.com prometheus.local.com</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font><a href=\"http://alertmanager.local.com/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://alertmanager.local.com/</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，查看当前激活的告警</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813858882-40dfbb97-749d-4cf4-b79b-02dfa018a3fa.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font><a href=\"http://prometheus.local.com/targets\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://prometheus.local.com/targets</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，查看targets已全部up</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813870278-f52a4a68-aca7-4ea7-8964-0be9efccd42e.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font><a href=\"http://grafana.local.com/login\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://grafana.local.com/login</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，默认用户名和密码是admin&#x2F;admin</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813882935-61131e36-ed0a-41fd-9c20-ea4e8a71edc2.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看数据源，以为我们自动配置Prometheus数据源</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813895510-86a615e8-c0a0-4c36-bb6b-b9b40d22ed5d.jpeg\"></p>\n<h2 id=\"8094d557\"><font style=\"background-color:rgba(255, 255, 255, 0);\">targets异常处理</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看targets可发现有两个监控任务没有对应的instance，这和serviceMonitor资源对象有关</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813909963-bdc64819-89b3-4ed4-9071-a8e3fcd6c7e6.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于prometheus-serviceMonitorKubeScheduler文件中，selector匹配的是service的标签，但是namespace中并没有app.kubernetes.io&#x2F;name的service</font></p>\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeSchedulerService.yaml并apply创建资源</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">    namespace: kube-system</span><br><span class=\"line\">    name: kube-scheduler</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      app.kubernetes.io/name: kube-scheduler</span><br><span class=\"line\">spec:</span><br><span class=\"line\">    selector:</span><br><span class=\"line\">      component: kube-scheduler</span><br><span class=\"line\">    type: ClusterIP</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - name: https-metrics</span><br><span class=\"line\">      port: 10259</span><br><span class=\"line\">      targetPort: 10259</span><br><span class=\"line\">      protocol: TCP</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeControllerManagerService.yaml并apply创建资源</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">    namespace: kube-system</span><br><span class=\"line\">    name: kube-controller-manager</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      app.kubernetes.io/name: kube-controller-manager</span><br><span class=\"line\">spec:</span><br><span class=\"line\">    selector:</span><br><span class=\"line\">      component: kube-controller-manager</span><br><span class=\"line\">    type: ClusterIP</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - name: https-metrics</span><br><span class=\"line\">      port: 10257</span><br><span class=\"line\">      targetPort: 10257</span><br><span class=\"line\">      protocol: TCP</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">再次查看targets信息</font></li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813969703-36af3983-6b25-42e6-afaf-b85b13f7855e.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">发现虽然加载了targets，但是无法访问该端口。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">需要请修改master节点的&#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-controller-manager.yaml 文件和 &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-scheduler.yaml 文件，将其中的 - –bind-address&#x3D;127.0.0.1 修改为 - –bind-address&#x3D;0.0.0.0</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改完保存文件，pod会自动重启。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"48a6122b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署pushgateway(可选)</font></h1>\n---\n\n<h2 id=\"5e69a94c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源清单</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">pushgateway目录下，创建这三个yaml文件。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayServiceMonitor.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: monitoring.coreos.com/v1</span><br><span class=\"line\">kind: ServiceMonitor</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    prometheus: k8s</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  endpoints:</span><br><span class=\"line\">  - honorLabels: true</span><br><span class=\"line\">    port: http</span><br><span class=\"line\">  jobLabel: pushgateway</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: prometheus-pushgateway</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayService.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: prometheus-pushgateway</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - name: http</span><br><span class=\"line\">    port: 9091</span><br><span class=\"line\">    nodePort: 30400</span><br><span class=\"line\">    targetPort: metrics</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app: prometheus-pushgateway</span><br><span class=\"line\">#  type: ClusterIP</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayDeployment.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: prometheus-pushgateway</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: prometheus-pushgateway</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: prometheus-pushgateway</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - image: prom/pushgateway:v1.10.0</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            path: /#/status</span><br><span class=\"line\">            port: 9091</span><br><span class=\"line\">          initialDelaySeconds: 10</span><br><span class=\"line\">          timeoutSeconds: 10</span><br><span class=\"line\">        name: prometheus-pushgateway</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 9091</span><br><span class=\"line\">          name: metrics</span><br><span class=\"line\">        readinessProbe:</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            path: /#/status</span><br><span class=\"line\">            port: 9091</span><br><span class=\"line\">          initialDelaySeconds: 10</span><br><span class=\"line\">          timeoutSeconds: 10</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            cpu: 50m</span><br><span class=\"line\">            memory: 100Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 50m</span><br><span class=\"line\">            memory: 100Mi</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-ingress.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`prometheus-pushgateway.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: prometheus-pushgateway</span><br><span class=\"line\">        port: 9091</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f .</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"eca8abf0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737814086186-b0c70632-a294-474f-8d17-9514ff77cd90.jpeg\"></p>\n<h1 id=\"1f318234\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高级配置</font></h1>\n---\n\n<h2 id=\"3b5e4f43\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana配置修改</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">默认grafana使用UTC时区和sqllite数据库，可按需调整</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># pwd</span><br><span class=\"line\">/opt/k8s/kube-prometheus/manifests</span><br><span class=\"line\"># cat grafana-config.yaml                </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/component: grafana</span><br><span class=\"line\">    app.kubernetes.io/name: grafana</span><br><span class=\"line\">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class=\"line\">    app.kubernetes.io/version: 11.2.1</span><br><span class=\"line\">  name: grafana-config</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">stringData:</span><br><span class=\"line\">  grafana.ini: |</span><br><span class=\"line\">    [date_formats] # 时区设置</span><br><span class=\"line\">    default_timezone = Asia/Shanghai</span><br><span class=\"line\">    [database] # 数据库设置</span><br><span class=\"line\">    type = mysql</span><br><span class=\"line\">    host = cluster-mysql-master.mysql.svc:3306</span><br><span class=\"line\">    name = grafana</span><br><span class=\"line\">    user = grafana</span><br><span class=\"line\">    password = password</span><br><span class=\"line\">type: Opaque</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e80a0cad\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据持久化存储</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">默认的的存储为</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;emptyDir&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">，生产环境建议更换为</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;persistentVolumeClaim&lt;/font&gt;</code></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建grafana-pvc</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cat grafana-pvc.yaml      </span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: grafana-pvc</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteMany</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 500Mi</span><br><span class=\"line\"># kubectl apply -f grafana-pvc.yaml   </span><br><span class=\"line\">persistentvolumeclaim/grafana-pvc created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改grafana</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cp /opt/k8s/kube-prometheus/manifests/grafana-deployment.yaml .</span><br><span class=\"line\"># vim grafana-deployment.yaml </span><br><span class=\"line\">volumes:</span><br><span class=\"line\">- name: grafana-storage</span><br><span class=\"line\">  persistentVolumeClaim:</span><br><span class=\"line\">    claimName: grafana-pvc</span><br><span class=\"line\"># kubectl apply -f grafana-deployment.yaml </span><br><span class=\"line\">deployment.apps/grafana configured</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改prometheus</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cp /opt/k8s/kube-prometheus/manifests/prometheus-prometheus.yaml .</span><br><span class=\"line\"># vim prometheus-prometheus.yaml </span><br><span class=\"line\">spec:</span><br><span class=\"line\">  image: quay.io/prometheus/prometheus:v2.54.1</span><br><span class=\"line\">  retention: 30d # 数据保留天数</span><br><span class=\"line\">  storage: # 持久化配置</span><br><span class=\"line\">    volumeClaimTemplate:</span><br><span class=\"line\">      spec:</span><br><span class=\"line\">        storageClassName: nfs   </span><br><span class=\"line\">        accessModes: [&quot;ReadWriteOnce&quot;]</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            storage: 500Gi</span><br><span class=\"line\"># kubectl apply -f prometheus-prometheus.yaml          </span><br><span class=\"line\">prometheus.monitoring.coreos.com/k8s configured</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f28d5761\"><font style=\"background-color:rgba(255, 255, 255, 0);\">node exporter新增ip标签</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">默认情况下node exporter指标只有主机名没有ip标签，可添加全局IP标签。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cp ../kube-prometheus/manifests/nodeExporter-serviceMonitor.yaml .</span><br><span class=\"line\"># vim nodeExporter-serviceMonitor.yaml </span><br><span class=\"line\">apiVersion: monitoring.coreos.com/v1</span><br><span class=\"line\">kind: ServiceMonitor</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/component: exporter</span><br><span class=\"line\">    app.kubernetes.io/name: node-exporter</span><br><span class=\"line\">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class=\"line\">    app.kubernetes.io/version: 1.8.2</span><br><span class=\"line\">  name: node-exporter</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  endpoints:</span><br><span class=\"line\">  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class=\"line\">    interval: 15s</span><br><span class=\"line\">    port: https</span><br><span class=\"line\">    relabelings:</span><br><span class=\"line\">    - action: replace</span><br><span class=\"line\">      regex: (.*)</span><br><span class=\"line\">      replacement: $1</span><br><span class=\"line\">      sourceLabels:</span><br><span class=\"line\">      - __meta_kubernetes_pod_node_name</span><br><span class=\"line\">      targetLabel: instance</span><br><span class=\"line\">    - action: replace</span><br><span class=\"line\">      sourceLabels: </span><br><span class=\"line\">      - __meta_kubernetes_pod_host_ip</span><br><span class=\"line\">      targetLabel: ip</span><br><span class=\"line\">    scheme: https</span><br><span class=\"line\">    tlsConfig:</span><br><span class=\"line\">      insecureSkipVerify: true</span><br><span class=\"line\">  jobLabel: app.kubernetes.io/name</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.kubernetes.io/component: exporter</span><br><span class=\"line\">      app.kubernetes.io/name: node-exporter</span><br><span class=\"line\">      app.kubernetes.io/part-of: kube-prometheus</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n","excerpt":"","more":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果已安装metrics-server需要先卸载，否则冲突</font></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"adfb3ce8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">组件说明</font></h1>\n---\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如kubectl,hpa,scheduler等。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">NodeExporter：用于各node的关键度量指标状态数据。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">KubeStateMetrics：收集kubernetes集群内资源对象数据，制定告警规则。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus：采用pull方式收集apiserver，scheduler，controller-manager，kubelet组件数据，通过http协议传输。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana：是可视化数据统计和监控平台。</font></li>\n</ol>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font><a href=\"https://github.com/prometheus-operator/kube-prometheus\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/prometheus-operator/kube-prometheus</font></a></p>\n<h2 id=\"6a6cc2b2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">克隆项目至本地</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/prometheus-operator/kube-prometheus.git</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1dcabd41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源对象</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 k8s-install]# kubectl create namespace monitoring </span><br><span class=\"line\">[root@master1 k8s-install]# cd kube-prometheus/</span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl apply --server-side -f manifests/setup</span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl wait \\</span><br><span class=\"line\">\t--for condition=Established \\</span><br><span class=\"line\">\t--all CustomResourceDefinition \\</span><br><span class=\"line\">\t--namespace=monitoring</span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl apply -f manifests/</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fea33636\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证查看</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看pod状态</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 kube-prometheus]# kubectl get pod -n monitoring </span><br><span class=\"line\">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">alertmanager-main-0                    2/2     Running   0          61s</span><br><span class=\"line\">alertmanager-main-1                    2/2     Running   0          61s</span><br><span class=\"line\">alertmanager-main-2                    2/2     Running   0          61s</span><br><span class=\"line\">blackbox-exporter-576df9484f-lr6xd     3/3     Running   0          107s</span><br><span class=\"line\">grafana-795ddfd4bd-jxlrw               1/1     Running   0          105s</span><br><span class=\"line\">kube-state-metrics-bdfdcd5cd-7dgwl     3/3     Running   0          104s</span><br><span class=\"line\">node-exporter-4qnrz                    2/2     Running   0          104s</span><br><span class=\"line\">node-exporter-8hjr7                    2/2     Running   0          104s</span><br><span class=\"line\">node-exporter-8s5hp                    2/2     Running   0          103s</span><br><span class=\"line\">node-exporter-kgb48                    2/2     Running   0          104s</span><br><span class=\"line\">node-exporter-p8b7q                    2/2     Running   0          103s</span><br><span class=\"line\">node-exporter-v4nz7                    2/2     Running   0          103s</span><br><span class=\"line\">prometheus-adapter-65b6bd474c-qvdb8    1/1     Running   0          102s</span><br><span class=\"line\">prometheus-adapter-65b6bd474c-vlxhn    1/1     Running   0          102s</span><br><span class=\"line\">prometheus-k8s-0                       1/2     Running   0          58s</span><br><span class=\"line\">prometheus-k8s-1                       2/2     Running   0          58s</span><br><span class=\"line\">prometheus-operator-6565b7b5f5-mgclf   2/2     Running   0          101s</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看top信息</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 kube-prometheus]# kubectl top node</span><br><span class=\"line\">NAME      CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class=\"line\">master1   579m         14%    2357Mi          66%       </span><br><span class=\"line\">master2   383m         9%     1697Mi          48%       </span><br><span class=\"line\">master3   482m         12%    2069Mi          58%       </span><br><span class=\"line\">work1     131m         3%     1327Mi          37%       </span><br><span class=\"line\">work2     132m         3%     1134Mi          32%       </span><br><span class=\"line\">work3     176m         4%     1100Mi          31%       </span><br><span class=\"line\">[root@master1 kube-prometheus]# kubectl top pod</span><br><span class=\"line\">NAME                     CPU(cores)   MEMORY(bytes)   </span><br><span class=\"line\">myapp-58bbc79c4f-cc9g5   0m           1Mi             </span><br><span class=\"line\">myapp-58bbc79c4f-txnp5   0m           1Mi             </span><br><span class=\"line\">myapp-58bbc79c4f-zvlcr   0m           1Mi</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"200078c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ingress资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以ingress-nginx为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 manifests]# cat ingress.yaml</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: alertmanager</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: alertmanager.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: alertmanager-main</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 9093 </span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: grafana</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: grafana.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: grafana</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 3000</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: prometheus</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: prometheus.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: prometheus-k8s</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 9090</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"10b4cf9a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web访问验证</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">新增hosts解析记录</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">192.168.10.10 alertmanager.local.com grafana.local.com prometheus.local.com</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font><a href=\"http://alertmanager.local.com/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://alertmanager.local.com/</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，查看当前激活的告警</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813858882-40dfbb97-749d-4cf4-b79b-02dfa018a3fa.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font><a href=\"http://prometheus.local.com/targets\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://prometheus.local.com/targets</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，查看targets已全部up</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813870278-f52a4a68-aca7-4ea7-8964-0be9efccd42e.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">访问</font><a href=\"http://grafana.local.com/login\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://grafana.local.com/login</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，默认用户名和密码是admin&#x2F;admin</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813882935-61131e36-ed0a-41fd-9c20-ea4e8a71edc2.jpeg\"></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看数据源，以为我们自动配置Prometheus数据源</font></li>\n</ul>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813895510-86a615e8-c0a0-4c36-bb6b-b9b40d22ed5d.jpeg\"></p>\n<h2 id=\"8094d557\"><font style=\"background-color:rgba(255, 255, 255, 0);\">targets异常处理</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看targets可发现有两个监控任务没有对应的instance，这和serviceMonitor资源对象有关</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813909963-bdc64819-89b3-4ed4-9071-a8e3fcd6c7e6.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于prometheus-serviceMonitorKubeScheduler文件中，selector匹配的是service的标签，但是namespace中并没有app.kubernetes.io&#x2F;name的service</font></p>\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeSchedulerService.yaml并apply创建资源</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">    namespace: kube-system</span><br><span class=\"line\">    name: kube-scheduler</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      app.kubernetes.io/name: kube-scheduler</span><br><span class=\"line\">spec:</span><br><span class=\"line\">    selector:</span><br><span class=\"line\">      component: kube-scheduler</span><br><span class=\"line\">    type: ClusterIP</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - name: https-metrics</span><br><span class=\"line\">      port: 10259</span><br><span class=\"line\">      targetPort: 10259</span><br><span class=\"line\">      protocol: TCP</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">新建prometheus-kubeControllerManagerService.yaml并apply创建资源</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">    namespace: kube-system</span><br><span class=\"line\">    name: kube-controller-manager</span><br><span class=\"line\">    labels:</span><br><span class=\"line\">      app.kubernetes.io/name: kube-controller-manager</span><br><span class=\"line\">spec:</span><br><span class=\"line\">    selector:</span><br><span class=\"line\">      component: kube-controller-manager</span><br><span class=\"line\">    type: ClusterIP</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - name: https-metrics</span><br><span class=\"line\">      port: 10257</span><br><span class=\"line\">      targetPort: 10257</span><br><span class=\"line\">      protocol: TCP</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">再次查看targets信息</font></li>\n</ol>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737813969703-36af3983-6b25-42e6-afaf-b85b13f7855e.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">发现虽然加载了targets，但是无法访问该端口。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">需要请修改master节点的&#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-controller-manager.yaml 文件和 &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;kube-scheduler.yaml 文件，将其中的 - –bind-address&#x3D;127.0.0.1 修改为 - –bind-address&#x3D;0.0.0.0</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改完保存文件，pod会自动重启。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"48a6122b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署pushgateway(可选)</font></h1>\n---\n\n<h2 id=\"5e69a94c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源清单</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">pushgateway目录下，创建这三个yaml文件。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayServiceMonitor.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: monitoring.coreos.com/v1</span><br><span class=\"line\">kind: ServiceMonitor</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    prometheus: k8s</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  endpoints:</span><br><span class=\"line\">  - honorLabels: true</span><br><span class=\"line\">    port: http</span><br><span class=\"line\">  jobLabel: pushgateway</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: prometheus-pushgateway</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayService.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: prometheus-pushgateway</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - name: http</span><br><span class=\"line\">    port: 9091</span><br><span class=\"line\">    nodePort: 30400</span><br><span class=\"line\">    targetPort: metrics</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app: prometheus-pushgateway</span><br><span class=\"line\">#  type: ClusterIP</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-pushgatewayDeployment.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: prometheus-pushgateway</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 1</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: prometheus-pushgateway</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: prometheus-pushgateway</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - image: prom/pushgateway:v1.10.0</span><br><span class=\"line\">        livenessProbe:</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            path: /#/status</span><br><span class=\"line\">            port: 9091</span><br><span class=\"line\">          initialDelaySeconds: 10</span><br><span class=\"line\">          timeoutSeconds: 10</span><br><span class=\"line\">        name: prometheus-pushgateway</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 9091</span><br><span class=\"line\">          name: metrics</span><br><span class=\"line\">        readinessProbe:</span><br><span class=\"line\">          httpGet:</span><br><span class=\"line\">            path: /#/status</span><br><span class=\"line\">            port: 9091</span><br><span class=\"line\">          initialDelaySeconds: 10</span><br><span class=\"line\">          timeoutSeconds: 10</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            cpu: 50m</span><br><span class=\"line\">            memory: 100Mi</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            cpu: 50m</span><br><span class=\"line\">            memory: 100Mi</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">prometheus-ingress.yaml</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: prometheus-pushgateway</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`prometheus-pushgateway.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: prometheus-pushgateway</span><br><span class=\"line\">        port: 9091</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f .</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"eca8abf0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737814086186-b0c70632-a294-474f-8d17-9514ff77cd90.jpeg\"></p>\n<h1 id=\"1f318234\"><font style=\"background-color:rgba(255, 255, 255, 0);\">高级配置</font></h1>\n---\n\n<h2 id=\"3b5e4f43\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Grafana配置修改</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">默认grafana使用UTC时区和sqllite数据库，可按需调整</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># pwd</span><br><span class=\"line\">/opt/k8s/kube-prometheus/manifests</span><br><span class=\"line\"># cat grafana-config.yaml                </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/component: grafana</span><br><span class=\"line\">    app.kubernetes.io/name: grafana</span><br><span class=\"line\">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class=\"line\">    app.kubernetes.io/version: 11.2.1</span><br><span class=\"line\">  name: grafana-config</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">stringData:</span><br><span class=\"line\">  grafana.ini: |</span><br><span class=\"line\">    [date_formats] # 时区设置</span><br><span class=\"line\">    default_timezone = Asia/Shanghai</span><br><span class=\"line\">    [database] # 数据库设置</span><br><span class=\"line\">    type = mysql</span><br><span class=\"line\">    host = cluster-mysql-master.mysql.svc:3306</span><br><span class=\"line\">    name = grafana</span><br><span class=\"line\">    user = grafana</span><br><span class=\"line\">    password = password</span><br><span class=\"line\">type: Opaque</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e80a0cad\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据持久化存储</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">默认的的存储为</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;emptyDir&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">，生产环境建议更换为</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;persistentVolumeClaim&lt;/font&gt;</code></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建grafana-pvc</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cat grafana-pvc.yaml      </span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: grafana-pvc</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteMany</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 500Mi</span><br><span class=\"line\"># kubectl apply -f grafana-pvc.yaml   </span><br><span class=\"line\">persistentvolumeclaim/grafana-pvc created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改grafana</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cp /opt/k8s/kube-prometheus/manifests/grafana-deployment.yaml .</span><br><span class=\"line\"># vim grafana-deployment.yaml </span><br><span class=\"line\">volumes:</span><br><span class=\"line\">- name: grafana-storage</span><br><span class=\"line\">  persistentVolumeClaim:</span><br><span class=\"line\">    claimName: grafana-pvc</span><br><span class=\"line\"># kubectl apply -f grafana-deployment.yaml </span><br><span class=\"line\">deployment.apps/grafana configured</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改prometheus</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cp /opt/k8s/kube-prometheus/manifests/prometheus-prometheus.yaml .</span><br><span class=\"line\"># vim prometheus-prometheus.yaml </span><br><span class=\"line\">spec:</span><br><span class=\"line\">  image: quay.io/prometheus/prometheus:v2.54.1</span><br><span class=\"line\">  retention: 30d # 数据保留天数</span><br><span class=\"line\">  storage: # 持久化配置</span><br><span class=\"line\">    volumeClaimTemplate:</span><br><span class=\"line\">      spec:</span><br><span class=\"line\">        storageClassName: nfs   </span><br><span class=\"line\">        accessModes: [&quot;ReadWriteOnce&quot;]</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            storage: 500Gi</span><br><span class=\"line\"># kubectl apply -f prometheus-prometheus.yaml          </span><br><span class=\"line\">prometheus.monitoring.coreos.com/k8s configured</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f28d5761\"><font style=\"background-color:rgba(255, 255, 255, 0);\">node exporter新增ip标签</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">默认情况下node exporter指标只有主机名没有ip标签，可添加全局IP标签。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cp ../kube-prometheus/manifests/nodeExporter-serviceMonitor.yaml .</span><br><span class=\"line\"># vim nodeExporter-serviceMonitor.yaml </span><br><span class=\"line\">apiVersion: monitoring.coreos.com/v1</span><br><span class=\"line\">kind: ServiceMonitor</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app.kubernetes.io/component: exporter</span><br><span class=\"line\">    app.kubernetes.io/name: node-exporter</span><br><span class=\"line\">    app.kubernetes.io/part-of: kube-prometheus</span><br><span class=\"line\">    app.kubernetes.io/version: 1.8.2</span><br><span class=\"line\">  name: node-exporter</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  endpoints:</span><br><span class=\"line\">  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class=\"line\">    interval: 15s</span><br><span class=\"line\">    port: https</span><br><span class=\"line\">    relabelings:</span><br><span class=\"line\">    - action: replace</span><br><span class=\"line\">      regex: (.*)</span><br><span class=\"line\">      replacement: $1</span><br><span class=\"line\">      sourceLabels:</span><br><span class=\"line\">      - __meta_kubernetes_pod_node_name</span><br><span class=\"line\">      targetLabel: instance</span><br><span class=\"line\">    - action: replace</span><br><span class=\"line\">      sourceLabels: </span><br><span class=\"line\">      - __meta_kubernetes_pod_host_ip</span><br><span class=\"line\">      targetLabel: ip</span><br><span class=\"line\">    scheme: https</span><br><span class=\"line\">    tlsConfig:</span><br><span class=\"line\">      insecureSkipVerify: true</span><br><span class=\"line\">  jobLabel: app.kubernetes.io/name</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app.kubernetes.io/component: exporter</span><br><span class=\"line\">      app.kubernetes.io/name: node-exporter</span><br><span class=\"line\">      app.kubernetes.io/part-of: kube-prometheus</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n"},{"title":"部署ELK日志收集","date":"2025-03-11T10:00:00.000Z","_content":"> <font style=\"background-color:rgba(255, 255, 255, 0);\">以3节点为例，存储使用local pv使用最大io性能，所有节点即是master节点也是data节点。完整内容可参考文档：</font>\n>\n\n> [<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/162609409</font>](https://www.cuiliangblog.cn/detail/section/162609409)\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"0b32f354\"><font style=\"background-color:rgba(255, 255, 255, 0);\">系统参数调整</font></h1>\n---\n\n<h2 id=\"b27228a9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改文件描述符数目</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">设置环境变量</font>\n\n```plain\n# 修改环境变量文件\nvim /etc/profile\nulimit -n 65535\n# 使配置生效\nsource /etc/profile\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改limits.conf配置文件</font>\n\n```plain\n# 修改limits.conf配置\nvim /etc/security/limits.conf\n* soft nofile 65535\n* hard nofile 65535\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font>\n\n```plain\n# ulimit -n\n65535\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h2 id=\"651ac674\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改虚拟内存数大小</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">内核设置可以直接在主机上设置，也可以通过具有特权的初始化容器中设置，通常情况下直接在主机上设置。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">临时设置</font>\n\n```plain\n# sysctl -w vm.max_map_count=262144\nvm.max_map_count = 262144\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">永久设置</font>\n\n```plain\ncat >> /etc/sysctl.conf << EOF\nvm.max_map_count=262144\nEOF\n# sysctl -p \nvm.max_map_count = 262144\n```\n\n<h1 id=\"6a435bf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建local pv资源</font></h1>\n---\n\n<h2 id=\"8115e1c9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建StorageClass</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font>\n\n```plain\n[root@tiaoban eck]# cat > storageClass.yaml << EOF\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer\nEOF\n[root@tiaoban eck]# kubectl apply -f storageClass.yaml \nstorageclass.storage.k8s.io/local-storage created\n[root@tiaoban eck]# kubectl get storageclass\nNAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nlocal-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s\n```\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data/es-data</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data/es-data</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data/es-data</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们需要提前在各个节点下创建对应的数据存储目录。</font>\n\n```plain\nmkdir -p /data/es-data\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv资源：</font>\n\n```plain\n[root@tiaoban eck]# cat > pv.yaml << EOF\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-data-pv0\n  labels:\n    app: es-pv0\nspec:\n  capacity:\n    storage: 50Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain # 删除策略\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data/es-data # 本地存储路径\n  nodeAffinity: # 调度至k8s-test1节点\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - k8s-test1\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-data-pv1\n  labels:\n    app: es-pv1\nspec:\n  capacity:\n    storage: 50Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain # 删除策略\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data/es-data # 本地存储路径\n  nodeAffinity: \n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - k8s-test2\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-data-pv2\n  labels:\n    app: es-pv2\nspec:\n  capacity:\n    storage: 50Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain # 删除策略\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data/es-data # 本地存储路径\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - k8s-test3\nEOF\n[root@tiaoban eck]# kubectl apply -f pv.yaml \npersistentvolume/es-data-pv0 created\npersistentvolume/es-data-pv1 created\npersistentvolume/es-data-pv2 created\n[root@tiaoban eck]# kubectl get pv | grep es\nes-data-pv0                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s\nes-data-pv1                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s\nes-data-pv2                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s\n```\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 = volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font>\n\n```plain\n[root@tiaoban eck]# cat > pvc.yaml << EOF\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: elasticsearch-data-elasticsearch-es-all-0\n  namespace: elk\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: es-pv0\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: elasticsearch-data-elasticsearch-es-all-1\n  namespace: elk\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: es-pv1\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: elasticsearch-data-elasticsearch-es-all-2\n  namespace: elk\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: es-pv2\nEOF\n[root@tiaoban eck]# kubectl create ns elk\nnamespace/elk created\n[root@tiaoban eck]# kubectl apply -f pvc.yaml \npersistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-0 created\npersistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-1 created\npersistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-2 created\n[root@tiaoban eck]# kubectl get pvc -n elk\nNAME                                        STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE\nelasticsearch-data-elasticsearch-es-all-0   Pending                                      local-storage   <unset>                 53s\nelasticsearch-data-elasticsearch-es-all-1   Pending                                      local-storage   <unset>                 53s\nelasticsearch-data-elasticsearch-es-all-2   Pending                                      local-storage   <unset>                 53s\n```\n\n<h1 id=\"5df6bac6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ECK部署</font></h1>\n---\n\n<h2 id=\"de76b7b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署CRD资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/crds.yaml\n[root@tiaoban eck]# kubectl apply -f crds.yaml \ncustomresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/elasticsearchautoscalers.autoscaling.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/logstashes.logstash.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/stackconfigpolicies.stackconfigpolicy.k8s.elastic.co created\n```\n\n<h2 id=\"95f9c118\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署Operator</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/operator.yaml\n[root@tiaoban eck]# kubectl apply -f operator.yaml \nnamespace/elastic-system created\nserviceaccount/elastic-operator created\nsecret/elastic-webhook-server-cert created\nconfigmap/elastic-operator created\nclusterrole.rbac.authorization.k8s.io/elastic-operator created\nclusterrole.rbac.authorization.k8s.io/elastic-operator-view created\nclusterrole.rbac.authorization.k8s.io/elastic-operator-edit created\nclusterrolebinding.rbac.authorization.k8s.io/elastic-operator created\nservice/elastic-webhook-server created\nstatefulset.apps/elastic-operator created\nvalidatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created\n```\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# kubectl get pod -n elastic-system \nNAME                 READY   STATUS    RESTARTS   AGE\nelastic-operator-0   1/1     Running   0          2s\n[root@tiaoban eck]# kubectl get svc -n elastic-system \nNAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\nelastic-webhook-server   ClusterIP   10.103.185.159   <none>        443/TCP   5m55s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当看到elastic-operator-0状态为Running时，表示eck已成功部署并运行在k8s集群上。</font>\n\n---\n\n<h1 id=\"e0dd4812\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Elasticsearch部署</font></h1>\n---\n\n<h2 id=\"e6087b0d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建elasticsearch集群</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# cat > es.yaml << EOF\napiVersion: elasticsearch.k8s.elastic.co/v1\nkind: Elasticsearch\nmetadata:\n  namespace: elk\n  name: elasticsearch\nspec:\n  version: 8.15.3\n  image: harbor.local.com/elk/elasticsearch:8.15.3 # 自定义镜像地址，如果不指定则从elastic官方镜像仓库拉取\n  nodeSets:\n  - name: all # 节点名称\n    count: 3  # 节点数量\n    volumeClaimTemplates:\n    - metadata:\n        name: elasticsearch-data\n      spec:\n        accessModes:\n        - ReadWriteOnce\n        resources:\n          requests:\n            storage: 50Gi # 指定master节点存储容量，与pvc容量保持一致。\n        storageClassName: local-storage\n    podTemplate:\n      spec:\n        containers:\n        - name: elasticsearch\n          env:\n          - name: ES_JAVA_OPTS           # 指定节点JVM大小\n            value: \"-Xms1g -Xmx1g\"\n          resources:\n            limits:\t\t\t\t\t\t\t\t\t\t\t# 资源限制值，通常为JVM的2倍\n              cpu: 1\n              memory: 2Gi\n            requests:\t\t\t\t\t\t\t\t\t\t# 资源请求值，通常与JVM保持一致\n              cpu: 500m\n              memory: 1Gi\nEOF\n[root@tiaoban eck]# kubectl apply -f es.yaml\nelasticsearch.elasticsearch.k8s.elastic.co/elasticsearch created\n```\n\n<h2 id=\"9778d05d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看并验证资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# kubectl get pod -n elk\nNAME                     READY   STATUS    RESTARTS   AGE\nelasticsearch-es-all-0   1/1     Running   0          3m48s\nelasticsearch-es-all-1   1/1     Running   0          3m48s\nelasticsearch-es-all-2   1/1     Running   0          3m48s\n[root@tiaoban eck]# kubectl get svc -n elk\nNAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\nelasticsearch-es-all             ClusterIP   None            <none>        9200/TCP   4m7s\nelasticsearch-es-http            ClusterIP   10.96.196.197   <none>        9200/TCP   4m9s\nelasticsearch-es-internal-http   ClusterIP   10.98.63.89     <none>        9200/TCP   4m9s\nelasticsearch-es-transport       ClusterIP   None            <none>        9300/TCP   4m9s\n[root@tiaoban eck]# kubectl get es -n elk\nNAME            HEALTH   NODES   VERSION   PHASE   AGE\nelasticsearch   green    3       8.15.3    Ready   4m22s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取elastic用户密码</font>\n\n```plain\n[root@tiaoban eck]# kubectl get secrets -n elk elasticsearch-es-elastic-user -o go-template='{{.data.elastic | base64decode}}'\nA1i529P3q783xblCSChV8zY1\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">导出CA证书</font>\n\n```plain\n[root@tiaoban eck]# kubectl -n elk get secret elasticsearch-es-http-certs-public -o go-template='{{index .data \"ca.crt\" | base64decode }}' > ca.crt\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font>\n\n```plain\n[root@rockylinux /]# curl -k https://elastic:A1i529P3q783xblCSChV8zY1@elasticsearch-es-http.elk.svc:9200/_cat/nodes?v\nip          heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name\n10.244.0.55            8          71   8    0.65    0.69     0.66 cdfhilmrstw -      elasticsearch-es-all-0\n10.244.2.32           45          72   9    0.90    0.98     0.82 cdfhilmrstw *      elasticsearch-es-all-2\n10.244.1.24           25          70   7    1.04    0.91     0.73 cdfhilmrstw -      elasticsearch-es-all-1\n```\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">自签证书创建secret资源</font>\n\n```plain\n[root@tiaoban eck]# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=elk-tls\"\nGenerating a RSA private key\nwriting new private key to 'tls.key'\n[root@tiaoban eck]# kubectl create secret tls -n elk elk-tls --cert=tls.crt --key=tls.key\nsecret/elk-tls created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建IngressRouter规则文件和ServersTransport文件，配置insecureSkipVerify使得traefik代理访问后端服务时跳过证书验证。</font>\n\n```plain\n[root@tiaoban eck]# cat > es-ingress.yaml << EOF\napiVersion: traefik.io/v1alpha1\nkind: ServersTransport\nmetadata:\n  name: elasticsearch-transport\n  namespace: elk\nspec:\n  serverName: \"elasticsearch.local.com\"\n  insecureSkipVerify: true\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: elasticsearch\n  namespace: elk\nspec:\n  entryPoints:\n    - websecure                  \n  routes:\n  - match: Host(`elasticsearch.local.com`)\n    kind: Rule\n    services:\n    - name: elasticsearch-es-http\n      port: 9200\n      serversTransport: elasticsearch-transport\n  tls:\n    secretName: elk-tls\nEOF\n[root@tiaoban eck]# kubectl apply -f es.yaml\nserverstransport.traefik.io/elasticsearch-transport created\ningressroute.traefik.io/elasticsearch created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts后访问验证</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892129822-ebb80e32-5d69-4e48-9c60-e940dd21b19e.jpeg)\n\n<h1 id=\"e20976d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Kibana部署</font></h1>\n---\n\n<h2 id=\"c7e46e28\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建kibana资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# cat > kibana.yaml << EOF\napiVersion: kibana.k8s.elastic.co/v1\nkind: Kibana\nmetadata:\n  name: kibana\n  namespace: elk\nspec:\n  version: 8.15.3\n  image: harbor.local.com/elk/kibana:8.15.3\n  count: 1\n  elasticsearchRef: # 与Elasticsearch资源名称匹配\n    name: elasticsearch\n  podTemplate:\n    spec:\n      containers:\n      - name: kibana\n        env:\n          - name: NODE_OPTIONS\n            value: \"--max-old-space-size=2048\"\n          - name: SERVER_PUBLICBASEURL\n            value: \"https://kibana.local.com\"\n          - name: I18N_LOCALE # 中文配置\n            value: \"zh-CN\"\n        resources:\n          requests:\n            memory: 1Gi\n            cpu: 0.5\n          limits:\n            memory: 2Gi\n            cpu: 2\nEOF\n[root@tiaoban eck]# kubectl apply -f kibana.yaml\nkibana.kibana.k8s.elastic.co/kibana created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font>\n\n```plain\n[root@tiaoban eck]# kubectl get pod -n elk | grep kibana\nkibana-kb-6698c6c45d-r7jj6   1/1     Running       0          3m39s\n[root@tiaoban eck]# kubectl get svc -n elk | grep kibana\nkibana-kb-http                   ClusterIP   10.105.217.119   <none>        5601/TCP   3m43s\n[root@tiaoban eck]# kubectl get kibana -n elk\nNAME     HEALTH   NODES   VERSION   AGE\nkibana   green    1       8.15.3     3m50s\n```\n\n<h2 id=\"fd33b243\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Ingress资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# cat > kibana-ingress.yaml << EOF\napiVersion: traefik.io/v1alpha1\nkind: ServersTransport\nmetadata:\n  name: kibana-transport\n  namespace: elk\nspec:\n  serverName: \"kibana.local.com\"\n  insecureSkipVerify: true\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: kibana\n  namespace: elk\nspec:\n  entryPoints:\n    - websecure             \n  routes:\n  - match: Host(`kibana.local.com`)\n    kind: Rule\n    services:\n    - name: kibana-kb-http\n      port: 5601\n      serversTransport: kibana-transport\n  tls:\n    secretName: elk-tls\nEOF\n[root@tiaoban eck]# kubectl apply -f kibana.yaml\nserverstransport.traefik.io/kibana-transport created\ningressroute.traefik.io/kibana created\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">客户端添加hosts记录后访问kibana测试</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892189533-8b40ab8f-903d-4572-a6e5-ed6c0be06c0b.jpeg)\n\n","source":"_posts/13.部署ELK日志收集.md","raw":"---\ntitle: 部署ELK日志收集\ndate: 2025-03-11 18:00:00\n---\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以3节点为例，存储使用local pv使用最大io性能，所有节点即是master节点也是data节点。完整内容可参考文档：</font>\n>\n\n> [<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/162609409</font>](https://www.cuiliangblog.cn/detail/section/162609409)\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"0b32f354\"><font style=\"background-color:rgba(255, 255, 255, 0);\">系统参数调整</font></h1>\n---\n\n<h2 id=\"b27228a9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改文件描述符数目</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">设置环境变量</font>\n\n```plain\n# 修改环境变量文件\nvim /etc/profile\nulimit -n 65535\n# 使配置生效\nsource /etc/profile\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改limits.conf配置文件</font>\n\n```plain\n# 修改limits.conf配置\nvim /etc/security/limits.conf\n* soft nofile 65535\n* hard nofile 65535\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font>\n\n```plain\n# ulimit -n\n65535\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h2 id=\"651ac674\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改虚拟内存数大小</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">内核设置可以直接在主机上设置，也可以通过具有特权的初始化容器中设置，通常情况下直接在主机上设置。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">临时设置</font>\n\n```plain\n# sysctl -w vm.max_map_count=262144\nvm.max_map_count = 262144\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">永久设置</font>\n\n```plain\ncat >> /etc/sysctl.conf << EOF\nvm.max_map_count=262144\nEOF\n# sysctl -p \nvm.max_map_count = 262144\n```\n\n<h1 id=\"6a435bf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建local pv资源</font></h1>\n---\n\n<h2 id=\"8115e1c9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建StorageClass</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font>\n\n```plain\n[root@tiaoban eck]# cat > storageClass.yaml << EOF\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer\nEOF\n[root@tiaoban eck]# kubectl apply -f storageClass.yaml \nstorageclass.storage.k8s.io/local-storage created\n[root@tiaoban eck]# kubectl get storageclass\nNAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nlocal-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s\n```\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data/es-data</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data/es-data</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data/es-data</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们需要提前在各个节点下创建对应的数据存储目录。</font>\n\n```plain\nmkdir -p /data/es-data\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv资源：</font>\n\n```plain\n[root@tiaoban eck]# cat > pv.yaml << EOF\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-data-pv0\n  labels:\n    app: es-pv0\nspec:\n  capacity:\n    storage: 50Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain # 删除策略\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data/es-data # 本地存储路径\n  nodeAffinity: # 调度至k8s-test1节点\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - k8s-test1\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-data-pv1\n  labels:\n    app: es-pv1\nspec:\n  capacity:\n    storage: 50Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain # 删除策略\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data/es-data # 本地存储路径\n  nodeAffinity: \n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - k8s-test2\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: es-data-pv2\n  labels:\n    app: es-pv2\nspec:\n  capacity:\n    storage: 50Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain # 删除策略\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data/es-data # 本地存储路径\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - k8s-test3\nEOF\n[root@tiaoban eck]# kubectl apply -f pv.yaml \npersistentvolume/es-data-pv0 created\npersistentvolume/es-data-pv1 created\npersistentvolume/es-data-pv2 created\n[root@tiaoban eck]# kubectl get pv | grep es\nes-data-pv0                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s\nes-data-pv1                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s\nes-data-pv2                                50Gi       RWO            Retain           Available                         local-storage   <unset>                          43s\n```\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 = volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font>\n\n```plain\n[root@tiaoban eck]# cat > pvc.yaml << EOF\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: elasticsearch-data-elasticsearch-es-all-0\n  namespace: elk\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: es-pv0\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: elasticsearch-data-elasticsearch-es-all-1\n  namespace: elk\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: es-pv1\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: elasticsearch-data-elasticsearch-es-all-2\n  namespace: elk\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: es-pv2\nEOF\n[root@tiaoban eck]# kubectl create ns elk\nnamespace/elk created\n[root@tiaoban eck]# kubectl apply -f pvc.yaml \npersistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-0 created\npersistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-1 created\npersistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-2 created\n[root@tiaoban eck]# kubectl get pvc -n elk\nNAME                                        STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE\nelasticsearch-data-elasticsearch-es-all-0   Pending                                      local-storage   <unset>                 53s\nelasticsearch-data-elasticsearch-es-all-1   Pending                                      local-storage   <unset>                 53s\nelasticsearch-data-elasticsearch-es-all-2   Pending                                      local-storage   <unset>                 53s\n```\n\n<h1 id=\"5df6bac6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ECK部署</font></h1>\n---\n\n<h2 id=\"de76b7b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署CRD资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/crds.yaml\n[root@tiaoban eck]# kubectl apply -f crds.yaml \ncustomresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/elasticsearchautoscalers.autoscaling.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/logstashes.logstash.k8s.elastic.co created\ncustomresourcedefinition.apiextensions.k8s.io/stackconfigpolicies.stackconfigpolicy.k8s.elastic.co created\n```\n\n<h2 id=\"95f9c118\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署Operator</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/operator.yaml\n[root@tiaoban eck]# kubectl apply -f operator.yaml \nnamespace/elastic-system created\nserviceaccount/elastic-operator created\nsecret/elastic-webhook-server-cert created\nconfigmap/elastic-operator created\nclusterrole.rbac.authorization.k8s.io/elastic-operator created\nclusterrole.rbac.authorization.k8s.io/elastic-operator-view created\nclusterrole.rbac.authorization.k8s.io/elastic-operator-edit created\nclusterrolebinding.rbac.authorization.k8s.io/elastic-operator created\nservice/elastic-webhook-server created\nstatefulset.apps/elastic-operator created\nvalidatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created\n```\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# kubectl get pod -n elastic-system \nNAME                 READY   STATUS    RESTARTS   AGE\nelastic-operator-0   1/1     Running   0          2s\n[root@tiaoban eck]# kubectl get svc -n elastic-system \nNAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\nelastic-webhook-server   ClusterIP   10.103.185.159   <none>        443/TCP   5m55s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当看到elastic-operator-0状态为Running时，表示eck已成功部署并运行在k8s集群上。</font>\n\n---\n\n<h1 id=\"e0dd4812\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Elasticsearch部署</font></h1>\n---\n\n<h2 id=\"e6087b0d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建elasticsearch集群</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# cat > es.yaml << EOF\napiVersion: elasticsearch.k8s.elastic.co/v1\nkind: Elasticsearch\nmetadata:\n  namespace: elk\n  name: elasticsearch\nspec:\n  version: 8.15.3\n  image: harbor.local.com/elk/elasticsearch:8.15.3 # 自定义镜像地址，如果不指定则从elastic官方镜像仓库拉取\n  nodeSets:\n  - name: all # 节点名称\n    count: 3  # 节点数量\n    volumeClaimTemplates:\n    - metadata:\n        name: elasticsearch-data\n      spec:\n        accessModes:\n        - ReadWriteOnce\n        resources:\n          requests:\n            storage: 50Gi # 指定master节点存储容量，与pvc容量保持一致。\n        storageClassName: local-storage\n    podTemplate:\n      spec:\n        containers:\n        - name: elasticsearch\n          env:\n          - name: ES_JAVA_OPTS           # 指定节点JVM大小\n            value: \"-Xms1g -Xmx1g\"\n          resources:\n            limits:\t\t\t\t\t\t\t\t\t\t\t# 资源限制值，通常为JVM的2倍\n              cpu: 1\n              memory: 2Gi\n            requests:\t\t\t\t\t\t\t\t\t\t# 资源请求值，通常与JVM保持一致\n              cpu: 500m\n              memory: 1Gi\nEOF\n[root@tiaoban eck]# kubectl apply -f es.yaml\nelasticsearch.elasticsearch.k8s.elastic.co/elasticsearch created\n```\n\n<h2 id=\"9778d05d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看并验证资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# kubectl get pod -n elk\nNAME                     READY   STATUS    RESTARTS   AGE\nelasticsearch-es-all-0   1/1     Running   0          3m48s\nelasticsearch-es-all-1   1/1     Running   0          3m48s\nelasticsearch-es-all-2   1/1     Running   0          3m48s\n[root@tiaoban eck]# kubectl get svc -n elk\nNAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\nelasticsearch-es-all             ClusterIP   None            <none>        9200/TCP   4m7s\nelasticsearch-es-http            ClusterIP   10.96.196.197   <none>        9200/TCP   4m9s\nelasticsearch-es-internal-http   ClusterIP   10.98.63.89     <none>        9200/TCP   4m9s\nelasticsearch-es-transport       ClusterIP   None            <none>        9300/TCP   4m9s\n[root@tiaoban eck]# kubectl get es -n elk\nNAME            HEALTH   NODES   VERSION   PHASE   AGE\nelasticsearch   green    3       8.15.3    Ready   4m22s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取elastic用户密码</font>\n\n```plain\n[root@tiaoban eck]# kubectl get secrets -n elk elasticsearch-es-elastic-user -o go-template='{{.data.elastic | base64decode}}'\nA1i529P3q783xblCSChV8zY1\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">导出CA证书</font>\n\n```plain\n[root@tiaoban eck]# kubectl -n elk get secret elasticsearch-es-http-certs-public -o go-template='{{index .data \"ca.crt\" | base64decode }}' > ca.crt\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font>\n\n```plain\n[root@rockylinux /]# curl -k https://elastic:A1i529P3q783xblCSChV8zY1@elasticsearch-es-http.elk.svc:9200/_cat/nodes?v\nip          heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name\n10.244.0.55            8          71   8    0.65    0.69     0.66 cdfhilmrstw -      elasticsearch-es-all-0\n10.244.2.32           45          72   9    0.90    0.98     0.82 cdfhilmrstw *      elasticsearch-es-all-2\n10.244.1.24           25          70   7    1.04    0.91     0.73 cdfhilmrstw -      elasticsearch-es-all-1\n```\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">自签证书创建secret资源</font>\n\n```plain\n[root@tiaoban eck]# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=elk-tls\"\nGenerating a RSA private key\nwriting new private key to 'tls.key'\n[root@tiaoban eck]# kubectl create secret tls -n elk elk-tls --cert=tls.crt --key=tls.key\nsecret/elk-tls created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建IngressRouter规则文件和ServersTransport文件，配置insecureSkipVerify使得traefik代理访问后端服务时跳过证书验证。</font>\n\n```plain\n[root@tiaoban eck]# cat > es-ingress.yaml << EOF\napiVersion: traefik.io/v1alpha1\nkind: ServersTransport\nmetadata:\n  name: elasticsearch-transport\n  namespace: elk\nspec:\n  serverName: \"elasticsearch.local.com\"\n  insecureSkipVerify: true\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: elasticsearch\n  namespace: elk\nspec:\n  entryPoints:\n    - websecure                  \n  routes:\n  - match: Host(`elasticsearch.local.com`)\n    kind: Rule\n    services:\n    - name: elasticsearch-es-http\n      port: 9200\n      serversTransport: elasticsearch-transport\n  tls:\n    secretName: elk-tls\nEOF\n[root@tiaoban eck]# kubectl apply -f es.yaml\nserverstransport.traefik.io/elasticsearch-transport created\ningressroute.traefik.io/elasticsearch created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts后访问验证</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892129822-ebb80e32-5d69-4e48-9c60-e940dd21b19e.jpeg)\n\n<h1 id=\"e20976d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Kibana部署</font></h1>\n---\n\n<h2 id=\"c7e46e28\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建kibana资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# cat > kibana.yaml << EOF\napiVersion: kibana.k8s.elastic.co/v1\nkind: Kibana\nmetadata:\n  name: kibana\n  namespace: elk\nspec:\n  version: 8.15.3\n  image: harbor.local.com/elk/kibana:8.15.3\n  count: 1\n  elasticsearchRef: # 与Elasticsearch资源名称匹配\n    name: elasticsearch\n  podTemplate:\n    spec:\n      containers:\n      - name: kibana\n        env:\n          - name: NODE_OPTIONS\n            value: \"--max-old-space-size=2048\"\n          - name: SERVER_PUBLICBASEURL\n            value: \"https://kibana.local.com\"\n          - name: I18N_LOCALE # 中文配置\n            value: \"zh-CN\"\n        resources:\n          requests:\n            memory: 1Gi\n            cpu: 0.5\n          limits:\n            memory: 2Gi\n            cpu: 2\nEOF\n[root@tiaoban eck]# kubectl apply -f kibana.yaml\nkibana.kibana.k8s.elastic.co/kibana created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font>\n\n```plain\n[root@tiaoban eck]# kubectl get pod -n elk | grep kibana\nkibana-kb-6698c6c45d-r7jj6   1/1     Running       0          3m39s\n[root@tiaoban eck]# kubectl get svc -n elk | grep kibana\nkibana-kb-http                   ClusterIP   10.105.217.119   <none>        5601/TCP   3m43s\n[root@tiaoban eck]# kubectl get kibana -n elk\nNAME     HEALTH   NODES   VERSION   AGE\nkibana   green    1       8.15.3     3m50s\n```\n\n<h2 id=\"fd33b243\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Ingress资源</font></h2>\n---\n\n```plain\n[root@tiaoban eck]# cat > kibana-ingress.yaml << EOF\napiVersion: traefik.io/v1alpha1\nkind: ServersTransport\nmetadata:\n  name: kibana-transport\n  namespace: elk\nspec:\n  serverName: \"kibana.local.com\"\n  insecureSkipVerify: true\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: kibana\n  namespace: elk\nspec:\n  entryPoints:\n    - websecure             \n  routes:\n  - match: Host(`kibana.local.com`)\n    kind: Rule\n    services:\n    - name: kibana-kb-http\n      port: 5601\n      serversTransport: kibana-transport\n  tls:\n    secretName: elk-tls\nEOF\n[root@tiaoban eck]# kubectl apply -f kibana.yaml\nserverstransport.traefik.io/kibana-transport created\ningressroute.traefik.io/kibana created\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">客户端添加hosts记录后访问kibana测试</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892189533-8b40ab8f-903d-4572-a6e5-ed6c0be06c0b.jpeg)\n\n","slug":"13.部署ELK日志收集","published":1,"updated":"2025-03-30T13:15:48.542Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlj000btsv19v1eamv7","content":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以3节点为例，存储使用local pv使用最大io性能，所有节点即是master节点也是data节点。完整内容可参考文档：</font></p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.cuiliangblog.cn/detail/section/162609409\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/162609409</font></a></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"0b32f354\"><font style=\"background-color:rgba(255, 255, 255, 0);\">系统参数调整</font></h1>\n---\n\n<h2 id=\"b27228a9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改文件描述符数目</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">设置环境变量</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改环境变量文件</span><br><span class=\"line\">vim /etc/profile</span><br><span class=\"line\">ulimit -n 65535</span><br><span class=\"line\"># 使配置生效</span><br><span class=\"line\">source /etc/profile</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改limits.conf配置文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改limits.conf配置</span><br><span class=\"line\">vim /etc/security/limits.conf</span><br><span class=\"line\">* soft nofile 65535</span><br><span class=\"line\">* hard nofile 65535</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># ulimit -n</span><br><span class=\"line\">65535</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h2 id=\"651ac674\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改虚拟内存数大小</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">内核设置可以直接在主机上设置，也可以通过具有特权的初始化容器中设置，通常情况下直接在主机上设置。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">临时设置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># sysctl -w vm.max_map_count=262144</span><br><span class=\"line\">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">永久设置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF</span><br><span class=\"line\">vm.max_map_count=262144</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># sysctl -p </span><br><span class=\"line\">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6a435bf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建local pv资源</font></h1>\n---\n\n<h2 id=\"8115e1c9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建StorageClass</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; storageClass.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: storage.k8s.io/v1</span><br><span class=\"line\">kind: StorageClass</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: local-storage</span><br><span class=\"line\">provisioner: kubernetes.io/no-provisioner</span><br><span class=\"line\">volumeBindingMode: WaitForFirstConsumer</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f storageClass.yaml </span><br><span class=\"line\">storageclass.storage.k8s.io/local-storage created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get storageclass</span><br><span class=\"line\">NAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span><br><span class=\"line\">local-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data&#x2F;es-data</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data&#x2F;es-data</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test3</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data&#x2F;es-data</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们需要提前在各个节点下创建对应的数据存储目录。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -p /data/es-data</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv资源：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; pv.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-data-pv0</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: es-pv0</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 50Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain # 删除策略</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data/es-data # 本地存储路径</span><br><span class=\"line\">  nodeAffinity: # 调度至k8s-test1节点</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - k8s-test1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-data-pv1</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: es-pv1</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 50Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain # 删除策略</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data/es-data # 本地存储路径</span><br><span class=\"line\">  nodeAffinity: </span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - k8s-test2</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-data-pv2</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: es-pv2</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 50Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain # 删除策略</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data/es-data # 本地存储路径</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - k8s-test3</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f pv.yaml </span><br><span class=\"line\">persistentvolume/es-data-pv0 created</span><br><span class=\"line\">persistentvolume/es-data-pv1 created</span><br><span class=\"line\">persistentvolume/es-data-pv2 created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get pv | grep es</span><br><span class=\"line\">es-data-pv0                                50Gi       RWO            Retain           Available                         local-storage   &lt;unset&gt;                          43s</span><br><span class=\"line\">es-data-pv1                                50Gi       RWO            Retain           Available                         local-storage   &lt;unset&gt;                          43s</span><br><span class=\"line\">es-data-pv2                                50Gi       RWO            Retain           Available                         local-storage   &lt;unset&gt;                          43s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 &#x3D; volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; pvc.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-data-elasticsearch-es-all-0</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: es-pv0</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-data-elasticsearch-es-all-1</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: es-pv1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-data-elasticsearch-es-all-2</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: es-pv2</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl create ns elk</span><br><span class=\"line\">namespace/elk created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f pvc.yaml </span><br><span class=\"line\">persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-0 created</span><br><span class=\"line\">persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-1 created</span><br><span class=\"line\">persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-2 created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get pvc -n elk</span><br><span class=\"line\">NAME                                        STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE</span><br><span class=\"line\">elasticsearch-data-elasticsearch-es-all-0   Pending                                      local-storage   &lt;unset&gt;                 53s</span><br><span class=\"line\">elasticsearch-data-elasticsearch-es-all-1   Pending                                      local-storage   &lt;unset&gt;                 53s</span><br><span class=\"line\">elasticsearch-data-elasticsearch-es-all-2   Pending                                      local-storage   &lt;unset&gt;                 53s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"5df6bac6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ECK部署</font></h1>\n---\n\n<h2 id=\"de76b7b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署CRD资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/crds.yaml</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f crds.yaml </span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/elasticsearchautoscalers.autoscaling.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/logstashes.logstash.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/stackconfigpolicies.stackconfigpolicy.k8s.elastic.co created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"95f9c118\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署Operator</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/operator.yaml</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f operator.yaml </span><br><span class=\"line\">namespace/elastic-system created</span><br><span class=\"line\">serviceaccount/elastic-operator created</span><br><span class=\"line\">secret/elastic-webhook-server-cert created</span><br><span class=\"line\">configmap/elastic-operator created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/elastic-operator created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/elastic-operator-view created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/elastic-operator-edit created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created</span><br><span class=\"line\">service/elastic-webhook-server created</span><br><span class=\"line\">statefulset.apps/elastic-operator created</span><br><span class=\"line\">validatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get pod -n elastic-system </span><br><span class=\"line\">NAME                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">elastic-operator-0   1/1     Running   0          2s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get svc -n elastic-system </span><br><span class=\"line\">NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE</span><br><span class=\"line\">elastic-webhook-server   ClusterIP   10.103.185.159   &lt;none&gt;        443/TCP   5m55s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当看到elastic-operator-0状态为Running时，表示eck已成功部署并运行在k8s集群上。</font></p>\n<hr>\n<h1 id=\"e0dd4812\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Elasticsearch部署</font></h1>\n---\n\n<h2 id=\"e6087b0d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建elasticsearch集群</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; es.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: elasticsearch.k8s.elastic.co/v1</span><br><span class=\"line\">kind: Elasticsearch</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">  name: elasticsearch</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  version: 8.15.3</span><br><span class=\"line\">  image: harbor.local.com/elk/elasticsearch:8.15.3 # 自定义镜像地址，如果不指定则从elastic官方镜像仓库拉取</span><br><span class=\"line\">  nodeSets:</span><br><span class=\"line\">  - name: all # 节点名称</span><br><span class=\"line\">    count: 3  # 节点数量</span><br><span class=\"line\">    volumeClaimTemplates:</span><br><span class=\"line\">    - metadata:</span><br><span class=\"line\">        name: elasticsearch-data</span><br><span class=\"line\">      spec:</span><br><span class=\"line\">        accessModes:</span><br><span class=\"line\">        - ReadWriteOnce</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            storage: 50Gi # 指定master节点存储容量，与pvc容量保持一致。</span><br><span class=\"line\">        storageClassName: local-storage</span><br><span class=\"line\">    podTemplate:</span><br><span class=\"line\">      spec:</span><br><span class=\"line\">        containers:</span><br><span class=\"line\">        - name: elasticsearch</span><br><span class=\"line\">          env:</span><br><span class=\"line\">          - name: ES_JAVA_OPTS           # 指定节点JVM大小</span><br><span class=\"line\">            value: &quot;-Xms1g -Xmx1g&quot;</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:\t\t\t\t\t\t\t\t\t\t\t# 资源限制值，通常为JVM的2倍</span><br><span class=\"line\">              cpu: 1</span><br><span class=\"line\">              memory: 2Gi</span><br><span class=\"line\">            requests:\t\t\t\t\t\t\t\t\t\t# 资源请求值，通常与JVM保持一致</span><br><span class=\"line\">              cpu: 500m</span><br><span class=\"line\">              memory: 1Gi</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f es.yaml</span><br><span class=\"line\">elasticsearch.elasticsearch.k8s.elastic.co/elasticsearch created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"9778d05d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看并验证资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get pod -n elk</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">elasticsearch-es-all-0   1/1     Running   0          3m48s</span><br><span class=\"line\">elasticsearch-es-all-1   1/1     Running   0          3m48s</span><br><span class=\"line\">elasticsearch-es-all-2   1/1     Running   0          3m48s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get svc -n elk</span><br><span class=\"line\">NAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class=\"line\">elasticsearch-es-all             ClusterIP   None            &lt;none&gt;        9200/TCP   4m7s</span><br><span class=\"line\">elasticsearch-es-http            ClusterIP   10.96.196.197   &lt;none&gt;        9200/TCP   4m9s</span><br><span class=\"line\">elasticsearch-es-internal-http   ClusterIP   10.98.63.89     &lt;none&gt;        9200/TCP   4m9s</span><br><span class=\"line\">elasticsearch-es-transport       ClusterIP   None            &lt;none&gt;        9300/TCP   4m9s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get es -n elk</span><br><span class=\"line\">NAME            HEALTH   NODES   VERSION   PHASE   AGE</span><br><span class=\"line\">elasticsearch   green    3       8.15.3    Ready   4m22s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取elastic用户密码</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get secrets -n elk elasticsearch-es-elastic-user -o go-template=&#x27;&#123;&#123;.data.elastic | base64decode&#125;&#125;&#x27;</span><br><span class=\"line\">A1i529P3q783xblCSChV8zY1</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">导出CA证书</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl -n elk get secret elasticsearch-es-http-certs-public -o go-template=&#x27;&#123;&#123;index .data &quot;ca.crt&quot; | base64decode &#125;&#125;&#x27; &gt; ca.crt</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@rockylinux /]# curl -k https://elastic:A1i529P3q783xblCSChV8zY1@elasticsearch-es-http.elk.svc:9200/_cat/nodes?v</span><br><span class=\"line\">ip          heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name</span><br><span class=\"line\">10.244.0.55            8          71   8    0.65    0.69     0.66 cdfhilmrstw -      elasticsearch-es-all-0</span><br><span class=\"line\">10.244.2.32           45          72   9    0.90    0.98     0.82 cdfhilmrstw *      elasticsearch-es-all-2</span><br><span class=\"line\">10.244.1.24           25          70   7    1.04    0.91     0.73 cdfhilmrstw -      elasticsearch-es-all-1</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">自签证书创建secret资源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=elk-tls&quot;</span><br><span class=\"line\">Generating a RSA private key</span><br><span class=\"line\">writing new private key to &#x27;tls.key&#x27;</span><br><span class=\"line\">[root@tiaoban eck]# kubectl create secret tls -n elk elk-tls --cert=tls.crt --key=tls.key</span><br><span class=\"line\">secret/elk-tls created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建IngressRouter规则文件和ServersTransport文件，配置insecureSkipVerify使得traefik代理访问后端服务时跳过证书验证。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; es-ingress.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: ServersTransport</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-transport</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  serverName: &quot;elasticsearch.local.com&quot;</span><br><span class=\"line\">  insecureSkipVerify: true</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - websecure                  </span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`elasticsearch.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">    - name: elasticsearch-es-http</span><br><span class=\"line\">      port: 9200</span><br><span class=\"line\">      serversTransport: elasticsearch-transport</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">    secretName: elk-tls</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f es.yaml</span><br><span class=\"line\">serverstransport.traefik.io/elasticsearch-transport created</span><br><span class=\"line\">ingressroute.traefik.io/elasticsearch created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts后访问验证</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892129822-ebb80e32-5d69-4e48-9c60-e940dd21b19e.jpeg\"></p>\n<h1 id=\"e20976d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Kibana部署</font></h1>\n---\n\n<h2 id=\"c7e46e28\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建kibana资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; kibana.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: kibana.k8s.elastic.co/v1</span><br><span class=\"line\">kind: Kibana</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kibana</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  version: 8.15.3</span><br><span class=\"line\">  image: harbor.local.com/elk/kibana:8.15.3</span><br><span class=\"line\">  count: 1</span><br><span class=\"line\">  elasticsearchRef: # 与Elasticsearch资源名称匹配</span><br><span class=\"line\">    name: elasticsearch</span><br><span class=\"line\">  podTemplate:</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: kibana</span><br><span class=\"line\">        env:</span><br><span class=\"line\">          - name: NODE_OPTIONS</span><br><span class=\"line\">            value: &quot;--max-old-space-size=2048&quot;</span><br><span class=\"line\">          - name: SERVER_PUBLICBASEURL</span><br><span class=\"line\">            value: &quot;https://kibana.local.com&quot;</span><br><span class=\"line\">          - name: I18N_LOCALE # 中文配置</span><br><span class=\"line\">            value: &quot;zh-CN&quot;</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            memory: 1Gi</span><br><span class=\"line\">            cpu: 0.5</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            memory: 2Gi</span><br><span class=\"line\">            cpu: 2</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f kibana.yaml</span><br><span class=\"line\">kibana.kibana.k8s.elastic.co/kibana created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get pod -n elk | grep kibana</span><br><span class=\"line\">kibana-kb-6698c6c45d-r7jj6   1/1     Running       0          3m39s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get svc -n elk | grep kibana</span><br><span class=\"line\">kibana-kb-http                   ClusterIP   10.105.217.119   &lt;none&gt;        5601/TCP   3m43s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get kibana -n elk</span><br><span class=\"line\">NAME     HEALTH   NODES   VERSION   AGE</span><br><span class=\"line\">kibana   green    1       8.15.3     3m50s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fd33b243\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Ingress资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; kibana-ingress.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: ServersTransport</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kibana-transport</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  serverName: &quot;kibana.local.com&quot;</span><br><span class=\"line\">  insecureSkipVerify: true</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kibana</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - websecure             </span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`kibana.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">    - name: kibana-kb-http</span><br><span class=\"line\">      port: 5601</span><br><span class=\"line\">      serversTransport: kibana-transport</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">    secretName: elk-tls</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f kibana.yaml</span><br><span class=\"line\">serverstransport.traefik.io/kibana-transport created</span><br><span class=\"line\">ingressroute.traefik.io/kibana created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">客户端添加hosts记录后访问kibana测试</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892189533-8b40ab8f-903d-4572-a6e5-ed6c0be06c0b.jpeg\"></p>\n","excerpt":"","more":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以3节点为例，存储使用local pv使用最大io性能，所有节点即是master节点也是data节点。完整内容可参考文档：</font></p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.cuiliangblog.cn/detail/section/162609409\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/162609409</font></a></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"0b32f354\"><font style=\"background-color:rgba(255, 255, 255, 0);\">系统参数调整</font></h1>\n---\n\n<h2 id=\"b27228a9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改文件描述符数目</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">设置环境变量</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改环境变量文件</span><br><span class=\"line\">vim /etc/profile</span><br><span class=\"line\">ulimit -n 65535</span><br><span class=\"line\"># 使配置生效</span><br><span class=\"line\">source /etc/profile</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改limits.conf配置文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改limits.conf配置</span><br><span class=\"line\">vim /etc/security/limits.conf</span><br><span class=\"line\">* soft nofile 65535</span><br><span class=\"line\">* hard nofile 65535</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># ulimit -n</span><br><span class=\"line\">65535</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h2 id=\"651ac674\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改虚拟内存数大小</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">内核设置可以直接在主机上设置，也可以通过具有特权的初始化容器中设置，通常情况下直接在主机上设置。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">临时设置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># sysctl -w vm.max_map_count=262144</span><br><span class=\"line\">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">永久设置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF</span><br><span class=\"line\">vm.max_map_count=262144</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># sysctl -p </span><br><span class=\"line\">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6a435bf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建local pv资源</font></h1>\n---\n\n<h2 id=\"8115e1c9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建StorageClass</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; storageClass.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: storage.k8s.io/v1</span><br><span class=\"line\">kind: StorageClass</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: local-storage</span><br><span class=\"line\">provisioner: kubernetes.io/no-provisioner</span><br><span class=\"line\">volumeBindingMode: WaitForFirstConsumer</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f storageClass.yaml </span><br><span class=\"line\">storageclass.storage.k8s.io/local-storage created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get storageclass</span><br><span class=\"line\">NAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span><br><span class=\"line\">local-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data&#x2F;es-data</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data&#x2F;es-data</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">es-data-pv2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-test3</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data&#x2F;es-data</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">50G</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们需要提前在各个节点下创建对应的数据存储目录。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir -p /data/es-data</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv资源：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; pv.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-data-pv0</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: es-pv0</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 50Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain # 删除策略</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data/es-data # 本地存储路径</span><br><span class=\"line\">  nodeAffinity: # 调度至k8s-test1节点</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - k8s-test1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-data-pv1</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: es-pv1</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 50Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain # 删除策略</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data/es-data # 本地存储路径</span><br><span class=\"line\">  nodeAffinity: </span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - k8s-test2</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: es-data-pv2</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: es-pv2</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 50Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  persistentVolumeReclaimPolicy: Retain # 删除策略</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data/es-data # 本地存储路径</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - k8s-test3</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f pv.yaml </span><br><span class=\"line\">persistentvolume/es-data-pv0 created</span><br><span class=\"line\">persistentvolume/es-data-pv1 created</span><br><span class=\"line\">persistentvolume/es-data-pv2 created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get pv | grep es</span><br><span class=\"line\">es-data-pv0                                50Gi       RWO            Retain           Available                         local-storage   &lt;unset&gt;                          43s</span><br><span class=\"line\">es-data-pv1                                50Gi       RWO            Retain           Available                         local-storage   &lt;unset&gt;                          43s</span><br><span class=\"line\">es-data-pv2                                50Gi       RWO            Retain           Available                         local-storage   &lt;unset&gt;                          43s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 &#x3D; volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; pvc.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-data-elasticsearch-es-all-0</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: es-pv0</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-data-elasticsearch-es-all-1</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: es-pv1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-data-elasticsearch-es-all-2</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: es-pv2</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl create ns elk</span><br><span class=\"line\">namespace/elk created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f pvc.yaml </span><br><span class=\"line\">persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-0 created</span><br><span class=\"line\">persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-1 created</span><br><span class=\"line\">persistentvolumeclaim/elasticsearch-data-elasticsearch-es-all-2 created</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get pvc -n elk</span><br><span class=\"line\">NAME                                        STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    VOLUMEATTRIBUTESCLASS   AGE</span><br><span class=\"line\">elasticsearch-data-elasticsearch-es-all-0   Pending                                      local-storage   &lt;unset&gt;                 53s</span><br><span class=\"line\">elasticsearch-data-elasticsearch-es-all-1   Pending                                      local-storage   &lt;unset&gt;                 53s</span><br><span class=\"line\">elasticsearch-data-elasticsearch-es-all-2   Pending                                      local-storage   &lt;unset&gt;                 53s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"5df6bac6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ECK部署</font></h1>\n---\n\n<h2 id=\"de76b7b1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署CRD资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/crds.yaml</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f crds.yaml </span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/elasticsearchautoscalers.autoscaling.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/logstashes.logstash.k8s.elastic.co created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/stackconfigpolicies.stackconfigpolicy.k8s.elastic.co created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"95f9c118\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署Operator</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# wget https://download.elastic.co/downloads/eck/2.14.0/operator.yaml</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f operator.yaml </span><br><span class=\"line\">namespace/elastic-system created</span><br><span class=\"line\">serviceaccount/elastic-operator created</span><br><span class=\"line\">secret/elastic-webhook-server-cert created</span><br><span class=\"line\">configmap/elastic-operator created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/elastic-operator created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/elastic-operator-view created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/elastic-operator-edit created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/elastic-operator created</span><br><span class=\"line\">service/elastic-webhook-server created</span><br><span class=\"line\">statefulset.apps/elastic-operator created</span><br><span class=\"line\">validatingwebhookconfiguration.admissionregistration.k8s.io/elastic-webhook.k8s.elastic.co created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get pod -n elastic-system </span><br><span class=\"line\">NAME                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">elastic-operator-0   1/1     Running   0          2s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get svc -n elastic-system </span><br><span class=\"line\">NAME                     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE</span><br><span class=\"line\">elastic-webhook-server   ClusterIP   10.103.185.159   &lt;none&gt;        443/TCP   5m55s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当看到elastic-operator-0状态为Running时，表示eck已成功部署并运行在k8s集群上。</font></p>\n<hr>\n<h1 id=\"e0dd4812\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Elasticsearch部署</font></h1>\n---\n\n<h2 id=\"e6087b0d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建elasticsearch集群</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; es.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: elasticsearch.k8s.elastic.co/v1</span><br><span class=\"line\">kind: Elasticsearch</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">  name: elasticsearch</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  version: 8.15.3</span><br><span class=\"line\">  image: harbor.local.com/elk/elasticsearch:8.15.3 # 自定义镜像地址，如果不指定则从elastic官方镜像仓库拉取</span><br><span class=\"line\">  nodeSets:</span><br><span class=\"line\">  - name: all # 节点名称</span><br><span class=\"line\">    count: 3  # 节点数量</span><br><span class=\"line\">    volumeClaimTemplates:</span><br><span class=\"line\">    - metadata:</span><br><span class=\"line\">        name: elasticsearch-data</span><br><span class=\"line\">      spec:</span><br><span class=\"line\">        accessModes:</span><br><span class=\"line\">        - ReadWriteOnce</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            storage: 50Gi # 指定master节点存储容量，与pvc容量保持一致。</span><br><span class=\"line\">        storageClassName: local-storage</span><br><span class=\"line\">    podTemplate:</span><br><span class=\"line\">      spec:</span><br><span class=\"line\">        containers:</span><br><span class=\"line\">        - name: elasticsearch</span><br><span class=\"line\">          env:</span><br><span class=\"line\">          - name: ES_JAVA_OPTS           # 指定节点JVM大小</span><br><span class=\"line\">            value: &quot;-Xms1g -Xmx1g&quot;</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            limits:\t\t\t\t\t\t\t\t\t\t\t# 资源限制值，通常为JVM的2倍</span><br><span class=\"line\">              cpu: 1</span><br><span class=\"line\">              memory: 2Gi</span><br><span class=\"line\">            requests:\t\t\t\t\t\t\t\t\t\t# 资源请求值，通常与JVM保持一致</span><br><span class=\"line\">              cpu: 500m</span><br><span class=\"line\">              memory: 1Gi</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f es.yaml</span><br><span class=\"line\">elasticsearch.elasticsearch.k8s.elastic.co/elasticsearch created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"9778d05d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看并验证资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get pod -n elk</span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">elasticsearch-es-all-0   1/1     Running   0          3m48s</span><br><span class=\"line\">elasticsearch-es-all-1   1/1     Running   0          3m48s</span><br><span class=\"line\">elasticsearch-es-all-2   1/1     Running   0          3m48s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get svc -n elk</span><br><span class=\"line\">NAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class=\"line\">elasticsearch-es-all             ClusterIP   None            &lt;none&gt;        9200/TCP   4m7s</span><br><span class=\"line\">elasticsearch-es-http            ClusterIP   10.96.196.197   &lt;none&gt;        9200/TCP   4m9s</span><br><span class=\"line\">elasticsearch-es-internal-http   ClusterIP   10.98.63.89     &lt;none&gt;        9200/TCP   4m9s</span><br><span class=\"line\">elasticsearch-es-transport       ClusterIP   None            &lt;none&gt;        9300/TCP   4m9s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get es -n elk</span><br><span class=\"line\">NAME            HEALTH   NODES   VERSION   PHASE   AGE</span><br><span class=\"line\">elasticsearch   green    3       8.15.3    Ready   4m22s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取elastic用户密码</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get secrets -n elk elasticsearch-es-elastic-user -o go-template=&#x27;&#123;&#123;.data.elastic | base64decode&#125;&#125;&#x27;</span><br><span class=\"line\">A1i529P3q783xblCSChV8zY1</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">导出CA证书</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl -n elk get secret elasticsearch-es-http-certs-public -o go-template=&#x27;&#123;&#123;index .data &quot;ca.crt&quot; | base64decode &#125;&#125;&#x27; &gt; ca.crt</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@rockylinux /]# curl -k https://elastic:A1i529P3q783xblCSChV8zY1@elasticsearch-es-http.elk.svc:9200/_cat/nodes?v</span><br><span class=\"line\">ip          heap.percent ram.percent cpu load_1m load_5m load_15m node.role   master name</span><br><span class=\"line\">10.244.0.55            8          71   8    0.65    0.69     0.66 cdfhilmrstw -      elasticsearch-es-all-0</span><br><span class=\"line\">10.244.2.32           45          72   9    0.90    0.98     0.82 cdfhilmrstw *      elasticsearch-es-all-2</span><br><span class=\"line\">10.244.1.24           25          70   7    1.04    0.91     0.73 cdfhilmrstw -      elasticsearch-es-all-1</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">自签证书创建secret资源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=elk-tls&quot;</span><br><span class=\"line\">Generating a RSA private key</span><br><span class=\"line\">writing new private key to &#x27;tls.key&#x27;</span><br><span class=\"line\">[root@tiaoban eck]# kubectl create secret tls -n elk elk-tls --cert=tls.crt --key=tls.key</span><br><span class=\"line\">secret/elk-tls created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建IngressRouter规则文件和ServersTransport文件，配置insecureSkipVerify使得traefik代理访问后端服务时跳过证书验证。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; es-ingress.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: ServersTransport</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch-transport</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  serverName: &quot;elasticsearch.local.com&quot;</span><br><span class=\"line\">  insecureSkipVerify: true</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: elasticsearch</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - websecure                  </span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`elasticsearch.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">    - name: elasticsearch-es-http</span><br><span class=\"line\">      port: 9200</span><br><span class=\"line\">      serversTransport: elasticsearch-transport</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">    secretName: elk-tls</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f es.yaml</span><br><span class=\"line\">serverstransport.traefik.io/elasticsearch-transport created</span><br><span class=\"line\">ingressroute.traefik.io/elasticsearch created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts后访问验证</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892129822-ebb80e32-5d69-4e48-9c60-e940dd21b19e.jpeg\"></p>\n<h1 id=\"e20976d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Kibana部署</font></h1>\n---\n\n<h2 id=\"c7e46e28\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建kibana资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; kibana.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: kibana.k8s.elastic.co/v1</span><br><span class=\"line\">kind: Kibana</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kibana</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  version: 8.15.3</span><br><span class=\"line\">  image: harbor.local.com/elk/kibana:8.15.3</span><br><span class=\"line\">  count: 1</span><br><span class=\"line\">  elasticsearchRef: # 与Elasticsearch资源名称匹配</span><br><span class=\"line\">    name: elasticsearch</span><br><span class=\"line\">  podTemplate:</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: kibana</span><br><span class=\"line\">        env:</span><br><span class=\"line\">          - name: NODE_OPTIONS</span><br><span class=\"line\">            value: &quot;--max-old-space-size=2048&quot;</span><br><span class=\"line\">          - name: SERVER_PUBLICBASEURL</span><br><span class=\"line\">            value: &quot;https://kibana.local.com&quot;</span><br><span class=\"line\">          - name: I18N_LOCALE # 中文配置</span><br><span class=\"line\">            value: &quot;zh-CN&quot;</span><br><span class=\"line\">        resources:</span><br><span class=\"line\">          requests:</span><br><span class=\"line\">            memory: 1Gi</span><br><span class=\"line\">            cpu: 0.5</span><br><span class=\"line\">          limits:</span><br><span class=\"line\">            memory: 2Gi</span><br><span class=\"line\">            cpu: 2</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f kibana.yaml</span><br><span class=\"line\">kibana.kibana.k8s.elastic.co/kibana created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# kubectl get pod -n elk | grep kibana</span><br><span class=\"line\">kibana-kb-6698c6c45d-r7jj6   1/1     Running       0          3m39s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get svc -n elk | grep kibana</span><br><span class=\"line\">kibana-kb-http                   ClusterIP   10.105.217.119   &lt;none&gt;        5601/TCP   3m43s</span><br><span class=\"line\">[root@tiaoban eck]# kubectl get kibana -n elk</span><br><span class=\"line\">NAME     HEALTH   NODES   VERSION   AGE</span><br><span class=\"line\">kibana   green    1       8.15.3     3m50s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fd33b243\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Ingress资源</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban eck]# cat &gt; kibana-ingress.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: ServersTransport</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kibana-transport</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  serverName: &quot;kibana.local.com&quot;</span><br><span class=\"line\">  insecureSkipVerify: true</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kibana</span><br><span class=\"line\">  namespace: elk</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - websecure             </span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`kibana.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">    - name: kibana-kb-http</span><br><span class=\"line\">      port: 5601</span><br><span class=\"line\">      serversTransport: kibana-transport</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">    secretName: elk-tls</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban eck]# kubectl apply -f kibana.yaml</span><br><span class=\"line\">serverstransport.traefik.io/kibana-transport created</span><br><span class=\"line\">ingressroute.traefik.io/kibana created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">客户端添加hosts记录后访问kibana测试</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892189533-8b40ab8f-903d-4572-a6e5-ed6c0be06c0b.jpeg\"></p>\n"},{"title":"部署Kafka消息队列","date":"2025-03-11T10:00:00.000Z","_content":"> <font style=\"background-color:rgba(255, 255, 255, 0);\">生产环境推荐的kafka部署方式为operator方式部署，Strimzi是目前最主流的operator方案。集群数据量较小的话，可以采用NFS共享存储，数据量较大的话使用local pv存储。</font>\n>\n\n<h1 id=\"4cc34089\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署operator</font></h1>\n---\n\n<h2 id=\"b6a89aa3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署operator</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署方式为helm或yaml文件部署，此处以helm方式部署为例：</font>\n\n```plain\n[root@tiaoban kafka]# helm repo add strimzi https://strimzi.io/charts/\n\"strimzi\" has been added to your repositories\n[root@tiaoban kafka]# helm pull strimzi/strimzi-kafka-operator --untar\n[root@tiaoban kafka]# cd strimzi-kafka-operator\n[root@tiaoban strimzi-kafka-operator]# vim values.yaml\ndashboards: # 加载grafna dashboard\n  enabled: true\n  namespace: monitoring\n# 安装\n[root@k8s-master traefik]# helm install strimzi -n kafka . -f values.yaml --create-namespace\nNAME: strimzi\nLAST DEPLOYED: Sun Oct 20 20:21:54 2024\nNAMESPACE: kafka\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nThank you for installing strimzi-kafka-operator-0.43.0\n\nTo create a Kafka cluster refer to the following documentation.\n\nhttps://strimzi.io/docs/operators/latest/deploying.html#deploying-cluster-operator-helm-chart-str\n[root@tiaoban strimzi-kafka-operator]# kubectl get pod -n kafka\nNAME                                        READY   STATUS    RESTARTS   AGE\nstrimzi-cluster-operator-56fdbb99cb-gznkw   1/1     Running   0          17m\n```\n\n<h2 id=\"ca142d42\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取示例文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Strimzi官方仓库为我们提供了各种场景下的示例文件，资源清单下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/strimzi/strimzi-kafka-operator/releases</font>](https://github.com/strimzi/strimzi-kafka-operator/releases)\n\n```plain\n[root@tiaoban kafka]# ls\nstrimzi-kafka-operator\n[root@tiaoban kafka]# wget https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.43.0/strimzi-0.43.0.tar.gz\n[root@tiaoban kafka]# tar -zxf strimzi-0.43.0.tar.gz\n[root@tiaoban kafka]# cd strimzi-0.43.0/examples/kafka\n[root@tiaoban kafka]# tree.\n├── kafka-ephemeral-single.yaml\n├── kafka-ephemeral.yaml\n├── kafka-jbod.yaml\n├── kafka-persistent-single.yaml\n├── kafka-persistent.yaml\n├── kafka-with-node-pools.yaml\n└── kraft\n    ├── kafka-ephemeral.yaml\n    ├── kafka-jbod.yaml\n    ├── kafka-single-node.yaml\n    ├── kafka-with-dual-role-nodes.yaml\n    ├── kafka.yaml\n    └── README.md\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例文件说明：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的持久集群。（推荐）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点（每个节点使用多个持久卷）的持久集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent-single.yaml:部署具有单个 ZooKeeper 节点和单个 Kafka 节点的持久集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的临时群集。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral-single.yaml:部署具有三个 ZooKeeper 节点和一个 Kafka 节点的临时群集。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kraft模式文件说明：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-with-dual-role-nodes.yaml：部署一个 Kafka 集群，其中包含一个共享代理和控制器角色的节点池。（推荐）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka.yaml：部署具有一个控制器节点池和一个代理节点池的持久性 Kafka 集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml：部署一个临时 Kafka 集群，其中包含一个控制器节点池和一个代理节点池。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-single-node.yaml：部署具有单个节点的 Kafka 集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml：在每个代理节点中部署具有多个卷的 Kafka 集群。</font>\n\n<h1 id=\"536ddfac\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Zookeeper模式部署</font></h1>\n---\n\n<h2 id=\"2def4be1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，分别用于3个zookeeper和3个kafka持久化存储数据使用。</font>\n\n```plain\n[root@tiaoban kafka]# cat kafka-pvc.yaml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-my-cluster-zookeeper-0\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-my-cluster-zookeeper-1\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-my-cluster-zookeeper-2\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-kafka-0\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-kafka-1\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-kafka-2\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n```\n\n<h2 id=\"12970d41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka和zookeeper</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-persistent.yaml示例文件，部署三个 ZooKeeper 和三个 Kafka 节点的持久集群。</font>\n\n```plain\n[root@tiaoban kafka]# cat > kafka.yaml << EOF\napiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n  name: my-cluster\n  namespace: kafka\nspec:\n  kafka:\n    version: 3.5.1\n    replicas: 3\n    listeners:\n      - name: plain\n        port: 9092\n        type: internal\n        tls: false\n      - name: tls\n        port: 9093\n        type: internal\n        tls: true\n    config:\n      offsets.topic.replication.factor: 3\n      transaction.state.log.replication.factor: 3\n      transaction.state.log.min.isr: 2\n      default.replication.factor: 3\n      min.insync.replicas: 2\n      inter.broker.protocol.version: \"3.5\"\n    storage:\n      type: jbod\n      volumes:\n      - id: 0\n        type: persistent-claim\n        size: 100Gi\n        deleteClaim: false\n  zookeeper:\n    replicas: 3\n    storage:\n      type: persistent-claim\n      size: 100Gi\n      deleteClaim: false\n  entityOperator:\n    topicOperator: {}\n    userOperator: {}\nEOF\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font>\n\n```plain\n[root@tiaoban kafka]# kubectl get pod -n kafka\nNAME                                          READY   STATUS    RESTARTS   AGE\nmy-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s\nmy-cluster-kafka-0                            1/1     Running   0          2m54s\nmy-cluster-kafka-1                            1/1     Running   0          2m54s\nmy-cluster-kafka-2                            1/1     Running   0          2m54s\nmy-cluster-zookeeper-0                        1/1     Running   0          3m19s\nmy-cluster-zookeeper-1                        1/1     Running   0          3m19s\nmy-cluster-zookeeper-2                        1/1     Running   0          3m19s\nstrimzi-cluster-operator-56fdbb99cb-gznkw     1/1     Running   0          97m\n[root@tiaoban kafka]# kubectl get svc -n kafka\nNAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                        AGE\nmy-cluster-kafka-bootstrap    ClusterIP   10.99.246.133   <none>        9091/TCP,9092/TCP,9093/TCP                     3m3s\nmy-cluster-kafka-brokers      ClusterIP   None            <none>        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   3m3s\nmy-cluster-zookeeper-client   ClusterIP   10.109.106.29   <none>        2181/TCP                                       3m28s\nmy-cluster-zookeeper-nodes    ClusterIP   None            <none>        2181/TCP,2888/TCP,3888/TCP                     3m28s\n```\n\n<h1 id=\"47303cc8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">KRaft模式部署</font></h1>\n---\n\n<h2 id=\"xzvtA\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，用于kafka持久化存储数据使用。</font>\n\n```plain\n[root@tiaoban kafka]# cat > kafka-pvc.yaml << EOF\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-dual-role-0\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-dual-role-1\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-dual-role-2\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\nEOF\n```\n\n<h2 id=\"c1485a3b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-with-dual-role-nodes.yaml示例文件，部署一个控制代理节点和三个 Kafka 节点的持久集群。</font>\n\n```plain\n[root@tiaoban kafka]# cat > kafka.yaml << EOF\napiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaNodePool\nmetadata:\n  name: dual-role\n  namespace: kafka\n  labels:\n    strimzi.io/cluster: my-cluster\nspec:\n  replicas: 3\n  roles:\n    - controller\n    - broker\n  storage:\n    type: jbod\n    volumes:\n      - id: 0\n        type: persistent-claim\n        size: 10Gi\n        deleteClaim: false\n        kraftMetadata: shared\n---\napiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n  name: my-cluster\n  namespace: kafka\n  annotations:\n    strimzi.io/node-pools: enabled\n    strimzi.io/kraft: enabled\nspec:\n  kafka:\n    version: 3.8.0\n    metadataVersion: 3.8-IV0\n    listeners:\n      - name: plain\n        port: 9092\n        type: internal\n        tls: false\n      - name: tls\n        port: 9093\n        type: internal\n        tls: true\n    config:\n      offsets.topic.replication.factor: 3\n      transaction.state.log.replication.factor: 3\n      transaction.state.log.min.isr: 2\n      default.replication.factor: 3\n      min.insync.replicas: 2\n  entityOperator:\n    topicOperator: {}\n    userOperator: {}\n  kafkaExporter: {} # 启用exporter监控\nEOF\n```\n\n<h2 id=\"Y9NBE\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font>\n\n```plain\n[root@tiaoban kafka]# kubectl get pod -n kafka\nNAME                                          READY   STATUS    RESTARTS   AGE\nmy-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s\nNAME                                          READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES\nmy-cluster-dual-role-0                        1/1     Running   0          10m     10.244.3.65   k8s-test4   <none>           <none>\nmy-cluster-dual-role-1                        1/1     Running   0          10m     10.244.1.33   k8s-test2   <none>           <none>\nmy-cluster-dual-role-2                        1/1     Running   0          10m     10.244.2.46   k8s-test3   <none>           <none>\nmy-cluster-entity-operator-5dc6767689-jmnck   2/2     Running   0          9m26s   10.244.3.66   k8s-test4   <none>           <none>\nstrimzi-cluster-operator-7fb8ff4bd-fzfgw      1/1     Running   0          39m     10.244.3.64   k8s-test4   <none>           <none>\n[root@tiaoban kafka]# kubectl get svc -n kafka\nNAME                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                        AGE\nmy-cluster-kafka-bootstrap   ClusterIP   10.107.111.213   <none>        9091/TCP,9092/TCP,9093/TCP                     21m\nmy-cluster-kafka-brokers     ClusterIP   None             <none>        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   21m\n```\n\n<h1 id=\"41af4e22\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h1>\n---\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建configmap和ingress资源，在configmap中指定kafka连接地址。以traefik为例，创建ingress资源便于通过域名方式访问。</font>\n\n```plain\n[root@tiaoban kafka]# cat kafka-ui.yaml \napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kafka-ui-helm-values\n  namespace: kafka\ndata:\n  KAFKA_CLUSTERS_0_NAME: \"kafka-cluster\"\n  KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: \"my-cluster-kafka-brokers.kafka.svc:9092\"\n  AUTH_TYPE: \"DISABLED\"\n  MANAGEMENT_HEALTH_LDAP_ENABLED: \"FALSE\" \n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: kafka-ui\n  namespace: kafka\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`kafka-ui.local.com`) \n    kind: Rule\n    services:\n      - name: kafka-ui\n        port: 80\n[root@tiaoban kafka]# kubectl apply -f kafka-ui.yaml \nconfigmap/kafka-ui-helm-values created\ningressroute.traefik.containo.us/kafka-ui created\n```\n\n<h2 id=\"cs4WC\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">helm方式部署kafka-ui并指定配置文件</font>\n\n```plain\n[root@tiaoban kafka]# helm repo add kafka-ui https://provectus.github.io/kafka-ui-charts\n[root@tiaoban kafka]# helm install kafka-ui kafka-ui/kafka-ui -n kafka --set existingConfigMap=\"kafka-ui-helm-values\"\nNAME: kafka-ui\nLAST DEPLOYED: Mon Oct  9 09:56:45 2023\nNAMESPACE: kafka\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\n1. Get the application URL by running these commands:\n  export POD_NAME=$(kubectl get pods --namespace kafka -l \"app.kubernetes.io/name=kafka-ui,app.kubernetes.io/instance=kafka-ui\" -o jsonpath=\"{.items[0].metadata.name}\")\n  echo \"Visit http://127.0.0.1:8080 to use your application\"\n  kubectl --namespace kafka port-forward $POD_NAME 8080:8080\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证，添加hosts记录</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100 kafka-ui.local.com</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问测试。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892946714-217657ff-6bcd-42d0-b644-2389efd26ca5.jpeg)\n\n","source":"_posts/16.部署Kafka消息队列 副本.md","raw":"---\ntitle: 部署Kafka消息队列\ndate: 2025-03-11 18:00:00\n---\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">生产环境推荐的kafka部署方式为operator方式部署，Strimzi是目前最主流的operator方案。集群数据量较小的话，可以采用NFS共享存储，数据量较大的话使用local pv存储。</font>\n>\n\n<h1 id=\"4cc34089\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署operator</font></h1>\n---\n\n<h2 id=\"b6a89aa3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署operator</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署方式为helm或yaml文件部署，此处以helm方式部署为例：</font>\n\n```plain\n[root@tiaoban kafka]# helm repo add strimzi https://strimzi.io/charts/\n\"strimzi\" has been added to your repositories\n[root@tiaoban kafka]# helm pull strimzi/strimzi-kafka-operator --untar\n[root@tiaoban kafka]# cd strimzi-kafka-operator\n[root@tiaoban strimzi-kafka-operator]# vim values.yaml\ndashboards: # 加载grafna dashboard\n  enabled: true\n  namespace: monitoring\n# 安装\n[root@k8s-master traefik]# helm install strimzi -n kafka . -f values.yaml --create-namespace\nNAME: strimzi\nLAST DEPLOYED: Sun Oct 20 20:21:54 2024\nNAMESPACE: kafka\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nThank you for installing strimzi-kafka-operator-0.43.0\n\nTo create a Kafka cluster refer to the following documentation.\n\nhttps://strimzi.io/docs/operators/latest/deploying.html#deploying-cluster-operator-helm-chart-str\n[root@tiaoban strimzi-kafka-operator]# kubectl get pod -n kafka\nNAME                                        READY   STATUS    RESTARTS   AGE\nstrimzi-cluster-operator-56fdbb99cb-gznkw   1/1     Running   0          17m\n```\n\n<h2 id=\"ca142d42\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取示例文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Strimzi官方仓库为我们提供了各种场景下的示例文件，资源清单下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/strimzi/strimzi-kafka-operator/releases</font>](https://github.com/strimzi/strimzi-kafka-operator/releases)\n\n```plain\n[root@tiaoban kafka]# ls\nstrimzi-kafka-operator\n[root@tiaoban kafka]# wget https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.43.0/strimzi-0.43.0.tar.gz\n[root@tiaoban kafka]# tar -zxf strimzi-0.43.0.tar.gz\n[root@tiaoban kafka]# cd strimzi-0.43.0/examples/kafka\n[root@tiaoban kafka]# tree.\n├── kafka-ephemeral-single.yaml\n├── kafka-ephemeral.yaml\n├── kafka-jbod.yaml\n├── kafka-persistent-single.yaml\n├── kafka-persistent.yaml\n├── kafka-with-node-pools.yaml\n└── kraft\n    ├── kafka-ephemeral.yaml\n    ├── kafka-jbod.yaml\n    ├── kafka-single-node.yaml\n    ├── kafka-with-dual-role-nodes.yaml\n    ├── kafka.yaml\n    └── README.md\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例文件说明：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的持久集群。（推荐）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点（每个节点使用多个持久卷）的持久集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent-single.yaml:部署具有单个 ZooKeeper 节点和单个 Kafka 节点的持久集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的临时群集。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral-single.yaml:部署具有三个 ZooKeeper 节点和一个 Kafka 节点的临时群集。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kraft模式文件说明：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-with-dual-role-nodes.yaml：部署一个 Kafka 集群，其中包含一个共享代理和控制器角色的节点池。（推荐）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka.yaml：部署具有一个控制器节点池和一个代理节点池的持久性 Kafka 集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml：部署一个临时 Kafka 集群，其中包含一个控制器节点池和一个代理节点池。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-single-node.yaml：部署具有单个节点的 Kafka 集群。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml：在每个代理节点中部署具有多个卷的 Kafka 集群。</font>\n\n<h1 id=\"536ddfac\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Zookeeper模式部署</font></h1>\n---\n\n<h2 id=\"2def4be1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，分别用于3个zookeeper和3个kafka持久化存储数据使用。</font>\n\n```plain\n[root@tiaoban kafka]# cat kafka-pvc.yaml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-my-cluster-zookeeper-0\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-my-cluster-zookeeper-1\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-my-cluster-zookeeper-2\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-kafka-0\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-kafka-1\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-kafka-2\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 100Gi\n```\n\n<h2 id=\"12970d41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka和zookeeper</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-persistent.yaml示例文件，部署三个 ZooKeeper 和三个 Kafka 节点的持久集群。</font>\n\n```plain\n[root@tiaoban kafka]# cat > kafka.yaml << EOF\napiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n  name: my-cluster\n  namespace: kafka\nspec:\n  kafka:\n    version: 3.5.1\n    replicas: 3\n    listeners:\n      - name: plain\n        port: 9092\n        type: internal\n        tls: false\n      - name: tls\n        port: 9093\n        type: internal\n        tls: true\n    config:\n      offsets.topic.replication.factor: 3\n      transaction.state.log.replication.factor: 3\n      transaction.state.log.min.isr: 2\n      default.replication.factor: 3\n      min.insync.replicas: 2\n      inter.broker.protocol.version: \"3.5\"\n    storage:\n      type: jbod\n      volumes:\n      - id: 0\n        type: persistent-claim\n        size: 100Gi\n        deleteClaim: false\n  zookeeper:\n    replicas: 3\n    storage:\n      type: persistent-claim\n      size: 100Gi\n      deleteClaim: false\n  entityOperator:\n    topicOperator: {}\n    userOperator: {}\nEOF\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font>\n\n```plain\n[root@tiaoban kafka]# kubectl get pod -n kafka\nNAME                                          READY   STATUS    RESTARTS   AGE\nmy-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s\nmy-cluster-kafka-0                            1/1     Running   0          2m54s\nmy-cluster-kafka-1                            1/1     Running   0          2m54s\nmy-cluster-kafka-2                            1/1     Running   0          2m54s\nmy-cluster-zookeeper-0                        1/1     Running   0          3m19s\nmy-cluster-zookeeper-1                        1/1     Running   0          3m19s\nmy-cluster-zookeeper-2                        1/1     Running   0          3m19s\nstrimzi-cluster-operator-56fdbb99cb-gznkw     1/1     Running   0          97m\n[root@tiaoban kafka]# kubectl get svc -n kafka\nNAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                        AGE\nmy-cluster-kafka-bootstrap    ClusterIP   10.99.246.133   <none>        9091/TCP,9092/TCP,9093/TCP                     3m3s\nmy-cluster-kafka-brokers      ClusterIP   None            <none>        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   3m3s\nmy-cluster-zookeeper-client   ClusterIP   10.109.106.29   <none>        2181/TCP                                       3m28s\nmy-cluster-zookeeper-nodes    ClusterIP   None            <none>        2181/TCP,2888/TCP,3888/TCP                     3m28s\n```\n\n<h1 id=\"47303cc8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">KRaft模式部署</font></h1>\n---\n\n<h2 id=\"xzvtA\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，用于kafka持久化存储数据使用。</font>\n\n```plain\n[root@tiaoban kafka]# cat > kafka-pvc.yaml << EOF\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-dual-role-0\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-dual-role-1\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: data-0-my-cluster-dual-role-2\n  namespace: kafka\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\nEOF\n```\n\n<h2 id=\"c1485a3b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-with-dual-role-nodes.yaml示例文件，部署一个控制代理节点和三个 Kafka 节点的持久集群。</font>\n\n```plain\n[root@tiaoban kafka]# cat > kafka.yaml << EOF\napiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaNodePool\nmetadata:\n  name: dual-role\n  namespace: kafka\n  labels:\n    strimzi.io/cluster: my-cluster\nspec:\n  replicas: 3\n  roles:\n    - controller\n    - broker\n  storage:\n    type: jbod\n    volumes:\n      - id: 0\n        type: persistent-claim\n        size: 10Gi\n        deleteClaim: false\n        kraftMetadata: shared\n---\napiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n  name: my-cluster\n  namespace: kafka\n  annotations:\n    strimzi.io/node-pools: enabled\n    strimzi.io/kraft: enabled\nspec:\n  kafka:\n    version: 3.8.0\n    metadataVersion: 3.8-IV0\n    listeners:\n      - name: plain\n        port: 9092\n        type: internal\n        tls: false\n      - name: tls\n        port: 9093\n        type: internal\n        tls: true\n    config:\n      offsets.topic.replication.factor: 3\n      transaction.state.log.replication.factor: 3\n      transaction.state.log.min.isr: 2\n      default.replication.factor: 3\n      min.insync.replicas: 2\n  entityOperator:\n    topicOperator: {}\n    userOperator: {}\n  kafkaExporter: {} # 启用exporter监控\nEOF\n```\n\n<h2 id=\"Y9NBE\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font>\n\n```plain\n[root@tiaoban kafka]# kubectl get pod -n kafka\nNAME                                          READY   STATUS    RESTARTS   AGE\nmy-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s\nNAME                                          READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES\nmy-cluster-dual-role-0                        1/1     Running   0          10m     10.244.3.65   k8s-test4   <none>           <none>\nmy-cluster-dual-role-1                        1/1     Running   0          10m     10.244.1.33   k8s-test2   <none>           <none>\nmy-cluster-dual-role-2                        1/1     Running   0          10m     10.244.2.46   k8s-test3   <none>           <none>\nmy-cluster-entity-operator-5dc6767689-jmnck   2/2     Running   0          9m26s   10.244.3.66   k8s-test4   <none>           <none>\nstrimzi-cluster-operator-7fb8ff4bd-fzfgw      1/1     Running   0          39m     10.244.3.64   k8s-test4   <none>           <none>\n[root@tiaoban kafka]# kubectl get svc -n kafka\nNAME                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                        AGE\nmy-cluster-kafka-bootstrap   ClusterIP   10.107.111.213   <none>        9091/TCP,9092/TCP,9093/TCP                     21m\nmy-cluster-kafka-brokers     ClusterIP   None             <none>        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   21m\n```\n\n<h1 id=\"41af4e22\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h1>\n---\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建configmap和ingress资源，在configmap中指定kafka连接地址。以traefik为例，创建ingress资源便于通过域名方式访问。</font>\n\n```plain\n[root@tiaoban kafka]# cat kafka-ui.yaml \napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kafka-ui-helm-values\n  namespace: kafka\ndata:\n  KAFKA_CLUSTERS_0_NAME: \"kafka-cluster\"\n  KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: \"my-cluster-kafka-brokers.kafka.svc:9092\"\n  AUTH_TYPE: \"DISABLED\"\n  MANAGEMENT_HEALTH_LDAP_ENABLED: \"FALSE\" \n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: kafka-ui\n  namespace: kafka\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`kafka-ui.local.com`) \n    kind: Rule\n    services:\n      - name: kafka-ui\n        port: 80\n[root@tiaoban kafka]# kubectl apply -f kafka-ui.yaml \nconfigmap/kafka-ui-helm-values created\ningressroute.traefik.containo.us/kafka-ui created\n```\n\n<h2 id=\"cs4WC\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">helm方式部署kafka-ui并指定配置文件</font>\n\n```plain\n[root@tiaoban kafka]# helm repo add kafka-ui https://provectus.github.io/kafka-ui-charts\n[root@tiaoban kafka]# helm install kafka-ui kafka-ui/kafka-ui -n kafka --set existingConfigMap=\"kafka-ui-helm-values\"\nNAME: kafka-ui\nLAST DEPLOYED: Mon Oct  9 09:56:45 2023\nNAMESPACE: kafka\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\n1. Get the application URL by running these commands:\n  export POD_NAME=$(kubectl get pods --namespace kafka -l \"app.kubernetes.io/name=kafka-ui,app.kubernetes.io/instance=kafka-ui\" -o jsonpath=\"{.items[0].metadata.name}\")\n  echo \"Visit http://127.0.0.1:8080 to use your application\"\n  kubectl --namespace kafka port-forward $POD_NAME 8080:8080\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证，添加hosts记录</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100 kafka-ui.local.com</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问测试。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892946714-217657ff-6bcd-42d0-b644-2389efd26ca5.jpeg)\n\n","slug":"16.部署Kafka消息队列 副本","published":1,"updated":"2025-03-30T13:16:12.873Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlk000ctsv1ag2s0fib","content":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">生产环境推荐的kafka部署方式为operator方式部署，Strimzi是目前最主流的operator方案。集群数据量较小的话，可以采用NFS共享存储，数据量较大的话使用local pv存储。</font></p>\n</blockquote>\n<h1 id=\"4cc34089\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署operator</font></h1>\n---\n\n<h2 id=\"b6a89aa3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署operator</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署方式为helm或yaml文件部署，此处以helm方式部署为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# helm repo add strimzi https://strimzi.io/charts/</span><br><span class=\"line\">&quot;strimzi&quot; has been added to your repositories</span><br><span class=\"line\">[root@tiaoban kafka]# helm pull strimzi/strimzi-kafka-operator --untar</span><br><span class=\"line\">[root@tiaoban kafka]# cd strimzi-kafka-operator</span><br><span class=\"line\">[root@tiaoban strimzi-kafka-operator]# vim values.yaml</span><br><span class=\"line\">dashboards: # 加载grafna dashboard</span><br><span class=\"line\">  enabled: true</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\"># 安装</span><br><span class=\"line\">[root@k8s-master traefik]# helm install strimzi -n kafka . -f values.yaml --create-namespace</span><br><span class=\"line\">NAME: strimzi</span><br><span class=\"line\">LAST DEPLOYED: Sun Oct 20 20:21:54 2024</span><br><span class=\"line\">NAMESPACE: kafka</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Thank you for installing strimzi-kafka-operator-0.43.0</span><br><span class=\"line\"></span><br><span class=\"line\">To create a Kafka cluster refer to the following documentation.</span><br><span class=\"line\"></span><br><span class=\"line\">https://strimzi.io/docs/operators/latest/deploying.html#deploying-cluster-operator-helm-chart-str</span><br><span class=\"line\">[root@tiaoban strimzi-kafka-operator]# kubectl get pod -n kafka</span><br><span class=\"line\">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">strimzi-cluster-operator-56fdbb99cb-gznkw   1/1     Running   0          17m</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"ca142d42\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取示例文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Strimzi官方仓库为我们提供了各种场景下的示例文件，资源清单下载地址：</font><a href=\"https://github.com/strimzi/strimzi-kafka-operator/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/strimzi/strimzi-kafka-operator/releases</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# ls</span><br><span class=\"line\">strimzi-kafka-operator</span><br><span class=\"line\">[root@tiaoban kafka]# wget https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.43.0/strimzi-0.43.0.tar.gz</span><br><span class=\"line\">[root@tiaoban kafka]# tar -zxf strimzi-0.43.0.tar.gz</span><br><span class=\"line\">[root@tiaoban kafka]# cd strimzi-0.43.0/examples/kafka</span><br><span class=\"line\">[root@tiaoban kafka]# tree.</span><br><span class=\"line\">├── kafka-ephemeral-single.yaml</span><br><span class=\"line\">├── kafka-ephemeral.yaml</span><br><span class=\"line\">├── kafka-jbod.yaml</span><br><span class=\"line\">├── kafka-persistent-single.yaml</span><br><span class=\"line\">├── kafka-persistent.yaml</span><br><span class=\"line\">├── kafka-with-node-pools.yaml</span><br><span class=\"line\">└── kraft</span><br><span class=\"line\">    ├── kafka-ephemeral.yaml</span><br><span class=\"line\">    ├── kafka-jbod.yaml</span><br><span class=\"line\">    ├── kafka-single-node.yaml</span><br><span class=\"line\">    ├── kafka-with-dual-role-nodes.yaml</span><br><span class=\"line\">    ├── kafka.yaml</span><br><span class=\"line\">    └── README.md</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例文件说明：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的持久集群。（推荐）</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点（每个节点使用多个持久卷）的持久集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent-single.yaml:部署具有单个 ZooKeeper 节点和单个 Kafka 节点的持久集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的临时群集。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral-single.yaml:部署具有三个 ZooKeeper 节点和一个 Kafka 节点的临时群集。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kraft模式文件说明：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-with-dual-role-nodes.yaml：部署一个 Kafka 集群，其中包含一个共享代理和控制器角色的节点池。（推荐）</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka.yaml：部署具有一个控制器节点池和一个代理节点池的持久性 Kafka 集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml：部署一个临时 Kafka 集群，其中包含一个控制器节点池和一个代理节点池。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-single-node.yaml：部署具有单个节点的 Kafka 集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml：在每个代理节点中部署具有多个卷的 Kafka 集群。</font></li>\n</ul>\n<h1 id=\"536ddfac\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Zookeeper模式部署</font></h1>\n---\n\n<h2 id=\"2def4be1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，分别用于3个zookeeper和3个kafka持久化存储数据使用。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat kafka-pvc.yaml</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-my-cluster-zookeeper-0</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-my-cluster-zookeeper-1</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-my-cluster-zookeeper-2</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-kafka-0</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-kafka-1</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-kafka-2</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"12970d41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka和zookeeper</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-persistent.yaml示例文件，部署三个 ZooKeeper 和三个 Kafka 节点的持久集群。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat &gt; kafka.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: kafka.strimzi.io/v1beta2</span><br><span class=\"line\">kind: Kafka</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: my-cluster</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  kafka:</span><br><span class=\"line\">    version: 3.5.1</span><br><span class=\"line\">    replicas: 3</span><br><span class=\"line\">    listeners:</span><br><span class=\"line\">      - name: plain</span><br><span class=\"line\">        port: 9092</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: false</span><br><span class=\"line\">      - name: tls</span><br><span class=\"line\">        port: 9093</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: true</span><br><span class=\"line\">    config:</span><br><span class=\"line\">      offsets.topic.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.min.isr: 2</span><br><span class=\"line\">      default.replication.factor: 3</span><br><span class=\"line\">      min.insync.replicas: 2</span><br><span class=\"line\">      inter.broker.protocol.version: &quot;3.5&quot;</span><br><span class=\"line\">    storage:</span><br><span class=\"line\">      type: jbod</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - id: 0</span><br><span class=\"line\">        type: persistent-claim</span><br><span class=\"line\">        size: 100Gi</span><br><span class=\"line\">        deleteClaim: false</span><br><span class=\"line\">  zookeeper:</span><br><span class=\"line\">    replicas: 3</span><br><span class=\"line\">    storage:</span><br><span class=\"line\">      type: persistent-claim</span><br><span class=\"line\">      size: 100Gi</span><br><span class=\"line\">      deleteClaim: false</span><br><span class=\"line\">  entityOperator:</span><br><span class=\"line\">    topicOperator: &#123;&#125;</span><br><span class=\"line\">    userOperator: &#123;&#125;</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# kubectl get pod -n kafka</span><br><span class=\"line\">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">my-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s</span><br><span class=\"line\">my-cluster-kafka-0                            1/1     Running   0          2m54s</span><br><span class=\"line\">my-cluster-kafka-1                            1/1     Running   0          2m54s</span><br><span class=\"line\">my-cluster-kafka-2                            1/1     Running   0          2m54s</span><br><span class=\"line\">my-cluster-zookeeper-0                        1/1     Running   0          3m19s</span><br><span class=\"line\">my-cluster-zookeeper-1                        1/1     Running   0          3m19s</span><br><span class=\"line\">my-cluster-zookeeper-2                        1/1     Running   0          3m19s</span><br><span class=\"line\">strimzi-cluster-operator-56fdbb99cb-gznkw     1/1     Running   0          97m</span><br><span class=\"line\">[root@tiaoban kafka]# kubectl get svc -n kafka</span><br><span class=\"line\">NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                        AGE</span><br><span class=\"line\">my-cluster-kafka-bootstrap    ClusterIP   10.99.246.133   &lt;none&gt;        9091/TCP,9092/TCP,9093/TCP                     3m3s</span><br><span class=\"line\">my-cluster-kafka-brokers      ClusterIP   None            &lt;none&gt;        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   3m3s</span><br><span class=\"line\">my-cluster-zookeeper-client   ClusterIP   10.109.106.29   &lt;none&gt;        2181/TCP                                       3m28s</span><br><span class=\"line\">my-cluster-zookeeper-nodes    ClusterIP   None            &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP                     3m28s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"47303cc8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">KRaft模式部署</font></h1>\n---\n\n<h2 id=\"xzvtA\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，用于kafka持久化存储数据使用。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat &gt; kafka-pvc.yaml &lt;&lt; EOF</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-dual-role-0</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-dual-role-1</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-dual-role-2</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c1485a3b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-with-dual-role-nodes.yaml示例文件，部署一个控制代理节点和三个 Kafka 节点的持久集群。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat &gt; kafka.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: kafka.strimzi.io/v1beta2</span><br><span class=\"line\">kind: KafkaNodePool</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dual-role</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    strimzi.io/cluster: my-cluster</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  roles:</span><br><span class=\"line\">    - controller</span><br><span class=\"line\">    - broker</span><br><span class=\"line\">  storage:</span><br><span class=\"line\">    type: jbod</span><br><span class=\"line\">    volumes:</span><br><span class=\"line\">      - id: 0</span><br><span class=\"line\">        type: persistent-claim</span><br><span class=\"line\">        size: 10Gi</span><br><span class=\"line\">        deleteClaim: false</span><br><span class=\"line\">        kraftMetadata: shared</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kafka.strimzi.io/v1beta2</span><br><span class=\"line\">kind: Kafka</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: my-cluster</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    strimzi.io/node-pools: enabled</span><br><span class=\"line\">    strimzi.io/kraft: enabled</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  kafka:</span><br><span class=\"line\">    version: 3.8.0</span><br><span class=\"line\">    metadataVersion: 3.8-IV0</span><br><span class=\"line\">    listeners:</span><br><span class=\"line\">      - name: plain</span><br><span class=\"line\">        port: 9092</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: false</span><br><span class=\"line\">      - name: tls</span><br><span class=\"line\">        port: 9093</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: true</span><br><span class=\"line\">    config:</span><br><span class=\"line\">      offsets.topic.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.min.isr: 2</span><br><span class=\"line\">      default.replication.factor: 3</span><br><span class=\"line\">      min.insync.replicas: 2</span><br><span class=\"line\">  entityOperator:</span><br><span class=\"line\">    topicOperator: &#123;&#125;</span><br><span class=\"line\">    userOperator: &#123;&#125;</span><br><span class=\"line\">  kafkaExporter: &#123;&#125; # 启用exporter监控</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Y9NBE\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# kubectl get pod -n kafka</span><br><span class=\"line\">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">my-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s</span><br><span class=\"line\">NAME                                          READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">my-cluster-dual-role-0                        1/1     Running   0          10m     10.244.3.65   k8s-test4   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">my-cluster-dual-role-1                        1/1     Running   0          10m     10.244.1.33   k8s-test2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">my-cluster-dual-role-2                        1/1     Running   0          10m     10.244.2.46   k8s-test3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">my-cluster-entity-operator-5dc6767689-jmnck   2/2     Running   0          9m26s   10.244.3.66   k8s-test4   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">strimzi-cluster-operator-7fb8ff4bd-fzfgw      1/1     Running   0          39m     10.244.3.64   k8s-test4   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">[root@tiaoban kafka]# kubectl get svc -n kafka</span><br><span class=\"line\">NAME                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                        AGE</span><br><span class=\"line\">my-cluster-kafka-bootstrap   ClusterIP   10.107.111.213   &lt;none&gt;        9091/TCP,9092/TCP,9093/TCP                     21m</span><br><span class=\"line\">my-cluster-kafka-brokers     ClusterIP   None             &lt;none&gt;        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   21m</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"41af4e22\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h1>\n---\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建configmap和ingress资源，在configmap中指定kafka连接地址。以traefik为例，创建ingress资源便于通过域名方式访问。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat kafka-ui.yaml </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kafka-ui-helm-values</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">data:</span><br><span class=\"line\">  KAFKA_CLUSTERS_0_NAME: &quot;kafka-cluster&quot;</span><br><span class=\"line\">  KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: &quot;my-cluster-kafka-brokers.kafka.svc:9092&quot;</span><br><span class=\"line\">  AUTH_TYPE: &quot;DISABLED&quot;</span><br><span class=\"line\">  MANAGEMENT_HEALTH_LDAP_ENABLED: &quot;FALSE&quot; </span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kafka-ui</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`kafka-ui.local.com`) </span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: kafka-ui</span><br><span class=\"line\">        port: 80</span><br><span class=\"line\">[root@tiaoban kafka]# kubectl apply -f kafka-ui.yaml </span><br><span class=\"line\">configmap/kafka-ui-helm-values created</span><br><span class=\"line\">ingressroute.traefik.containo.us/kafka-ui created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"cs4WC\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">helm方式部署kafka-ui并指定配置文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# helm repo add kafka-ui https://provectus.github.io/kafka-ui-charts</span><br><span class=\"line\">[root@tiaoban kafka]# helm install kafka-ui kafka-ui/kafka-ui -n kafka --set existingConfigMap=&quot;kafka-ui-helm-values&quot;</span><br><span class=\"line\">NAME: kafka-ui</span><br><span class=\"line\">LAST DEPLOYED: Mon Oct  9 09:56:45 2023</span><br><span class=\"line\">NAMESPACE: kafka</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Get the application URL by running these commands:</span><br><span class=\"line\">  export POD_NAME=$(kubectl get pods --namespace kafka -l &quot;app.kubernetes.io/name=kafka-ui,app.kubernetes.io/instance=kafka-ui&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class=\"line\">  echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class=\"line\">  kubectl --namespace kafka port-forward $POD_NAME 8080:8080</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证，添加hosts记录</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;192.168.10.100 kafka-ui.local.com&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问测试。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892946714-217657ff-6bcd-42d0-b644-2389efd26ca5.jpeg\"></p>\n","excerpt":"","more":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">生产环境推荐的kafka部署方式为operator方式部署，Strimzi是目前最主流的operator方案。集群数据量较小的话，可以采用NFS共享存储，数据量较大的话使用local pv存储。</font></p>\n</blockquote>\n<h1 id=\"4cc34089\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署operator</font></h1>\n---\n\n<h2 id=\"b6a89aa3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署operator</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署方式为helm或yaml文件部署，此处以helm方式部署为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# helm repo add strimzi https://strimzi.io/charts/</span><br><span class=\"line\">&quot;strimzi&quot; has been added to your repositories</span><br><span class=\"line\">[root@tiaoban kafka]# helm pull strimzi/strimzi-kafka-operator --untar</span><br><span class=\"line\">[root@tiaoban kafka]# cd strimzi-kafka-operator</span><br><span class=\"line\">[root@tiaoban strimzi-kafka-operator]# vim values.yaml</span><br><span class=\"line\">dashboards: # 加载grafna dashboard</span><br><span class=\"line\">  enabled: true</span><br><span class=\"line\">  namespace: monitoring</span><br><span class=\"line\"># 安装</span><br><span class=\"line\">[root@k8s-master traefik]# helm install strimzi -n kafka . -f values.yaml --create-namespace</span><br><span class=\"line\">NAME: strimzi</span><br><span class=\"line\">LAST DEPLOYED: Sun Oct 20 20:21:54 2024</span><br><span class=\"line\">NAMESPACE: kafka</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Thank you for installing strimzi-kafka-operator-0.43.0</span><br><span class=\"line\"></span><br><span class=\"line\">To create a Kafka cluster refer to the following documentation.</span><br><span class=\"line\"></span><br><span class=\"line\">https://strimzi.io/docs/operators/latest/deploying.html#deploying-cluster-operator-helm-chart-str</span><br><span class=\"line\">[root@tiaoban strimzi-kafka-operator]# kubectl get pod -n kafka</span><br><span class=\"line\">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">strimzi-cluster-operator-56fdbb99cb-gznkw   1/1     Running   0          17m</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"ca142d42\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取示例文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Strimzi官方仓库为我们提供了各种场景下的示例文件，资源清单下载地址：</font><a href=\"https://github.com/strimzi/strimzi-kafka-operator/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/strimzi/strimzi-kafka-operator/releases</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# ls</span><br><span class=\"line\">strimzi-kafka-operator</span><br><span class=\"line\">[root@tiaoban kafka]# wget https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.43.0/strimzi-0.43.0.tar.gz</span><br><span class=\"line\">[root@tiaoban kafka]# tar -zxf strimzi-0.43.0.tar.gz</span><br><span class=\"line\">[root@tiaoban kafka]# cd strimzi-0.43.0/examples/kafka</span><br><span class=\"line\">[root@tiaoban kafka]# tree.</span><br><span class=\"line\">├── kafka-ephemeral-single.yaml</span><br><span class=\"line\">├── kafka-ephemeral.yaml</span><br><span class=\"line\">├── kafka-jbod.yaml</span><br><span class=\"line\">├── kafka-persistent-single.yaml</span><br><span class=\"line\">├── kafka-persistent.yaml</span><br><span class=\"line\">├── kafka-with-node-pools.yaml</span><br><span class=\"line\">└── kraft</span><br><span class=\"line\">    ├── kafka-ephemeral.yaml</span><br><span class=\"line\">    ├── kafka-jbod.yaml</span><br><span class=\"line\">    ├── kafka-single-node.yaml</span><br><span class=\"line\">    ├── kafka-with-dual-role-nodes.yaml</span><br><span class=\"line\">    ├── kafka.yaml</span><br><span class=\"line\">    └── README.md</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例文件说明：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的持久集群。（推荐）</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点（每个节点使用多个持久卷）的持久集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-persistent-single.yaml:部署具有单个 ZooKeeper 节点和单个 Kafka 节点的持久集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml:部署具有三个 ZooKeeper 和三个 Kafka 节点的临时群集。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral-single.yaml:部署具有三个 ZooKeeper 节点和一个 Kafka 节点的临时群集。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kraft模式文件说明：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-with-dual-role-nodes.yaml：部署一个 Kafka 集群，其中包含一个共享代理和控制器角色的节点池。（推荐）</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka.yaml：部署具有一个控制器节点池和一个代理节点池的持久性 Kafka 集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-ephemeral.yaml：部署一个临时 Kafka 集群，其中包含一个控制器节点池和一个代理节点池。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-single-node.yaml：部署具有单个节点的 Kafka 集群。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">kafka-jbod.yaml：在每个代理节点中部署具有多个卷的 Kafka 集群。</font></li>\n</ul>\n<h1 id=\"536ddfac\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Zookeeper模式部署</font></h1>\n---\n\n<h2 id=\"2def4be1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，分别用于3个zookeeper和3个kafka持久化存储数据使用。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat kafka-pvc.yaml</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-my-cluster-zookeeper-0</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-my-cluster-zookeeper-1</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-my-cluster-zookeeper-2</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-kafka-0</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-kafka-1</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-kafka-2</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 100Gi</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"12970d41\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka和zookeeper</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-persistent.yaml示例文件，部署三个 ZooKeeper 和三个 Kafka 节点的持久集群。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat &gt; kafka.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: kafka.strimzi.io/v1beta2</span><br><span class=\"line\">kind: Kafka</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: my-cluster</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  kafka:</span><br><span class=\"line\">    version: 3.5.1</span><br><span class=\"line\">    replicas: 3</span><br><span class=\"line\">    listeners:</span><br><span class=\"line\">      - name: plain</span><br><span class=\"line\">        port: 9092</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: false</span><br><span class=\"line\">      - name: tls</span><br><span class=\"line\">        port: 9093</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: true</span><br><span class=\"line\">    config:</span><br><span class=\"line\">      offsets.topic.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.min.isr: 2</span><br><span class=\"line\">      default.replication.factor: 3</span><br><span class=\"line\">      min.insync.replicas: 2</span><br><span class=\"line\">      inter.broker.protocol.version: &quot;3.5&quot;</span><br><span class=\"line\">    storage:</span><br><span class=\"line\">      type: jbod</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - id: 0</span><br><span class=\"line\">        type: persistent-claim</span><br><span class=\"line\">        size: 100Gi</span><br><span class=\"line\">        deleteClaim: false</span><br><span class=\"line\">  zookeeper:</span><br><span class=\"line\">    replicas: 3</span><br><span class=\"line\">    storage:</span><br><span class=\"line\">      type: persistent-claim</span><br><span class=\"line\">      size: 100Gi</span><br><span class=\"line\">      deleteClaim: false</span><br><span class=\"line\">  entityOperator:</span><br><span class=\"line\">    topicOperator: &#123;&#125;</span><br><span class=\"line\">    userOperator: &#123;&#125;</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# kubectl get pod -n kafka</span><br><span class=\"line\">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">my-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s</span><br><span class=\"line\">my-cluster-kafka-0                            1/1     Running   0          2m54s</span><br><span class=\"line\">my-cluster-kafka-1                            1/1     Running   0          2m54s</span><br><span class=\"line\">my-cluster-kafka-2                            1/1     Running   0          2m54s</span><br><span class=\"line\">my-cluster-zookeeper-0                        1/1     Running   0          3m19s</span><br><span class=\"line\">my-cluster-zookeeper-1                        1/1     Running   0          3m19s</span><br><span class=\"line\">my-cluster-zookeeper-2                        1/1     Running   0          3m19s</span><br><span class=\"line\">strimzi-cluster-operator-56fdbb99cb-gznkw     1/1     Running   0          97m</span><br><span class=\"line\">[root@tiaoban kafka]# kubectl get svc -n kafka</span><br><span class=\"line\">NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                        AGE</span><br><span class=\"line\">my-cluster-kafka-bootstrap    ClusterIP   10.99.246.133   &lt;none&gt;        9091/TCP,9092/TCP,9093/TCP                     3m3s</span><br><span class=\"line\">my-cluster-kafka-brokers      ClusterIP   None            &lt;none&gt;        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   3m3s</span><br><span class=\"line\">my-cluster-zookeeper-client   ClusterIP   10.109.106.29   &lt;none&gt;        2181/TCP                                       3m28s</span><br><span class=\"line\">my-cluster-zookeeper-nodes    ClusterIP   None            &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP                     3m28s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"47303cc8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">KRaft模式部署</font></h1>\n---\n\n<h2 id=\"xzvtA\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">此处以nfs存储为例，提前创建pvc资源，用于kafka持久化存储数据使用。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat &gt; kafka-pvc.yaml &lt;&lt; EOF</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-dual-role-0</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-dual-role-1</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-0-my-cluster-dual-role-2</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c1485a3b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考官方仓库的kafka-with-dual-role-nodes.yaml示例文件，部署一个控制代理节点和三个 Kafka 节点的持久集群。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat &gt; kafka.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: kafka.strimzi.io/v1beta2</span><br><span class=\"line\">kind: KafkaNodePool</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dual-role</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    strimzi.io/cluster: my-cluster</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  roles:</span><br><span class=\"line\">    - controller</span><br><span class=\"line\">    - broker</span><br><span class=\"line\">  storage:</span><br><span class=\"line\">    type: jbod</span><br><span class=\"line\">    volumes:</span><br><span class=\"line\">      - id: 0</span><br><span class=\"line\">        type: persistent-claim</span><br><span class=\"line\">        size: 10Gi</span><br><span class=\"line\">        deleteClaim: false</span><br><span class=\"line\">        kraftMetadata: shared</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kafka.strimzi.io/v1beta2</span><br><span class=\"line\">kind: Kafka</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: my-cluster</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    strimzi.io/node-pools: enabled</span><br><span class=\"line\">    strimzi.io/kraft: enabled</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  kafka:</span><br><span class=\"line\">    version: 3.8.0</span><br><span class=\"line\">    metadataVersion: 3.8-IV0</span><br><span class=\"line\">    listeners:</span><br><span class=\"line\">      - name: plain</span><br><span class=\"line\">        port: 9092</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: false</span><br><span class=\"line\">      - name: tls</span><br><span class=\"line\">        port: 9093</span><br><span class=\"line\">        type: internal</span><br><span class=\"line\">        tls: true</span><br><span class=\"line\">    config:</span><br><span class=\"line\">      offsets.topic.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.replication.factor: 3</span><br><span class=\"line\">      transaction.state.log.min.isr: 2</span><br><span class=\"line\">      default.replication.factor: 3</span><br><span class=\"line\">      min.insync.replicas: 2</span><br><span class=\"line\">  entityOperator:</span><br><span class=\"line\">    topicOperator: &#123;&#125;</span><br><span class=\"line\">    userOperator: &#123;&#125;</span><br><span class=\"line\">  kafkaExporter: &#123;&#125; # 启用exporter监控</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Y9NBE\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息，已成功创建相关pod和svc资源。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# kubectl get pod -n kafka</span><br><span class=\"line\">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">my-cluster-entity-operator-7c68d4b9d9-tg56j   3/3     Running   0          2m15s</span><br><span class=\"line\">NAME                                          READY   STATUS    RESTARTS   AGE     IP            NODE        NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">my-cluster-dual-role-0                        1/1     Running   0          10m     10.244.3.65   k8s-test4   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">my-cluster-dual-role-1                        1/1     Running   0          10m     10.244.1.33   k8s-test2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">my-cluster-dual-role-2                        1/1     Running   0          10m     10.244.2.46   k8s-test3   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">my-cluster-entity-operator-5dc6767689-jmnck   2/2     Running   0          9m26s   10.244.3.66   k8s-test4   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">strimzi-cluster-operator-7fb8ff4bd-fzfgw      1/1     Running   0          39m     10.244.3.64   k8s-test4   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">[root@tiaoban kafka]# kubectl get svc -n kafka</span><br><span class=\"line\">NAME                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                        AGE</span><br><span class=\"line\">my-cluster-kafka-bootstrap   ClusterIP   10.107.111.213   &lt;none&gt;        9091/TCP,9092/TCP,9093/TCP                     21m</span><br><span class=\"line\">my-cluster-kafka-brokers     ClusterIP   None             &lt;none&gt;        9090/TCP,9091/TCP,8443/TCP,9092/TCP,9093/TCP   21m</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"41af4e22\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h1>\n---\n\n<h2 id=\"e8928169\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建configmap和ingress资源，在configmap中指定kafka连接地址。以traefik为例，创建ingress资源便于通过域名方式访问。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# cat kafka-ui.yaml </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kafka-ui-helm-values</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">data:</span><br><span class=\"line\">  KAFKA_CLUSTERS_0_NAME: &quot;kafka-cluster&quot;</span><br><span class=\"line\">  KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: &quot;my-cluster-kafka-brokers.kafka.svc:9092&quot;</span><br><span class=\"line\">  AUTH_TYPE: &quot;DISABLED&quot;</span><br><span class=\"line\">  MANAGEMENT_HEALTH_LDAP_ENABLED: &quot;FALSE&quot; </span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: kafka-ui</span><br><span class=\"line\">  namespace: kafka</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`kafka-ui.local.com`) </span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: kafka-ui</span><br><span class=\"line\">        port: 80</span><br><span class=\"line\">[root@tiaoban kafka]# kubectl apply -f kafka-ui.yaml </span><br><span class=\"line\">configmap/kafka-ui-helm-values created</span><br><span class=\"line\">ingressroute.traefik.containo.us/kafka-ui created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"cs4WC\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署kafka-ui</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">helm方式部署kafka-ui并指定配置文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban kafka]# helm repo add kafka-ui https://provectus.github.io/kafka-ui-charts</span><br><span class=\"line\">[root@tiaoban kafka]# helm install kafka-ui kafka-ui/kafka-ui -n kafka --set existingConfigMap=&quot;kafka-ui-helm-values&quot;</span><br><span class=\"line\">NAME: kafka-ui</span><br><span class=\"line\">LAST DEPLOYED: Mon Oct  9 09:56:45 2023</span><br><span class=\"line\">NAMESPACE: kafka</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Get the application URL by running these commands:</span><br><span class=\"line\">  export POD_NAME=$(kubectl get pods --namespace kafka -l &quot;app.kubernetes.io/name=kafka-ui,app.kubernetes.io/instance=kafka-ui&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class=\"line\">  echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class=\"line\">  kubectl --namespace kafka port-forward $POD_NAME 8080:8080</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证，添加hosts记录</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;192.168.10.100 kafka-ui.local.com&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问测试。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737892946714-217657ff-6bcd-42d0-b644-2389efd26ca5.jpeg\"></p>\n"},{"title":"部署Rabbit MQ消息队列","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"d9d372b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Kubernetes Operator</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官网的文档 </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/operator-overview.html</font>](https://link.zhihu.com/?target=https%3A//www.rabbitmq.com/kubernetes/operator/operator-overview.html)\n\n```plain\n# Operator的yaml文件地址\n# wget https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml\n\n# 安装\n# kubectl apply -f cluster-operator.yml \nnamespace/rabbitmq-system created\ncustomresourcedefinition.apiextensions.k8s.io/rabbitmqclusters.rabbitmq.com created\nserviceaccount/rabbitmq-cluster-operator created\nrole.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-role created\nclusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-operator-role created\nclusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-service-binding-role created\nrolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-rolebinding created\nclusterrolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-operator-rolebinding created\ndeployment.apps/rabbitmq-cluster-operator created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装完之后查看Operator是否启动正常, 默认pod在 rabbitmq-system命名空间下</font>\n\n```plain\n# kubectl get pod -n rabbitmq-system\nNAME                                        READY   STATUS    RESTARTS   AGE\nrabbitmq-cluster-operator-9d69fc79f-kp7ff   1/1     Running   0          8s\n```\n\n<h1 id=\"bfa008dd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装rabbitmq</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装mq时，会使用storageClass创建pvc，所以k8s需要提前配置好storageClass。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">自定义mq的yaml文件，配置项可以参考官网文档</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/using-operator#overview</font>](https://www.rabbitmq.com/kubernetes/operator/using-operator#overview)\n\n```plain\napiVersion: rabbitmq.com/v1beta1\nkind: RabbitmqCluster\nmetadata:\n  name: rabbitmq-cluster\n  namespace: rabbitmq\n  labels:\n    app: rabbitmq-cluster\nspec:\n  replicas: 3\n  image: harbor.local.com/rabbitmq/rabbitmq:3.13.7-management\n  persistence:\n    storageClassName: nfs\n    storage: 5Gi\n  resources:\n    limits:\n      cpu: 2\n      memory: 4Gi\n  rabbitmq:\n    additionalPlugins:\n      - rabbitmq_prometheus # 启用prometheus插件\n    additionalConfig: |\n      default_vhost = vhost      #配置Virtual Hosts\n      default_user = admin       #配置登录账号\n      default_pass = 123.com      #配置账号密码\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建并查看资源</font>\n\n```plain\n# kubectl get pod -n rabbitmq\nNAME                        READY   STATUS    RESTARTS   AGE\nrabbitmq-cluster-server-0   1/1     Running   0          58s\nrabbitmq-cluster-server-1   1/1     Running   0          58s\nrabbitmq-cluster-server-2   1/1     Running   0          58s\n# kubectl get svc -n rabbitmq                                   \nNAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                        AGE\nrabbitmq-cluster         ClusterIP   10.109.153.87   <none>        5672/TCP,15672/TCP,15692/TCP   66s\nrabbitmq-cluster-nodes   ClusterIP   None            <none>        4369/TCP,25672/TCP             66s\n# kubectl get secrets -n rabbitmq                                                                            \nNAME                             TYPE     DATA   AGE\nrabbitmq-cluster-default-user    Opaque   8      2m41s\nrabbitmq-cluster-erlang-cookie   Opaque   1      2m41s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建管理员用户与权限</font>\n\n```plain\n# kubectl exec -it -n rabbitmq rabbitmq-cluster-server-1 -- bash\nDefaulted container \"rabbitmq\" out of: rabbitmq, setup-container (init)\nrabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl add_user admin 123.com\nAdding user \"admin\" ...\nDone. Don't forget to grant the user permissions to some virtual hosts! See 'rabbitmqctl help set_permissions' to learn more.\nrabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_user_tags admin administrator\nSetting tags for user \"admin\" to [administrator] ...\nrabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_permissions -p / admin \".*\" \".*\" \".*\"\nSetting permissions for user \"admin\" in vhost \"/\" ...\n```\n\n<h1 id=\"167c2c3f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress和nodeport资源</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">rabbitmq端口暴露</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n  name: rabbitmq-nodeport\n  namespace: rabbitmq\nspec:\n  type: NodePort\n  selector:\n    app.kubernetes.io/name: rabbitmq-cluster\n  ports:\n  - name: amqp\n    port: 5672\n    protocol: TCP\n    targetPort: 5672\n    nodePort: 30005\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web管理页面ingress</font>\n\n```plain\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: grafana\n  namespace: rabbitmq\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`rabbitmq.local.com`)\n    kind: Rule\n    services:\n      - name: rabbitmq-cluster\n        port: 15672\n```\n\n<h1 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893103207-00c9ba96-3959-4e47-b9d9-213e445bd44f.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">python测试脚本，发送消息</font>\n\n```plain\nimport pika\n\n\ndef connect_rabbitmq(username, password, host, port=5672):\n    # 创建带有用户名和密码认证的 RabbitMQ 连接\n    credentials = pika.PlainCredentials(username, password)\n    connection = pika.BlockingConnection(\n        pika.ConnectionParameters(host=host, port=port, credentials=credentials)\n    )\n    return connection\n\n\ndef send_message_to_queue(message, queue_name, username, password, host):\n    # 建立连接\n    connection = connect_rabbitmq(username, password, host)\n    channel = connection.channel()\n\n    # 声明队列（如果不存在则创建）\n    channel.queue_declare(queue=queue_name)\n\n    # 向指定队列发送消息\n    channel.basic_publish(\n        exchange='',\n        routing_key=queue_name,\n        body=message\n    )\n    print(f\"Sent message to queue {queue_name}\")\n\n    # 关闭连接\n    connection.close()\n\n\nif __name__ == \"__main__\":\n    # 配置 RabbitMQ 用户认证信息\n    username = \"admin\"\n    password = \"123.com\"\n    host = \"192.168.10.10\"  # 可替换为 RabbitMQ 主机地址\n\n    # 要发送的消息内容和目标队列\n    message = \"Hello, RabbitMQ with Auth!\"\n    queue_name = \"single_queue\"\n\n    # 向单个队列发送消息\n    send_message_to_queue(message, queue_name, username, password, host)\n\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看web页面成功收到消息。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893125711-190bb554-f771-4a7a-89d7-b477e2266fea.jpeg)\n\n","source":"_posts/17.部署Rabbit MQ消息队列.md","raw":"---\ntitle: 部署Rabbit MQ消息队列\ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"d9d372b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Kubernetes Operator</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官网的文档 </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/operator-overview.html</font>](https://link.zhihu.com/?target=https%3A//www.rabbitmq.com/kubernetes/operator/operator-overview.html)\n\n```plain\n# Operator的yaml文件地址\n# wget https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml\n\n# 安装\n# kubectl apply -f cluster-operator.yml \nnamespace/rabbitmq-system created\ncustomresourcedefinition.apiextensions.k8s.io/rabbitmqclusters.rabbitmq.com created\nserviceaccount/rabbitmq-cluster-operator created\nrole.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-role created\nclusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-operator-role created\nclusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-service-binding-role created\nrolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-rolebinding created\nclusterrolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-operator-rolebinding created\ndeployment.apps/rabbitmq-cluster-operator created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装完之后查看Operator是否启动正常, 默认pod在 rabbitmq-system命名空间下</font>\n\n```plain\n# kubectl get pod -n rabbitmq-system\nNAME                                        READY   STATUS    RESTARTS   AGE\nrabbitmq-cluster-operator-9d69fc79f-kp7ff   1/1     Running   0          8s\n```\n\n<h1 id=\"bfa008dd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装rabbitmq</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装mq时，会使用storageClass创建pvc，所以k8s需要提前配置好storageClass。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">自定义mq的yaml文件，配置项可以参考官网文档</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/using-operator#overview</font>](https://www.rabbitmq.com/kubernetes/operator/using-operator#overview)\n\n```plain\napiVersion: rabbitmq.com/v1beta1\nkind: RabbitmqCluster\nmetadata:\n  name: rabbitmq-cluster\n  namespace: rabbitmq\n  labels:\n    app: rabbitmq-cluster\nspec:\n  replicas: 3\n  image: harbor.local.com/rabbitmq/rabbitmq:3.13.7-management\n  persistence:\n    storageClassName: nfs\n    storage: 5Gi\n  resources:\n    limits:\n      cpu: 2\n      memory: 4Gi\n  rabbitmq:\n    additionalPlugins:\n      - rabbitmq_prometheus # 启用prometheus插件\n    additionalConfig: |\n      default_vhost = vhost      #配置Virtual Hosts\n      default_user = admin       #配置登录账号\n      default_pass = 123.com      #配置账号密码\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建并查看资源</font>\n\n```plain\n# kubectl get pod -n rabbitmq\nNAME                        READY   STATUS    RESTARTS   AGE\nrabbitmq-cluster-server-0   1/1     Running   0          58s\nrabbitmq-cluster-server-1   1/1     Running   0          58s\nrabbitmq-cluster-server-2   1/1     Running   0          58s\n# kubectl get svc -n rabbitmq                                   \nNAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                        AGE\nrabbitmq-cluster         ClusterIP   10.109.153.87   <none>        5672/TCP,15672/TCP,15692/TCP   66s\nrabbitmq-cluster-nodes   ClusterIP   None            <none>        4369/TCP,25672/TCP             66s\n# kubectl get secrets -n rabbitmq                                                                            \nNAME                             TYPE     DATA   AGE\nrabbitmq-cluster-default-user    Opaque   8      2m41s\nrabbitmq-cluster-erlang-cookie   Opaque   1      2m41s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建管理员用户与权限</font>\n\n```plain\n# kubectl exec -it -n rabbitmq rabbitmq-cluster-server-1 -- bash\nDefaulted container \"rabbitmq\" out of: rabbitmq, setup-container (init)\nrabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl add_user admin 123.com\nAdding user \"admin\" ...\nDone. Don't forget to grant the user permissions to some virtual hosts! See 'rabbitmqctl help set_permissions' to learn more.\nrabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_user_tags admin administrator\nSetting tags for user \"admin\" to [administrator] ...\nrabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_permissions -p / admin \".*\" \".*\" \".*\"\nSetting permissions for user \"admin\" in vhost \"/\" ...\n```\n\n<h1 id=\"167c2c3f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress和nodeport资源</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">rabbitmq端口暴露</font>\n\n```plain\napiVersion: v1\nkind: Service\nmetadata:\n  name: rabbitmq-nodeport\n  namespace: rabbitmq\nspec:\n  type: NodePort\n  selector:\n    app.kubernetes.io/name: rabbitmq-cluster\n  ports:\n  - name: amqp\n    port: 5672\n    protocol: TCP\n    targetPort: 5672\n    nodePort: 30005\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web管理页面ingress</font>\n\n```plain\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: grafana\n  namespace: rabbitmq\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`rabbitmq.local.com`)\n    kind: Rule\n    services:\n      - name: rabbitmq-cluster\n        port: 15672\n```\n\n<h1 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893103207-00c9ba96-3959-4e47-b9d9-213e445bd44f.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">python测试脚本，发送消息</font>\n\n```plain\nimport pika\n\n\ndef connect_rabbitmq(username, password, host, port=5672):\n    # 创建带有用户名和密码认证的 RabbitMQ 连接\n    credentials = pika.PlainCredentials(username, password)\n    connection = pika.BlockingConnection(\n        pika.ConnectionParameters(host=host, port=port, credentials=credentials)\n    )\n    return connection\n\n\ndef send_message_to_queue(message, queue_name, username, password, host):\n    # 建立连接\n    connection = connect_rabbitmq(username, password, host)\n    channel = connection.channel()\n\n    # 声明队列（如果不存在则创建）\n    channel.queue_declare(queue=queue_name)\n\n    # 向指定队列发送消息\n    channel.basic_publish(\n        exchange='',\n        routing_key=queue_name,\n        body=message\n    )\n    print(f\"Sent message to queue {queue_name}\")\n\n    # 关闭连接\n    connection.close()\n\n\nif __name__ == \"__main__\":\n    # 配置 RabbitMQ 用户认证信息\n    username = \"admin\"\n    password = \"123.com\"\n    host = \"192.168.10.10\"  # 可替换为 RabbitMQ 主机地址\n\n    # 要发送的消息内容和目标队列\n    message = \"Hello, RabbitMQ with Auth!\"\n    queue_name = \"single_queue\"\n\n    # 向单个队列发送消息\n    send_message_to_queue(message, queue_name, username, password, host)\n\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看web页面成功收到消息。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893125711-190bb554-f771-4a7a-89d7-b477e2266fea.jpeg)\n\n","slug":"17.部署Rabbit MQ消息队列","published":1,"updated":"2025-03-30T13:16:35.461Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjll000dtsv10y9fe58p","content":"<h1 id=\"d9d372b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Kubernetes Operator</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">官网的文档 </font><a href=\"https://link.zhihu.com/?target=https://www.rabbitmq.com/kubernetes/operator/operator-overview.html\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/operator-overview.html</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Operator的yaml文件地址</span><br><span class=\"line\"># wget https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml</span><br><span class=\"line\"></span><br><span class=\"line\"># 安装</span><br><span class=\"line\"># kubectl apply -f cluster-operator.yml </span><br><span class=\"line\">namespace/rabbitmq-system created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/rabbitmqclusters.rabbitmq.com created</span><br><span class=\"line\">serviceaccount/rabbitmq-cluster-operator created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-role created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-operator-role created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-service-binding-role created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-rolebinding created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-operator-rolebinding created</span><br><span class=\"line\">deployment.apps/rabbitmq-cluster-operator created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装完之后查看Operator是否启动正常, 默认pod在 rabbitmq-system命名空间下</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl get pod -n rabbitmq-system</span><br><span class=\"line\">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">rabbitmq-cluster-operator-9d69fc79f-kp7ff   1/1     Running   0          8s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"bfa008dd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装rabbitmq</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mq时，会使用storageClass创建pvc，所以k8s需要提前配置好storageClass。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">自定义mq的yaml文件，配置项可以参考官网文档</font><a href=\"https://www.rabbitmq.com/kubernetes/operator/using-operator#overview\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/using-operator#overview</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: rabbitmq.com/v1beta1</span><br><span class=\"line\">kind: RabbitmqCluster</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: rabbitmq-cluster</span><br><span class=\"line\">  namespace: rabbitmq</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: rabbitmq-cluster</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  image: harbor.local.com/rabbitmq/rabbitmq:3.13.7-management</span><br><span class=\"line\">  persistence:</span><br><span class=\"line\">    storageClassName: nfs</span><br><span class=\"line\">    storage: 5Gi</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    limits:</span><br><span class=\"line\">      cpu: 2</span><br><span class=\"line\">      memory: 4Gi</span><br><span class=\"line\">  rabbitmq:</span><br><span class=\"line\">    additionalPlugins:</span><br><span class=\"line\">      - rabbitmq_prometheus # 启用prometheus插件</span><br><span class=\"line\">    additionalConfig: |</span><br><span class=\"line\">      default_vhost = vhost      #配置Virtual Hosts</span><br><span class=\"line\">      default_user = admin       #配置登录账号</span><br><span class=\"line\">      default_pass = 123.com      #配置账号密码</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建并查看资源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl get pod -n rabbitmq</span><br><span class=\"line\">NAME                        READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">rabbitmq-cluster-server-0   1/1     Running   0          58s</span><br><span class=\"line\">rabbitmq-cluster-server-1   1/1     Running   0          58s</span><br><span class=\"line\">rabbitmq-cluster-server-2   1/1     Running   0          58s</span><br><span class=\"line\"># kubectl get svc -n rabbitmq                                   </span><br><span class=\"line\">NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                        AGE</span><br><span class=\"line\">rabbitmq-cluster         ClusterIP   10.109.153.87   &lt;none&gt;        5672/TCP,15672/TCP,15692/TCP   66s</span><br><span class=\"line\">rabbitmq-cluster-nodes   ClusterIP   None            &lt;none&gt;        4369/TCP,25672/TCP             66s</span><br><span class=\"line\"># kubectl get secrets -n rabbitmq                                                                            </span><br><span class=\"line\">NAME                             TYPE     DATA   AGE</span><br><span class=\"line\">rabbitmq-cluster-default-user    Opaque   8      2m41s</span><br><span class=\"line\">rabbitmq-cluster-erlang-cookie   Opaque   1      2m41s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建管理员用户与权限</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl exec -it -n rabbitmq rabbitmq-cluster-server-1 -- bash</span><br><span class=\"line\">Defaulted container &quot;rabbitmq&quot; out of: rabbitmq, setup-container (init)</span><br><span class=\"line\">rabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl add_user admin 123.com</span><br><span class=\"line\">Adding user &quot;admin&quot; ...</span><br><span class=\"line\">Done. Don&#x27;t forget to grant the user permissions to some virtual hosts! See &#x27;rabbitmqctl help set_permissions&#x27; to learn more.</span><br><span class=\"line\">rabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_user_tags admin administrator</span><br><span class=\"line\">Setting tags for user &quot;admin&quot; to [administrator] ...</span><br><span class=\"line\">rabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</span><br><span class=\"line\">Setting permissions for user &quot;admin&quot; in vhost &quot;/&quot; ...</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"167c2c3f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress和nodeport资源</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">rabbitmq端口暴露</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: rabbitmq-nodeport</span><br><span class=\"line\">  namespace: rabbitmq</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.kubernetes.io/name: rabbitmq-cluster</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - name: amqp</span><br><span class=\"line\">    port: 5672</span><br><span class=\"line\">    protocol: TCP</span><br><span class=\"line\">    targetPort: 5672</span><br><span class=\"line\">    nodePort: 30005</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">web管理页面ingress</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: grafana</span><br><span class=\"line\">  namespace: rabbitmq</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`rabbitmq.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: rabbitmq-cluster</span><br><span class=\"line\">        port: 15672</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893103207-00c9ba96-3959-4e47-b9d9-213e445bd44f.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">python测试脚本，发送消息</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import pika</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def connect_rabbitmq(username, password, host, port=5672):</span><br><span class=\"line\">    # 创建带有用户名和密码认证的 RabbitMQ 连接</span><br><span class=\"line\">    credentials = pika.PlainCredentials(username, password)</span><br><span class=\"line\">    connection = pika.BlockingConnection(</span><br><span class=\"line\">        pika.ConnectionParameters(host=host, port=port, credentials=credentials)</span><br><span class=\"line\">    )</span><br><span class=\"line\">    return connection</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def send_message_to_queue(message, queue_name, username, password, host):</span><br><span class=\"line\">    # 建立连接</span><br><span class=\"line\">    connection = connect_rabbitmq(username, password, host)</span><br><span class=\"line\">    channel = connection.channel()</span><br><span class=\"line\"></span><br><span class=\"line\">    # 声明队列（如果不存在则创建）</span><br><span class=\"line\">    channel.queue_declare(queue=queue_name)</span><br><span class=\"line\"></span><br><span class=\"line\">    # 向指定队列发送消息</span><br><span class=\"line\">    channel.basic_publish(</span><br><span class=\"line\">        exchange=&#x27;&#x27;,</span><br><span class=\"line\">        routing_key=queue_name,</span><br><span class=\"line\">        body=message</span><br><span class=\"line\">    )</span><br><span class=\"line\">    print(f&quot;Sent message to queue &#123;queue_name&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # 关闭连接</span><br><span class=\"line\">    connection.close()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &quot;__main__&quot;:</span><br><span class=\"line\">    # 配置 RabbitMQ 用户认证信息</span><br><span class=\"line\">    username = &quot;admin&quot;</span><br><span class=\"line\">    password = &quot;123.com&quot;</span><br><span class=\"line\">    host = &quot;192.168.10.10&quot;  # 可替换为 RabbitMQ 主机地址</span><br><span class=\"line\"></span><br><span class=\"line\">    # 要发送的消息内容和目标队列</span><br><span class=\"line\">    message = &quot;Hello, RabbitMQ with Auth!&quot;</span><br><span class=\"line\">    queue_name = &quot;single_queue&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    # 向单个队列发送消息</span><br><span class=\"line\">    send_message_to_queue(message, queue_name, username, password, host)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看web页面成功收到消息。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893125711-190bb554-f771-4a7a-89d7-b477e2266fea.jpeg\"></p>\n","excerpt":"","more":"<h1 id=\"d9d372b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Kubernetes Operator</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">官网的文档 </font><a href=\"https://link.zhihu.com/?target=https://www.rabbitmq.com/kubernetes/operator/operator-overview.html\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/operator-overview.html</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Operator的yaml文件地址</span><br><span class=\"line\"># wget https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml</span><br><span class=\"line\"></span><br><span class=\"line\"># 安装</span><br><span class=\"line\"># kubectl apply -f cluster-operator.yml </span><br><span class=\"line\">namespace/rabbitmq-system created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/rabbitmqclusters.rabbitmq.com created</span><br><span class=\"line\">serviceaccount/rabbitmq-cluster-operator created</span><br><span class=\"line\">role.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-role created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-operator-role created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/rabbitmq-cluster-service-binding-role created</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-leader-election-rolebinding created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/rabbitmq-cluster-operator-rolebinding created</span><br><span class=\"line\">deployment.apps/rabbitmq-cluster-operator created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装完之后查看Operator是否启动正常, 默认pod在 rabbitmq-system命名空间下</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl get pod -n rabbitmq-system</span><br><span class=\"line\">NAME                                        READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">rabbitmq-cluster-operator-9d69fc79f-kp7ff   1/1     Running   0          8s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"bfa008dd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装rabbitmq</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mq时，会使用storageClass创建pvc，所以k8s需要提前配置好storageClass。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">自定义mq的yaml文件，配置项可以参考官网文档</font><a href=\"https://www.rabbitmq.com/kubernetes/operator/using-operator#overview\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.rabbitmq.com/kubernetes/operator/using-operator#overview</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: rabbitmq.com/v1beta1</span><br><span class=\"line\">kind: RabbitmqCluster</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: rabbitmq-cluster</span><br><span class=\"line\">  namespace: rabbitmq</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: rabbitmq-cluster</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  replicas: 3</span><br><span class=\"line\">  image: harbor.local.com/rabbitmq/rabbitmq:3.13.7-management</span><br><span class=\"line\">  persistence:</span><br><span class=\"line\">    storageClassName: nfs</span><br><span class=\"line\">    storage: 5Gi</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    limits:</span><br><span class=\"line\">      cpu: 2</span><br><span class=\"line\">      memory: 4Gi</span><br><span class=\"line\">  rabbitmq:</span><br><span class=\"line\">    additionalPlugins:</span><br><span class=\"line\">      - rabbitmq_prometheus # 启用prometheus插件</span><br><span class=\"line\">    additionalConfig: |</span><br><span class=\"line\">      default_vhost = vhost      #配置Virtual Hosts</span><br><span class=\"line\">      default_user = admin       #配置登录账号</span><br><span class=\"line\">      default_pass = 123.com      #配置账号密码</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建并查看资源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl get pod -n rabbitmq</span><br><span class=\"line\">NAME                        READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">rabbitmq-cluster-server-0   1/1     Running   0          58s</span><br><span class=\"line\">rabbitmq-cluster-server-1   1/1     Running   0          58s</span><br><span class=\"line\">rabbitmq-cluster-server-2   1/1     Running   0          58s</span><br><span class=\"line\"># kubectl get svc -n rabbitmq                                   </span><br><span class=\"line\">NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                        AGE</span><br><span class=\"line\">rabbitmq-cluster         ClusterIP   10.109.153.87   &lt;none&gt;        5672/TCP,15672/TCP,15692/TCP   66s</span><br><span class=\"line\">rabbitmq-cluster-nodes   ClusterIP   None            &lt;none&gt;        4369/TCP,25672/TCP             66s</span><br><span class=\"line\"># kubectl get secrets -n rabbitmq                                                                            </span><br><span class=\"line\">NAME                             TYPE     DATA   AGE</span><br><span class=\"line\">rabbitmq-cluster-default-user    Opaque   8      2m41s</span><br><span class=\"line\">rabbitmq-cluster-erlang-cookie   Opaque   1      2m41s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建管理员用户与权限</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl exec -it -n rabbitmq rabbitmq-cluster-server-1 -- bash</span><br><span class=\"line\">Defaulted container &quot;rabbitmq&quot; out of: rabbitmq, setup-container (init)</span><br><span class=\"line\">rabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl add_user admin 123.com</span><br><span class=\"line\">Adding user &quot;admin&quot; ...</span><br><span class=\"line\">Done. Don&#x27;t forget to grant the user permissions to some virtual hosts! See &#x27;rabbitmqctl help set_permissions&#x27; to learn more.</span><br><span class=\"line\">rabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_user_tags admin administrator</span><br><span class=\"line\">Setting tags for user &quot;admin&quot; to [administrator] ...</span><br><span class=\"line\">rabbitmq@rabbitmq-cluster-server-1:/$ rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</span><br><span class=\"line\">Setting permissions for user &quot;admin&quot; in vhost &quot;/&quot; ...</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"167c2c3f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress和nodeport资源</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">rabbitmq端口暴露</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: rabbitmq-nodeport</span><br><span class=\"line\">  namespace: rabbitmq</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  type: NodePort</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    app.kubernetes.io/name: rabbitmq-cluster</span><br><span class=\"line\">  ports:</span><br><span class=\"line\">  - name: amqp</span><br><span class=\"line\">    port: 5672</span><br><span class=\"line\">    protocol: TCP</span><br><span class=\"line\">    targetPort: 5672</span><br><span class=\"line\">    nodePort: 30005</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">web管理页面ingress</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: grafana</span><br><span class=\"line\">  namespace: rabbitmq</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`rabbitmq.local.com`)</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: rabbitmq-cluster</span><br><span class=\"line\">        port: 15672</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893103207-00c9ba96-3959-4e47-b9d9-213e445bd44f.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">python测试脚本，发送消息</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import pika</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def connect_rabbitmq(username, password, host, port=5672):</span><br><span class=\"line\">    # 创建带有用户名和密码认证的 RabbitMQ 连接</span><br><span class=\"line\">    credentials = pika.PlainCredentials(username, password)</span><br><span class=\"line\">    connection = pika.BlockingConnection(</span><br><span class=\"line\">        pika.ConnectionParameters(host=host, port=port, credentials=credentials)</span><br><span class=\"line\">    )</span><br><span class=\"line\">    return connection</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def send_message_to_queue(message, queue_name, username, password, host):</span><br><span class=\"line\">    # 建立连接</span><br><span class=\"line\">    connection = connect_rabbitmq(username, password, host)</span><br><span class=\"line\">    channel = connection.channel()</span><br><span class=\"line\"></span><br><span class=\"line\">    # 声明队列（如果不存在则创建）</span><br><span class=\"line\">    channel.queue_declare(queue=queue_name)</span><br><span class=\"line\"></span><br><span class=\"line\">    # 向指定队列发送消息</span><br><span class=\"line\">    channel.basic_publish(</span><br><span class=\"line\">        exchange=&#x27;&#x27;,</span><br><span class=\"line\">        routing_key=queue_name,</span><br><span class=\"line\">        body=message</span><br><span class=\"line\">    )</span><br><span class=\"line\">    print(f&quot;Sent message to queue &#123;queue_name&#125;&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">    # 关闭连接</span><br><span class=\"line\">    connection.close()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &quot;__main__&quot;:</span><br><span class=\"line\">    # 配置 RabbitMQ 用户认证信息</span><br><span class=\"line\">    username = &quot;admin&quot;</span><br><span class=\"line\">    password = &quot;123.com&quot;</span><br><span class=\"line\">    host = &quot;192.168.10.10&quot;  # 可替换为 RabbitMQ 主机地址</span><br><span class=\"line\"></span><br><span class=\"line\">    # 要发送的消息内容和目标队列</span><br><span class=\"line\">    message = &quot;Hello, RabbitMQ with Auth!&quot;</span><br><span class=\"line\">    queue_name = &quot;single_queue&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">    # 向单个队列发送消息</span><br><span class=\"line\">    send_message_to_queue(message, queue_name, username, password, host)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看web页面成功收到消息。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737893125711-190bb554-f771-4a7a-89d7-b477e2266fea.jpeg\"></p>\n"},{"title":"ETCD--安装部署","date":"2025-03-05T11:08:06.000Z","_content":"<h1 id=\"331764a2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署(单机)</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果在测试开发环境，想要测试和使用etcd服务，只需要部署一个单点的 etcd 服务即可。</font>\n\n<h2 id=\"2ef72e59\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装软件</font>\n\n```plain\n# 下载软件包\n[root@linux9 ~]# wget https://github.com/etcd-io/etcd/releases/download/v3.4.23/etcd-v3.4.23-linux-amd64.tar.gz\n[root@linux9 ~]# ls\netcd-v3.4.23-linux-amd64.tar.gz\n\n# 解压到指定目录\n[root@linux9 ~]# tar -zxf etcd-v3.4.23-linux-amd64.tar.gz -C /usr/local\n[root@linux9 ~]# cd /usr/local/etc\netc/                      etcd-v3.4.23-linux-amd64/ \n[root@linux9 ~]# cd /usr/local/etcd-v3.4.23-linux-amd64/\n[root@linux9 etcd-v3.4.23-linux-amd64]# ls\nDocumentation  README-etcdctl.md  README.md  READMEv2-etcdctl.md  etcd  etcdctl\n\n# 添加环境变量\n[root@linux9 etcd-v3.4.23-linux-amd64]# vim /etc/profile\nexport PATH=\"$PATH:/usr/local/etcd-v3.4.23-linux-amd64\"\n[root@linux9 etcd-v3.4.23-linux-amd64]# source /etc/profile\n\n# 验证\n[root@linux9 etcd-v3.4.23-linux-amd64]# etcdctl version\netcdctl version: 3.4.23\nAPI version: 3.4\n[root@linux9 etcd-v3.4.23-linux-amd64]# etcd --version\netcd Version: 3.4.23\nGit SHA: c8b7831\nGo Version: go1.17.13\nGo OS/Arch: linux/amd64\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">添加systemd服务配置</font>\n\n```plain\n# 创建数据目录与配置文件目录\n[root@linux9 ~]# mkdir -p /etc/etcd\n[root@linux9 ~]# mkdir -p /data/etcd\n\n# systemd 服务配置文件\n[root@linux9 ~]# cat /usr/lib/systemd/system/etcd.service\n[Unit]\nDescription=Etcd Server\nAfter=network.target\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nType=notify\nEnvironmentFile=/etc/etcd/etcd.conf\nExecStart=/usr/local/etcd-v3.4.23-linux-amd64/etcd --config-file=/etc/etcd/etcd.conf\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n\n# 创建etcd配置文件\n[root@linux9 ~]# cat /etc/etcd/etcd.conf\n# 节点名称\nname: 'etcd-1'\n# 指定节点的数据存储目录\ndata-dir: '/data/etcd'\n# 对外提供服务的地址，客户端会连接到这里和 etcd 交互\nlisten-client-urls: 'http://192.168.10.128:2379,http://127.0.0.1:2379'\n\n# 启动etcd服务并添加开机自启动\n[root@linux9 ~]# systemctl daemon-reload\n[root@linux9 ~]# systemctl start etcd\n[root@linux9 ~]# systemctl enable etcd\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">除了可以使用配置文件指定配置外，也可以直接通过命令行参数指定配置，常用的命令行参数如下(推荐使用配置文件)，命令行参数参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/configuration/</font>](https://etcd.io/docs/v3.5/op-guide/configuration/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，配置文件参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample</font>](https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample)\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">说明</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–name</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd节点名字如果在集群环境中，name必须是唯一的，建议用主机名称或者机器ID。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–data-dir</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储目录</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd启动的时候，通过这个配置找到其他ectd节点的地址列表，格式：‘节点名字1=http://节点ip1:2380,节点名字1=http://节点ip1:2380,…’</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster-state</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">初始化的时候，集群的状态 “new” 或者 \"existing\"两种状态，new代表新建的集群，existing表示加入已经存在的集群。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–advertise-client-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">如果–listen-client-urls配置了，多个监听客户端请求的地址，这个参数可以给出，建议客户端使用什么地址访问etcd。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">服务端之间通讯使用的地址列表。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">监听客户端请求的地址列表，格式：‘http://localhost:2379’, 多个用逗号分隔。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">服务端节点之间通讯的监听地址，格式：‘http://localhost:2380’</font> |\n\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font>\n\n```plain\n# 查看集群状态\n[root@linux9 ~]# etcdctl endpoint status --cluster -w table\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.128:2379 | 9a20d64f814efc90 |  3.4.23 |   20 kB |      true |      false |         2 |          4 |                  4 |        |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n# 设置key value\n[root@linux9 ~]# etcdctl put greeting \"Hello, etcd\"\nOK\n# 获取value\n[root@linux9 ~]# etcdctl get greeting\ngreeting\nHello, etcd\n```\n\n<h2 id=\"84e66d38\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker容器部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档参考地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/container/</font>](https://etcd.io/docs/v3.5/op-guide/container/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，官方docker示例使用命令行参数启动，并不推荐。</font>\n\n```plain\n# 创建数据目录与配置文件目录\n[root@linux9 ~]# mkdir -p /etc/etcd\n[root@linux9 ~]# mkdir -p /data/etcd\n\n# 修改数据目录权限，否则无法写入数据\n[root@linux9 ~]# chown -R 1001:1001 /data/etcd/\n\n# 创建etcd配置文件\n[root@linux9 ~]# cat /etc/etcd/etcd.conf\n# 节点名称\nname: 'etcd-1'\n# 指定节点的数据存储目录\ndata-dir: '/data'\n# 对外提供服务的地址，客户端会连接到这里和 etcd 交互\nlisten-client-urls: 'http://0.0.0.0:2379'\n\n# 启动etcd容器\n[root@linux9 ~]# docker run -d --name etcd -p 2379:2379 -v /data/etcd:/data -v /etc/etcd:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf\n\n# 访问验证\n[root@linux9 etcd]# docker exec etcd sh -c \"etcd --version\"\netcd Version: 3.5.6\nGit SHA: cecbe35ce\nGo Version: go1.16.15\nGo OS/Arch: linux/amd64\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl version\"\netcdctl version: 3.5.6\nAPI version: 3.5\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl endpoint status --cluster -w table\"\n+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|        ENDPOINT        |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://172.17.0.2:2379 | 8e9e05c52164694d |   3.5.6 |   20 kB |      true |      false |         6 |         13 |                 13 |        |\n+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl put foo bar\"\nOK\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl get foo\"\nfoo\nbar\n```\n\n<h2 id=\"8d85811c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web管理工具etcdkeeper部署</font></h2>\n```plain\n[root@linux9 ~]# docker run -d -p 8080:8080 --name=etcdkeeper evildecay/etcdkeeper:latest\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">1</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738849970258-d25ebf11-2527-4be4-8072-b63c3351cf98.jpeg)\n\n<h1 id=\"39e1af29\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署etcd集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在生产环境或对高可用有要求的环境下，需要使用 etcd 的高可用部署方式进行部署，etcd 的 raft 协议保障各个节点数据的一致性。至少使用三台以上奇数节点，才能达到最好的集群容错。</font>\n\n<h2 id=\"2810ee4c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">系统</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">IP地址</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">部署组件</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd1</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.11</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd2</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.12</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd3</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们以3个节点的高可用静态方式部署 etcd，3个节点的IP地址分别是192.168.10.100、192.168.10.11和192.168.10.12。每个节点etcd配置文件主要的差异就是当前节点的 IP 地址和命名。部署启动方法与单节点部署启动方式完全一致，只需要更改配置文件内容即可。</font>\n\n<h2 id=\"1bbbb204\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls用于监听客户端消息,必须设置为真实ip地址，如果机器为云主机，可以设置为云主机的私有ip地址或0.0.0.0(代表监听所有地址),不能设置为公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls用于监听其他member发送过来的消息，跟listen-client-urls一样，必须设置为真实ip地址,如果机器为云主机,不能设置为公网ip  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls用于监听其他member同步信号，该地址其他member必须能直接访问，所以如果是云主机该地址必须设置为云主机的公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster群集列表，该列表中的值必须跟各个member的initial-advertise-peer-urls值一样</font>\n\n<h2 id=\"848be749\"><font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban节点配置</font></h2>\n```plain\n# 节点名称\nname: \"etcd1\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.100:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.100:2379,http://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.100:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.100:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n```\n\n<h2 id=\"6dbce8aa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1节点配置</font></h2>\n```plain\n# 节点名称\nname: \"etcd2\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.11:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.11:2379,http://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.11:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.11:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n```\n\n<h2 id=\"807b27a0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2节点配置</font></h2>\n```plain\n# 节点名称\nname: \"etcd3\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.12:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.12:2379,http://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.12:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.12:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n```plain\n[root@k8s-master etcd]# etcdctl endpoint status --cluster -w table\n+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|         ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |      true |      false |         3 |          9 |                  9 |        |\n| http://192.168.10.10:2379 | 8c632555af4d958d |  3.4.23 |   16 kB |     false |      false |         3 |          9 |                  9 |        |\n| http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         3 |          9 |                  9 |        |\n+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@k8s-master etcd]# etcdctl put foo bar\nOK\n[root@k8s-master etcd]# etcdctl get foo\nfoo\nbar\n```\n\n<h1 id=\"934b36d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署TLS加密集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 支持通过 TLS 协议的加密通讯，在实际企业生产环境中，出于安全规范要求，建议开启TLS加密。TLS 通道可以用于加密内部的集群通讯，也可以用于加密客户端请求。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 的 TLS 有两对，一对是 etcd 和 client 端的 TLS 配置。一对是 etcd 之间的 peer 的 TLS 配置。有很多方式可以创建CA证书和私钥，其中比较流行的有两种</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">openssl</font>\n+ [<font style=\"background-color:rgba(255, 255, 255, 0);\">cfssl</font>](https://pkg.cfssl.org/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档推荐使用cfssl生成证书</font>\n\n<h2 id=\"2d216623\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装cfssl</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/cloudflare/cfssl/releases</font>](https://github.com/cloudflare/cfssl/releases)\n\n```plain\n[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssl_1.6.3_linux_amd64\n[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssljson_1.6.3_linux_amd64\n[root@tiaoban ~]# mv cfssl_1.6.3_linux_amd64 /usr/bin/cfssl\n[root@tiaoban ~]# mv cfssljson_1.6.3_linux_amd64 /usr/bin/cfssljson\n[root@tiaoban ~]# chmod +x /usr/bin/{cfssl,cfssljson}\n[root@tiaoban ~]# cfssl version\nVersion: 1.6.3\nRuntime: go1.18\n```\n\n<h2 id=\"f8a74222\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建默认配置文件</font></h2>\n```plain\n[root@tiaoban ~]# cfssl print-defaults config > ca-config.json\n[root@tiaoban ~]# cfssl print-defaults csr > ca-csr.json\n```\n\n<h2 id=\"929e8577\"><font style=\"background-color:rgba(255, 255, 255, 0);\">证书类型</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端证书用于服务器验证客户端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器端证书用于客户端验证服务器端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对等证书由etcd集群成员使用，同时使用客户端认证和服务器端认证</font>\n\n<h2 id=\"b81c6516\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建 CA 证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于各个组件都需要配置证书，并且依赖 CA 证书来签发证书，所以我们首先要生成好 CA 证书以及后续的签发配置文件</font>\n\n```plain\n# 修改ca-config配置\n[root@tiaoban etcd]# cat > ca-config.json <<EOF\n{\n    \"signing\": {\n        \"default\": {\n            \"expiry\": \"43800h\"\n        },\n        \"profiles\": {\n            \"server\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\"\n                ]\n            },\n            \"client\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"client auth\"\n                ]\n            },\n            \"peer\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\",\n                    \"client auth\"\n                ]\n            }\n        }\n    }\n}\nEOF\n# 配置证书请求\n[root@tiaoban etcd]# cat > ca-csr.json <<EOF\n{\n  \"CN\": \"Etcd\",\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"Etcd\",\n      \"OU\": \"CA\"\n    }\n  ]\n}\nEOF\n# 生成CA证书\n[root@tiaoban etcd]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -\n[root@tiaoban etcd]# ls\nca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">生成的文件中有下面三个后面会用到:</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">ca-key.pem: CA 证书密钥</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">ca.pem: CA 证书</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">ca-config.json: 证书签发配置，用 CA 证书来签发其它证书时需要用</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">csr 文件字段解释:</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">CN: Common Name，apiserver 从证书中提取该字段作为请求的用户名 (User Name)</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Organization，apiserver 从证书中提取该字段作为请求用户所属的组 (Group)</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于这里是 CA 证书，是签发其它证书的根证书，这个证书密钥不会分发出去作为 client 证书，所有组件使用的 client 证书都是由 CA 证书签发而来，所以 CA 证书的 CN 和 O 的名称并不重要，后续其它签发出来的证书的 CN 和 O 的名称才是有用的</font>\n\n<h2 id=\"6f7fc89f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成服务器端证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意hosts字段需要加上etcd全部节点的IP/主机名信息及127.0.0.1</font>\n\n```plain\n# 配置证书请求\n[root@tiaoban etcd]# cat > server-csr.json <<EOF\n{\n    \"CN\": \"server\",\n    \"hosts\": [\n        \"127.0.0.1\",\n        \"192.168.10.100\",\n        \"192.168.10.11\",\n        \"192.168.10.12\"\n    ],\n    \"key\": {\n        \"algo\": \"ecdsa\",\n        \"size\": 256\n    },\n    \"names\": [\n        {\n            \"C\": \"CN\",\n            \"L\": \"BeiJing\",\n            \"ST\": \"BeiJing\"\n        }\n    ]\n}\nEOF\n# 创建服务器端证书和私钥\n[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server-csr.json | cfssljson -bare server\n# 生成以下文件\n[root@tiaoban etcd]# ls server*\nserver.csr  server-csr.json  server-key.pem  server.pem\n```\n\n<h2 id=\"9758d425\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成客户端证书</font></h2>\n```plain\n# 配置证书请求\n[root@tiaoban etcd]# cat > client-csr.json <<EOF\n{\n    \"CN\": \"client\",\n    \"hosts\": [\n        \"\"\n    ],\n    \"key\": {\n        \"algo\": \"ecdsa\",\n        \"size\": 256\n    },\n    \"names\": [\n        {\n            \"C\": \"CN\",\n            \"L\": \"BeiJing\",\n            \"ST\": \"BeiJing\"\n        }\n    ]\n}\nEOF\n# 创建客户端证书和私钥\n[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client-csr.json | cfssljson -bare client\n# 生成以下文件\n[root@tiaoban etcd]# ls client*\nclient.csr  client-csr.json  client-key.pem  client.pem\n```\n\n<h2 id=\"07dcf88f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成对等证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">peer证书可以统一，也可以分别生成，如果需要统一，则需要在hosts字段加上所有节点的IP/主机名信息，如果分开生成，则hosts字段只需要填写对应节点的IP/主机名信息即可</font>\n\n```plain\n# 配置证书请求\n[root@tiaoban etcd]# cat > peer-csr.json <<EOF\n{\n    \"CN\": \"peer\",\n    \"hosts\": [\n        \"192.168.10.100\",\n        \"192.168.10.11\",\n        \"192.168.10.12\"\n    ],\n    \"key\": {\n        \"algo\": \"ecdsa\",\n        \"size\": 256\n    },\n    \"names\": [\n        {\n            \"C\": \"CN\",\n            \"L\": \"BeiJing\",\n            \"ST\": \"BeiJing\"\n        }\n    ]\n}\nEOF\n# 创建对等证书和私钥\n[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer peer-csr.json | cfssljson -bare peer\n# 生成以下文件\n[root@tiaoban etcd]# ls peer*\npeer.csr  peer-csr.json  peer-key.pem  peer.pem\n```\n\n<h2 id=\"b8513fa5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝密钥到所有节点并更新系统证书库</font></h2>\n```plain\n[root@tiaoban etcd]# mkdir -p /etc/etcd/pki\n[root@tiaoban etcd]# cp ca.pem server.pem server-key.pem peer.pem peer-key.pem /etc/etcd/pki/\n[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work1:/etc/etcd/pki/  \n[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work2:/etc/etcd/pki/\n[root@tiaoban etcd]# yum install ca-certificates -y  \n[root@tiaoban etcd]# update-ca-trust\n```\n\n<h2 id=\"f0af8621\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改etcd配置并重启etcd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要是将原本的http链接全部改为https，并指定证书密钥地址</font>\n\n```plain\n[root@tiaoban etcd]# cat /etc/etcd/etcd.conf\n# 节点名称\nname: \"etcd1\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"https://192.168.10.100:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"https://192.168.10.100:2379,https://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"https://192.168.10.100:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"https://192.168.10.100:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=https://192.168.10.100:2380,etcd2=https://192.168.10.11:2380,etcd3=https://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n# 日志配置\nlogger: zap\n\n# 客户端加密\nclient-transport-security:\n  cert-file: \"/etc/etcd/pki/server.pem\"\n  key-file: \"/etc/etcd/pki/server-key.pem\"\n  client-cert-auth: True\n  trusted-ca-file: \"/etc/etcd/pki/ca.pem\"\n\n# 节点加密\npeer-transport-security:\n  cert-file: \"/etc/etcd/pki/peer.pem\"\n  key-file: \"/etc/etcd/pki/peer-key.pem\"\n  client-cert-auth: True\n  trusted-ca-file: \"/etc/etcd/pki/ca.pem\"\n```\n\n<h2 id=\"046e223e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n```plain\n[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem endpoint status --cluster -w table\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|  https://192.168.10.11:2379 | 6571fb7574e87dba |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |\n|  https://192.168.10.12:2379 | 9b449b0ff1d4c375 |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |\n| https://192.168.10.100:2379 | f330bec74ce6cc42 |  3.4.23 |   20 kB |      true |      false |       310 |         46 |                 46 |        |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem put /foo/bar \"hello world\"\nOK    \n[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem get /foo/bar\n/foo/bar\nhello world\n```\n\n<h1 id=\"df8bef0b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署etcd集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用helm可以快速部署一个etcd集群，集成了配置基于角色的访问控制和 TLS 加密，并且可以按需开启定时备份和监控指标采集。</font>\n\n<h2 id=\"106d5e32\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加仓库，获取安装包</font></h2>\n```plain\n[root@k8s-master k8s-test]# cd etcd/\n[root@k8s-master etcd]# helm repo add my-repo https://charts.bitnami.com/bitnami\n\"my-repo\" has been added to your repositories\n[root@k8s-master etcd]# helm pull my-repo/etcd\n[root@k8s-master etcd]# ls\netcd-8.8.0.tgz\n[root@k8s-master etcd]# tar -zxf etcd-8.8.0.tgz\n[root@k8s-master etcd]# ls\netcd  etcd-8.8.0.tgz\n[root@k8s-master etcd]# cd etcd/\n[root@k8s-master etcd]# ls\nChart.lock  charts  Chart.yaml  README.md  templates  values.yaml\n```\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n```plain\n[root@k8s-master etcd]# vim values.yaml\n# 自定义root密码\n 96 auth:\n 97   ## Role-based access control parameters\n 98   ## ref: https://etcd.io/docs/current/op-guide/authentication/\n 99   ##\n100   rbac:\n101     ## @param auth.rbac.create Switch to enable RBAC authentication\n102     ##\n103     create: true\n104     ## @param auth.rbac.allowNoneAuthentication Allow to use etcd without configuring RBAC authentication\n105     ##\n106     allowNoneAuthentication: true\n107     ## @param auth.rbac.rootPassword Root user password. The root user is always `root`\n108     ##\n109     rootPassword: \"123456\" # 指定root密码\n\n# 自定义存储方式\n575 persistence:\n576   ## @param persistence.enabled If true, use a Persistent Volume Claim. If false, use emptyDir.\n577   ##\n578   enabled: true # 如果没有sc，此处改为false\n579   ## @param persistence.storageClass Persistent Volume Storage Class\n580   ## If defined, storageClassName: <storageClass>\n581   ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n582   ## If undefined (the default) or set to null, no storageClassName spec is\n583   ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n584   ##   GKE, AWS & OpenStack)\n585   ##\n586   storageClass: \"nfs-client\" # 填写sc名称\n\n# 修改副本数，建议奇数3个起步\n257 ## @param replicaCount Number of etcd replicas to deploy\n258 ##\n259 replicaCount: 3\n```\n\n<h2 id=\"367c6336\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装etcd服务</font></h2>\n```plain\n[root@k8s-master etcd]# kubectl create ns etcd\nnamespace/etcd created\n[root@k8s-master etcd]# helm install etcd -n etcd ../etcd\nNAME: etcd\nLAST DEPLOYED: Fri Mar 17 20:43:31 2023\nNAMESPACE: etcd\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCHART NAME: etcd\nCHART VERSION: 8.8.0\nAPP VERSION: 3.5.7\n\n** Please be patient while the chart is being deployed **\n\netcd can be accessed via port 2379 on the following DNS name from within your cluster:\n\netcd.etcd.svc.cluster.local\n\nTo create a pod that you can use as a etcd client run the following command:\n\nkubectl run etcd-client --restart='Never' --image docker.io/bitnami/etcd:3.5.7-debian-11-r14 --env ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=\"{.data.etcd-root-password}\" | base64 -d) --env ETCDCTL_ENDPOINTS=\"etcd.etcd.svc.cluster.local:2379\" --namespace etcd --command -- sleep infinity\n\nThen, you can set/get a key using the commands below:\n\nkubectl exec --namespace etcd -it etcd-client -- bash\netcdctl --user root:$ROOT_PASSWORD put /message Hello\netcdctl --user root:$ROOT_PASSWORD get /message\n\nTo connect to your etcd server from outside the cluster execute the following commands:\n\nkubectl port-forward --namespace etcd svc/etcd 2379:2379 &\necho \"etcd URL: http://127.0.0.1:2379\"\n\n* As rbac is enabled you should add the flag `--user root:$ETCD_ROOT_PASSWORD` to the etcdctl commands. Use the command below to export the password:\n\nexport ETCD_ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=\"{.data.etcd-root-password}\" | base64 -d)\n```\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n```plain\n[root@k8s-master etcd]# kubectl get pod -n etcd -o wide\nNAME     READY   STATUS    RESTARTS        AGE     IP             NODE        NOMINATED NODE   READINESS GATES\netcd-0   1/1     Running   0               1m13s   10.244.1.154   k8s-work1   <none>           <none>\netcd-1   1/1     Running   0               1m13s   10.244.2.50    k8s-work2   <none>           <none>\netcd-2   1/1     Running   0               1m13s   10.244.1.155   k8s-work1   <none>           <none>\n[root@k8s-master etcd]# kubectl get svc -n etcd \nNAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\netcd            ClusterIP   10.102.32.213   <none>        2379/TCP,2380/TCP   9m48s\netcd-headless   ClusterIP   None            <none>        2379/TCP,2380/TCP   9m48s\n```\n\n<h2 id=\"e6efac8c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问测试</font></h2>\n","source":"_posts/2.ETCD——安装部署.md","raw":"---\ntitle: ETCD--安装部署\ndate: 2025-03-05 19:08:06\n---\n<h1 id=\"331764a2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署(单机)</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果在测试开发环境，想要测试和使用etcd服务，只需要部署一个单点的 etcd 服务即可。</font>\n\n<h2 id=\"2ef72e59\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装软件</font>\n\n```plain\n# 下载软件包\n[root@linux9 ~]# wget https://github.com/etcd-io/etcd/releases/download/v3.4.23/etcd-v3.4.23-linux-amd64.tar.gz\n[root@linux9 ~]# ls\netcd-v3.4.23-linux-amd64.tar.gz\n\n# 解压到指定目录\n[root@linux9 ~]# tar -zxf etcd-v3.4.23-linux-amd64.tar.gz -C /usr/local\n[root@linux9 ~]# cd /usr/local/etc\netc/                      etcd-v3.4.23-linux-amd64/ \n[root@linux9 ~]# cd /usr/local/etcd-v3.4.23-linux-amd64/\n[root@linux9 etcd-v3.4.23-linux-amd64]# ls\nDocumentation  README-etcdctl.md  README.md  READMEv2-etcdctl.md  etcd  etcdctl\n\n# 添加环境变量\n[root@linux9 etcd-v3.4.23-linux-amd64]# vim /etc/profile\nexport PATH=\"$PATH:/usr/local/etcd-v3.4.23-linux-amd64\"\n[root@linux9 etcd-v3.4.23-linux-amd64]# source /etc/profile\n\n# 验证\n[root@linux9 etcd-v3.4.23-linux-amd64]# etcdctl version\netcdctl version: 3.4.23\nAPI version: 3.4\n[root@linux9 etcd-v3.4.23-linux-amd64]# etcd --version\netcd Version: 3.4.23\nGit SHA: c8b7831\nGo Version: go1.17.13\nGo OS/Arch: linux/amd64\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">添加systemd服务配置</font>\n\n```plain\n# 创建数据目录与配置文件目录\n[root@linux9 ~]# mkdir -p /etc/etcd\n[root@linux9 ~]# mkdir -p /data/etcd\n\n# systemd 服务配置文件\n[root@linux9 ~]# cat /usr/lib/systemd/system/etcd.service\n[Unit]\nDescription=Etcd Server\nAfter=network.target\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nType=notify\nEnvironmentFile=/etc/etcd/etcd.conf\nExecStart=/usr/local/etcd-v3.4.23-linux-amd64/etcd --config-file=/etc/etcd/etcd.conf\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n\n# 创建etcd配置文件\n[root@linux9 ~]# cat /etc/etcd/etcd.conf\n# 节点名称\nname: 'etcd-1'\n# 指定节点的数据存储目录\ndata-dir: '/data/etcd'\n# 对外提供服务的地址，客户端会连接到这里和 etcd 交互\nlisten-client-urls: 'http://192.168.10.128:2379,http://127.0.0.1:2379'\n\n# 启动etcd服务并添加开机自启动\n[root@linux9 ~]# systemctl daemon-reload\n[root@linux9 ~]# systemctl start etcd\n[root@linux9 ~]# systemctl enable etcd\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">除了可以使用配置文件指定配置外，也可以直接通过命令行参数指定配置，常用的命令行参数如下(推荐使用配置文件)，命令行参数参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/configuration/</font>](https://etcd.io/docs/v3.5/op-guide/configuration/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，配置文件参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample</font>](https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample)\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">说明</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–name</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd节点名字如果在集群环境中，name必须是唯一的，建议用主机名称或者机器ID。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–data-dir</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储目录</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd启动的时候，通过这个配置找到其他ectd节点的地址列表，格式：‘节点名字1=http://节点ip1:2380,节点名字1=http://节点ip1:2380,…’</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster-state</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">初始化的时候，集群的状态 “new” 或者 \"existing\"两种状态，new代表新建的集群，existing表示加入已经存在的集群。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–advertise-client-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">如果–listen-client-urls配置了，多个监听客户端请求的地址，这个参数可以给出，建议客户端使用什么地址访问etcd。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">服务端之间通讯使用的地址列表。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">监听客户端请求的地址列表，格式：‘http://localhost:2379’, 多个用逗号分隔。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">服务端节点之间通讯的监听地址，格式：‘http://localhost:2380’</font> |\n\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font>\n\n```plain\n# 查看集群状态\n[root@linux9 ~]# etcdctl endpoint status --cluster -w table\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.128:2379 | 9a20d64f814efc90 |  3.4.23 |   20 kB |      true |      false |         2 |          4 |                  4 |        |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n# 设置key value\n[root@linux9 ~]# etcdctl put greeting \"Hello, etcd\"\nOK\n# 获取value\n[root@linux9 ~]# etcdctl get greeting\ngreeting\nHello, etcd\n```\n\n<h2 id=\"84e66d38\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker容器部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档参考地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/container/</font>](https://etcd.io/docs/v3.5/op-guide/container/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，官方docker示例使用命令行参数启动，并不推荐。</font>\n\n```plain\n# 创建数据目录与配置文件目录\n[root@linux9 ~]# mkdir -p /etc/etcd\n[root@linux9 ~]# mkdir -p /data/etcd\n\n# 修改数据目录权限，否则无法写入数据\n[root@linux9 ~]# chown -R 1001:1001 /data/etcd/\n\n# 创建etcd配置文件\n[root@linux9 ~]# cat /etc/etcd/etcd.conf\n# 节点名称\nname: 'etcd-1'\n# 指定节点的数据存储目录\ndata-dir: '/data'\n# 对外提供服务的地址，客户端会连接到这里和 etcd 交互\nlisten-client-urls: 'http://0.0.0.0:2379'\n\n# 启动etcd容器\n[root@linux9 ~]# docker run -d --name etcd -p 2379:2379 -v /data/etcd:/data -v /etc/etcd:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf\n\n# 访问验证\n[root@linux9 etcd]# docker exec etcd sh -c \"etcd --version\"\netcd Version: 3.5.6\nGit SHA: cecbe35ce\nGo Version: go1.16.15\nGo OS/Arch: linux/amd64\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl version\"\netcdctl version: 3.5.6\nAPI version: 3.5\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl endpoint status --cluster -w table\"\n+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|        ENDPOINT        |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://172.17.0.2:2379 | 8e9e05c52164694d |   3.5.6 |   20 kB |      true |      false |         6 |         13 |                 13 |        |\n+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl put foo bar\"\nOK\n[root@linux9 etcd]# docker exec etcd sh -c \"etcdctl get foo\"\nfoo\nbar\n```\n\n<h2 id=\"8d85811c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web管理工具etcdkeeper部署</font></h2>\n```plain\n[root@linux9 ~]# docker run -d -p 8080:8080 --name=etcdkeeper evildecay/etcdkeeper:latest\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">1</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738849970258-d25ebf11-2527-4be4-8072-b63c3351cf98.jpeg)\n\n<h1 id=\"39e1af29\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署etcd集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在生产环境或对高可用有要求的环境下，需要使用 etcd 的高可用部署方式进行部署，etcd 的 raft 协议保障各个节点数据的一致性。至少使用三台以上奇数节点，才能达到最好的集群容错。</font>\n\n<h2 id=\"2810ee4c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">系统</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">IP地址</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">部署组件</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd1</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.11</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd2</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.12</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd3</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们以3个节点的高可用静态方式部署 etcd，3个节点的IP地址分别是192.168.10.100、192.168.10.11和192.168.10.12。每个节点etcd配置文件主要的差异就是当前节点的 IP 地址和命名。部署启动方法与单节点部署启动方式完全一致，只需要更改配置文件内容即可。</font>\n\n<h2 id=\"1bbbb204\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls用于监听客户端消息,必须设置为真实ip地址，如果机器为云主机，可以设置为云主机的私有ip地址或0.0.0.0(代表监听所有地址),不能设置为公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls用于监听其他member发送过来的消息，跟listen-client-urls一样，必须设置为真实ip地址,如果机器为云主机,不能设置为公网ip  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls用于监听其他member同步信号，该地址其他member必须能直接访问，所以如果是云主机该地址必须设置为云主机的公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster群集列表，该列表中的值必须跟各个member的initial-advertise-peer-urls值一样</font>\n\n<h2 id=\"848be749\"><font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban节点配置</font></h2>\n```plain\n# 节点名称\nname: \"etcd1\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.100:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.100:2379,http://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.100:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.100:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n```\n\n<h2 id=\"6dbce8aa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1节点配置</font></h2>\n```plain\n# 节点名称\nname: \"etcd2\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.11:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.11:2379,http://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.11:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.11:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n```\n\n<h2 id=\"807b27a0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2节点配置</font></h2>\n```plain\n# 节点名称\nname: \"etcd3\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.12:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.12:2379,http://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.12:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.12:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n```plain\n[root@k8s-master etcd]# etcdctl endpoint status --cluster -w table\n+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|         ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |      true |      false |         3 |          9 |                  9 |        |\n| http://192.168.10.10:2379 | 8c632555af4d958d |  3.4.23 |   16 kB |     false |      false |         3 |          9 |                  9 |        |\n| http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         3 |          9 |                  9 |        |\n+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@k8s-master etcd]# etcdctl put foo bar\nOK\n[root@k8s-master etcd]# etcdctl get foo\nfoo\nbar\n```\n\n<h1 id=\"934b36d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署TLS加密集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 支持通过 TLS 协议的加密通讯，在实际企业生产环境中，出于安全规范要求，建议开启TLS加密。TLS 通道可以用于加密内部的集群通讯，也可以用于加密客户端请求。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 的 TLS 有两对，一对是 etcd 和 client 端的 TLS 配置。一对是 etcd 之间的 peer 的 TLS 配置。有很多方式可以创建CA证书和私钥，其中比较流行的有两种</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">openssl</font>\n+ [<font style=\"background-color:rgba(255, 255, 255, 0);\">cfssl</font>](https://pkg.cfssl.org/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档推荐使用cfssl生成证书</font>\n\n<h2 id=\"2d216623\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装cfssl</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/cloudflare/cfssl/releases</font>](https://github.com/cloudflare/cfssl/releases)\n\n```plain\n[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssl_1.6.3_linux_amd64\n[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssljson_1.6.3_linux_amd64\n[root@tiaoban ~]# mv cfssl_1.6.3_linux_amd64 /usr/bin/cfssl\n[root@tiaoban ~]# mv cfssljson_1.6.3_linux_amd64 /usr/bin/cfssljson\n[root@tiaoban ~]# chmod +x /usr/bin/{cfssl,cfssljson}\n[root@tiaoban ~]# cfssl version\nVersion: 1.6.3\nRuntime: go1.18\n```\n\n<h2 id=\"f8a74222\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建默认配置文件</font></h2>\n```plain\n[root@tiaoban ~]# cfssl print-defaults config > ca-config.json\n[root@tiaoban ~]# cfssl print-defaults csr > ca-csr.json\n```\n\n<h2 id=\"929e8577\"><font style=\"background-color:rgba(255, 255, 255, 0);\">证书类型</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端证书用于服务器验证客户端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器端证书用于客户端验证服务器端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对等证书由etcd集群成员使用，同时使用客户端认证和服务器端认证</font>\n\n<h2 id=\"b81c6516\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建 CA 证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于各个组件都需要配置证书，并且依赖 CA 证书来签发证书，所以我们首先要生成好 CA 证书以及后续的签发配置文件</font>\n\n```plain\n# 修改ca-config配置\n[root@tiaoban etcd]# cat > ca-config.json <<EOF\n{\n    \"signing\": {\n        \"default\": {\n            \"expiry\": \"43800h\"\n        },\n        \"profiles\": {\n            \"server\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\"\n                ]\n            },\n            \"client\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"client auth\"\n                ]\n            },\n            \"peer\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\",\n                    \"client auth\"\n                ]\n            }\n        }\n    }\n}\nEOF\n# 配置证书请求\n[root@tiaoban etcd]# cat > ca-csr.json <<EOF\n{\n  \"CN\": \"Etcd\",\n  \"key\": {\n    \"algo\": \"rsa\",\n    \"size\": 2048\n  },\n  \"names\": [\n    {\n      \"C\": \"CN\",\n      \"ST\": \"BeiJing\",\n      \"L\": \"BeiJing\",\n      \"O\": \"Etcd\",\n      \"OU\": \"CA\"\n    }\n  ]\n}\nEOF\n# 生成CA证书\n[root@tiaoban etcd]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -\n[root@tiaoban etcd]# ls\nca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">生成的文件中有下面三个后面会用到:</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">ca-key.pem: CA 证书密钥</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">ca.pem: CA 证书</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">ca-config.json: 证书签发配置，用 CA 证书来签发其它证书时需要用</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">csr 文件字段解释:</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">CN: Common Name，apiserver 从证书中提取该字段作为请求的用户名 (User Name)</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Organization，apiserver 从证书中提取该字段作为请求用户所属的组 (Group)</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于这里是 CA 证书，是签发其它证书的根证书，这个证书密钥不会分发出去作为 client 证书，所有组件使用的 client 证书都是由 CA 证书签发而来，所以 CA 证书的 CN 和 O 的名称并不重要，后续其它签发出来的证书的 CN 和 O 的名称才是有用的</font>\n\n<h2 id=\"6f7fc89f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成服务器端证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意hosts字段需要加上etcd全部节点的IP/主机名信息及127.0.0.1</font>\n\n```plain\n# 配置证书请求\n[root@tiaoban etcd]# cat > server-csr.json <<EOF\n{\n    \"CN\": \"server\",\n    \"hosts\": [\n        \"127.0.0.1\",\n        \"192.168.10.100\",\n        \"192.168.10.11\",\n        \"192.168.10.12\"\n    ],\n    \"key\": {\n        \"algo\": \"ecdsa\",\n        \"size\": 256\n    },\n    \"names\": [\n        {\n            \"C\": \"CN\",\n            \"L\": \"BeiJing\",\n            \"ST\": \"BeiJing\"\n        }\n    ]\n}\nEOF\n# 创建服务器端证书和私钥\n[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server-csr.json | cfssljson -bare server\n# 生成以下文件\n[root@tiaoban etcd]# ls server*\nserver.csr  server-csr.json  server-key.pem  server.pem\n```\n\n<h2 id=\"9758d425\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成客户端证书</font></h2>\n```plain\n# 配置证书请求\n[root@tiaoban etcd]# cat > client-csr.json <<EOF\n{\n    \"CN\": \"client\",\n    \"hosts\": [\n        \"\"\n    ],\n    \"key\": {\n        \"algo\": \"ecdsa\",\n        \"size\": 256\n    },\n    \"names\": [\n        {\n            \"C\": \"CN\",\n            \"L\": \"BeiJing\",\n            \"ST\": \"BeiJing\"\n        }\n    ]\n}\nEOF\n# 创建客户端证书和私钥\n[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client-csr.json | cfssljson -bare client\n# 生成以下文件\n[root@tiaoban etcd]# ls client*\nclient.csr  client-csr.json  client-key.pem  client.pem\n```\n\n<h2 id=\"07dcf88f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成对等证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">peer证书可以统一，也可以分别生成，如果需要统一，则需要在hosts字段加上所有节点的IP/主机名信息，如果分开生成，则hosts字段只需要填写对应节点的IP/主机名信息即可</font>\n\n```plain\n# 配置证书请求\n[root@tiaoban etcd]# cat > peer-csr.json <<EOF\n{\n    \"CN\": \"peer\",\n    \"hosts\": [\n        \"192.168.10.100\",\n        \"192.168.10.11\",\n        \"192.168.10.12\"\n    ],\n    \"key\": {\n        \"algo\": \"ecdsa\",\n        \"size\": 256\n    },\n    \"names\": [\n        {\n            \"C\": \"CN\",\n            \"L\": \"BeiJing\",\n            \"ST\": \"BeiJing\"\n        }\n    ]\n}\nEOF\n# 创建对等证书和私钥\n[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer peer-csr.json | cfssljson -bare peer\n# 生成以下文件\n[root@tiaoban etcd]# ls peer*\npeer.csr  peer-csr.json  peer-key.pem  peer.pem\n```\n\n<h2 id=\"b8513fa5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝密钥到所有节点并更新系统证书库</font></h2>\n```plain\n[root@tiaoban etcd]# mkdir -p /etc/etcd/pki\n[root@tiaoban etcd]# cp ca.pem server.pem server-key.pem peer.pem peer-key.pem /etc/etcd/pki/\n[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work1:/etc/etcd/pki/  \n[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work2:/etc/etcd/pki/\n[root@tiaoban etcd]# yum install ca-certificates -y  \n[root@tiaoban etcd]# update-ca-trust\n```\n\n<h2 id=\"f0af8621\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改etcd配置并重启etcd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要是将原本的http链接全部改为https，并指定证书密钥地址</font>\n\n```plain\n[root@tiaoban etcd]# cat /etc/etcd/etcd.conf\n# 节点名称\nname: \"etcd1\"\n# 数据存储目录\ndata-dir: \"/data/etcd\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"https://192.168.10.100:2379\"\n# 监听客户端请求的地址列表\nlisten-client-urls: \"https://192.168.10.100:2379,https://127.0.0.1:2379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"https://192.168.10.100:2380\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"https://192.168.10.100:2380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=https://192.168.10.100:2380,etcd2=https://192.168.10.11:2380,etcd3=https://192.168.10.12:2380\"\n# etcd集群的初始集群令牌\ninitial-cluster-token: 'etcd-cluster'\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'new'\n# 日志配置\nlogger: zap\n\n# 客户端加密\nclient-transport-security:\n  cert-file: \"/etc/etcd/pki/server.pem\"\n  key-file: \"/etc/etcd/pki/server-key.pem\"\n  client-cert-auth: True\n  trusted-ca-file: \"/etc/etcd/pki/ca.pem\"\n\n# 节点加密\npeer-transport-security:\n  cert-file: \"/etc/etcd/pki/peer.pem\"\n  key-file: \"/etc/etcd/pki/peer-key.pem\"\n  client-cert-auth: True\n  trusted-ca-file: \"/etc/etcd/pki/ca.pem\"\n```\n\n<h2 id=\"046e223e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n```plain\n[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem endpoint status --cluster -w table\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|  https://192.168.10.11:2379 | 6571fb7574e87dba |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |\n|  https://192.168.10.12:2379 | 9b449b0ff1d4c375 |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |\n| https://192.168.10.100:2379 | f330bec74ce6cc42 |  3.4.23 |   20 kB |      true |      false |       310 |         46 |                 46 |        |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem put /foo/bar \"hello world\"\nOK    \n[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem get /foo/bar\n/foo/bar\nhello world\n```\n\n<h1 id=\"df8bef0b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署etcd集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用helm可以快速部署一个etcd集群，集成了配置基于角色的访问控制和 TLS 加密，并且可以按需开启定时备份和监控指标采集。</font>\n\n<h2 id=\"106d5e32\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加仓库，获取安装包</font></h2>\n```plain\n[root@k8s-master k8s-test]# cd etcd/\n[root@k8s-master etcd]# helm repo add my-repo https://charts.bitnami.com/bitnami\n\"my-repo\" has been added to your repositories\n[root@k8s-master etcd]# helm pull my-repo/etcd\n[root@k8s-master etcd]# ls\netcd-8.8.0.tgz\n[root@k8s-master etcd]# tar -zxf etcd-8.8.0.tgz\n[root@k8s-master etcd]# ls\netcd  etcd-8.8.0.tgz\n[root@k8s-master etcd]# cd etcd/\n[root@k8s-master etcd]# ls\nChart.lock  charts  Chart.yaml  README.md  templates  values.yaml\n```\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n```plain\n[root@k8s-master etcd]# vim values.yaml\n# 自定义root密码\n 96 auth:\n 97   ## Role-based access control parameters\n 98   ## ref: https://etcd.io/docs/current/op-guide/authentication/\n 99   ##\n100   rbac:\n101     ## @param auth.rbac.create Switch to enable RBAC authentication\n102     ##\n103     create: true\n104     ## @param auth.rbac.allowNoneAuthentication Allow to use etcd without configuring RBAC authentication\n105     ##\n106     allowNoneAuthentication: true\n107     ## @param auth.rbac.rootPassword Root user password. The root user is always `root`\n108     ##\n109     rootPassword: \"123456\" # 指定root密码\n\n# 自定义存储方式\n575 persistence:\n576   ## @param persistence.enabled If true, use a Persistent Volume Claim. If false, use emptyDir.\n577   ##\n578   enabled: true # 如果没有sc，此处改为false\n579   ## @param persistence.storageClass Persistent Volume Storage Class\n580   ## If defined, storageClassName: <storageClass>\n581   ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n582   ## If undefined (the default) or set to null, no storageClassName spec is\n583   ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n584   ##   GKE, AWS & OpenStack)\n585   ##\n586   storageClass: \"nfs-client\" # 填写sc名称\n\n# 修改副本数，建议奇数3个起步\n257 ## @param replicaCount Number of etcd replicas to deploy\n258 ##\n259 replicaCount: 3\n```\n\n<h2 id=\"367c6336\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装etcd服务</font></h2>\n```plain\n[root@k8s-master etcd]# kubectl create ns etcd\nnamespace/etcd created\n[root@k8s-master etcd]# helm install etcd -n etcd ../etcd\nNAME: etcd\nLAST DEPLOYED: Fri Mar 17 20:43:31 2023\nNAMESPACE: etcd\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCHART NAME: etcd\nCHART VERSION: 8.8.0\nAPP VERSION: 3.5.7\n\n** Please be patient while the chart is being deployed **\n\netcd can be accessed via port 2379 on the following DNS name from within your cluster:\n\netcd.etcd.svc.cluster.local\n\nTo create a pod that you can use as a etcd client run the following command:\n\nkubectl run etcd-client --restart='Never' --image docker.io/bitnami/etcd:3.5.7-debian-11-r14 --env ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=\"{.data.etcd-root-password}\" | base64 -d) --env ETCDCTL_ENDPOINTS=\"etcd.etcd.svc.cluster.local:2379\" --namespace etcd --command -- sleep infinity\n\nThen, you can set/get a key using the commands below:\n\nkubectl exec --namespace etcd -it etcd-client -- bash\netcdctl --user root:$ROOT_PASSWORD put /message Hello\netcdctl --user root:$ROOT_PASSWORD get /message\n\nTo connect to your etcd server from outside the cluster execute the following commands:\n\nkubectl port-forward --namespace etcd svc/etcd 2379:2379 &\necho \"etcd URL: http://127.0.0.1:2379\"\n\n* As rbac is enabled you should add the flag `--user root:$ETCD_ROOT_PASSWORD` to the etcdctl commands. Use the command below to export the password:\n\nexport ETCD_ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=\"{.data.etcd-root-password}\" | base64 -d)\n```\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n```plain\n[root@k8s-master etcd]# kubectl get pod -n etcd -o wide\nNAME     READY   STATUS    RESTARTS        AGE     IP             NODE        NOMINATED NODE   READINESS GATES\netcd-0   1/1     Running   0               1m13s   10.244.1.154   k8s-work1   <none>           <none>\netcd-1   1/1     Running   0               1m13s   10.244.2.50    k8s-work2   <none>           <none>\netcd-2   1/1     Running   0               1m13s   10.244.1.155   k8s-work1   <none>           <none>\n[root@k8s-master etcd]# kubectl get svc -n etcd \nNAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\netcd            ClusterIP   10.102.32.213   <none>        2379/TCP,2380/TCP   9m48s\netcd-headless   ClusterIP   None            <none>        2379/TCP,2380/TCP   9m48s\n```\n\n<h2 id=\"e6efac8c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问测试</font></h2>\n","slug":"2.ETCD——安装部署","published":1,"updated":"2025-03-30T13:04:09.937Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjll000etsv1dxnle6w7","content":"<h1 id=\"331764a2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署(单机)</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果在测试开发环境，想要测试和使用etcd服务，只需要部署一个单点的 etcd 服务即可。</font></p>\n<h2 id=\"2ef72e59\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装软件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载软件包</span><br><span class=\"line\">[root@linux9 ~]# wget https://github.com/etcd-io/etcd/releases/download/v3.4.23/etcd-v3.4.23-linux-amd64.tar.gz</span><br><span class=\"line\">[root@linux9 ~]# ls</span><br><span class=\"line\">etcd-v3.4.23-linux-amd64.tar.gz</span><br><span class=\"line\"></span><br><span class=\"line\"># 解压到指定目录</span><br><span class=\"line\">[root@linux9 ~]# tar -zxf etcd-v3.4.23-linux-amd64.tar.gz -C /usr/local</span><br><span class=\"line\">[root@linux9 ~]# cd /usr/local/etc</span><br><span class=\"line\">etc/                      etcd-v3.4.23-linux-amd64/ </span><br><span class=\"line\">[root@linux9 ~]# cd /usr/local/etcd-v3.4.23-linux-amd64/</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# ls</span><br><span class=\"line\">Documentation  README-etcdctl.md  README.md  READMEv2-etcdctl.md  etcd  etcdctl</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加环境变量</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# vim /etc/profile</span><br><span class=\"line\">export PATH=&quot;$PATH:/usr/local/etcd-v3.4.23-linux-amd64&quot;</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# source /etc/profile</span><br><span class=\"line\"></span><br><span class=\"line\"># 验证</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# etcdctl version</span><br><span class=\"line\">etcdctl version: 3.4.23</span><br><span class=\"line\">API version: 3.4</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# etcd --version</span><br><span class=\"line\">etcd Version: 3.4.23</span><br><span class=\"line\">Git SHA: c8b7831</span><br><span class=\"line\">Go Version: go1.17.13</span><br><span class=\"line\">Go OS/Arch: linux/amd64</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">添加systemd服务配置</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建数据目录与配置文件目录</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /etc/etcd</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /data/etcd</span><br><span class=\"line\"></span><br><span class=\"line\"># systemd 服务配置文件</span><br><span class=\"line\">[root@linux9 ~]# cat /usr/lib/systemd/system/etcd.service</span><br><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=Etcd Server</span><br><span class=\"line\">After=network.target</span><br><span class=\"line\">After=network-online.target</span><br><span class=\"line\">Wants=network-online.target</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Type=notify</span><br><span class=\"line\">EnvironmentFile=/etc/etcd/etcd.conf</span><br><span class=\"line\">ExecStart=/usr/local/etcd-v3.4.23-linux-amd64/etcd --config-file=/etc/etcd/etcd.conf</span><br><span class=\"line\">Restart=on-failure</span><br><span class=\"line\">LimitNOFILE=65536</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建etcd配置文件</span><br><span class=\"line\">[root@linux9 ~]# cat /etc/etcd/etcd.conf</span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd-1&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data/etcd&#x27;</span><br><span class=\"line\"># 对外提供服务的地址，客户端会连接到这里和 etcd 交互</span><br><span class=\"line\">listen-client-urls: &#x27;http://192.168.10.128:2379,http://127.0.0.1:2379&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动etcd服务并添加开机自启动</span><br><span class=\"line\">[root@linux9 ~]# systemctl daemon-reload</span><br><span class=\"line\">[root@linux9 ~]# systemctl start etcd</span><br><span class=\"line\">[root@linux9 ~]# systemctl enable etcd</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">除了可以使用配置文件指定配置外，也可以直接通过命令行参数指定配置，常用的命令行参数如下(推荐使用配置文件)，命令行参数参考文档：</font><a href=\"https://etcd.io/docs/v3.5/op-guide/configuration/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/configuration/</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，配置文件参考文档：</font><a href=\"https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample</font></a></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">说明</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–name</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd节点名字如果在集群环境中，name必须是唯一的，建议用主机名称或者机器ID。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–data-dir</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储目录</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd启动的时候，通过这个配置找到其他ectd节点的地址列表，格式：‘节点名字1&#x3D;http:&#x2F;&#x2F;节点ip1:2380,节点名字1&#x3D;http:&#x2F;&#x2F;节点ip1:2380,…’</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster-state</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化的时候，集群的状态 “new” 或者 “existing”两种状态，new代表新建的集群，existing表示加入已经存在的集群。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–advertise-client-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">如果–listen-client-urls配置了，多个监听客户端请求的地址，这个参数可以给出，建议客户端使用什么地址访问etcd。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务端之间通讯使用的地址列表。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">监听客户端请求的地址列表，格式：‘<a href=\"http://localhost:2379’\">http://localhost:2379’</a>, 多个用逗号分隔。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务端节点之间通讯的监听地址，格式：‘<a href=\"http://localhost:2380’\">http://localhost:2380’</a></font></td>\n</tr>\n</tbody></table>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看集群状态</span><br><span class=\"line\">[root@linux9 ~]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.128:2379 | 9a20d64f814efc90 |  3.4.23 |   20 kB |      true |      false |         2 |          4 |                  4 |        |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\"># 设置key value</span><br><span class=\"line\">[root@linux9 ~]# etcdctl put greeting &quot;Hello, etcd&quot;</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 获取value</span><br><span class=\"line\">[root@linux9 ~]# etcdctl get greeting</span><br><span class=\"line\">greeting</span><br><span class=\"line\">Hello, etcd</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"84e66d38\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker容器部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档参考地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/container/</font>](https://etcd.io/docs/v3.5/op-guide/container/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，官方docker示例使用命令行参数启动，并不推荐。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建数据目录与配置文件目录</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /etc/etcd</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /data/etcd</span><br><span class=\"line\"></span><br><span class=\"line\"># 修改数据目录权限，否则无法写入数据</span><br><span class=\"line\">[root@linux9 ~]# chown -R 1001:1001 /data/etcd/</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建etcd配置文件</span><br><span class=\"line\">[root@linux9 ~]# cat /etc/etcd/etcd.conf</span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd-1&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data&#x27;</span><br><span class=\"line\"># 对外提供服务的地址，客户端会连接到这里和 etcd 交互</span><br><span class=\"line\">listen-client-urls: &#x27;http://0.0.0.0:2379&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动etcd容器</span><br><span class=\"line\">[root@linux9 ~]# docker run -d --name etcd -p 2379:2379 -v /data/etcd:/data -v /etc/etcd:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf</span><br><span class=\"line\"></span><br><span class=\"line\"># 访问验证</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcd --version&quot;</span><br><span class=\"line\">etcd Version: 3.5.6</span><br><span class=\"line\">Git SHA: cecbe35ce</span><br><span class=\"line\">Go Version: go1.16.15</span><br><span class=\"line\">Go OS/Arch: linux/amd64</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl version&quot;</span><br><span class=\"line\">etcdctl version: 3.5.6</span><br><span class=\"line\">API version: 3.5</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl endpoint status --cluster -w table&quot;</span><br><span class=\"line\">+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|        ENDPOINT        |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://172.17.0.2:2379 | 8e9e05c52164694d |   3.5.6 |   20 kB |      true |      false |         6 |         13 |                 13 |        |</span><br><span class=\"line\">+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl put foo bar&quot;</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl get foo&quot;</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"8d85811c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web管理工具etcdkeeper部署</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@linux9 ~]# docker run -d -p 8080:8080 --name=etcdkeeper evildecay/etcdkeeper:latest</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">1</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738849970258-d25ebf11-2527-4be4-8072-b63c3351cf98.jpeg\"></p>\n<h1 id=\"39e1af29\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署etcd集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在生产环境或对高可用有要求的环境下，需要使用 etcd 的高可用部署方式进行部署，etcd 的 raft 协议保障各个节点数据的一致性。至少使用三台以上奇数节点，才能达到最好的集群容错。</font></p>\n<h2 id=\"2810ee4c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">系统</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">IP地址</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">部署组件</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd1</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.11</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd2</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.12</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd3</font> |\n\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们以3个节点的高可用静态方式部署 etcd，3个节点的IP地址分别是192.168.10.100、192.168.10.11和192.168.10.12。每个节点etcd配置文件主要的差异就是当前节点的 IP 地址和命名。部署启动方法与单节点部署启动方式完全一致，只需要更改配置文件内容即可。</font></p>\n<h2 id=\"1bbbb204\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls用于监听客户端消息,必须设置为真实ip地址，如果机器为云主机，可以设置为云主机的私有ip地址或0.0.0.0(代表监听所有地址),不能设置为公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls用于监听其他member发送过来的消息，跟listen-client-urls一样，必须设置为真实ip地址,如果机器为云主机,不能设置为公网ip  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls用于监听其他member同步信号，该地址其他member必须能直接访问，所以如果是云主机该地址必须设置为云主机的公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster群集列表，该列表中的值必须跟各个member的initial-advertise-peer-urls值一样</font>\n\n<h2 id=\"848be749\"><font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban节点配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd1&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.100:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.100:2379,http://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.100:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.100:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6dbce8aa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1节点配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd2&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.11:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.11:2379,http://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.11:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.11:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"807b27a0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2节点配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd3&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.12:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.12:2379,http://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|         ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |      true |      false |         3 |          9 |                  9 |        |</span><br><span class=\"line\">| http://192.168.10.10:2379 | 8c632555af4d958d |  3.4.23 |   16 kB |     false |      false |         3 |          9 |                  9 |        |</span><br><span class=\"line\">| http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         3 |          9 |                  9 |        |</span><br><span class=\"line\">+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@k8s-master etcd]# etcdctl put foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@k8s-master etcd]# etcdctl get foo</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"934b36d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署TLS加密集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 支持通过 TLS 协议的加密通讯，在实际企业生产环境中，出于安全规范要求，建议开启TLS加密。TLS 通道可以用于加密内部的集群通讯，也可以用于加密客户端请求。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 的 TLS 有两对，一对是 etcd 和 client 端的 TLS 配置。一对是 etcd 之间的 peer 的 TLS 配置。有很多方式可以创建CA证书和私钥，其中比较流行的有两种</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">openssl</font></li>\n<li><a href=\"https://pkg.cfssl.org/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">cfssl</font></a></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档推荐使用cfssl生成证书</font></p>\n<h2 id=\"2d216623\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装cfssl</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/cloudflare/cfssl/releases</font>](https://github.com/cloudflare/cfssl/releases)\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssl_1.6.3_linux_amd64</span><br><span class=\"line\">[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssljson_1.6.3_linux_amd64</span><br><span class=\"line\">[root@tiaoban ~]# mv cfssl_1.6.3_linux_amd64 /usr/bin/cfssl</span><br><span class=\"line\">[root@tiaoban ~]# mv cfssljson_1.6.3_linux_amd64 /usr/bin/cfssljson</span><br><span class=\"line\">[root@tiaoban ~]# chmod +x /usr/bin/&#123;cfssl,cfssljson&#125;</span><br><span class=\"line\">[root@tiaoban ~]# cfssl version</span><br><span class=\"line\">Version: 1.6.3</span><br><span class=\"line\">Runtime: go1.18</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f8a74222\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建默认配置文件</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cfssl print-defaults config &gt; ca-config.json</span><br><span class=\"line\">[root@tiaoban ~]# cfssl print-defaults csr &gt; ca-csr.json</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"929e8577\"><font style=\"background-color:rgba(255, 255, 255, 0);\">证书类型</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端证书用于服务器验证客户端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器端证书用于客户端验证服务器端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对等证书由etcd集群成员使用，同时使用客户端认证和服务器端认证</font>\n\n<h2 id=\"b81c6516\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建 CA 证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于各个组件都需要配置证书，并且依赖 CA 证书来签发证书，所以我们首先要生成好 CA 证书以及后续的签发配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改ca-config配置</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; ca-config.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;signing&quot;: &#123;</span><br><span class=\"line\">        &quot;default&quot;: &#123;</span><br><span class=\"line\">            &quot;expiry&quot;: &quot;43800h&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;profiles&quot;: &#123;</span><br><span class=\"line\">            &quot;server&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;client&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;peer&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; ca-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;CN&quot;: &quot;Etcd&quot;,</span><br><span class=\"line\">  &quot;key&quot;: &#123;</span><br><span class=\"line\">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class=\"line\">    &quot;size&quot;: 2048</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;names&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">      &quot;O&quot;: &quot;Etcd&quot;,</span><br><span class=\"line\">      &quot;OU&quot;: &quot;CA&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 生成CA证书</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br><span class=\"line\">[root@tiaoban etcd]# ls</span><br><span class=\"line\">ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">生成的文件中有下面三个后面会用到:</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">ca-key.pem: CA 证书密钥</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">ca.pem: CA 证书</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">ca-config.json: 证书签发配置，用 CA 证书来签发其它证书时需要用</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">csr 文件字段解释:</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">CN: Common Name，apiserver 从证书中提取该字段作为请求的用户名 (User Name)</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Organization，apiserver 从证书中提取该字段作为请求用户所属的组 (Group)</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于这里是 CA 证书，是签发其它证书的根证书，这个证书密钥不会分发出去作为 client 证书，所有组件使用的 client 证书都是由 CA 证书签发而来，所以 CA 证书的 CN 和 O 的名称并不重要，后续其它签发出来的证书的 CN 和 O 的名称才是有用的</font></p>\n<h2 id=\"6f7fc89f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成服务器端证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意hosts字段需要加上etcd全部节点的IP/主机名信息及127.0.0.1</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; server-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;server&quot;,</span><br><span class=\"line\">    &quot;hosts&quot;: [</span><br><span class=\"line\">        &quot;127.0.0.1&quot;,</span><br><span class=\"line\">        &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;192.168.10.11&quot;,</span><br><span class=\"line\">        &quot;192.168.10.12&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;ecdsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 256</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 创建服务器端证书和私钥</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server-csr.json | cfssljson -bare server</span><br><span class=\"line\"># 生成以下文件</span><br><span class=\"line\">[root@tiaoban etcd]# ls server*</span><br><span class=\"line\">server.csr  server-csr.json  server-key.pem  server.pem</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"9758d425\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成客户端证书</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; client-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;client&quot;,</span><br><span class=\"line\">    &quot;hosts&quot;: [</span><br><span class=\"line\">        &quot;&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;ecdsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 256</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 创建客户端证书和私钥</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client-csr.json | cfssljson -bare client</span><br><span class=\"line\"># 生成以下文件</span><br><span class=\"line\">[root@tiaoban etcd]# ls client*</span><br><span class=\"line\">client.csr  client-csr.json  client-key.pem  client.pem</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"07dcf88f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成对等证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">peer证书可以统一，也可以分别生成，如果需要统一，则需要在hosts字段加上所有节点的IP/主机名信息，如果分开生成，则hosts字段只需要填写对应节点的IP/主机名信息即可</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; peer-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;peer&quot;,</span><br><span class=\"line\">    &quot;hosts&quot;: [</span><br><span class=\"line\">        &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;192.168.10.11&quot;,</span><br><span class=\"line\">        &quot;192.168.10.12&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;ecdsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 256</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 创建对等证书和私钥</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer peer-csr.json | cfssljson -bare peer</span><br><span class=\"line\"># 生成以下文件</span><br><span class=\"line\">[root@tiaoban etcd]# ls peer*</span><br><span class=\"line\">peer.csr  peer-csr.json  peer-key.pem  peer.pem</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"b8513fa5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝密钥到所有节点并更新系统证书库</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# mkdir -p /etc/etcd/pki</span><br><span class=\"line\">[root@tiaoban etcd]# cp ca.pem server.pem server-key.pem peer.pem peer-key.pem /etc/etcd/pki/</span><br><span class=\"line\">[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work1:/etc/etcd/pki/  </span><br><span class=\"line\">[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work2:/etc/etcd/pki/</span><br><span class=\"line\">[root@tiaoban etcd]# yum install ca-certificates -y  </span><br><span class=\"line\">[root@tiaoban etcd]# update-ca-trust</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f0af8621\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改etcd配置并重启etcd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要是将原本的http链接全部改为https，并指定证书密钥地址</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# cat /etc/etcd/etcd.conf</span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd1&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;https://192.168.10.100:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;https://192.168.10.100:2379,https://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;https://192.168.10.100:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;https://192.168.10.100:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=https://192.168.10.100:2380,etcd2=https://192.168.10.11:2380,etcd3=https://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br><span class=\"line\"># 日志配置</span><br><span class=\"line\">logger: zap</span><br><span class=\"line\"></span><br><span class=\"line\"># 客户端加密</span><br><span class=\"line\">client-transport-security:</span><br><span class=\"line\">  cert-file: &quot;/etc/etcd/pki/server.pem&quot;</span><br><span class=\"line\">  key-file: &quot;/etc/etcd/pki/server-key.pem&quot;</span><br><span class=\"line\">  client-cert-auth: True</span><br><span class=\"line\">  trusted-ca-file: &quot;/etc/etcd/pki/ca.pem&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># 节点加密</span><br><span class=\"line\">peer-transport-security:</span><br><span class=\"line\">  cert-file: &quot;/etc/etcd/pki/peer.pem&quot;</span><br><span class=\"line\">  key-file: &quot;/etc/etcd/pki/peer-key.pem&quot;</span><br><span class=\"line\">  client-cert-auth: True</span><br><span class=\"line\">  trusted-ca-file: &quot;/etc/etcd/pki/ca.pem&quot;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem endpoint status --cluster -w table</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|  https://192.168.10.11:2379 | 6571fb7574e87dba |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |</span><br><span class=\"line\">|  https://192.168.10.12:2379 | 9b449b0ff1d4c375 |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |</span><br><span class=\"line\">| https://192.168.10.100:2379 | f330bec74ce6cc42 |  3.4.23 |   20 kB |      true |      false |       310 |         46 |                 46 |        |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem put /foo/bar &quot;hello world&quot;</span><br><span class=\"line\">OK    </span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem get /foo/bar</span><br><span class=\"line\">/foo/bar</span><br><span class=\"line\">hello world</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"df8bef0b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署etcd集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用helm可以快速部署一个etcd集群，集成了配置基于角色的访问控制和 TLS 加密，并且可以按需开启定时备份和监控指标采集。</font></p>\n<h2 id=\"106d5e32\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加仓库，获取安装包</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-test]# cd etcd/</span><br><span class=\"line\">[root@k8s-master etcd]# helm repo add my-repo https://charts.bitnami.com/bitnami</span><br><span class=\"line\">&quot;my-repo&quot; has been added to your repositories</span><br><span class=\"line\">[root@k8s-master etcd]# helm pull my-repo/etcd</span><br><span class=\"line\">[root@k8s-master etcd]# ls</span><br><span class=\"line\">etcd-8.8.0.tgz</span><br><span class=\"line\">[root@k8s-master etcd]# tar -zxf etcd-8.8.0.tgz</span><br><span class=\"line\">[root@k8s-master etcd]# ls</span><br><span class=\"line\">etcd  etcd-8.8.0.tgz</span><br><span class=\"line\">[root@k8s-master etcd]# cd etcd/</span><br><span class=\"line\">[root@k8s-master etcd]# ls</span><br><span class=\"line\">Chart.lock  charts  Chart.yaml  README.md  templates  values.yaml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# vim values.yaml</span><br><span class=\"line\"># 自定义root密码</span><br><span class=\"line\"> 96 auth:</span><br><span class=\"line\"> 97   ## Role-based access control parameters</span><br><span class=\"line\"> 98   ## ref: https://etcd.io/docs/current/op-guide/authentication/</span><br><span class=\"line\"> 99   ##</span><br><span class=\"line\">100   rbac:</span><br><span class=\"line\">101     ## @param auth.rbac.create Switch to enable RBAC authentication</span><br><span class=\"line\">102     ##</span><br><span class=\"line\">103     create: true</span><br><span class=\"line\">104     ## @param auth.rbac.allowNoneAuthentication Allow to use etcd without configuring RBAC authentication</span><br><span class=\"line\">105     ##</span><br><span class=\"line\">106     allowNoneAuthentication: true</span><br><span class=\"line\">107     ## @param auth.rbac.rootPassword Root user password. The root user is always `root`</span><br><span class=\"line\">108     ##</span><br><span class=\"line\">109     rootPassword: &quot;123456&quot; # 指定root密码</span><br><span class=\"line\"></span><br><span class=\"line\"># 自定义存储方式</span><br><span class=\"line\">575 persistence:</span><br><span class=\"line\">576   ## @param persistence.enabled If true, use a Persistent Volume Claim. If false, use emptyDir.</span><br><span class=\"line\">577   ##</span><br><span class=\"line\">578   enabled: true # 如果没有sc，此处改为false</span><br><span class=\"line\">579   ## @param persistence.storageClass Persistent Volume Storage Class</span><br><span class=\"line\">580   ## If defined, storageClassName: &lt;storageClass&gt;</span><br><span class=\"line\">581   ## If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</span><br><span class=\"line\">582   ## If undefined (the default) or set to null, no storageClassName spec is</span><br><span class=\"line\">583   ##   set, choosing the default provisioner.  (gp2 on AWS, standard on</span><br><span class=\"line\">584   ##   GKE, AWS &amp; OpenStack)</span><br><span class=\"line\">585   ##</span><br><span class=\"line\">586   storageClass: &quot;nfs-client&quot; # 填写sc名称</span><br><span class=\"line\"></span><br><span class=\"line\"># 修改副本数，建议奇数3个起步</span><br><span class=\"line\">257 ## @param replicaCount Number of etcd replicas to deploy</span><br><span class=\"line\">258 ##</span><br><span class=\"line\">259 replicaCount: 3</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"367c6336\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装etcd服务</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# kubectl create ns etcd</span><br><span class=\"line\">namespace/etcd created</span><br><span class=\"line\">[root@k8s-master etcd]# helm install etcd -n etcd ../etcd</span><br><span class=\"line\">NAME: etcd</span><br><span class=\"line\">LAST DEPLOYED: Fri Mar 17 20:43:31 2023</span><br><span class=\"line\">NAMESPACE: etcd</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">CHART NAME: etcd</span><br><span class=\"line\">CHART VERSION: 8.8.0</span><br><span class=\"line\">APP VERSION: 3.5.7</span><br><span class=\"line\"></span><br><span class=\"line\">** Please be patient while the chart is being deployed **</span><br><span class=\"line\"></span><br><span class=\"line\">etcd can be accessed via port 2379 on the following DNS name from within your cluster:</span><br><span class=\"line\"></span><br><span class=\"line\">etcd.etcd.svc.cluster.local</span><br><span class=\"line\"></span><br><span class=\"line\">To create a pod that you can use as a etcd client run the following command:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl run etcd-client --restart=&#x27;Never&#x27; --image docker.io/bitnami/etcd:3.5.7-debian-11-r14 --env ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=&quot;&#123;.data.etcd-root-password&#125;&quot; | base64 -d) --env ETCDCTL_ENDPOINTS=&quot;etcd.etcd.svc.cluster.local:2379&quot; --namespace etcd --command -- sleep infinity</span><br><span class=\"line\"></span><br><span class=\"line\">Then, you can set/get a key using the commands below:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl exec --namespace etcd -it etcd-client -- bash</span><br><span class=\"line\">etcdctl --user root:$ROOT_PASSWORD put /message Hello</span><br><span class=\"line\">etcdctl --user root:$ROOT_PASSWORD get /message</span><br><span class=\"line\"></span><br><span class=\"line\">To connect to your etcd server from outside the cluster execute the following commands:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl port-forward --namespace etcd svc/etcd 2379:2379 &amp;</span><br><span class=\"line\">echo &quot;etcd URL: http://127.0.0.1:2379&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">* As rbac is enabled you should add the flag `--user root:$ETCD_ROOT_PASSWORD` to the etcdctl commands. Use the command below to export the password:</span><br><span class=\"line\"></span><br><span class=\"line\">export ETCD_ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=&quot;&#123;.data.etcd-root-password&#125;&quot; | base64 -d)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# kubectl get pod -n etcd -o wide</span><br><span class=\"line\">NAME     READY   STATUS    RESTARTS        AGE     IP             NODE        NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">etcd-0   1/1     Running   0               1m13s   10.244.1.154   k8s-work1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-1   1/1     Running   0               1m13s   10.244.2.50    k8s-work2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-2   1/1     Running   0               1m13s   10.244.1.155   k8s-work1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">[root@k8s-master etcd]# kubectl get svc -n etcd </span><br><span class=\"line\">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">etcd            ClusterIP   10.102.32.213   &lt;none&gt;        2379/TCP,2380/TCP   9m48s</span><br><span class=\"line\">etcd-headless   ClusterIP   None            &lt;none&gt;        2379/TCP,2380/TCP   9m48s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e6efac8c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问测试</font></h2>\n","excerpt":"","more":"<h1 id=\"331764a2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署(单机)</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果在测试开发环境，想要测试和使用etcd服务，只需要部署一个单点的 etcd 服务即可。</font></p>\n<h2 id=\"2ef72e59\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装软件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载软件包</span><br><span class=\"line\">[root@linux9 ~]# wget https://github.com/etcd-io/etcd/releases/download/v3.4.23/etcd-v3.4.23-linux-amd64.tar.gz</span><br><span class=\"line\">[root@linux9 ~]# ls</span><br><span class=\"line\">etcd-v3.4.23-linux-amd64.tar.gz</span><br><span class=\"line\"></span><br><span class=\"line\"># 解压到指定目录</span><br><span class=\"line\">[root@linux9 ~]# tar -zxf etcd-v3.4.23-linux-amd64.tar.gz -C /usr/local</span><br><span class=\"line\">[root@linux9 ~]# cd /usr/local/etc</span><br><span class=\"line\">etc/                      etcd-v3.4.23-linux-amd64/ </span><br><span class=\"line\">[root@linux9 ~]# cd /usr/local/etcd-v3.4.23-linux-amd64/</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# ls</span><br><span class=\"line\">Documentation  README-etcdctl.md  README.md  READMEv2-etcdctl.md  etcd  etcdctl</span><br><span class=\"line\"></span><br><span class=\"line\"># 添加环境变量</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# vim /etc/profile</span><br><span class=\"line\">export PATH=&quot;$PATH:/usr/local/etcd-v3.4.23-linux-amd64&quot;</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# source /etc/profile</span><br><span class=\"line\"></span><br><span class=\"line\"># 验证</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# etcdctl version</span><br><span class=\"line\">etcdctl version: 3.4.23</span><br><span class=\"line\">API version: 3.4</span><br><span class=\"line\">[root@linux9 etcd-v3.4.23-linux-amd64]# etcd --version</span><br><span class=\"line\">etcd Version: 3.4.23</span><br><span class=\"line\">Git SHA: c8b7831</span><br><span class=\"line\">Go Version: go1.17.13</span><br><span class=\"line\">Go OS/Arch: linux/amd64</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">添加systemd服务配置</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建数据目录与配置文件目录</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /etc/etcd</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /data/etcd</span><br><span class=\"line\"></span><br><span class=\"line\"># systemd 服务配置文件</span><br><span class=\"line\">[root@linux9 ~]# cat /usr/lib/systemd/system/etcd.service</span><br><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=Etcd Server</span><br><span class=\"line\">After=network.target</span><br><span class=\"line\">After=network-online.target</span><br><span class=\"line\">Wants=network-online.target</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Type=notify</span><br><span class=\"line\">EnvironmentFile=/etc/etcd/etcd.conf</span><br><span class=\"line\">ExecStart=/usr/local/etcd-v3.4.23-linux-amd64/etcd --config-file=/etc/etcd/etcd.conf</span><br><span class=\"line\">Restart=on-failure</span><br><span class=\"line\">LimitNOFILE=65536</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建etcd配置文件</span><br><span class=\"line\">[root@linux9 ~]# cat /etc/etcd/etcd.conf</span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd-1&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data/etcd&#x27;</span><br><span class=\"line\"># 对外提供服务的地址，客户端会连接到这里和 etcd 交互</span><br><span class=\"line\">listen-client-urls: &#x27;http://192.168.10.128:2379,http://127.0.0.1:2379&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动etcd服务并添加开机自启动</span><br><span class=\"line\">[root@linux9 ~]# systemctl daemon-reload</span><br><span class=\"line\">[root@linux9 ~]# systemctl start etcd</span><br><span class=\"line\">[root@linux9 ~]# systemctl enable etcd</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">除了可以使用配置文件指定配置外，也可以直接通过命令行参数指定配置，常用的命令行参数如下(推荐使用配置文件)，命令行参数参考文档：</font><a href=\"https://etcd.io/docs/v3.5/op-guide/configuration/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/configuration/</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">，配置文件参考文档：</font><a href=\"https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/etcd-io/etcd/blob/main/etcd.conf.yml.sample</font></a></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">说明</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–name</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd节点名字如果在集群环境中，name必须是唯一的，建议用主机名称或者机器ID。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–data-dir</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储目录</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd启动的时候，通过这个配置找到其他ectd节点的地址列表，格式：‘节点名字1&#x3D;http:&#x2F;&#x2F;节点ip1:2380,节点名字1&#x3D;http:&#x2F;&#x2F;节点ip1:2380,…’</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster-state</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化的时候，集群的状态 “new” 或者 “existing”两种状态，new代表新建的集群，existing表示加入已经存在的集群。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–advertise-client-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">如果–listen-client-urls配置了，多个监听客户端请求的地址，这个参数可以给出，建议客户端使用什么地址访问etcd。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务端之间通讯使用的地址列表。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">监听客户端请求的地址列表，格式：‘<a href=\"http://localhost:2379’\">http://localhost:2379’</a>, 多个用逗号分隔。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">服务端节点之间通讯的监听地址，格式：‘<a href=\"http://localhost:2380’\">http://localhost:2380’</a></font></td>\n</tr>\n</tbody></table>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看集群状态</span><br><span class=\"line\">[root@linux9 ~]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.128:2379 | 9a20d64f814efc90 |  3.4.23 |   20 kB |      true |      false |         2 |          4 |                  4 |        |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\"># 设置key value</span><br><span class=\"line\">[root@linux9 ~]# etcdctl put greeting &quot;Hello, etcd&quot;</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 获取value</span><br><span class=\"line\">[root@linux9 ~]# etcdctl get greeting</span><br><span class=\"line\">greeting</span><br><span class=\"line\">Hello, etcd</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"84e66d38\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker容器部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档参考地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://etcd.io/docs/v3.5/op-guide/container/</font>](https://etcd.io/docs/v3.5/op-guide/container/)<font style=\"background-color:rgba(255, 255, 255, 0);\">，官方docker示例使用命令行参数启动，并不推荐。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建数据目录与配置文件目录</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /etc/etcd</span><br><span class=\"line\">[root@linux9 ~]# mkdir -p /data/etcd</span><br><span class=\"line\"></span><br><span class=\"line\"># 修改数据目录权限，否则无法写入数据</span><br><span class=\"line\">[root@linux9 ~]# chown -R 1001:1001 /data/etcd/</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建etcd配置文件</span><br><span class=\"line\">[root@linux9 ~]# cat /etc/etcd/etcd.conf</span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd-1&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data&#x27;</span><br><span class=\"line\"># 对外提供服务的地址，客户端会连接到这里和 etcd 交互</span><br><span class=\"line\">listen-client-urls: &#x27;http://0.0.0.0:2379&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动etcd容器</span><br><span class=\"line\">[root@linux9 ~]# docker run -d --name etcd -p 2379:2379 -v /data/etcd:/data -v /etc/etcd:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf</span><br><span class=\"line\"></span><br><span class=\"line\"># 访问验证</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcd --version&quot;</span><br><span class=\"line\">etcd Version: 3.5.6</span><br><span class=\"line\">Git SHA: cecbe35ce</span><br><span class=\"line\">Go Version: go1.16.15</span><br><span class=\"line\">Go OS/Arch: linux/amd64</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl version&quot;</span><br><span class=\"line\">etcdctl version: 3.5.6</span><br><span class=\"line\">API version: 3.5</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl endpoint status --cluster -w table&quot;</span><br><span class=\"line\">+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|        ENDPOINT        |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://172.17.0.2:2379 | 8e9e05c52164694d |   3.5.6 |   20 kB |      true |      false |         6 |         13 |                 13 |        |</span><br><span class=\"line\">+------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl put foo bar&quot;</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@linux9 etcd]# docker exec etcd sh -c &quot;etcdctl get foo&quot;</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"8d85811c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web管理工具etcdkeeper部署</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@linux9 ~]# docker run -d -p 8080:8080 --name=etcdkeeper evildecay/etcdkeeper:latest</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">1</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738849970258-d25ebf11-2527-4be4-8072-b63c3351cf98.jpeg\"></p>\n<h1 id=\"39e1af29\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制文件部署etcd集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在生产环境或对高可用有要求的环境下，需要使用 etcd 的高可用部署方式进行部署，etcd 的 raft 协议保障各个节点数据的一致性。至少使用三台以上奇数节点，才能达到最好的集群容错。</font></p>\n<h2 id=\"2810ee4c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色规划</font></h2>\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">系统</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">IP地址</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">部署组件</font>** |\n| --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.100</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd1</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.11</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd2</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">CentOS 8.5</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.12</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcd3</font> |\n\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们以3个节点的高可用静态方式部署 etcd，3个节点的IP地址分别是192.168.10.100、192.168.10.11和192.168.10.12。每个节点etcd配置文件主要的差异就是当前节点的 IP 地址和命名。部署启动方法与单节点部署启动方式完全一致，只需要更改配置文件内容即可。</font></p>\n<h2 id=\"1bbbb204\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-client-urls用于监听客户端消息,必须设置为真实ip地址，如果机器为云主机，可以设置为云主机的私有ip地址或0.0.0.0(代表监听所有地址),不能设置为公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–listen-peer-urls用于监听其他member发送过来的消息，跟listen-client-urls一样，必须设置为真实ip地址,如果机器为云主机,不能设置为公网ip  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-advertise-peer-urls用于监听其他member同步信号，该地址其他member必须能直接访问，所以如果是云主机该地址必须设置为云主机的公网ip地址  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">–initial-cluster群集列表，该列表中的值必须跟各个member的initial-advertise-peer-urls值一样</font>\n\n<h2 id=\"848be749\"><font style=\"background-color:rgba(255, 255, 255, 0);\">tiaoban节点配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd1&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.100:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.100:2379,http://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.100:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.100:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6dbce8aa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work1节点配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd2&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.11:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.11:2379,http://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.11:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.11:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"807b27a0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">k8s-work2节点配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd3&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.12:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.12:2379,http://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|         ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |      true |      false |         3 |          9 |                  9 |        |</span><br><span class=\"line\">| http://192.168.10.10:2379 | 8c632555af4d958d |  3.4.23 |   16 kB |     false |      false |         3 |          9 |                  9 |        |</span><br><span class=\"line\">| http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         3 |          9 |                  9 |        |</span><br><span class=\"line\">+---------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@k8s-master etcd]# etcdctl put foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@k8s-master etcd]# etcdctl get foo</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"934b36d4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署TLS加密集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 支持通过 TLS 协议的加密通讯，在实际企业生产环境中，出于安全规范要求，建议开启TLS加密。TLS 通道可以用于加密内部的集群通讯，也可以用于加密客户端请求。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd 的 TLS 有两对，一对是 etcd 和 client 端的 TLS 配置。一对是 etcd 之间的 peer 的 TLS 配置。有很多方式可以创建CA证书和私钥，其中比较流行的有两种</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">openssl</font></li>\n<li><a href=\"https://pkg.cfssl.org/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">cfssl</font></a></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档推荐使用cfssl生成证书</font></p>\n<h2 id=\"2d216623\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载安装cfssl</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/cloudflare/cfssl/releases</font>](https://github.com/cloudflare/cfssl/releases)\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssl_1.6.3_linux_amd64</span><br><span class=\"line\">[root@tiaoban ~]# wget https://github.com/cloudflare/cfssl/releases/download/v1.6.3/cfssljson_1.6.3_linux_amd64</span><br><span class=\"line\">[root@tiaoban ~]# mv cfssl_1.6.3_linux_amd64 /usr/bin/cfssl</span><br><span class=\"line\">[root@tiaoban ~]# mv cfssljson_1.6.3_linux_amd64 /usr/bin/cfssljson</span><br><span class=\"line\">[root@tiaoban ~]# chmod +x /usr/bin/&#123;cfssl,cfssljson&#125;</span><br><span class=\"line\">[root@tiaoban ~]# cfssl version</span><br><span class=\"line\">Version: 1.6.3</span><br><span class=\"line\">Runtime: go1.18</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f8a74222\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建默认配置文件</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cfssl print-defaults config &gt; ca-config.json</span><br><span class=\"line\">[root@tiaoban ~]# cfssl print-defaults csr &gt; ca-csr.json</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"929e8577\"><font style=\"background-color:rgba(255, 255, 255, 0);\">证书类型</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">客户端证书用于服务器验证客户端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务器端证书用于客户端验证服务器端身份</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对等证书由etcd集群成员使用，同时使用客户端认证和服务器端认证</font>\n\n<h2 id=\"b81c6516\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建 CA 证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于各个组件都需要配置证书，并且依赖 CA 证书来签发证书，所以我们首先要生成好 CA 证书以及后续的签发配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 修改ca-config配置</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; ca-config.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;signing&quot;: &#123;</span><br><span class=\"line\">        &quot;default&quot;: &#123;</span><br><span class=\"line\">            &quot;expiry&quot;: &quot;43800h&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;profiles&quot;: &#123;</span><br><span class=\"line\">            &quot;server&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;client&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;peer&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; ca-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;CN&quot;: &quot;Etcd&quot;,</span><br><span class=\"line\">  &quot;key&quot;: &#123;</span><br><span class=\"line\">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class=\"line\">    &quot;size&quot;: 2048</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;names&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">      &quot;O&quot;: &quot;Etcd&quot;,</span><br><span class=\"line\">      &quot;OU&quot;: &quot;CA&quot;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 生成CA证书</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br><span class=\"line\">[root@tiaoban etcd]# ls</span><br><span class=\"line\">ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">生成的文件中有下面三个后面会用到:</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">ca-key.pem: CA 证书密钥</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">ca.pem: CA 证书</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">ca-config.json: 证书签发配置，用 CA 证书来签发其它证书时需要用</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">csr 文件字段解释:</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">CN: Common Name，apiserver 从证书中提取该字段作为请求的用户名 (User Name)</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Organization，apiserver 从证书中提取该字段作为请求用户所属的组 (Group)</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于这里是 CA 证书，是签发其它证书的根证书，这个证书密钥不会分发出去作为 client 证书，所有组件使用的 client 证书都是由 CA 证书签发而来，所以 CA 证书的 CN 和 O 的名称并不重要，后续其它签发出来的证书的 CN 和 O 的名称才是有用的</font></p>\n<h2 id=\"6f7fc89f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成服务器端证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意hosts字段需要加上etcd全部节点的IP/主机名信息及127.0.0.1</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; server-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;server&quot;,</span><br><span class=\"line\">    &quot;hosts&quot;: [</span><br><span class=\"line\">        &quot;127.0.0.1&quot;,</span><br><span class=\"line\">        &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;192.168.10.11&quot;,</span><br><span class=\"line\">        &quot;192.168.10.12&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;ecdsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 256</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 创建服务器端证书和私钥</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server-csr.json | cfssljson -bare server</span><br><span class=\"line\"># 生成以下文件</span><br><span class=\"line\">[root@tiaoban etcd]# ls server*</span><br><span class=\"line\">server.csr  server-csr.json  server-key.pem  server.pem</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"9758d425\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成客户端证书</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; client-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;client&quot;,</span><br><span class=\"line\">    &quot;hosts&quot;: [</span><br><span class=\"line\">        &quot;&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;ecdsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 256</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 创建客户端证书和私钥</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client-csr.json | cfssljson -bare client</span><br><span class=\"line\"># 生成以下文件</span><br><span class=\"line\">[root@tiaoban etcd]# ls client*</span><br><span class=\"line\">client.csr  client-csr.json  client-key.pem  client.pem</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"07dcf88f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成对等证书</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">peer证书可以统一，也可以分别生成，如果需要统一，则需要在hosts字段加上所有节点的IP/主机名信息，如果分开生成，则hosts字段只需要填写对应节点的IP/主机名信息即可</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 配置证书请求</span><br><span class=\"line\">[root@tiaoban etcd]# cat &gt; peer-csr.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;peer&quot;,</span><br><span class=\"line\">    &quot;hosts&quot;: [</span><br><span class=\"line\">        &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;192.168.10.11&quot;,</span><br><span class=\"line\">        &quot;192.168.10.12&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;ecdsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 256</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;BeiJing&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"># 创建对等证书和私钥</span><br><span class=\"line\">[root@tiaoban etcd]# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer peer-csr.json | cfssljson -bare peer</span><br><span class=\"line\"># 生成以下文件</span><br><span class=\"line\">[root@tiaoban etcd]# ls peer*</span><br><span class=\"line\">peer.csr  peer-csr.json  peer-key.pem  peer.pem</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"b8513fa5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝密钥到所有节点并更新系统证书库</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# mkdir -p /etc/etcd/pki</span><br><span class=\"line\">[root@tiaoban etcd]# cp ca.pem server.pem server-key.pem peer.pem peer-key.pem /etc/etcd/pki/</span><br><span class=\"line\">[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work1:/etc/etcd/pki/  </span><br><span class=\"line\">[root@tiaoban etcd]# scp ca.pem server.pem server-key.pem peer.pem peer-key.pem k8s-work2:/etc/etcd/pki/</span><br><span class=\"line\">[root@tiaoban etcd]# yum install ca-certificates -y  </span><br><span class=\"line\">[root@tiaoban etcd]# update-ca-trust</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f0af8621\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改etcd配置并重启etcd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要是将原本的http链接全部改为https，并指定证书密钥地址</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# cat /etc/etcd/etcd.conf</span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &quot;etcd1&quot;</span><br><span class=\"line\"># 数据存储目录</span><br><span class=\"line\">data-dir: &quot;/data/etcd&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;https://192.168.10.100:2379&quot;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;https://192.168.10.100:2379,https://127.0.0.1:2379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;https://192.168.10.100:2380&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;https://192.168.10.100:2380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=https://192.168.10.100:2380,etcd2=https://192.168.10.11:2380,etcd3=https://192.168.10.12:2380&quot;</span><br><span class=\"line\"># etcd集群的初始集群令牌</span><br><span class=\"line\">initial-cluster-token: &#x27;etcd-cluster&#x27;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;new&#x27;</span><br><span class=\"line\"># 日志配置</span><br><span class=\"line\">logger: zap</span><br><span class=\"line\"></span><br><span class=\"line\"># 客户端加密</span><br><span class=\"line\">client-transport-security:</span><br><span class=\"line\">  cert-file: &quot;/etc/etcd/pki/server.pem&quot;</span><br><span class=\"line\">  key-file: &quot;/etc/etcd/pki/server-key.pem&quot;</span><br><span class=\"line\">  client-cert-auth: True</span><br><span class=\"line\">  trusted-ca-file: &quot;/etc/etcd/pki/ca.pem&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># 节点加密</span><br><span class=\"line\">peer-transport-security:</span><br><span class=\"line\">  cert-file: &quot;/etc/etcd/pki/peer.pem&quot;</span><br><span class=\"line\">  key-file: &quot;/etc/etcd/pki/peer-key.pem&quot;</span><br><span class=\"line\">  client-cert-auth: True</span><br><span class=\"line\">  trusted-ca-file: &quot;/etc/etcd/pki/ca.pem&quot;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem endpoint status --cluster -w table</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|  https://192.168.10.11:2379 | 6571fb7574e87dba |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |</span><br><span class=\"line\">|  https://192.168.10.12:2379 | 9b449b0ff1d4c375 |  3.4.23 |   20 kB |     false |      false |       310 |         46 |                 46 |        |</span><br><span class=\"line\">| https://192.168.10.100:2379 | f330bec74ce6cc42 |  3.4.23 |   20 kB |      true |      false |       310 |         46 |                 46 |        |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem put /foo/bar &quot;hello world&quot;</span><br><span class=\"line\">OK    </span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --endpoints=https://192.168.10.100:2379 --cacert=ca.pem --cert=client.pem --key=client-key.pem get /foo/bar</span><br><span class=\"line\">/foo/bar</span><br><span class=\"line\">hello world</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"df8bef0b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署etcd集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用helm可以快速部署一个etcd集群，集成了配置基于角色的访问控制和 TLS 加密，并且可以按需开启定时备份和监控指标采集。</font></p>\n<h2 id=\"106d5e32\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加仓库，获取安装包</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-test]# cd etcd/</span><br><span class=\"line\">[root@k8s-master etcd]# helm repo add my-repo https://charts.bitnami.com/bitnami</span><br><span class=\"line\">&quot;my-repo&quot; has been added to your repositories</span><br><span class=\"line\">[root@k8s-master etcd]# helm pull my-repo/etcd</span><br><span class=\"line\">[root@k8s-master etcd]# ls</span><br><span class=\"line\">etcd-8.8.0.tgz</span><br><span class=\"line\">[root@k8s-master etcd]# tar -zxf etcd-8.8.0.tgz</span><br><span class=\"line\">[root@k8s-master etcd]# ls</span><br><span class=\"line\">etcd  etcd-8.8.0.tgz</span><br><span class=\"line\">[root@k8s-master etcd]# cd etcd/</span><br><span class=\"line\">[root@k8s-master etcd]# ls</span><br><span class=\"line\">Chart.lock  charts  Chart.yaml  README.md  templates  values.yaml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# vim values.yaml</span><br><span class=\"line\"># 自定义root密码</span><br><span class=\"line\"> 96 auth:</span><br><span class=\"line\"> 97   ## Role-based access control parameters</span><br><span class=\"line\"> 98   ## ref: https://etcd.io/docs/current/op-guide/authentication/</span><br><span class=\"line\"> 99   ##</span><br><span class=\"line\">100   rbac:</span><br><span class=\"line\">101     ## @param auth.rbac.create Switch to enable RBAC authentication</span><br><span class=\"line\">102     ##</span><br><span class=\"line\">103     create: true</span><br><span class=\"line\">104     ## @param auth.rbac.allowNoneAuthentication Allow to use etcd without configuring RBAC authentication</span><br><span class=\"line\">105     ##</span><br><span class=\"line\">106     allowNoneAuthentication: true</span><br><span class=\"line\">107     ## @param auth.rbac.rootPassword Root user password. The root user is always `root`</span><br><span class=\"line\">108     ##</span><br><span class=\"line\">109     rootPassword: &quot;123456&quot; # 指定root密码</span><br><span class=\"line\"></span><br><span class=\"line\"># 自定义存储方式</span><br><span class=\"line\">575 persistence:</span><br><span class=\"line\">576   ## @param persistence.enabled If true, use a Persistent Volume Claim. If false, use emptyDir.</span><br><span class=\"line\">577   ##</span><br><span class=\"line\">578   enabled: true # 如果没有sc，此处改为false</span><br><span class=\"line\">579   ## @param persistence.storageClass Persistent Volume Storage Class</span><br><span class=\"line\">580   ## If defined, storageClassName: &lt;storageClass&gt;</span><br><span class=\"line\">581   ## If set to &quot;-&quot;, storageClassName: &quot;&quot;, which disables dynamic provisioning</span><br><span class=\"line\">582   ## If undefined (the default) or set to null, no storageClassName spec is</span><br><span class=\"line\">583   ##   set, choosing the default provisioner.  (gp2 on AWS, standard on</span><br><span class=\"line\">584   ##   GKE, AWS &amp; OpenStack)</span><br><span class=\"line\">585   ##</span><br><span class=\"line\">586   storageClass: &quot;nfs-client&quot; # 填写sc名称</span><br><span class=\"line\"></span><br><span class=\"line\"># 修改副本数，建议奇数3个起步</span><br><span class=\"line\">257 ## @param replicaCount Number of etcd replicas to deploy</span><br><span class=\"line\">258 ##</span><br><span class=\"line\">259 replicaCount: 3</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"367c6336\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装etcd服务</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# kubectl create ns etcd</span><br><span class=\"line\">namespace/etcd created</span><br><span class=\"line\">[root@k8s-master etcd]# helm install etcd -n etcd ../etcd</span><br><span class=\"line\">NAME: etcd</span><br><span class=\"line\">LAST DEPLOYED: Fri Mar 17 20:43:31 2023</span><br><span class=\"line\">NAMESPACE: etcd</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">CHART NAME: etcd</span><br><span class=\"line\">CHART VERSION: 8.8.0</span><br><span class=\"line\">APP VERSION: 3.5.7</span><br><span class=\"line\"></span><br><span class=\"line\">** Please be patient while the chart is being deployed **</span><br><span class=\"line\"></span><br><span class=\"line\">etcd can be accessed via port 2379 on the following DNS name from within your cluster:</span><br><span class=\"line\"></span><br><span class=\"line\">etcd.etcd.svc.cluster.local</span><br><span class=\"line\"></span><br><span class=\"line\">To create a pod that you can use as a etcd client run the following command:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl run etcd-client --restart=&#x27;Never&#x27; --image docker.io/bitnami/etcd:3.5.7-debian-11-r14 --env ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=&quot;&#123;.data.etcd-root-password&#125;&quot; | base64 -d) --env ETCDCTL_ENDPOINTS=&quot;etcd.etcd.svc.cluster.local:2379&quot; --namespace etcd --command -- sleep infinity</span><br><span class=\"line\"></span><br><span class=\"line\">Then, you can set/get a key using the commands below:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl exec --namespace etcd -it etcd-client -- bash</span><br><span class=\"line\">etcdctl --user root:$ROOT_PASSWORD put /message Hello</span><br><span class=\"line\">etcdctl --user root:$ROOT_PASSWORD get /message</span><br><span class=\"line\"></span><br><span class=\"line\">To connect to your etcd server from outside the cluster execute the following commands:</span><br><span class=\"line\"></span><br><span class=\"line\">kubectl port-forward --namespace etcd svc/etcd 2379:2379 &amp;</span><br><span class=\"line\">echo &quot;etcd URL: http://127.0.0.1:2379&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">* As rbac is enabled you should add the flag `--user root:$ETCD_ROOT_PASSWORD` to the etcdctl commands. Use the command below to export the password:</span><br><span class=\"line\"></span><br><span class=\"line\">export ETCD_ROOT_PASSWORD=$(kubectl get secret --namespace etcd etcd -o jsonpath=&quot;&#123;.data.etcd-root-password&#125;&quot; | base64 -d)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master etcd]# kubectl get pod -n etcd -o wide</span><br><span class=\"line\">NAME     READY   STATUS    RESTARTS        AGE     IP             NODE        NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">etcd-0   1/1     Running   0               1m13s   10.244.1.154   k8s-work1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-1   1/1     Running   0               1m13s   10.244.2.50    k8s-work2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">etcd-2   1/1     Running   0               1m13s   10.244.1.155   k8s-work1   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\">[root@k8s-master etcd]# kubectl get svc -n etcd </span><br><span class=\"line\">NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">etcd            ClusterIP   10.102.32.213   &lt;none&gt;        2379/TCP,2380/TCP   9m48s</span><br><span class=\"line\">etcd-headless   ClusterIP   None            &lt;none&gt;        2379/TCP,2380/TCP   9m48s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e6efac8c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问测试</font></h2>\n"},{"title":"分布式存储","date":"2025-03-17T11:30:00.000Z","_content":"<h1 id=\"48ea327c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统</font></h1>\n---\n\n<h2 id=\"61a3ec66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统（Distributed File System，DFS）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点（可简单的理解为一台计算机）相连；或是若干不同的逻辑磁盘分区或卷标组合在一起而形成的完整的有层次的文件系统。DFS为分布在网络上任意位置的资源提供一个逻辑上的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">树形文件</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E6%A0%91%E5%BD%A2%E6%96%87%E4%BB%B6&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构，从而使用户访问分布在网络上的共享文件更加简便。</font>\n\n<h2 id=\"f094dd87\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统一般文件系统存储数据的方式数据分散的存储在多台服务器上集中存放所有数据，在一台服务器上特点</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式网络</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">存储系统采用可扩展的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=2&q=%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">，利用多台服务器分担负荷，利用位置服务器定位存储信息，不但提高了</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统的可靠性</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">、可用性和存取效率，还易于扩展，避免单点故障。传统的网络存储系统采用集中的服务器存放所有数据，到一定程度服务器会成为系统性能的瓶颈，也是可靠性和安全性的焦点，不能满足大规模存储应用的需要。</font>\n\n<h1 id=\"8affb878\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统</font></h1>\n---\n\n<h2 id=\"61a3ec66-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存系统，是将数据分散存储在多台独立的设备上，从而解决传统的存储系统的容量和性能限制。所有如果存储服务器的可靠性和安全性无法满足大规模存储应用的需要，那么它就会成为分布式文件系统的性能瓶颈。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统可以理解为多台单机存储系统各司其职、协同合作，统一的对外提供存储服务。</font>\n\n<h2 id=\"f094dd87-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统采用可扩展的系统结构，利用多台存储服务器分摊存储压力，利用位置服务器定位存储信息，它不但提高了系统的可靠性、可用性和存取效率，还易于扩展。</font>\n\n<h1 id=\"20b5c053\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统对比</font></h1>\n---\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">适用场景</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主要特性</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">优点</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点</font>** |\n| --- | --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">HDFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">大数据处理（如Hadoop）</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">面向批处理，写多读少，数据分块存储，主从架构</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高吞吐量，适合大规模数据分析</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高延迟，不支持低延迟随机读写</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">Ceph</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">通用存储（对象、块、文件）</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于CRUSH算法，无中心架构，强一致性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高可用性，扩展性强，支持多种存储方式</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">配置复杂，性能调优难度较高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">GlusterFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能存储、虚拟化平台</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">无元数据服务器，完全分布式，适合横向扩展</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">容易扩展，支持不同存储类型的集成</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">元数据操作效率低，适合小文件的性能一般</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">MooseFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">归档存储、备份系统</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主从架构，数据冗余，支持故障自动恢复</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">简单易用，管理灵活</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">元数据服务器是单点瓶颈</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">Lustre</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算（HPC）</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">面向并行文件访问，专为高性能计算优化</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">性能极高，支持并行读写</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">部署复杂，对网络延迟敏感</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">BeeGFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算、AI训练</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">分布式元数据管理，优化并行处理</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">部署灵活，元数据分布提高性能</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">社区支持较少，适配性有限</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">IPFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">分布式Web存储、内容分发</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于内容寻址，P2P架构，去中心化</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">去中心化，高扩展性，数据去重</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">不适合低延迟随机访问，实时性要求高的场景不适合</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储，云原生场景</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">兼容S3协议，轻量化设计，支持Kubernetes集成</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">部署简单，高性能，支持对象级别的存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">不适合传统分布式文件访问场景，元数据存储依赖外部组件</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">JuiceFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">云原生分析，日志存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于对象存储的文件系统，可支持不同的云存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">性能较高，成本较低，支持弹性扩展</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对元数据服务依赖较大，延迟可能受底层对象存储影响</font> |\n\n\n<h1 id=\"8059c1a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式数据存储原理</font></h1>\n---\n\n<h2 id=\"9115842b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储流程</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853015703-f6f4a322-61e0-44e4-b5e4-cd5067714c6d.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在分布式存储引擎中存放文件属性信息以及每个文件对应的节点磁盘信息，在数据节点中存储具体的数据内容。</font>\n\n<h2 id=\"d9bcfefa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储角色</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当我们将数据存储到分布式系统上的时候，通过路由机制，将我们的请求转发给对应的存储节点上，所以存储元数据的节点我们称为 NameNode，而存储具体数据的节点称为 DataNode</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当我们存储的数据较大是，我们会先将存储的数据信息发送给元数据控制节点，然后控制节点进行数据拆分，实现并行存储的逻辑效果，每个数据块称为一个 shard。</font>\n\n","source":"_posts/2.分布式存储 副本.md","raw":"---\ntitle: 分布式存储 \ndate: 2025-03-17 19:30:00\n---\n<h1 id=\"48ea327c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统</font></h1>\n---\n\n<h2 id=\"61a3ec66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统（Distributed File System，DFS）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点（可简单的理解为一台计算机）相连；或是若干不同的逻辑磁盘分区或卷标组合在一起而形成的完整的有层次的文件系统。DFS为分布在网络上任意位置的资源提供一个逻辑上的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">树形文件</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E6%A0%91%E5%BD%A2%E6%96%87%E4%BB%B6&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构，从而使用户访问分布在网络上的共享文件更加简便。</font>\n\n<h2 id=\"f094dd87\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统一般文件系统存储数据的方式数据分散的存储在多台服务器上集中存放所有数据，在一台服务器上特点</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式网络</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">存储系统采用可扩展的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=2&q=%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">，利用多台服务器分担负荷，利用位置服务器定位存储信息，不但提高了</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统的可靠性</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">、可用性和存取效率，还易于扩展，避免单点故障。传统的网络存储系统采用集中的服务器存放所有数据，到一定程度服务器会成为系统性能的瓶颈，也是可靠性和安全性的焦点，不能满足大规模存储应用的需要。</font>\n\n<h1 id=\"8affb878\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统</font></h1>\n---\n\n<h2 id=\"61a3ec66-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存系统，是将数据分散存储在多台独立的设备上，从而解决传统的存储系统的容量和性能限制。所有如果存储服务器的可靠性和安全性无法满足大规模存储应用的需要，那么它就会成为分布式文件系统的性能瓶颈。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统可以理解为多台单机存储系统各司其职、协同合作，统一的对外提供存储服务。</font>\n\n<h2 id=\"f094dd87-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统采用可扩展的系统结构，利用多台存储服务器分摊存储压力，利用位置服务器定位存储信息，它不但提高了系统的可靠性、可用性和存取效率，还易于扩展。</font>\n\n<h1 id=\"20b5c053\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统对比</font></h1>\n---\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">适用场景</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主要特性</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">优点</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">缺点</font>** |\n| --- | --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">HDFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">大数据处理（如Hadoop）</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">面向批处理，写多读少，数据分块存储，主从架构</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高吞吐量，适合大规模数据分析</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高延迟，不支持低延迟随机读写</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">Ceph</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">通用存储（对象、块、文件）</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于CRUSH算法，无中心架构，强一致性</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高可用性，扩展性强，支持多种存储方式</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">配置复杂，性能调优难度较高</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">GlusterFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能存储、虚拟化平台</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">无元数据服务器，完全分布式，适合横向扩展</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">容易扩展，支持不同存储类型的集成</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">元数据操作效率低，适合小文件的性能一般</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">MooseFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">归档存储、备份系统</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">主从架构，数据冗余，支持故障自动恢复</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">简单易用，管理灵活</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">元数据服务器是单点瓶颈</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">Lustre</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算（HPC）</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">面向并行文件访问，专为高性能计算优化</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">性能极高，支持并行读写</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">部署复杂，对网络延迟敏感</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">BeeGFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算、AI训练</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">分布式元数据管理，优化并行处理</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">部署灵活，元数据分布提高性能</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">社区支持较少，适配性有限</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">IPFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">分布式Web存储、内容分发</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于内容寻址，P2P架构，去中心化</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">去中心化，高扩展性，数据去重</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">不适合低延迟随机访问，实时性要求高的场景不适合</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储，云原生场景</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">兼容S3协议，轻量化设计，支持Kubernetes集成</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">部署简单，高性能，支持对象级别的存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">不适合传统分布式文件访问场景，元数据存储依赖外部组件</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">JuiceFS</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">云原生分析，日志存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于对象存储的文件系统，可支持不同的云存储</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">性能较高，成本较低，支持弹性扩展</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对元数据服务依赖较大，延迟可能受底层对象存储影响</font> |\n\n\n<h1 id=\"8059c1a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式数据存储原理</font></h1>\n---\n\n<h2 id=\"9115842b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储流程</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853015703-f6f4a322-61e0-44e4-b5e4-cd5067714c6d.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在分布式存储引擎中存放文件属性信息以及每个文件对应的节点磁盘信息，在数据节点中存储具体的数据内容。</font>\n\n<h2 id=\"d9bcfefa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储角色</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当我们将数据存储到分布式系统上的时候，通过路由机制，将我们的请求转发给对应的存储节点上，所以存储元数据的节点我们称为 NameNode，而存储具体数据的节点称为 DataNode</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当我们存储的数据较大是，我们会先将存储的数据信息发送给元数据控制节点，然后控制节点进行数据拆分，实现并行存储的逻辑效果，每个数据块称为一个 shard。</font>\n\n","slug":"2.分布式存储 副本","published":1,"updated":"2025-03-30T13:17:43.838Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlm000ftsv14i356yta","content":"<h1 id=\"48ea327c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统</font></h1>\n---\n\n<h2 id=\"61a3ec66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统（Distributed File System，DFS）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点（可简单的理解为一台计算机）相连；或是若干不同的逻辑磁盘分区或卷标组合在一起而形成的完整的有层次的文件系统。DFS为分布在网络上任意位置的资源提供一个逻辑上的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">树形文件</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E6%A0%91%E5%BD%A2%E6%96%87%E4%BB%B6&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构，从而使用户访问分布在网络上的共享文件更加简便。</font>\n\n<h2 id=\"f094dd87\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统一般文件系统存储数据的方式数据分散的存储在多台服务器上集中存放所有数据，在一台服务器上特点</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式网络</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">存储系统采用可扩展的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=2&q=%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">，利用多台服务器分担负荷，利用位置服务器定位存储信息，不但提高了</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统的可靠性</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">、可用性和存取效率，还易于扩展，避免单点故障。传统的网络存储系统采用集中的服务器存放所有数据，到一定程度服务器会成为系统性能的瓶颈，也是可靠性和安全性的焦点，不能满足大规模存储应用的需要。</font>\n\n<h1 id=\"8affb878\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统</font></h1>\n---\n\n<h2 id=\"61a3ec66-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存系统，是将数据分散存储在多台独立的设备上，从而解决传统的存储系统的容量和性能限制。所有如果存储服务器的可靠性和安全性无法满足大规模存储应用的需要，那么它就会成为分布式文件系统的性能瓶颈。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统可以理解为多台单机存储系统各司其职、协同合作，统一的对外提供存储服务。</font></p>\n<h2 id=\"f094dd87-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统采用可扩展的系统结构，利用多台存储服务器分摊存储压力，利用位置服务器定位存储信息，它不但提高了系统的可靠性、可用性和存取效率，还易于扩展。</font>\n\n<h1 id=\"20b5c053\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统对比</font></h1>\n---\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">适用场景</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">主要特性</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">优点</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">HDFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">大数据处理（如Hadoop）</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">面向批处理，写多读少，数据分块存储，主从架构</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高吞吐量，适合大规模数据分析</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高延迟，不支持低延迟随机读写</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">Ceph</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">通用存储（对象、块、文件）</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于CRUSH算法，无中心架构，强一致性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用性，扩展性强，支持多种存储方式</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">配置复杂，性能调优难度较高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">GlusterFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高性能存储、虚拟化平台</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">无元数据服务器，完全分布式，适合横向扩展</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">容易扩展，支持不同存储类型的集成</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">元数据操作效率低，适合小文件的性能一般</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">MooseFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">归档存储、备份系统</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主从架构，数据冗余，支持故障自动恢复</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">简单易用，管理灵活</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">元数据服务器是单点瓶颈</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">Lustre</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算（HPC）</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">面向并行文件访问，专为高性能计算优化</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">性能极高，支持并行读写</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">部署复杂，对网络延迟敏感</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">BeeGFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算、AI训练</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式元数据管理，优化并行处理</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">部署灵活，元数据分布提高性能</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">社区支持较少，适配性有限</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">IPFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式Web存储、内容分发</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于内容寻址，P2P架构，去中心化</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">去中心化，高扩展性，数据去重</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">不适合低延迟随机访问，实时性要求高的场景不适合</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储，云原生场景</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">兼容S3协议，轻量化设计，支持Kubernetes集成</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">部署简单，高性能，支持对象级别的存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">不适合传统分布式文件访问场景，元数据存储依赖外部组件</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">JuiceFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">云原生分析，日志存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于对象存储的文件系统，可支持不同的云存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">性能较高，成本较低，支持弹性扩展</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对元数据服务依赖较大，延迟可能受底层对象存储影响</font></td>\n</tr>\n</tbody></table>\n<h1 id=\"8059c1a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式数据存储原理</font></h1>\n---\n\n<h2 id=\"9115842b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储流程</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853015703-f6f4a322-61e0-44e4-b5e4-cd5067714c6d.jpeg)\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在分布式存储引擎中存放文件属性信息以及每个文件对应的节点磁盘信息，在数据节点中存储具体的数据内容。</font></p>\n<h2 id=\"d9bcfefa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储角色</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当我们将数据存储到分布式系统上的时候，通过路由机制，将我们的请求转发给对应的存储节点上，所以存储元数据的节点我们称为 NameNode，而存储具体数据的节点称为 DataNode</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当我们存储的数据较大是，我们会先将存储的数据信息发送给元数据控制节点，然后控制节点进行数据拆分，实现并行存储的逻辑效果，每个数据块称为一个 shard。</font></p>\n","excerpt":"","more":"<h1 id=\"48ea327c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统</font></h1>\n---\n\n<h2 id=\"61a3ec66\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统（Distributed File System，DFS）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点（可简单的理解为一台计算机）相连；或是若干不同的逻辑磁盘分区或卷标组合在一起而形成的完整的有层次的文件系统。DFS为分布在网络上任意位置的资源提供一个逻辑上的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">树形文件</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E6%A0%91%E5%BD%A2%E6%96%87%E4%BB%B6&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构，从而使用户访问分布在网络上的共享文件更加简便。</font>\n\n<h2 id=\"f094dd87\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统一般文件系统存储数据的方式数据分散的存储在多台服务器上集中存放所有数据，在一台服务器上特点</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式网络</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E5%88%86%E5%B8%83%E5%BC%8F%E7%BD%91%E7%BB%9C&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">存储系统采用可扩展的</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统结构</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=2&q=%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">，利用多台服务器分担负荷，利用位置服务器定位存储信息，不但提高了</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">系统的可靠性</font>](https://zhida.zhihu.com/search?content_id=177552397&content_type=Article&match_order=1&q=%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7&zhida_source=entity)<font style=\"background-color:rgba(255, 255, 255, 0);\">、可用性和存取效率，还易于扩展，避免单点故障。传统的网络存储系统采用集中的服务器存放所有数据，到一定程度服务器会成为系统性能的瓶颈，也是可靠性和安全性的焦点，不能满足大规模存储应用的需要。</font>\n\n<h1 id=\"8affb878\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统</font></h1>\n---\n\n<h2 id=\"61a3ec66-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">介绍</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存系统，是将数据分散存储在多台独立的设备上，从而解决传统的存储系统的容量和性能限制。所有如果存储服务器的可靠性和安全性无法满足大规模存储应用的需要，那么它就会成为分布式文件系统的性能瓶颈。</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统可以理解为多台单机存储系统各司其职、协同合作，统一的对外提供存储服务。</font></p>\n<h2 id=\"f094dd87-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">优势</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">分布式存储系统采用可扩展的系统结构，利用多台存储服务器分摊存储压力，利用位置服务器定位存储信息，它不但提高了系统的可靠性、可用性和存取效率，还易于扩展。</font>\n\n<h1 id=\"20b5c053\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式文件系统对比</font></h1>\n---\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">适用场景</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">主要特性</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">优点</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">缺点</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">HDFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">大数据处理（如Hadoop）</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">面向批处理，写多读少，数据分块存储，主从架构</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高吞吐量，适合大规模数据分析</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高延迟，不支持低延迟随机读写</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">Ceph</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">通用存储（对象、块、文件）</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于CRUSH算法，无中心架构，强一致性</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高可用性，扩展性强，支持多种存储方式</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">配置复杂，性能调优难度较高</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">GlusterFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高性能存储、虚拟化平台</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">无元数据服务器，完全分布式，适合横向扩展</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">容易扩展，支持不同存储类型的集成</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">元数据操作效率低，适合小文件的性能一般</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">MooseFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">归档存储、备份系统</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">主从架构，数据冗余，支持故障自动恢复</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">简单易用，管理灵活</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">元数据服务器是单点瓶颈</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">Lustre</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算（HPC）</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">面向并行文件访问，专为高性能计算优化</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">性能极高，支持并行读写</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">部署复杂，对网络延迟敏感</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">BeeGFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">高性能计算、AI训练</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式元数据管理，优化并行处理</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">部署灵活，元数据分布提高性能</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">社区支持较少，适配性有限</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">IPFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式Web存储、内容分发</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于内容寻址，P2P架构，去中心化</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">去中心化，高扩展性，数据去重</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">不适合低延迟随机访问，实时性要求高的场景不适合</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储，云原生场景</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">兼容S3协议，轻量化设计，支持Kubernetes集成</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">部署简单，高性能，支持对象级别的存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">不适合传统分布式文件访问场景，元数据存储依赖外部组件</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">JuiceFS</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">云原生分析，日志存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于对象存储的文件系统，可支持不同的云存储</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">性能较高，成本较低，支持弹性扩展</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对元数据服务依赖较大，延迟可能受底层对象存储影响</font></td>\n</tr>\n</tbody></table>\n<h1 id=\"8059c1a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">分布式数据存储原理</font></h1>\n---\n\n<h2 id=\"9115842b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储流程</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853015703-f6f4a322-61e0-44e4-b5e4-cd5067714c6d.jpeg)\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在分布式存储引擎中存放文件属性信息以及每个文件对应的节点磁盘信息，在数据节点中存储具体的数据内容。</font></p>\n<h2 id=\"d9bcfefa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">存储角色</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当我们将数据存储到分布式系统上的时候，通过路由机制，将我们的请求转发给对应的存储节点上，所以存储元数据的节点我们称为 NameNode，而存储具体数据的节点称为 DataNode</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">当我们存储的数据较大是，我们会先将存储的数据信息发送给元数据控制节点，然后控制节点进行数据拆分，实现并行存储的逻辑效果，每个数据块称为一个 shard。</font></p>\n"},{"title":"安装容器运行时(Docker)","date":"2025-03-11T10:00:00.000Z","_content":"> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作全部节点执行，如果使用docker作为容器运行时，最高支持的k8s版本为1.23.17。</font>\n>\n\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的docker版本范围，具体参考官方文档</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font>](https://github.com/kubernetes/kubernetes/releases)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以1.23.X为例，查看</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</font>](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800680473-87a8453f-5b3e-4046-9392-dc420cf4043f.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的docker版本为20.10.7以上，也不用安装最新版本的docker，以免出现docker版本与k8s版本不匹配的现象，此处就以安装20.10.7为例。</font>\n\n<h1 id=\"6232cdc9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker安装</font></h1>\n---\n\n<h2 id=\"1eed2ebc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL安装</font></h2>\n---\n\n```shell\n# 安装前源准备\n[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 \n# 配置yum源\n[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo \n# 查看可安装的docker版本\n[root@k8s-master ~]# yum list docker-ce --showduplicates | sort -r \n# 安装20.10.6版本docker\n[root@k8s-master ~]# yum install -y docker-ce-20.10.7\n```\n\n<h2 id=\"453626fa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian安装</font></h2>\n```shell\n# 安装前源准备\napt install -y apt-transport-https ca-certificates curl software-properties-common\n# 配置yum源\ncurl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -\nadd-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\napt-get -y update\n# 查看可安装的docker版本\napt-cache madison docker-ce | sort -V\n# 安装docker\napt-get -y install docker-ce=5:20.10.24~3-0~ubuntu-focal\nmkdir -p /etc/docker\ntee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\n        \"https://mirror.ccs.tencentyun.com\",\n        \"https://o2j0mc5x.mirror.aliyuncs.com\"\n    ]\n}\nEOF\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n```\n\n<h1 id=\"bfff1adc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">禁用iptables的forward调用链</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">docker 1.13以上版本默认禁用iptables的forward调用链，因此需要执行开启命令：</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@k8s-master ~]# iptables -P FORWARD ACCEPT</font>`\n\n<h1 id=\"1a6d8795\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改docker cgroup driver为systemd</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">systemd 是 Kubernetes 自带的 cgroup 管理器，负责为每个进程分配 cgroupfs，但 Docker 的 cgroup driver 默认是 cgroupfs，这样就同时运行了两个 cgroup 控制管理器。当资源有压力时，有可能会出现不稳定的情况。</font>\n\n```shell\n[root@k8s-master ~]# mkdir -p /etc/docker\n[root@k8s-master ~]# vim /etc/docker/daemon.json \n{\n    \"registry-mirrors\": [\n        \"https://mirror.ccs.tencentyun.com\",\n        \"https://o2j0mc5x.mirror.aliyuncs.com\"\n    ],\n    \"exec-opts\": [\n        \"native.cgroupdriver=systemd\"\n    ]\n}\n[root@k8s-master ~]# systemctl daemon-reload \n[root@k8s-master ~]# systemctl enable docker \n[root@k8s-master ~]# systemctl start docker \n[root@k8s-master ~]# docker info | grep Driver\n Storage Driver: overlay2\n Logging Driver: json-file\n Cgroup Driver: systemd\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n","source":"_posts/2.安装容器运行时(Docker).md","raw":"---\ntitle: 安装容器运行时(Docker)\ndate: 2025-03-11 18:00:00\n---\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作全部节点执行，如果使用docker作为容器运行时，最高支持的k8s版本为1.23.17。</font>\n>\n\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的docker版本范围，具体参考官方文档</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font>](https://github.com/kubernetes/kubernetes/releases)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以1.23.X为例，查看</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</font>](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800680473-87a8453f-5b3e-4046-9392-dc420cf4043f.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的docker版本为20.10.7以上，也不用安装最新版本的docker，以免出现docker版本与k8s版本不匹配的现象，此处就以安装20.10.7为例。</font>\n\n<h1 id=\"6232cdc9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker安装</font></h1>\n---\n\n<h2 id=\"1eed2ebc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL安装</font></h2>\n---\n\n```shell\n# 安装前源准备\n[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 \n# 配置yum源\n[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo \n# 查看可安装的docker版本\n[root@k8s-master ~]# yum list docker-ce --showduplicates | sort -r \n# 安装20.10.6版本docker\n[root@k8s-master ~]# yum install -y docker-ce-20.10.7\n```\n\n<h2 id=\"453626fa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian安装</font></h2>\n```shell\n# 安装前源准备\napt install -y apt-transport-https ca-certificates curl software-properties-common\n# 配置yum源\ncurl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -\nadd-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\napt-get -y update\n# 查看可安装的docker版本\napt-cache madison docker-ce | sort -V\n# 安装docker\napt-get -y install docker-ce=5:20.10.24~3-0~ubuntu-focal\nmkdir -p /etc/docker\ntee /etc/docker/daemon.json <<-'EOF'\n{\n  \"registry-mirrors\": [\n        \"https://mirror.ccs.tencentyun.com\",\n        \"https://o2j0mc5x.mirror.aliyuncs.com\"\n    ]\n}\nEOF\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n```\n\n<h1 id=\"bfff1adc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">禁用iptables的forward调用链</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">docker 1.13以上版本默认禁用iptables的forward调用链，因此需要执行开启命令：</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@k8s-master ~]# iptables -P FORWARD ACCEPT</font>`\n\n<h1 id=\"1a6d8795\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改docker cgroup driver为systemd</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">systemd 是 Kubernetes 自带的 cgroup 管理器，负责为每个进程分配 cgroupfs，但 Docker 的 cgroup driver 默认是 cgroupfs，这样就同时运行了两个 cgroup 控制管理器。当资源有压力时，有可能会出现不稳定的情况。</font>\n\n```shell\n[root@k8s-master ~]# mkdir -p /etc/docker\n[root@k8s-master ~]# vim /etc/docker/daemon.json \n{\n    \"registry-mirrors\": [\n        \"https://mirror.ccs.tencentyun.com\",\n        \"https://o2j0mc5x.mirror.aliyuncs.com\"\n    ],\n    \"exec-opts\": [\n        \"native.cgroupdriver=systemd\"\n    ]\n}\n[root@k8s-master ~]# systemctl daemon-reload \n[root@k8s-master ~]# systemctl enable docker \n[root@k8s-master ~]# systemctl start docker \n[root@k8s-master ~]# docker info | grep Driver\n Storage Driver: overlay2\n Logging Driver: json-file\n Cgroup Driver: systemd\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n","slug":"2.安装容器运行时(Docker)","published":1,"updated":"2025-03-30T13:10:18.818Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjln000gtsv16jizhmh7","content":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作全部节点执行，如果使用docker作为容器运行时，最高支持的k8s版本为1.23.17。</font></p>\n</blockquote>\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的docker版本范围，具体参考官方文档</font><a href=\"https://github.com/kubernetes/kubernetes/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以1.23.X为例，查看</font><a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</font></a></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800680473-87a8453f-5b3e-4046-9392-dc420cf4043f.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的docker版本为20.10.7以上，也不用安装最新版本的docker，以免出现docker版本与k8s版本不匹配的现象，此处就以安装20.10.7为例。</font></p>\n<h1 id=\"6232cdc9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker安装</font></h1>\n---\n\n<h2 id=\"1eed2ebc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL安装</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装前源准备</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">配置yum源</span></span><br><span class=\"line\">[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看可安装的docker版本</span></span><br><span class=\"line\">[root@k8s-master ~]# yum list docker-ce --showduplicates | sort -r </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装20.10.6版本docker</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y docker-ce-20.10.7</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"453626fa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian安装</font></h2>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装前源准备</span></span><br><span class=\"line\">apt install -y apt-transport-https ca-certificates curl software-properties-common</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">配置yum源</span></span><br><span class=\"line\">curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class=\"line\">add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class=\"line\">apt-get -y update</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看可安装的docker版本</span></span><br><span class=\"line\">apt-cache madison docker-ce | sort -V</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装docker</span></span><br><span class=\"line\">apt-get -y install docker-ce=5:20.10.24~3-0~ubuntu-focal</span><br><span class=\"line\">mkdir -p /etc/docker</span><br><span class=\"line\">tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;registry-mirrors&quot;: [</span><br><span class=\"line\">        &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class=\"line\">        &quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\">systemctl daemon-reload</span><br><span class=\"line\">systemctl enable docker</span><br><span class=\"line\">systemctl restart docker</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"bfff1adc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">禁用iptables的forward调用链</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">docker 1.13以上版本默认禁用iptables的forward调用链，因此需要执行开启命令：</font></p>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;[root@k8s-master ~]# iptables -P FORWARD ACCEPT&lt;/font&gt;</code></p>\n<h1 id=\"1a6d8795\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改docker cgroup driver为systemd</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">systemd 是 Kubernetes 自带的 cgroup 管理器，负责为每个进程分配 cgroupfs，但 Docker 的 cgroup driver 默认是 cgroupfs，这样就同时运行了两个 cgroup 控制管理器。当资源有压力时，有可能会出现不稳定的情况。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# mkdir -p /etc/docker</span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/docker/daemon.json </span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;: [</span><br><span class=\"line\">        &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class=\"line\">        &quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;exec-opts&quot;: [</span><br><span class=\"line\">        &quot;native.cgroupdriver=systemd&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">[root@k8s-master ~]# systemctl daemon-reload </span><br><span class=\"line\">[root@k8s-master ~]# systemctl enable docker </span><br><span class=\"line\">[root@k8s-master ~]# systemctl start docker </span><br><span class=\"line\">[root@k8s-master ~]# docker info | grep Driver</span><br><span class=\"line\"> Storage Driver: overlay2</span><br><span class=\"line\"> Logging Driver: json-file</span><br><span class=\"line\"> Cgroup Driver: systemd</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n","excerpt":"","more":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作全部节点执行，如果使用docker作为容器运行时，最高支持的k8s版本为1.23.17。</font></p>\n</blockquote>\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的docker版本范围，具体参考官方文档</font><a href=\"https://github.com/kubernetes/kubernetes/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以1.23.X为例，查看</font><a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md</font></a></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800680473-87a8453f-5b3e-4046-9392-dc420cf4043f.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的docker版本为20.10.7以上，也不用安装最新版本的docker，以免出现docker版本与k8s版本不匹配的现象，此处就以安装20.10.7为例。</font></p>\n<h1 id=\"6232cdc9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">docker安装</font></h1>\n---\n\n<h2 id=\"1eed2ebc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL安装</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装前源准备</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">配置yum源</span></span><br><span class=\"line\">[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看可安装的docker版本</span></span><br><span class=\"line\">[root@k8s-master ~]# yum list docker-ce --showduplicates | sort -r </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装20.10.6版本docker</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y docker-ce-20.10.7</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"453626fa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian安装</font></h2>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装前源准备</span></span><br><span class=\"line\">apt install -y apt-transport-https ca-certificates curl software-properties-common</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">配置yum源</span></span><br><span class=\"line\">curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class=\"line\">add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class=\"line\">apt-get -y update</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看可安装的docker版本</span></span><br><span class=\"line\">apt-cache madison docker-ce | sort -V</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装docker</span></span><br><span class=\"line\">apt-get -y install docker-ce=5:20.10.24~3-0~ubuntu-focal</span><br><span class=\"line\">mkdir -p /etc/docker</span><br><span class=\"line\">tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;registry-mirrors&quot;: [</span><br><span class=\"line\">        &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class=\"line\">        &quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\">systemctl daemon-reload</span><br><span class=\"line\">systemctl enable docker</span><br><span class=\"line\">systemctl restart docker</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"bfff1adc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">禁用iptables的forward调用链</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">docker 1.13以上版本默认禁用iptables的forward调用链，因此需要执行开启命令：</font></p>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;[root@k8s-master ~]# iptables -P FORWARD ACCEPT&lt;/font&gt;</code></p>\n<h1 id=\"1a6d8795\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改docker cgroup driver为systemd</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">systemd 是 Kubernetes 自带的 cgroup 管理器，负责为每个进程分配 cgroupfs，但 Docker 的 cgroup driver 默认是 cgroupfs，这样就同时运行了两个 cgroup 控制管理器。当资源有压力时，有可能会出现不稳定的情况。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# mkdir -p /etc/docker</span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/docker/daemon.json </span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;: [</span><br><span class=\"line\">        &quot;https://mirror.ccs.tencentyun.com&quot;,</span><br><span class=\"line\">        &quot;https://o2j0mc5x.mirror.aliyuncs.com&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;exec-opts&quot;: [</span><br><span class=\"line\">        &quot;native.cgroupdriver=systemd&quot;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">[root@k8s-master ~]# systemctl daemon-reload </span><br><span class=\"line\">[root@k8s-master ~]# systemctl enable docker </span><br><span class=\"line\">[root@k8s-master ~]# systemctl start docker </span><br><span class=\"line\">[root@k8s-master ~]# docker info | grep Driver</span><br><span class=\"line\"> Storage Driver: overlay2</span><br><span class=\"line\"> Logging Driver: json-file</span><br><span class=\"line\"> Cgroup Driver: systemd</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n"},{"title":"部署helm包管理工具","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"f11a4b4f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Helm</font></h1>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">官方参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://helm.sh/docs/intro/quickstart/</font>](https://helm.sh/docs/intro/quickstart/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的安装方式有两种：预编译的二进制程序和源码编译安装。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Helm项目托管在GitHub之上，项目地址为</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/helm/helm/releases</font>](https://github.com/helm/helm/releases)<font style=\"background-color:rgba(255, 255, 255, 0);\">。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的运行依赖于本地安装并配置完成的kubectl方能与运行于Kubernetes集群之上的Tiller服务器进行通信，因此，运行Helm的节点也应该是可以正常使用kubectl命令的主机，或者至少是有着可用kubeconfig配置文件的主机。</font>\n\n<h2 id=\"552ec97e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载压缩包并解压</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# wget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz\n[root@k8s-master k8s-install]# tar -zxvf helm-v3.16.2-linux-amd64.tar.gz\n```\n\n<h2 id=\"85a7ab47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">移动到环境变量目录中</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# mv linux-amd64/helm /usr/local/bin/ \n# 加载环境变量\n[root@k8s-master k8s-install]# source <(helm completion bash) >> ~/.bash_profile \n[root@k8s-master k8s-install]# source ~/.bash_profile \n```\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# helm version\nversion.BuildInfo{Version:\"v3.16.2\", GitCommit:\"3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e\", GitTreeState:\"clean\", GoVersion:\"go1.20.7\"}\n```\n\n<h1 id=\"1c15269a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加Helm的官方仓库</font></h1>\n---\n\n<h2 id=\"6f3419de\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加官方Charts仓库</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# helm repo add stable https://charts.helm.sh/stable\n```\n\n<h2 id=\"00b7396e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看官方Charts仓库</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# helm search repo stable\n```\n\n<h1 id=\"083a9ea8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm dashboard</font></h1>\n<h2 id=\"b0ff454a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">前提条件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署nfs共享存储，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/116191364</font>](https://www.cuiliangblog.cn/detail/section/116191364)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署ingress，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/140101250</font>](https://www.cuiliangblog.cn/detail/section/140101250)\n\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n```plain\n[root@k8s-master k8s-install]# kubectl create ns helm\n[root@k8s-master k8s-install]# helm repo add komodorio https://helm-charts.komodor.io\n[root@master1 k8s-install]# helm pull komodorio/helm-dashboard --untar\n[root@master1 k8s-install]# cd helm-dashboard/\n[root@master1 helm-dashboard]# ls\nChart.yaml  README.md  templates  values.yaml\n[root@master1 helm-dashboard]# vim values.yaml\ndashboard:\n  persistence:\n    storageClass: nfs-client # 指定使用nfs存储\n[root@k8s-master k8s-install]# helm install helm-dashboard -n helm . -f values.yaml\nNAME: helm-dashboard\nLAST DEPLOYED: Mon Sep 25 22:43:38 2023\nNAMESPACE: helm\nSTATUS: deployed\nREVISION: 1\nNOTES:\nThank you for installing Helm Dashboard.\nHelm Dashboard can be accessed:\n  * Within your cluster, at the following DNS name at port 8080:\n\n    helm-dashboard.helm.svc.cluster.local\n\n  * From outside the cluster, run these commands in the same shell:\n\n    export POD_NAME=$(kubectl get pods --namespace helm -l \"app.kubernetes.io/name=helm-dashboard,app.kubernetes.io/instance=helm-dashboard\" -o jsonpath=\"{.items[0].metadata.name}\")\n    export CONTAINER_PORT=$(kubectl get pod --namespace helm $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n    echo \"Visit http://127.0.0.1:8080 to use your application\"\n    kubectl --namespace helm port-forward $POD_NAME 8080:$CONTAINER_PORT\n\nVisit our repo at:\nhttps://github.com/komodorio/helm-dashboard\n```\n\n<h2 id=\"16f6e13b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress资源</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例</font>\n\n```plain\n[root@master1 helm-dashboard]# cat ingress.yaml \napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: helm-dashboard\n  namespace: helm\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`helm.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: helm-dashboard  # 与svc的name一致\n        port: 8080     # 与svc的port一致\n[root@master1 helm-dashboard]# kubectl apply -f ingress.yaml \ningressroute.traefik.containo.us/helm-dashboard created\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts解析记录</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm.local.com 192.168.10.10</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问验证</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810479823-33abad4b-bb9a-4357-bcb1-f82eab6376f9.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n","source":"_posts/2.部署helm包管理工具.md","raw":"---\ntitle: 部署helm包管理工具\ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"f11a4b4f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Helm</font></h1>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">官方参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://helm.sh/docs/intro/quickstart/</font>](https://helm.sh/docs/intro/quickstart/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的安装方式有两种：预编译的二进制程序和源码编译安装。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Helm项目托管在GitHub之上，项目地址为</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/helm/helm/releases</font>](https://github.com/helm/helm/releases)<font style=\"background-color:rgba(255, 255, 255, 0);\">。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的运行依赖于本地安装并配置完成的kubectl方能与运行于Kubernetes集群之上的Tiller服务器进行通信，因此，运行Helm的节点也应该是可以正常使用kubectl命令的主机，或者至少是有着可用kubeconfig配置文件的主机。</font>\n\n<h2 id=\"552ec97e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载压缩包并解压</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# wget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz\n[root@k8s-master k8s-install]# tar -zxvf helm-v3.16.2-linux-amd64.tar.gz\n```\n\n<h2 id=\"85a7ab47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">移动到环境变量目录中</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# mv linux-amd64/helm /usr/local/bin/ \n# 加载环境变量\n[root@k8s-master k8s-install]# source <(helm completion bash) >> ~/.bash_profile \n[root@k8s-master k8s-install]# source ~/.bash_profile \n```\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# helm version\nversion.BuildInfo{Version:\"v3.16.2\", GitCommit:\"3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e\", GitTreeState:\"clean\", GoVersion:\"go1.20.7\"}\n```\n\n<h1 id=\"1c15269a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加Helm的官方仓库</font></h1>\n---\n\n<h2 id=\"6f3419de\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加官方Charts仓库</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# helm repo add stable https://charts.helm.sh/stable\n```\n\n<h2 id=\"00b7396e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看官方Charts仓库</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# helm search repo stable\n```\n\n<h1 id=\"083a9ea8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm dashboard</font></h1>\n<h2 id=\"b0ff454a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">前提条件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署nfs共享存储，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/116191364</font>](https://www.cuiliangblog.cn/detail/section/116191364)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署ingress，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/140101250</font>](https://www.cuiliangblog.cn/detail/section/140101250)\n\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n```plain\n[root@k8s-master k8s-install]# kubectl create ns helm\n[root@k8s-master k8s-install]# helm repo add komodorio https://helm-charts.komodor.io\n[root@master1 k8s-install]# helm pull komodorio/helm-dashboard --untar\n[root@master1 k8s-install]# cd helm-dashboard/\n[root@master1 helm-dashboard]# ls\nChart.yaml  README.md  templates  values.yaml\n[root@master1 helm-dashboard]# vim values.yaml\ndashboard:\n  persistence:\n    storageClass: nfs-client # 指定使用nfs存储\n[root@k8s-master k8s-install]# helm install helm-dashboard -n helm . -f values.yaml\nNAME: helm-dashboard\nLAST DEPLOYED: Mon Sep 25 22:43:38 2023\nNAMESPACE: helm\nSTATUS: deployed\nREVISION: 1\nNOTES:\nThank you for installing Helm Dashboard.\nHelm Dashboard can be accessed:\n  * Within your cluster, at the following DNS name at port 8080:\n\n    helm-dashboard.helm.svc.cluster.local\n\n  * From outside the cluster, run these commands in the same shell:\n\n    export POD_NAME=$(kubectl get pods --namespace helm -l \"app.kubernetes.io/name=helm-dashboard,app.kubernetes.io/instance=helm-dashboard\" -o jsonpath=\"{.items[0].metadata.name}\")\n    export CONTAINER_PORT=$(kubectl get pod --namespace helm $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n    echo \"Visit http://127.0.0.1:8080 to use your application\"\n    kubectl --namespace helm port-forward $POD_NAME 8080:$CONTAINER_PORT\n\nVisit our repo at:\nhttps://github.com/komodorio/helm-dashboard\n```\n\n<h2 id=\"16f6e13b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress资源</font></h2>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例</font>\n\n```plain\n[root@master1 helm-dashboard]# cat ingress.yaml \napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: helm-dashboard\n  namespace: helm\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`helm.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: helm-dashboard  # 与svc的name一致\n        port: 8080     # 与svc的port一致\n[root@master1 helm-dashboard]# kubectl apply -f ingress.yaml \ningressroute.traefik.containo.us/helm-dashboard created\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts解析记录</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm.local.com 192.168.10.10</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问验证</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810479823-33abad4b-bb9a-4357-bcb1-f82eab6376f9.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n","slug":"2.部署helm包管理工具","published":1,"updated":"2025-03-30T13:10:15.127Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjln000htsv1fxyd2a08","content":"<h1 id=\"f11a4b4f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Helm</font></h1>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">官方参考文档：</font><a href=\"https://helm.sh/docs/intro/quickstart/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://helm.sh/docs/intro/quickstart/</font></a></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的安装方式有两种：预编译的二进制程序和源码编译安装。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm项目托管在GitHub之上，项目地址为</font><a href=\"https://github.com/helm/helm/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/helm/helm/releases</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的运行依赖于本地安装并配置完成的kubectl方能与运行于Kubernetes集群之上的Tiller服务器进行通信，因此，运行Helm的节点也应该是可以正常使用kubectl命令的主机，或者至少是有着可用kubeconfig配置文件的主机。</font></li>\n</ul>\n<h2 id=\"552ec97e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载压缩包并解压</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# wget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz</span><br><span class=\"line\">[root@k8s-master k8s-install]# tar -zxvf helm-v3.16.2-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"85a7ab47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">移动到环境变量目录中</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# mv linux-amd64/helm /usr/local/bin/ </span><br><span class=\"line\"># 加载环境变量</span><br><span class=\"line\">[root@k8s-master k8s-install]# source &lt;(helm completion bash) &gt;&gt; ~/.bash_profile </span><br><span class=\"line\">[root@k8s-master k8s-install]# source ~/.bash_profile </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# helm version</span><br><span class=\"line\">version.BuildInfo&#123;Version:&quot;v3.16.2&quot;, GitCommit:&quot;3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.20.7&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"1c15269a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加Helm的官方仓库</font></h1>\n---\n\n<h2 id=\"6f3419de\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加官方Charts仓库</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# helm repo add stable https://charts.helm.sh/stable</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"00b7396e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看官方Charts仓库</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# helm search repo stable</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"083a9ea8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm dashboard</font></h1>\n<h2 id=\"b0ff454a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">前提条件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署nfs共享存储，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/116191364</font>](https://www.cuiliangblog.cn/detail/section/116191364)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署ingress，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/140101250</font>](https://www.cuiliangblog.cn/detail/section/140101250)\n\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# kubectl create ns helm</span><br><span class=\"line\">[root@k8s-master k8s-install]# helm repo add komodorio https://helm-charts.komodor.io</span><br><span class=\"line\">[root@master1 k8s-install]# helm pull komodorio/helm-dashboard --untar</span><br><span class=\"line\">[root@master1 k8s-install]# cd helm-dashboard/</span><br><span class=\"line\">[root@master1 helm-dashboard]# ls</span><br><span class=\"line\">Chart.yaml  README.md  templates  values.yaml</span><br><span class=\"line\">[root@master1 helm-dashboard]# vim values.yaml</span><br><span class=\"line\">dashboard:</span><br><span class=\"line\">  persistence:</span><br><span class=\"line\">    storageClass: nfs-client # 指定使用nfs存储</span><br><span class=\"line\">[root@k8s-master k8s-install]# helm install helm-dashboard -n helm . -f values.yaml</span><br><span class=\"line\">NAME: helm-dashboard</span><br><span class=\"line\">LAST DEPLOYED: Mon Sep 25 22:43:38 2023</span><br><span class=\"line\">NAMESPACE: helm</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Thank you for installing Helm Dashboard.</span><br><span class=\"line\">Helm Dashboard can be accessed:</span><br><span class=\"line\">  * Within your cluster, at the following DNS name at port 8080:</span><br><span class=\"line\"></span><br><span class=\"line\">    helm-dashboard.helm.svc.cluster.local</span><br><span class=\"line\"></span><br><span class=\"line\">  * From outside the cluster, run these commands in the same shell:</span><br><span class=\"line\"></span><br><span class=\"line\">    export POD_NAME=$(kubectl get pods --namespace helm -l &quot;app.kubernetes.io/name=helm-dashboard,app.kubernetes.io/instance=helm-dashboard&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class=\"line\">    export CONTAINER_PORT=$(kubectl get pod --namespace helm $POD_NAME -o jsonpath=&quot;&#123;.spec.containers[0].ports[0].containerPort&#125;&quot;)</span><br><span class=\"line\">    echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class=\"line\">    kubectl --namespace helm port-forward $POD_NAME 8080:$CONTAINER_PORT</span><br><span class=\"line\"></span><br><span class=\"line\">Visit our repo at:</span><br><span class=\"line\">https://github.com/komodorio/helm-dashboard</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"16f6e13b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress资源</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 helm-dashboard]# cat ingress.yaml </span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: helm-dashboard</span><br><span class=\"line\">  namespace: helm</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`helm.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: helm-dashboard  # 与svc的name一致</span><br><span class=\"line\">        port: 8080     # 与svc的port一致</span><br><span class=\"line\">[root@master1 helm-dashboard]# kubectl apply -f ingress.yaml </span><br><span class=\"line\">ingressroute.traefik.containo.us/helm-dashboard created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts解析记录</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;helm.local.com 192.168.10.10&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问验证</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810479823-33abad4b-bb9a-4357-bcb1-f82eab6376f9.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n","excerpt":"","more":"<h1 id=\"f11a4b4f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装Helm</font></h1>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">官方参考文档：</font><a href=\"https://helm.sh/docs/intro/quickstart/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://helm.sh/docs/intro/quickstart/</font></a></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的安装方式有两种：预编译的二进制程序和源码编译安装。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm项目托管在GitHub之上，项目地址为</font><a href=\"https://github.com/helm/helm/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/helm/helm/releases</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm的运行依赖于本地安装并配置完成的kubectl方能与运行于Kubernetes集群之上的Tiller服务器进行通信，因此，运行Helm的节点也应该是可以正常使用kubectl命令的主机，或者至少是有着可用kubeconfig配置文件的主机。</font></li>\n</ul>\n<h2 id=\"552ec97e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载压缩包并解压</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# wget https://get.helm.sh/helm-v3.16.2-linux-amd64.tar.gz</span><br><span class=\"line\">[root@k8s-master k8s-install]# tar -zxvf helm-v3.16.2-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"85a7ab47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">移动到环境变量目录中</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# mv linux-amd64/helm /usr/local/bin/ </span><br><span class=\"line\"># 加载环境变量</span><br><span class=\"line\">[root@k8s-master k8s-install]# source &lt;(helm completion bash) &gt;&gt; ~/.bash_profile </span><br><span class=\"line\">[root@k8s-master k8s-install]# source ~/.bash_profile </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"cd8992b6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# helm version</span><br><span class=\"line\">version.BuildInfo&#123;Version:&quot;v3.16.2&quot;, GitCommit:&quot;3a31588ad33fe3b89af5a2a54ee1d25bfe6eaa5e&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.20.7&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"1c15269a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加Helm的官方仓库</font></h1>\n---\n\n<h2 id=\"6f3419de\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加官方Charts仓库</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# helm repo add stable https://charts.helm.sh/stable</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"00b7396e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看官方Charts仓库</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# helm search repo stable</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"083a9ea8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm dashboard</font></h1>\n<h2 id=\"b0ff454a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">前提条件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署nfs共享存储，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/116191364</font>](https://www.cuiliangblog.cn/detail/section/116191364)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">部署ingress，参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://www.cuiliangblog.cn/detail/section/140101250</font>](https://www.cuiliangblog.cn/detail/section/140101250)\n\n<h2 id=\"a9f94dcd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# kubectl create ns helm</span><br><span class=\"line\">[root@k8s-master k8s-install]# helm repo add komodorio https://helm-charts.komodor.io</span><br><span class=\"line\">[root@master1 k8s-install]# helm pull komodorio/helm-dashboard --untar</span><br><span class=\"line\">[root@master1 k8s-install]# cd helm-dashboard/</span><br><span class=\"line\">[root@master1 helm-dashboard]# ls</span><br><span class=\"line\">Chart.yaml  README.md  templates  values.yaml</span><br><span class=\"line\">[root@master1 helm-dashboard]# vim values.yaml</span><br><span class=\"line\">dashboard:</span><br><span class=\"line\">  persistence:</span><br><span class=\"line\">    storageClass: nfs-client # 指定使用nfs存储</span><br><span class=\"line\">[root@k8s-master k8s-install]# helm install helm-dashboard -n helm . -f values.yaml</span><br><span class=\"line\">NAME: helm-dashboard</span><br><span class=\"line\">LAST DEPLOYED: Mon Sep 25 22:43:38 2023</span><br><span class=\"line\">NAMESPACE: helm</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Thank you for installing Helm Dashboard.</span><br><span class=\"line\">Helm Dashboard can be accessed:</span><br><span class=\"line\">  * Within your cluster, at the following DNS name at port 8080:</span><br><span class=\"line\"></span><br><span class=\"line\">    helm-dashboard.helm.svc.cluster.local</span><br><span class=\"line\"></span><br><span class=\"line\">  * From outside the cluster, run these commands in the same shell:</span><br><span class=\"line\"></span><br><span class=\"line\">    export POD_NAME=$(kubectl get pods --namespace helm -l &quot;app.kubernetes.io/name=helm-dashboard,app.kubernetes.io/instance=helm-dashboard&quot; -o jsonpath=&quot;&#123;.items[0].metadata.name&#125;&quot;)</span><br><span class=\"line\">    export CONTAINER_PORT=$(kubectl get pod --namespace helm $POD_NAME -o jsonpath=&quot;&#123;.spec.containers[0].ports[0].containerPort&#125;&quot;)</span><br><span class=\"line\">    echo &quot;Visit http://127.0.0.1:8080 to use your application&quot;</span><br><span class=\"line\">    kubectl --namespace helm port-forward $POD_NAME 8080:$CONTAINER_PORT</span><br><span class=\"line\"></span><br><span class=\"line\">Visit our repo at:</span><br><span class=\"line\">https://github.com/komodorio/helm-dashboard</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"16f6e13b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加ingress资源</font></h2>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 helm-dashboard]# cat ingress.yaml </span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: helm-dashboard</span><br><span class=\"line\">  namespace: helm</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`helm.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: helm-dashboard  # 与svc的name一致</span><br><span class=\"line\">        port: 8080     # 与svc的port一致</span><br><span class=\"line\">[root@master1 helm-dashboard]# kubectl apply -f ingress.yaml </span><br><span class=\"line\">ingressroute.traefik.containo.us/helm-dashboard created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts解析记录</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;helm.local.com 192.168.10.10&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">，然后访问验证</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810479823-33abad4b-bb9a-4357-bcb1-f82eab6376f9.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n"},{"title":"存储类型","date":"2025-03-17T10:00:00.000Z","_content":"<h1 id=\"731db23c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">块存储</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">块存储是一种低级别的数据存储方式，它将数据分成固定大小的块，每个块都有独立的地址。块存储通常用于需要快速读写数据的场景，如数据库、虚拟机磁盘和操作系统磁盘。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217458-6f2a3d55-beb1-4a9a-bfe1-201a34f4d7f5.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如图所示，如果我们通过 web01 服务器往存储设备里面写入数据，写入存储设备的数据会先通过 web01 的缓冲区。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果数据存储在 web01 缓冲区的这个时间段，web02 服务器需要访问 web01 写入的数据，这个时候 web02 服务器的本地缓存、本地硬盘和存储设备的硬盘都没有 web01 写入的数据，这就会出现数据不一致的问题。</font>\n\n<h2 id=\"b4d3c72e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">提供类似硬盘的存储结构，应用程序可以直接读取和写入存储块。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能，适用于需要快速访问数据的应用。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">块级存储系统允许多种文件系统（如EXT4、NTFS等）来管理数据。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">一般通过网络或专用存储硬件提供（如iSCSI、Fibre Channel等）。</font>\n\n<h2 id=\"3dbf0c11\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据库存储（高性能要求的数据库）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟化环境中虚拟机的磁盘。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统级别的存储需求。</font>\n\n<h1 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储是基于传统文件系统的存储方式，它将数据存储为文件，并通过目录结构进行组织。用户可以通过文件路径来访问数据。常见的文件存储系统包括网络附加存储（NAS）和本地文件系统。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217327-19543b71-b8ab-477c-a0d4-c1fb5c3087f8.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在存储设备划分出一个硬盘，将划分出的硬盘制作成文件系统，将文件系统挂载到/code 目录下，客户端在使用的时候，直接关联的时存储设备的/code 目录。不同于块存储的方式，存储设备的检索过程是在存储设备里面完成的。</font>\n\n<h2 id=\"b4d3c72e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">以文件为单位进行存储，文件有路径、名称等属性。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">支持文件夹和目录结构，适用于传统的文件管理。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">适合需要共享和多用户访问的场景。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储通常通过NFS、SMB等协议进行访问。</font>\n\n<h2 id=\"3dbf0c11-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件共享和协作办公。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多用户文件访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">企业内部的文档存储和管理。</font>\n\n<h1 id=\"74cef116\"><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储是一种基于对象的数据存储方式，它将数据封装成对象，每个对象包括数据本身、元数据和唯一的标识符。对象存储系统通常用于存储大量非结构化数据，如图片、视频、备份数据和日志。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217305-4fbfe4ed-eb88-487f-afd7-06e778cdc7e9.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储没有文件系统的概念，不会随着客户端数量的增多而造成压力的成倍增长。数据的存储分为元数据 +实际数据，类似 key:value 形式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">客户端访问存储设备是通过 url 地址进行访问的。</font>\n\n<h2 id=\"b4d3c72e-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储为对象而不是文件或块，每个对象有唯一的ID进行访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高度扩展性，能够存储大量数据，适合大规模存储需求。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储通常不需要特定的文件系统支持，数据存储在分布式系统中。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">通过HTTP API进行访问，如AWS S3、Azure Blob Storage等。</font>\n\n<h2 id=\"3dbf0c11-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">云存储和备份。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">媒体文件存储（如图片、视频、音频）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">日志和大数据分析。</font>\n\n","source":"_posts/3.存储类型 副本.md","raw":"---\ntitle: 存储类型\ndate: 2025-03-17 18:00:00\n---\n<h1 id=\"731db23c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">块存储</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">块存储是一种低级别的数据存储方式，它将数据分成固定大小的块，每个块都有独立的地址。块存储通常用于需要快速读写数据的场景，如数据库、虚拟机磁盘和操作系统磁盘。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217458-6f2a3d55-beb1-4a9a-bfe1-201a34f4d7f5.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如图所示，如果我们通过 web01 服务器往存储设备里面写入数据，写入存储设备的数据会先通过 web01 的缓冲区。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果数据存储在 web01 缓冲区的这个时间段，web02 服务器需要访问 web01 写入的数据，这个时候 web02 服务器的本地缓存、本地硬盘和存储设备的硬盘都没有 web01 写入的数据，这就会出现数据不一致的问题。</font>\n\n<h2 id=\"b4d3c72e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">提供类似硬盘的存储结构，应用程序可以直接读取和写入存储块。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能，适用于需要快速访问数据的应用。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">块级存储系统允许多种文件系统（如EXT4、NTFS等）来管理数据。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">一般通过网络或专用存储硬件提供（如iSCSI、Fibre Channel等）。</font>\n\n<h2 id=\"3dbf0c11\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据库存储（高性能要求的数据库）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟化环境中虚拟机的磁盘。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统级别的存储需求。</font>\n\n<h1 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储是基于传统文件系统的存储方式，它将数据存储为文件，并通过目录结构进行组织。用户可以通过文件路径来访问数据。常见的文件存储系统包括网络附加存储（NAS）和本地文件系统。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217327-19543b71-b8ab-477c-a0d4-c1fb5c3087f8.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在存储设备划分出一个硬盘，将划分出的硬盘制作成文件系统，将文件系统挂载到/code 目录下，客户端在使用的时候，直接关联的时存储设备的/code 目录。不同于块存储的方式，存储设备的检索过程是在存储设备里面完成的。</font>\n\n<h2 id=\"b4d3c72e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">以文件为单位进行存储，文件有路径、名称等属性。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">支持文件夹和目录结构，适用于传统的文件管理。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">适合需要共享和多用户访问的场景。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储通常通过NFS、SMB等协议进行访问。</font>\n\n<h2 id=\"3dbf0c11-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件共享和协作办公。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多用户文件访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">企业内部的文档存储和管理。</font>\n\n<h1 id=\"74cef116\"><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储是一种基于对象的数据存储方式，它将数据封装成对象，每个对象包括数据本身、元数据和唯一的标识符。对象存储系统通常用于存储大量非结构化数据，如图片、视频、备份数据和日志。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217305-4fbfe4ed-eb88-487f-afd7-06e778cdc7e9.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储没有文件系统的概念，不会随着客户端数量的增多而造成压力的成倍增长。数据的存储分为元数据 +实际数据，类似 key:value 形式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">客户端访问存储设备是通过 url 地址进行访问的。</font>\n\n<h2 id=\"b4d3c72e-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储为对象而不是文件或块，每个对象有唯一的ID进行访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高度扩展性，能够存储大量数据，适合大规模存储需求。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储通常不需要特定的文件系统支持，数据存储在分布式系统中。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">通过HTTP API进行访问，如AWS S3、Azure Blob Storage等。</font>\n\n<h2 id=\"3dbf0c11-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">云存储和备份。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">媒体文件存储（如图片、视频、音频）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">日志和大数据分析。</font>\n\n","slug":"3.存储类型 副本","published":1,"updated":"2025-03-30T13:18:19.079Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlo000itsv1cugg6f0h","content":"<h1 id=\"731db23c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">块存储</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">块存储是一种低级别的数据存储方式，它将数据分成固定大小的块，每个块都有独立的地址。块存储通常用于需要快速读写数据的场景，如数据库、虚拟机磁盘和操作系统磁盘。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217458-6f2a3d55-beb1-4a9a-bfe1-201a34f4d7f5.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如图所示，如果我们通过 web01 服务器往存储设备里面写入数据，写入存储设备的数据会先通过 web01 的缓冲区。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果数据存储在 web01 缓冲区的这个时间段，web02 服务器需要访问 web01 写入的数据，这个时候 web02 服务器的本地缓存、本地硬盘和存储设备的硬盘都没有 web01 写入的数据，这就会出现数据不一致的问题。</font></p>\n<h2 id=\"b4d3c72e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">提供类似硬盘的存储结构，应用程序可以直接读取和写入存储块。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能，适用于需要快速访问数据的应用。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">块级存储系统允许多种文件系统（如EXT4、NTFS等）来管理数据。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">一般通过网络或专用存储硬件提供（如iSCSI、Fibre Channel等）。</font>\n\n<h2 id=\"3dbf0c11\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据库存储（高性能要求的数据库）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟化环境中虚拟机的磁盘。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统级别的存储需求。</font>\n\n<h1 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储是基于传统文件系统的存储方式，它将数据存储为文件，并通过目录结构进行组织。用户可以通过文件路径来访问数据。常见的文件存储系统包括网络附加存储（NAS）和本地文件系统。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217327-19543b71-b8ab-477c-a0d4-c1fb5c3087f8.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在存储设备划分出一个硬盘，将划分出的硬盘制作成文件系统，将文件系统挂载到&#x2F;code 目录下，客户端在使用的时候，直接关联的时存储设备的&#x2F;code 目录。不同于块存储的方式，存储设备的检索过程是在存储设备里面完成的。</font></p>\n<h2 id=\"b4d3c72e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">以文件为单位进行存储，文件有路径、名称等属性。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">支持文件夹和目录结构，适用于传统的文件管理。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">适合需要共享和多用户访问的场景。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储通常通过NFS、SMB等协议进行访问。</font>\n\n<h2 id=\"3dbf0c11-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件共享和协作办公。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多用户文件访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">企业内部的文档存储和管理。</font>\n\n<h1 id=\"74cef116\"><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储是一种基于对象的数据存储方式，它将数据封装成对象，每个对象包括数据本身、元数据和唯一的标识符。对象存储系统通常用于存储大量非结构化数据，如图片、视频、备份数据和日志。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217305-4fbfe4ed-eb88-487f-afd7-06e778cdc7e9.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储没有文件系统的概念，不会随着客户端数量的增多而造成压力的成倍增长。数据的存储分为元数据 +实际数据，类似 key:value 形式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">客户端访问存储设备是通过 url 地址进行访问的。</font></p>\n<h2 id=\"b4d3c72e-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储为对象而不是文件或块，每个对象有唯一的ID进行访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高度扩展性，能够存储大量数据，适合大规模存储需求。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储通常不需要特定的文件系统支持，数据存储在分布式系统中。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">通过HTTP API进行访问，如AWS S3、Azure Blob Storage等。</font>\n\n<h2 id=\"3dbf0c11-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">云存储和备份。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">媒体文件存储（如图片、视频、音频）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">日志和大数据分析。</font>\n\n","excerpt":"","more":"<h1 id=\"731db23c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">块存储</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">块存储是一种低级别的数据存储方式，它将数据分成固定大小的块，每个块都有独立的地址。块存储通常用于需要快速读写数据的场景，如数据库、虚拟机磁盘和操作系统磁盘。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217458-6f2a3d55-beb1-4a9a-bfe1-201a34f4d7f5.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如图所示，如果我们通过 web01 服务器往存储设备里面写入数据，写入存储设备的数据会先通过 web01 的缓冲区。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果数据存储在 web01 缓冲区的这个时间段，web02 服务器需要访问 web01 写入的数据，这个时候 web02 服务器的本地缓存、本地硬盘和存储设备的硬盘都没有 web01 写入的数据，这就会出现数据不一致的问题。</font></p>\n<h2 id=\"b4d3c72e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">提供类似硬盘的存储结构，应用程序可以直接读取和写入存储块。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高性能，适用于需要快速访问数据的应用。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">块级存储系统允许多种文件系统（如EXT4、NTFS等）来管理数据。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">一般通过网络或专用存储硬件提供（如iSCSI、Fibre Channel等）。</font>\n\n<h2 id=\"3dbf0c11\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据库存储（高性能要求的数据库）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">虚拟化环境中虚拟机的磁盘。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件系统级别的存储需求。</font>\n\n<h1 id=\"ca1b68a5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储是基于传统文件系统的存储方式，它将数据存储为文件，并通过目录结构进行组织。用户可以通过文件路径来访问数据。常见的文件存储系统包括网络附加存储（NAS）和本地文件系统。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217327-19543b71-b8ab-477c-a0d4-c1fb5c3087f8.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在存储设备划分出一个硬盘，将划分出的硬盘制作成文件系统，将文件系统挂载到&#x2F;code 目录下，客户端在使用的时候，直接关联的时存储设备的&#x2F;code 目录。不同于块存储的方式，存储设备的检索过程是在存储设备里面完成的。</font></p>\n<h2 id=\"b4d3c72e-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">以文件为单位进行存储，文件有路径、名称等属性。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">支持文件夹和目录结构，适用于传统的文件管理。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">适合需要共享和多用户访问的场景。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件存储通常通过NFS、SMB等协议进行访问。</font>\n\n<h2 id=\"3dbf0c11-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">文件共享和协作办公。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多用户文件访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">企业内部的文档存储和管理。</font>\n\n<h1 id=\"74cef116\"><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储是一种基于对象的数据存储方式，它将数据封装成对象，每个对象包括数据本身、元数据和唯一的标识符。对象存储系统通常用于存储大量非结构化数据，如图片、视频、备份数据和日志。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738853217305-4fbfe4ed-eb88-487f-afd7-06e778cdc7e9.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储没有文件系统的概念，不会随着客户端数量的增多而造成压力的成倍增长。数据的存储分为元数据 +实际数据，类似 key:value 形式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">客户端访问存储设备是通过 url 地址进行访问的。</font></p>\n<h2 id=\"b4d3c72e-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储为对象而不是文件或块，每个对象有唯一的ID进行访问。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">高度扩展性，能够存储大量数据，适合大规模存储需求。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">对象存储通常不需要特定的文件系统支持，数据存储在分布式系统中。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">通过HTTP API进行访问，如AWS S3、Azure Blob Storage等。</font>\n\n<h2 id=\"3dbf0c11-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">应用场景</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">云存储和备份。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">媒体文件存储（如图片、视频、音频）。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">日志和大数据分析。</font>\n\n"},{"title":"ETCD--常用命令","date":"2025-03-05T11:08:06.000Z","_content":"<h2 id=\"dd367c2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群管理命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl是一个</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">命令行的客户端</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">，它提供了一些命令，可以方便我们在对服务进行测试或者手动修改数据库内容。etcdctl命令基本用法如下所示：</font>\n\n```plain\netcdctl [global options] command [command options] [args...]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">具体的命令选项参数可以通过 etcdctl command --help来获取相关帮助</font>\n\n<h3 id=\"3867e350\"><font style=\"background-color:rgba(255, 255, 255, 0);\">环境变量</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果遇到使用了TLS加密的集群，通常每条指令都需要指定证书路径和etcd节点地址，可以把相关命令行参数添加在环境变量中，在**~/.bashrc**添加以下内容：</font>\n\n```plain\n[root@tiaoban etcd]# cat ~/.bashrc\nHOST_1=https://192.168.10.100:2379\nHOST_2=https://192.168.10.11:2379\nHOST_3=https://192.168.10.12:2379\nENDPOINTS=${HOST_1},${HOST_2},${HOST_3}\n# 如果需要使用原生命令，在命令开头加一个\\ 例如：\\etcdctl command\nalias etcdctl=\"etcdctl --endpoints=${ENDPOINTS} --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem\"\nalias etcdctljson=\"etcdctl --endpoints=${ENDPOINTS} --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=json\"\nalias etcdctltable=\"etcdctl --endpoints=${ENDPOINTS} --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=table\"\n[root@tiaoban etcd]# source ~/.bashrc\n```\n\n<h3 id=\"c66c9b5d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd版本</font></h3>\n```plain\n[root@tiaoban etcd]# etcdctl version\netcdctl version: 3.4.23\nAPI version: 3.4\n```\n\n<h3 id=\"e65806ec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd集群节点信息</font></h3>\n```plain\n[root@tiaoban ~]# etcdctl member list -w table\n+------------------+---------+-------+----------------------------+----------------------------+------------+\n|        ID        | STATUS  | NAME  |         PEER ADDRS         |        CLIENT ADDRS        | IS LEARNER |\n+------------------+---------+-------+----------------------------+----------------------------+------------+\n| 2e0eda3ad6bc6e1e | started | etcd1 | http://192.168.10.100:2380 | http://192.168.10.100:2379 |      false |\n| 5d2c1bd3b22f796f | started | etcd3 |  http://192.168.10.12:2380 |  http://192.168.10.12:2379 |      false |\n| bc34c6bd673bdf9f | started | etcd2 |  http://192.168.10.11:2380 |  http://192.168.10.11:2379 |      false |\n+------------------+---------+-------+----------------------------+----------------------------+------------+\n```\n\n<h3 id=\"bcf18e5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群健康状态</font></h3>\n```plain\n[root@tiaoban ~]# etcdctl endpoint status -w table\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |          9 |                  9 |        |\n|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |\n|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@tiaoban ~]# etcdctl endpoint health -w table\n+---------------------+--------+------------+-------+\n|      ENDPOINT       | HEALTH |    TOOK    | ERROR |\n+---------------------+--------+------------+-------+\n| 192.168.10.100:2379 |   true | 4.391924ms |       |\n|  192.168.10.11:2379 |   true | 7.091404ms |       |\n|  192.168.10.12:2379 |   true | 7.571706ms |       |\n+---------------------+--------+------------+-------+\n```\n\n<h3 id=\"cd2c454b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看告警事件</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果内部出现问题，会触发告警，可以通过命令查看告警引起原因，命令如下所示：</font>\n\n```plain\netcdctl alarm <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用的子命令主要有两个：</font>\n\n```plain\n# 查看所有告警\netcdctl alarm list\n# 解除所有告警\netcdctl alarm disarm\n```\n\n<h3 id=\"c3514e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当集群部署完成后，后续可能需要进行节点扩缩容，就可以使用member命令管理节点。先查看当前集群信息</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         8 |         16 |                 16 |        |\n|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |\n|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在启动新的etcd节点前，先向etcd集群声明添加节点的peer-urls和节点名称</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl member add etcd4 --peer-urls=http://192.168.10.100:12380\nMember b112a60ec305e42a added to cluster cd30cff36981306b\n\nETCD_NAME=\"etcd4\"\nETCD_INITIAL_CLUSTER=\"etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:12380,etcd2=http://192.168.10.11:2380\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.10.100:12380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\n```\n\n```plain\n[root@tiaoban etcd]# mkdir -p /opt/docker/etcd/{conf,data}\n[root@tiaoban etcd]# chown -R 1001:1001 /opt/docker/etcd/data/\n[root@tiaoban etcd]# cat /opt/docker/etcd/conf/etcd.conf \n# 节点名称\nname: 'etcd4'\n# 指定节点的数据存储目录\ndata-dir: '/data'\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.100:12379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.100:12380\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.100:12379\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.100:12380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd2=http://192.168.10.11:2380,etcd4=http://192.168.10.100:12380\"\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'existing'\n[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf\na142f38c785f2b7c217fb15f01ac62addfeb22eeb44da00363b1f7b5ce398439\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd4启动后，查看集群节点信息：</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         11 |                 11 |        |\n|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |\n| http://192.168.10.100:12379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |\n|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<h3 id=\"8456c2a4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当etcd节点故障，启动etcd时报错</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">**member count is unequal**</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">。如果有保留的数据目录下的文件时，可以通过使用 member update 命令，在保留 etcd 数据的情况下初始化集群数据，重新构建一个新的etcd集群节点。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:12380节点故障，但数据目录文件有备份，启动一个新的节点，地址为：192.168.10.100:22380</font>\n\n```plain\n# 停用旧节点\n[root@tiaoban etcd]# docker stop etcd4\netcd4\n[root@tiaoban etcd]# docker rm etcd4\netcd4\n\n# 更新节点地址\n[root@tiaoban etcd]# cat conf/etcd.conf \n# 节点名称\nname: 'etcd4'\n# 指定节点的数据存储目录\ndata-dir: '/data'\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.100:22379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.100:22380\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.100:22379\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.100:22380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:22380\"\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'existing'\n\n# 启动新节点\n[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:3.4.23 etcd --config-file /conf/etcd.conf\n03c03ac7e6b50a8600cefe443ecafdb03f8f61f153b1a1138029c1726826d74e\n[root@tiaoban etcd]# docker ps\nCONTAINER ID   IMAGE                 COMMAND                   CREATED         STATUS         PORTS     NAMES\n03c03ac7e6b5   bitnami/etcd:3.4.23   \"/opt/bitnami/script…\"   3 seconds ago   Up 3 seconds             etcd4\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">执行更新member操作，指定新的节点地址。</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl member update b112a60ec305e42a --peer-urls=http://192.168.10.100:22380\nMember b112a60ec305e42a updated in cluster cd30cff36981306b\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群节点信息，节点信息更新完成。</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         14 |                 14 |        |\n|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |\n| http://192.168.10.100:22379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |\n|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<h3 id=\"93020cb7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl member remove <memberID> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:22379节点下线操作</font>\n\n```plain\n[root@tiaoban etcd]# docker stop etcd4\netcd4\n[root@tiaoban etcd]# docker rm etcd4\netcd4\n[root@tiaoban etcd]# etcdctl member remove b112a60ec305e42a\nMember b112a60ec305e42a removed from cluster cd30cff36981306b\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         16 |                 16 |        |\n|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |\n|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<h2 id=\"f4ce7445\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据库操作命令</font></h2>\n---\n\n<h3 id=\"7b67e8eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">增加(put)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加一个键值，基本用法如下所示：</font>\n\n```plain\netcdctl put [options] <key> <value> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">输出修改前的键值</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">其中value接受从stdin的输入内容</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果value是以横线-开始，将会被视为flag，如果不希望出现这种情况，可以使用两个横线代替–</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl put name cuiliang\nOK\n[root@tiaoban etcd]# etcdctl put location -- -beijing\nOK\n[root@tiaoban etcd]# etcdctl put foo1 bar1\nOK\n[root@tiaoban etcd]# etcdctl put foo2 bar2\nOK\n[root@tiaoban etcd]# etcdctl put foo3 bar3\nOK\n```\n\n<h3 id=\"b9026f46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询(get)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查询键值，基本用法如下所示：</font>\n\n```plain\netcdctl get [options] <key> [range_end] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–hex</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">以十六进制形式输出</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–limit number</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">设置输出结果的最大值</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配key</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–order</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对输出结果进行排序，ASCEND 或 DESCEND</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–sort-by</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">按给定字段排序，CREATE, KEY, MODIFY, VALUE, VERSION</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–print-value-only</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">仅输出value值</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，获取大于等于指定key的结果</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–keys-only</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">仅获取keys</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n```plain\n# 获取键值\n[root@tiaoban etcd]# etcdctl get name\nname\ncuiliang\n# 只获取值\n[root@tiaoban etcd]# etcdctl get location --print-value-only\n-beijing\n# 批量取从foo1到foo3的值，不包括foo3\n[root@tiaoban etcd]# etcdctl get foo foo3 --print-value-only\nbar1\nbar2\n# 批量获取前缀为foo的值\n[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only\nbar1\nbar2\nbar3\n# 批量获取符合前缀的前两个值\n[root@tiaoban etcd]# etcdctl get --prefix --limit=2 foo --print-value-only\nbar1\nbar2\n# 批量获取前缀为foo的值，并排序\n[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only --order DESCEND\nbar3\nbar2\nbar1\n```\n\n<h3 id=\"800a3375\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除(del)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除键值，基本用法如下所示：</font>\n\n```plain\netcdctl del [options] <key> [range_end] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配删除</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">输出删除的键值</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，删除大于等于指定key的结果</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n```plain\n# 删除name的键值\n[root@tiaoban etcd]# etcdctl del name\n1\n# 删除从foo1到foo3且不包含foo3的键值\n[root@tiaoban etcd]# etcdctl del foo1 foo3\n2\n# 删除前缀为foo的所有键值\n[root@tiaoban etcd]# etcdctl del --prefix foo\n1\n```\n\n<h3 id=\"1e15cca4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新(put覆盖)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加。</font>\n\n<h3 id=\"9634c1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询键历史记录查询</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd在每次键值变更时，都会记录变更信息，便于我们查看键变更记录</font>\n\n<h2 id=\"2c1031f0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">watch是监听键或前缀发生改变的事件流， 主要用法如下所示：</font>\n\n```plain\netcdctl watch [options] [key or prefix] [range_end] [--] [exec-command arg1 arg2 ...] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\n# 对某个key监听操作，当key1发生改变时，会返回最新值\netcdctl watch name\n# 监听key前缀\netcdctl watch name --prefix\n# 监听到改变后执行相关操作\netcdctl watch name --  etcdctl get age\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl watch name – etcdctl put name Kevin，如果写成，会不会变成死循环，导致无限监视，尽量避免。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n<h3 id=\"beae6e09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听单个键</font></h3>\n```plain\n# 启动监听命令\n[root@tiaoban etcd]# etcdctl watch foo\n\n#另一个控制台执行新增命令\n[root@tiaoban ~]# etcdctl put foo bar\nOK\n\n# 观察控制台监听输出\n[root@tiaoban etcd]# etcdctl watch foo\nPUT\nfoo\nbar\n\n#另一个控制台执行更新命令\n[root@tiaoban ~]# etcdctl put foo bar123\nOK\n\n# 观察控制台监听输出\n[root@tiaoban etcd]# etcdctl watch foo\nPUT\nfoo\nbar\nPUT\nfoo\nbar123\n\n#另一个控制台执行删除命令\n[root@tiaoban ~]# etcdctl del foo\n1\n\n# 观察控制台监听输出\n[root@tiaoban etcd]# etcdctl watch foo\nPUT\nfoo\nbar\nPUT\nfoo\nbar123\nDELETE\nfoo\n```\n\n<h3 id=\"8545b8fc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">同时监听多个键</font></h3>\n```plain\n# 监听前缀为foo的键\n[root@tiaoban etcd]# etcdctl watch --prefix foo\n# 另一个控制台执行操作\n[root@tiaoban ~]# etcdctl put foo1 bar1\nOK\n[root@tiaoban ~]# etcdctl put foo2 bar2\nOK\n[root@tiaoban ~]# etcdctl del foo1\n1\n# 观察控制台输出\n[root@tiaoban etcd]# etcdctl watch --prefix foo\nPUT\nfoo1\nbar1\nPUT\nfoo2\nbar2\nDELETE\nfoo1\n\n\n# 监听指定的多个键\n[root@tiaoban etcd]# etcdctl watch -i\nwatch name\nwatch location\n\n# 另一个控制台执行操作\n[root@tiaoban ~]# etcdctl put name cuiliang\nOK\n[root@tiaoban ~]# etcdctl del name\n1\n[root@tiaoban ~]# etcdctl put location beijing\nOK\n# 观察控制台输出\n[root@tiaoban etcd]# etcdctl watch -i\nwatch name\nwatch location\nPUT\nname\ncuiliang\nDELETE\nname\n\nPUT\nlocation\nbeijing\n```\n\n<h2 id=\"dc4e3ec3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">租约具有生命周期，需要为租约授予一个TTL(time to live)，将租约绑定到一个key上，则key的生命周期与租约一致，可续租，可撤销租约，类似于redis为键设置过期时间。其主要用法如下所示：</font>\n\n```plain\netcdctl lease <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"70ab4a10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl lease grant <ttl> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font>\n\n```plain\n# 设置60秒后过期时间\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a2b granted with TTL(60s)\n# 把foo和租约绑定，设置成60秒后过期\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a29 foo bar\nOK\n# 租约期内查询键值\n[root@tiaoban etcd]# etcdctl get foo\nfoo\nbar\n# 租约期外查询键值\n[root@tiaoban etcd]# etcdctl get foo\n返回为空\n```\n\n<h3 id=\"84e9d55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约信息，以便续租或查看租约是否仍然存在或已过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约详情主要用法如下所示：</font>\n\n```plain\netcdctl lease timetolive <leaseID> [options] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font>\n\n```plain\n# 添加一个50秒的租约\n[root@tiaoban etcd]# etcdctl lease grant 50\nlease 6e1e86f4c6512a32 granted with TTL(50s)\n# 将name键绑定到6e1e86f4c6512a32租约上\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a32 name cuiliang\nOK\n# 查看所有租约列表\n[root@tiaoban etcd]# etcdctl lease list\nfound 1 leases\n6e1e86f4c6512a32\n# 查看租约详情，remaining(6s) 剩余有效时间6秒；--keys 获取租约绑定的 key\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a32\nlease 6e1e86f4c6512a32 granted with TTL(50s), remaining(6s), attached keys([name])\n```\n\n<h3 id=\"536b7b10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约续约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过刷新 TTL 值来保持租约的有效，使其不会过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl lease keep-alive [options] <leaseID> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\n# 设置60秒后过期租约\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a36 granted with TTL(60s)\n# 把name和租约绑定，设置成 60 秒后过期\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a36 name cuiliang\nOK\n# 自动定时执行续约，续约成功后每次租约为60秒\n[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a36\nlease 6e1e86f4c6512a36 keepalived with TTL(60)\nlease 6e1e86f4c6512a36 keepalived with TTL(60)\nlease 6e1e86f4c6512a36 keepalived with TTL(60)\n……\n```\n\n<h3 id=\"92a5dd2d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过租约 ID 撤销租约，撤销租约将删除其所有绑定的 key。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl lease revoke <leaseID> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\n# 设置600秒后过期租约\n[root@tiaoban etcd]# etcdctl lease grant 600\nlease 6e1e86f4c6512a39 granted with TTL(600s)\n# 把foo和租约绑定，600秒后过期\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a39 foo bar\nOK\n# 查看租约详情\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39\nlease 6e1e86f4c6512a39 granted with TTL(600s), remaining(556s), attached keys([foo])\n# 删除租约\n[root@tiaoban etcd]# etcdctl lease revoke 6e1e86f4c6512a39\nlease 6e1e86f4c6512a39 revoked\n# 查看租约详情\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39\nlease 6e1e86f4c6512a39 already expired\n# 获取键值\n[root@tiaoban etcd]# etcdctl get foo\n返回为空\n```\n\n<h3 id=\"1f35a899\"><font style=\"background-color:rgba(255, 255, 255, 0);\">多key同一租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">一个租约支持绑定多个 key</font>\n\n```plain\n# 设置60秒后过期的租约\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a3e granted with TTL(60s)\n# foo1与租约绑定\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo1 bar1\nOK\n# foo2与租约绑定\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo2 bar2\nOK\n# 查看租约详情\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a3e\nlease 6e1e86f4c6512a3e granted with TTL(60s), remaining(14s), attached keys([foo1 foo2])\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">租约过期后，所有 key 值都会被删除，因此：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">当租约只绑定了一个 key 时，想删除这个 key，最好的办法是撤销它的租约，而不是直接删除这个 key。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">当租约没有绑定key时，应主动把它撤销掉，单纯删除 key 后，续约操作持续进行，会造成内存泄露。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">直接删除key演示：</font>\n\n```plain\n# 设置租约并绑定 zoo1\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a43 granted with TTL(60s)\n[root@tiaoban etcd]# etcdctl --lease=6e1e86f4c6512a43 put zoo1 val1\nOK\n# 续约\n[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\n\n# 此时在另一个控制台执行删除key操作：\n[root@tiaoban ~]# etcdctl del zoo1\n1\n# 单纯删除 key 后，续约操作持续进行，会造成内存泄露\n[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\n...\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">撤销key的租约演示：</font>\n\n```plain\n# 设置租约并绑定 zoo1\n[root@tiaoban etcd]# etcdctl lease grant 50\nlease 32698142c52a1717 granted with TTL(50s)\n[root@tiaoban etcd]# etcdctl --lease=32698142c52a1717 put zoo1 val1\nOK\n\n# 续约\n[root@tiaoban etcd]# etcdctl lease keep-alive 32698142c52a1717\nlease 32698142c52a1717 keepalived with TTL(50)\nlease 32698142c52a1717 keepalived with TTL(50)\n\n# 另一个控制台执行：etcdctl lease revoke 32698142c52a1717\n\n# 续约撤销并退出\nlease 32698142c52a1717 expired or revoked.\n[root@tiaoban etcd]# etcdctl get zoo1\n# 返回空\n```\n\n<h2 id=\"17c28d47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用于管理节点的快照，其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"f1184f61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot save <filename> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\netcdctl snapshot save etcd-snapshot.db\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"077a284f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot status <filename> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\netcdctl snapshot status etcd-snapshot.db -w table\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"af357963\"><font style=\"background-color:rgba(255, 255, 255, 0);\">恢复快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot restore <filename> [options] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"0255a4be\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复演示</font></h3>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">新建一个名为name的key</font>\n\n```plain\n[root@tiaoban ~]# etcdctl put name cuiliang\nOK\n[root@tiaoban ~]# etcdctl get name\nname\ncuiliang\n[root@tiaoban ~]# etcdctl endpoint status -w table\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |\n|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照，创建名为snap.db的备份文件</font>\n\n```plain\n[root@k8s-work1 ~]# etcdctl snapshot save snap.db\n{\"level\":\"info\",\"ts\":1679220752.5883558,\"caller\":\"snapshot/v3_snapshot.go:119\",\"msg\":\"created temporary db file\",\"path\":\"snap.db.part\"}\n{\"level\":\"info\",\"ts\":\"2023-03-19T18:12:32.592+0800\",\"caller\":\"clientv3/maintenance.go:200\",\"msg\":\"opened snapshot stream; downloading\"}\n{\"level\":\"info\",\"ts\":1679220752.5924425,\"caller\":\"snapshot/v3_snapshot.go:127\",\"msg\":\"fetching snapshot\",\"endpoint\":\"127.0.0.1:2379\"}\n{\"level\":\"info\",\"ts\":\"2023-03-19T18:12:32.595+0800\",\"caller\":\"clientv3/maintenance.go:208\",\"msg\":\"completed snapshot read; closing\"}\n{\"level\":\"info\",\"ts\":1679220752.597161,\"caller\":\"snapshot/v3_snapshot.go:142\",\"msg\":\"fetched snapshot\",\"endpoint\":\"127.0.0.1:2379\",\"size\":\"25 kB\",\"took\":0.008507131}\n{\"level\":\"info\",\"ts\":1679220752.5973082,\"caller\":\"snapshot/v3_snapshot.go:152\",\"msg\":\"saved\",\"path\":\"snap.db\"}\nSnapshot saved at snap.db\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看备份文件详情</font>\n\n```plain\n[root@k8s-work1 ~]# ls -lh snap.db \n-rw------- 1 root root 25K 3月  19 18:12 snap.db\n[root@k8s-work1 ~]# etcdctl snapshot status snap.db -w table\n+----------+----------+------------+------------+\n|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |\n+----------+----------+------------+------------+\n| 8f097221 |       39 |         47 |      25 kB |\n+----------+----------+------------+------------+\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">把快照文件传到其他节点</font>\n\n```plain\n[root@k8s-work1 ~]# scp snap.db 192.168.10.100:/root                                                                                                                      100%   24KB   6.9MB/s   00:00    \n[root@k8s-work1 ~]# scp snap.db 192.168.10.12:/root\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">停止所有节点的etcd服务，并删除数据目录</font>\n\n```plain\n[root@k8s-work1 ~]# systemctl stop etcd\n[root@k8s-work1 ~]# rm -rf /data/etcd\n# 其余两个节点相同操作\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">在所有节点上开始恢复数据</font>\n\n```plain\n[root@k8s-work1 ~]# etcdctl snapshot restore snap.db --name=etcd2 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.11:2380\n{\"level\":\"info\",\"ts\":1679221421.2932272,\"caller\":\"snapshot/v3_snapshot.go:296\",\"msg\":\"restoring snapshot\",\"path\":\"snap.db\",\"wal-dir\":\"/data/etcd/cluster.etcd/member/wal\",\"data-dir\":\"/data/etcd/cluster.etcd\",\"snap-dir\":\"/data/etcd/cluster.etcd/member/snap\"}\n{\"level\":\"info\",\"ts\":1679221421.3019996,\"caller\":\"membership/cluster.go:392\",\"msg\":\"added member\",\"cluster-id\":\"cd30cff36981306b\",\"local-member-id\":\"0\",\"added-peer-id\":\"2e0eda3ad6bc6e1e\",\"added-peer-peer-urls\":[\"http://192.168.10.100:2380\"]}\n{\"level\":\"info\",\"ts\":1679221421.30208,\"caller\":\"membership/cluster.go:392\",\"msg\":\"added member\",\"cluster-id\":\"cd30cff36981306b\",\"local-member-id\":\"0\",\"added-peer-id\":\"5d2c1bd3b22f796f\",\"added-peer-peer-urls\":[\"http://192.168.10.12:2380\"]}\n{\"level\":\"info\",\"ts\":1679221421.3021913,\"caller\":\"membership/cluster.go:392\",\"msg\":\"added member\",\"cluster-id\":\"cd30cff36981306b\",\"local-member-id\":\"0\",\"added-peer-id\":\"bc34c6bd673bdf9f\",\"added-peer-peer-urls\":[\"http://192.168.10.11:2380\"]}\n{\"level\":\"info\",\"ts\":1679221421.3094716,\"caller\":\"snapshot/v3_snapshot.go:309\",\"msg\":\"restored snapshot\",\"path\":\"snap.db\",\"wal-dir\":\"/data/etcd/cluster.etcd/member/wal\",\"data-dir\":\"/data/etcd/cluster.etcd\",\"snap-dir\":\"/data/etcd/cluster.etcd/member/snap\"}\n[root@tiaoban ~]# etcdctl snapshot restore snap.db --name=etcd1 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.100:2380\n[root@k8s-work2 ~]# etcdctl snapshot restore snap.db --name=etcd3 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.12:2380\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">所有节点重启etcd服务</font>\n\n```plain\n[root@tiaoban ~]# systemctl restart etcd\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font>\n\n```plain\n[root@tiaoban ~]# etcdctl get name\nname\ncuiliang\n[root@tiaoban ~]# etcdctl endpoint status -w table\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |\n|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重启etcd后，仍能正常获取name的值，并且节点ID未发生改变。</font>\n\n<h2 id=\"7c91fffc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd默认是没有开启访问控制的，如果开启外网访问etcd的话就需要考虑访问控制的问题，etcd提供了两种访问控制的方式：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">基于身份验证的访问控制</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">基于证书的访问控制</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从v3.2版本开始，如果使用参数 --client-cert-auth=true 启动etcd服务器，则客户端的TLS证书中的 “通用名称（CN）” 字段将用作 etcd 用户。在这种情况下，公用名将对用户进行身份验证，并且客户端不需要密码。如果同时传递了 --client-cert-auth=true 且客户端提供了 CN，并且客户端提供了用户名和密码，则将优先考虑基于用户名和密码的身份验证。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd有一个特殊用户root和一个特殊角色root：</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">root用户</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：root用户是etcd的超级管理员，拥有etcd的所有权限，在开启角色认证之前为们必须要先建立好root用户</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">root角色</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：具有该root角色的用户既具有全局读写访问权限，具有更新集群的身份验证配置的权限。此外，该root角色还授予常规集群维护的特权，包括修改集群成员资格，对存储进行碎片整理以及拍摄快照。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd的权限资源：</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">Users</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">: user用来设置身份认证(user:passwd)，一个用户可以拥有多个角色，每个角色被分配一定的权限(只读、只写、可读写)，用户分为root用户和非root用户。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">Roles</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">: 角色用来关联权限，角色主要三类：  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">root角色:默认创建root用户时即创建了root角色，该角色拥有所有权限；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">guest角色:默认自动创建，主要用于非认证使用。普通角色，  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">由root用户创建角色，并分配指定权限。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">Permissions</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">: 权限分为只读、只写、可读写三种权限，权限即对指定目录或key的读写权限。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果没有指定任何验证方式，即未显示指定以什么用户进行访问，那么默认会设定为 guest 角色。默认情况下 guest 也是具有全局访问权限的</font>\n\n<h3 id=\"7d94de1c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl user <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">add</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user add < user name or user:password > [options] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">添加新用户</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user delete < user name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">list</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user list [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有用户</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">get</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user get < user name > [options] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户详细信息</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">passwd</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user passwd < user name > [options] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">修改密码</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">grant-role</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user grant-role < user name > < role name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">赋予用户角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-role</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user revoke-role < user name > < role name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户角色</font> |\n\n\n<h3 id=\"3f856ec2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl role <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">add</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role add < role name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">添加角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role delete[flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">list</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role list [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">get</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role get[flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">获取角色详情</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">grant-permission</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role grant-permission [options] < role name > < permission type > < key > [endkey] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">把key操作权限授予给一个角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-permission</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role revoke-permission < role name > < key > [endkey] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">从角色中撤销key操作权限</font> |\n\n\n<h3 id=\"2c28d63a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启身份验证后，注意事项如下所示：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">开启身份验证：所有etcdctl命令操作都需要指定用户参数–user，参数值为用户名:密码</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">开启证书验证：所有etcdctl命令操作都需要添加证书参数–cacert</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证的步骤如下所示：</font>\n\n```plain\n# 添加root 用户，密码为123456\n[root@tiaoban ~]# etcdctl user add root:123456\nUser root created\n# 开启身份验证，开启为enable，取消为disable\n[root@tiaoban ~]# etcdctl auth enable --user=root:123456\nAuthentication Enabled\n# 在开启身份验证后，直接获取键值报错\n[root@tiaoban ~]# etcdctl get name\n{\"level\":\"warn\",\"ts\":\"2023-03-19T19:00:03.922+0800\",\"caller\":\"clientv3/retry_interceptor.go:62\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"endpoint://client-bdd66650-a0b8-4fb4-ab60-47336cfb7523/192.168.10.100:2379\",\"attempt\":0,\"error\":\"rpc error: code = InvalidArgument desc = etcdserver: user name is empty\"}\nError: etcdserver: user name is empty\n# 添加用户信息访问\n[root@tiaoban ~]# etcdctl get name --user=root:123456\nname\ncuiliang\n```\n\n<h3 id=\"debce981\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启了root身份验证后，就可以对普通用户和角色操作了。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">用户增删改查</font>**\n\n```plain\n# 增加普通用户\n[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456\nUser test created\n# 获取用户信息\n[root@tiaoban ~]# etcdctl user get test --user=root:123456\nUser: test\nRoles:\n# 查看所有用户\n[root@tiaoban ~]# etcdctl user list --user=root:123456\nroot\ntest\n# 修改用户密码\n[root@tiaoban ~]# etcdctl user passwd test --user=root:123456\nPassword of test: \nType password of test again for confirmation: \nPassword updated\n# 删除用户\n[root@tiaoban ~]# etcdctl user delete test --user=root:123456\nUser test deleted\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">角色增删改查</font>**\n\n```plain\n# 添加角色\n[root@tiaoban ~]# etcdctl role add test-role --user=root:123456\nRole test-role created\n# 获取角色详细信息\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\nKV Write:\n# 获取所有角色\n[root@tiaoban ~]# etcdctl role list --user=root:123456\nroot\ntest-role\n# 删除角色\n[root@tiaoban ~]# etcdctl role delete test-role --user=root:123456\nRole test-role deleted\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">用户角色绑定</font>**\n\n```plain\n# 增加普通用户\n[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456\nUser test created\n# 添加角色\n[root@tiaoban ~]# etcdctl role add test-role --user=root:123456\nRole test-role created\n# 将角色绑定给指定用户\n[root@tiaoban ~]# etcdctl user grant-role test test-role --user=root:123456\nRole test-role is granted to user test\n# 查看用户信息\n[root@tiaoban ~]# etcdctl user get test --user=root:123456\nUser: test\nRoles: test-role\n\n# 取消用户与角色绑定\n[root@tiaoban ~]# etcdctl user revoke-role test test-role --user=root:123456\nRole test-role is revoked from user test\n# 查看用户信息\n[root@tiaoban ~]# etcdctl user get test --user=root:123456\nUser: test\nRoles:\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">权限分为：只读（read）、只写(write)和读写(readwrite)权限</font>\n\n```plain\n# 使用test用户获取name值会报错，权限拒绝\n[root@tiaoban ~]# etcdctl get name --user=test:123\n{\"level\":\"warn\",\"ts\":\"2023-03-19T19:10:50.515+0800\",\"caller\":\"clientv3/retry_interceptor.go:62\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"endpoint://client-dbe4e470-b1f4-40a1-b48f-71fcab9f32f0/192.168.10.100:2379\",\"attempt\":0,\"error\":\"rpc error: code = PermissionDenied desc = etcdserver: permission denied\"}\nError: etcdserver: permission denied\n\n# 按key进行授权，test-role角色可以读写name\n[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite name  --user=root:123456\nRole test-role updated\n# 查看角色权限详情\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\n        name\nKV Write:\n        name\n\n# 也可以按key的prefix进行授权\n[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite foo --prefix=true --user=root:123456\nRole test-role updated\n# 查看角色权限详情\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\n        [foo, fop) (prefix foo)\n        name\nKV Write:\n        [foo, fop) (prefix foo)\n        name\n\n# 撤消角色授权\n[root@tiaoban ~]# etcdctl role revoke-permission test-role name --user=root:123456\nPermission of key name is revoked from role test-role\n# 查看角色权限详情\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\n        [foo, fop) (prefix foo)\nKV Write:\n        [foo, fop) (prefix foo)\n```\n\n","source":"_posts/3.ETCD——常用命令.md","raw":"---\ntitle: ETCD--常用命令\ndate: 2025-03-05 19:08:06\n---\n<h2 id=\"dd367c2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群管理命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl是一个</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">命令行的客户端</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">，它提供了一些命令，可以方便我们在对服务进行测试或者手动修改数据库内容。etcdctl命令基本用法如下所示：</font>\n\n```plain\netcdctl [global options] command [command options] [args...]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">具体的命令选项参数可以通过 etcdctl command --help来获取相关帮助</font>\n\n<h3 id=\"3867e350\"><font style=\"background-color:rgba(255, 255, 255, 0);\">环境变量</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果遇到使用了TLS加密的集群，通常每条指令都需要指定证书路径和etcd节点地址，可以把相关命令行参数添加在环境变量中，在**~/.bashrc**添加以下内容：</font>\n\n```plain\n[root@tiaoban etcd]# cat ~/.bashrc\nHOST_1=https://192.168.10.100:2379\nHOST_2=https://192.168.10.11:2379\nHOST_3=https://192.168.10.12:2379\nENDPOINTS=${HOST_1},${HOST_2},${HOST_3}\n# 如果需要使用原生命令，在命令开头加一个\\ 例如：\\etcdctl command\nalias etcdctl=\"etcdctl --endpoints=${ENDPOINTS} --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem\"\nalias etcdctljson=\"etcdctl --endpoints=${ENDPOINTS} --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=json\"\nalias etcdctltable=\"etcdctl --endpoints=${ENDPOINTS} --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=table\"\n[root@tiaoban etcd]# source ~/.bashrc\n```\n\n<h3 id=\"c66c9b5d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd版本</font></h3>\n```plain\n[root@tiaoban etcd]# etcdctl version\netcdctl version: 3.4.23\nAPI version: 3.4\n```\n\n<h3 id=\"e65806ec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd集群节点信息</font></h3>\n```plain\n[root@tiaoban ~]# etcdctl member list -w table\n+------------------+---------+-------+----------------------------+----------------------------+------------+\n|        ID        | STATUS  | NAME  |         PEER ADDRS         |        CLIENT ADDRS        | IS LEARNER |\n+------------------+---------+-------+----------------------------+----------------------------+------------+\n| 2e0eda3ad6bc6e1e | started | etcd1 | http://192.168.10.100:2380 | http://192.168.10.100:2379 |      false |\n| 5d2c1bd3b22f796f | started | etcd3 |  http://192.168.10.12:2380 |  http://192.168.10.12:2379 |      false |\n| bc34c6bd673bdf9f | started | etcd2 |  http://192.168.10.11:2380 |  http://192.168.10.11:2379 |      false |\n+------------------+---------+-------+----------------------------+----------------------------+------------+\n```\n\n<h3 id=\"bcf18e5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群健康状态</font></h3>\n```plain\n[root@tiaoban ~]# etcdctl endpoint status -w table\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |          9 |                  9 |        |\n|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |\n|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n[root@tiaoban ~]# etcdctl endpoint health -w table\n+---------------------+--------+------------+-------+\n|      ENDPOINT       | HEALTH |    TOOK    | ERROR |\n+---------------------+--------+------------+-------+\n| 192.168.10.100:2379 |   true | 4.391924ms |       |\n|  192.168.10.11:2379 |   true | 7.091404ms |       |\n|  192.168.10.12:2379 |   true | 7.571706ms |       |\n+---------------------+--------+------------+-------+\n```\n\n<h3 id=\"cd2c454b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看告警事件</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果内部出现问题，会触发告警，可以通过命令查看告警引起原因，命令如下所示：</font>\n\n```plain\netcdctl alarm <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用的子命令主要有两个：</font>\n\n```plain\n# 查看所有告警\netcdctl alarm list\n# 解除所有告警\netcdctl alarm disarm\n```\n\n<h3 id=\"c3514e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当集群部署完成后，后续可能需要进行节点扩缩容，就可以使用member命令管理节点。先查看当前集群信息</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         8 |         16 |                 16 |        |\n|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |\n|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在启动新的etcd节点前，先向etcd集群声明添加节点的peer-urls和节点名称</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl member add etcd4 --peer-urls=http://192.168.10.100:12380\nMember b112a60ec305e42a added to cluster cd30cff36981306b\n\nETCD_NAME=\"etcd4\"\nETCD_INITIAL_CLUSTER=\"etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:12380,etcd2=http://192.168.10.11:2380\"\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://192.168.10.100:12380\"\nETCD_INITIAL_CLUSTER_STATE=\"existing\"\n```\n\n```plain\n[root@tiaoban etcd]# mkdir -p /opt/docker/etcd/{conf,data}\n[root@tiaoban etcd]# chown -R 1001:1001 /opt/docker/etcd/data/\n[root@tiaoban etcd]# cat /opt/docker/etcd/conf/etcd.conf \n# 节点名称\nname: 'etcd4'\n# 指定节点的数据存储目录\ndata-dir: '/data'\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.100:12379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.100:12380\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.100:12379\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.100:12380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd2=http://192.168.10.11:2380,etcd4=http://192.168.10.100:12380\"\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'existing'\n[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf\na142f38c785f2b7c217fb15f01ac62addfeb22eeb44da00363b1f7b5ce398439\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd4启动后，查看集群节点信息：</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         11 |                 11 |        |\n|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |\n| http://192.168.10.100:12379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |\n|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<h3 id=\"8456c2a4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当etcd节点故障，启动etcd时报错</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">**member count is unequal**</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">。如果有保留的数据目录下的文件时，可以通过使用 member update 命令，在保留 etcd 数据的情况下初始化集群数据，重新构建一个新的etcd集群节点。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:12380节点故障，但数据目录文件有备份，启动一个新的节点，地址为：192.168.10.100:22380</font>\n\n```plain\n# 停用旧节点\n[root@tiaoban etcd]# docker stop etcd4\netcd4\n[root@tiaoban etcd]# docker rm etcd4\netcd4\n\n# 更新节点地址\n[root@tiaoban etcd]# cat conf/etcd.conf \n# 节点名称\nname: 'etcd4'\n# 指定节点的数据存储目录\ndata-dir: '/data'\n# 监听客户端请求的地址列表\nlisten-client-urls: \"http://192.168.10.100:22379\"\n# 监听URL，用于节点之间通信监听地址\nlisten-peer-urls: \"http://192.168.10.100:22380\"\n# 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点\nadvertise-client-urls: \"http://192.168.10.100:22379\"\n# 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点\ninitial-advertise-peer-urls: \"http://192.168.10.100:22380\"\n# etcd启动时，etcd集群的节点地址列表\ninitial-cluster: \"etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:22380\"\n# etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群\ninitial-cluster-state: 'existing'\n\n# 启动新节点\n[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:3.4.23 etcd --config-file /conf/etcd.conf\n03c03ac7e6b50a8600cefe443ecafdb03f8f61f153b1a1138029c1726826d74e\n[root@tiaoban etcd]# docker ps\nCONTAINER ID   IMAGE                 COMMAND                   CREATED         STATUS         PORTS     NAMES\n03c03ac7e6b5   bitnami/etcd:3.4.23   \"/opt/bitnami/script…\"   3 seconds ago   Up 3 seconds             etcd4\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">执行更新member操作，指定新的节点地址。</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl member update b112a60ec305e42a --peer-urls=http://192.168.10.100:22380\nMember b112a60ec305e42a updated in cluster cd30cff36981306b\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群节点信息，节点信息更新完成。</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         14 |                 14 |        |\n|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |\n| http://192.168.10.100:22379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |\n|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |\n+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<h3 id=\"93020cb7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl member remove <memberID> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:22379节点下线操作</font>\n\n```plain\n[root@tiaoban etcd]# docker stop etcd4\netcd4\n[root@tiaoban etcd]# docker rm etcd4\netcd4\n[root@tiaoban etcd]# etcdctl member remove b112a60ec305e42a\nMember b112a60ec305e42a removed from cluster cd30cff36981306b\n[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         16 |                 16 |        |\n|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |\n|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |\n+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<h2 id=\"f4ce7445\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据库操作命令</font></h2>\n---\n\n<h3 id=\"7b67e8eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">增加(put)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加一个键值，基本用法如下所示：</font>\n\n```plain\netcdctl put [options] <key> <value> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">输出修改前的键值</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">其中value接受从stdin的输入内容</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果value是以横线-开始，将会被视为flag，如果不希望出现这种情况，可以使用两个横线代替–</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n```plain\n[root@tiaoban etcd]# etcdctl put name cuiliang\nOK\n[root@tiaoban etcd]# etcdctl put location -- -beijing\nOK\n[root@tiaoban etcd]# etcdctl put foo1 bar1\nOK\n[root@tiaoban etcd]# etcdctl put foo2 bar2\nOK\n[root@tiaoban etcd]# etcdctl put foo3 bar3\nOK\n```\n\n<h3 id=\"b9026f46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询(get)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查询键值，基本用法如下所示：</font>\n\n```plain\netcdctl get [options] <key> [range_end] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–hex</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">以十六进制形式输出</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–limit number</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">设置输出结果的最大值</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配key</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–order</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对输出结果进行排序，ASCEND 或 DESCEND</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–sort-by</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">按给定字段排序，CREATE, KEY, MODIFY, VALUE, VERSION</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–print-value-only</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">仅输出value值</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，获取大于等于指定key的结果</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–keys-only</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">仅获取keys</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n```plain\n# 获取键值\n[root@tiaoban etcd]# etcdctl get name\nname\ncuiliang\n# 只获取值\n[root@tiaoban etcd]# etcdctl get location --print-value-only\n-beijing\n# 批量取从foo1到foo3的值，不包括foo3\n[root@tiaoban etcd]# etcdctl get foo foo3 --print-value-only\nbar1\nbar2\n# 批量获取前缀为foo的值\n[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only\nbar1\nbar2\nbar3\n# 批量获取符合前缀的前两个值\n[root@tiaoban etcd]# etcdctl get --prefix --limit=2 foo --print-value-only\nbar1\nbar2\n# 批量获取前缀为foo的值，并排序\n[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only --order DESCEND\nbar3\nbar2\nbar1\n```\n\n<h3 id=\"800a3375\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除(del)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除键值，基本用法如下所示：</font>\n\n```plain\netcdctl del [options] <key> [range_end] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配删除</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">输出删除的键值</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，删除大于等于指定key的结果</font> |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n```plain\n# 删除name的键值\n[root@tiaoban etcd]# etcdctl del name\n1\n# 删除从foo1到foo3且不包含foo3的键值\n[root@tiaoban etcd]# etcdctl del foo1 foo3\n2\n# 删除前缀为foo的所有键值\n[root@tiaoban etcd]# etcdctl del --prefix foo\n1\n```\n\n<h3 id=\"1e15cca4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新(put覆盖)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加。</font>\n\n<h3 id=\"9634c1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询键历史记录查询</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd在每次键值变更时，都会记录变更信息，便于我们查看键变更记录</font>\n\n<h2 id=\"2c1031f0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">watch是监听键或前缀发生改变的事件流， 主要用法如下所示：</font>\n\n```plain\netcdctl watch [options] [key or prefix] [range_end] [--] [exec-command arg1 arg2 ...] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\n# 对某个key监听操作，当key1发生改变时，会返回最新值\netcdctl watch name\n# 监听key前缀\netcdctl watch name --prefix\n# 监听到改变后执行相关操作\netcdctl watch name --  etcdctl get age\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl watch name – etcdctl put name Kevin，如果写成，会不会变成死循环，导致无限监视，尽量避免。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font>\n\n<h3 id=\"beae6e09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听单个键</font></h3>\n```plain\n# 启动监听命令\n[root@tiaoban etcd]# etcdctl watch foo\n\n#另一个控制台执行新增命令\n[root@tiaoban ~]# etcdctl put foo bar\nOK\n\n# 观察控制台监听输出\n[root@tiaoban etcd]# etcdctl watch foo\nPUT\nfoo\nbar\n\n#另一个控制台执行更新命令\n[root@tiaoban ~]# etcdctl put foo bar123\nOK\n\n# 观察控制台监听输出\n[root@tiaoban etcd]# etcdctl watch foo\nPUT\nfoo\nbar\nPUT\nfoo\nbar123\n\n#另一个控制台执行删除命令\n[root@tiaoban ~]# etcdctl del foo\n1\n\n# 观察控制台监听输出\n[root@tiaoban etcd]# etcdctl watch foo\nPUT\nfoo\nbar\nPUT\nfoo\nbar123\nDELETE\nfoo\n```\n\n<h3 id=\"8545b8fc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">同时监听多个键</font></h3>\n```plain\n# 监听前缀为foo的键\n[root@tiaoban etcd]# etcdctl watch --prefix foo\n# 另一个控制台执行操作\n[root@tiaoban ~]# etcdctl put foo1 bar1\nOK\n[root@tiaoban ~]# etcdctl put foo2 bar2\nOK\n[root@tiaoban ~]# etcdctl del foo1\n1\n# 观察控制台输出\n[root@tiaoban etcd]# etcdctl watch --prefix foo\nPUT\nfoo1\nbar1\nPUT\nfoo2\nbar2\nDELETE\nfoo1\n\n\n# 监听指定的多个键\n[root@tiaoban etcd]# etcdctl watch -i\nwatch name\nwatch location\n\n# 另一个控制台执行操作\n[root@tiaoban ~]# etcdctl put name cuiliang\nOK\n[root@tiaoban ~]# etcdctl del name\n1\n[root@tiaoban ~]# etcdctl put location beijing\nOK\n# 观察控制台输出\n[root@tiaoban etcd]# etcdctl watch -i\nwatch name\nwatch location\nPUT\nname\ncuiliang\nDELETE\nname\n\nPUT\nlocation\nbeijing\n```\n\n<h2 id=\"dc4e3ec3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">租约具有生命周期，需要为租约授予一个TTL(time to live)，将租约绑定到一个key上，则key的生命周期与租约一致，可续租，可撤销租约，类似于redis为键设置过期时间。其主要用法如下所示：</font>\n\n```plain\netcdctl lease <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"70ab4a10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl lease grant <ttl> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font>\n\n```plain\n# 设置60秒后过期时间\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a2b granted with TTL(60s)\n# 把foo和租约绑定，设置成60秒后过期\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a29 foo bar\nOK\n# 租约期内查询键值\n[root@tiaoban etcd]# etcdctl get foo\nfoo\nbar\n# 租约期外查询键值\n[root@tiaoban etcd]# etcdctl get foo\n返回为空\n```\n\n<h3 id=\"84e9d55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约信息，以便续租或查看租约是否仍然存在或已过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约详情主要用法如下所示：</font>\n\n```plain\netcdctl lease timetolive <leaseID> [options] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font>\n\n```plain\n# 添加一个50秒的租约\n[root@tiaoban etcd]# etcdctl lease grant 50\nlease 6e1e86f4c6512a32 granted with TTL(50s)\n# 将name键绑定到6e1e86f4c6512a32租约上\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a32 name cuiliang\nOK\n# 查看所有租约列表\n[root@tiaoban etcd]# etcdctl lease list\nfound 1 leases\n6e1e86f4c6512a32\n# 查看租约详情，remaining(6s) 剩余有效时间6秒；--keys 获取租约绑定的 key\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a32\nlease 6e1e86f4c6512a32 granted with TTL(50s), remaining(6s), attached keys([name])\n```\n\n<h3 id=\"536b7b10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约续约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过刷新 TTL 值来保持租约的有效，使其不会过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl lease keep-alive [options] <leaseID> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\n# 设置60秒后过期租约\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a36 granted with TTL(60s)\n# 把name和租约绑定，设置成 60 秒后过期\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a36 name cuiliang\nOK\n# 自动定时执行续约，续约成功后每次租约为60秒\n[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a36\nlease 6e1e86f4c6512a36 keepalived with TTL(60)\nlease 6e1e86f4c6512a36 keepalived with TTL(60)\nlease 6e1e86f4c6512a36 keepalived with TTL(60)\n……\n```\n\n<h3 id=\"92a5dd2d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过租约 ID 撤销租约，撤销租约将删除其所有绑定的 key。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n```plain\netcdctl lease revoke <leaseID> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\n# 设置600秒后过期租约\n[root@tiaoban etcd]# etcdctl lease grant 600\nlease 6e1e86f4c6512a39 granted with TTL(600s)\n# 把foo和租约绑定，600秒后过期\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a39 foo bar\nOK\n# 查看租约详情\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39\nlease 6e1e86f4c6512a39 granted with TTL(600s), remaining(556s), attached keys([foo])\n# 删除租约\n[root@tiaoban etcd]# etcdctl lease revoke 6e1e86f4c6512a39\nlease 6e1e86f4c6512a39 revoked\n# 查看租约详情\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39\nlease 6e1e86f4c6512a39 already expired\n# 获取键值\n[root@tiaoban etcd]# etcdctl get foo\n返回为空\n```\n\n<h3 id=\"1f35a899\"><font style=\"background-color:rgba(255, 255, 255, 0);\">多key同一租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">一个租约支持绑定多个 key</font>\n\n```plain\n# 设置60秒后过期的租约\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a3e granted with TTL(60s)\n# foo1与租约绑定\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo1 bar1\nOK\n# foo2与租约绑定\n[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo2 bar2\nOK\n# 查看租约详情\n[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a3e\nlease 6e1e86f4c6512a3e granted with TTL(60s), remaining(14s), attached keys([foo1 foo2])\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">租约过期后，所有 key 值都会被删除，因此：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">当租约只绑定了一个 key 时，想删除这个 key，最好的办法是撤销它的租约，而不是直接删除这个 key。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">当租约没有绑定key时，应主动把它撤销掉，单纯删除 key 后，续约操作持续进行，会造成内存泄露。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">直接删除key演示：</font>\n\n```plain\n# 设置租约并绑定 zoo1\n[root@tiaoban etcd]# etcdctl lease grant 60\nlease 6e1e86f4c6512a43 granted with TTL(60s)\n[root@tiaoban etcd]# etcdctl --lease=6e1e86f4c6512a43 put zoo1 val1\nOK\n# 续约\n[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\n\n# 此时在另一个控制台执行删除key操作：\n[root@tiaoban ~]# etcdctl del zoo1\n1\n# 单纯删除 key 后，续约操作持续进行，会造成内存泄露\n[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\nlease 6e1e86f4c6512a43 keepalived with TTL(60)\n...\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">撤销key的租约演示：</font>\n\n```plain\n# 设置租约并绑定 zoo1\n[root@tiaoban etcd]# etcdctl lease grant 50\nlease 32698142c52a1717 granted with TTL(50s)\n[root@tiaoban etcd]# etcdctl --lease=32698142c52a1717 put zoo1 val1\nOK\n\n# 续约\n[root@tiaoban etcd]# etcdctl lease keep-alive 32698142c52a1717\nlease 32698142c52a1717 keepalived with TTL(50)\nlease 32698142c52a1717 keepalived with TTL(50)\n\n# 另一个控制台执行：etcdctl lease revoke 32698142c52a1717\n\n# 续约撤销并退出\nlease 32698142c52a1717 expired or revoked.\n[root@tiaoban etcd]# etcdctl get zoo1\n# 返回空\n```\n\n<h2 id=\"17c28d47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用于管理节点的快照，其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"f1184f61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot save <filename> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\netcdctl snapshot save etcd-snapshot.db\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"077a284f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot status <filename> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font>\n\n```plain\netcdctl snapshot status etcd-snapshot.db -w table\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"af357963\"><font style=\"background-color:rgba(255, 255, 255, 0);\">恢复快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl snapshot restore <filename> [options] [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h3 id=\"0255a4be\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复演示</font></h3>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">新建一个名为name的key</font>\n\n```plain\n[root@tiaoban ~]# etcdctl put name cuiliang\nOK\n[root@tiaoban ~]# etcdctl get name\nname\ncuiliang\n[root@tiaoban ~]# etcdctl endpoint status -w table\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |\n|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照，创建名为snap.db的备份文件</font>\n\n```plain\n[root@k8s-work1 ~]# etcdctl snapshot save snap.db\n{\"level\":\"info\",\"ts\":1679220752.5883558,\"caller\":\"snapshot/v3_snapshot.go:119\",\"msg\":\"created temporary db file\",\"path\":\"snap.db.part\"}\n{\"level\":\"info\",\"ts\":\"2023-03-19T18:12:32.592+0800\",\"caller\":\"clientv3/maintenance.go:200\",\"msg\":\"opened snapshot stream; downloading\"}\n{\"level\":\"info\",\"ts\":1679220752.5924425,\"caller\":\"snapshot/v3_snapshot.go:127\",\"msg\":\"fetching snapshot\",\"endpoint\":\"127.0.0.1:2379\"}\n{\"level\":\"info\",\"ts\":\"2023-03-19T18:12:32.595+0800\",\"caller\":\"clientv3/maintenance.go:208\",\"msg\":\"completed snapshot read; closing\"}\n{\"level\":\"info\",\"ts\":1679220752.597161,\"caller\":\"snapshot/v3_snapshot.go:142\",\"msg\":\"fetched snapshot\",\"endpoint\":\"127.0.0.1:2379\",\"size\":\"25 kB\",\"took\":0.008507131}\n{\"level\":\"info\",\"ts\":1679220752.5973082,\"caller\":\"snapshot/v3_snapshot.go:152\",\"msg\":\"saved\",\"path\":\"snap.db\"}\nSnapshot saved at snap.db\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看备份文件详情</font>\n\n```plain\n[root@k8s-work1 ~]# ls -lh snap.db \n-rw------- 1 root root 25K 3月  19 18:12 snap.db\n[root@k8s-work1 ~]# etcdctl snapshot status snap.db -w table\n+----------+----------+------------+------------+\n|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |\n+----------+----------+------------+------------+\n| 8f097221 |       39 |         47 |      25 kB |\n+----------+----------+------------+------------+\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">把快照文件传到其他节点</font>\n\n```plain\n[root@k8s-work1 ~]# scp snap.db 192.168.10.100:/root                                                                                                                      100%   24KB   6.9MB/s   00:00    \n[root@k8s-work1 ~]# scp snap.db 192.168.10.12:/root\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">停止所有节点的etcd服务，并删除数据目录</font>\n\n```plain\n[root@k8s-work1 ~]# systemctl stop etcd\n[root@k8s-work1 ~]# rm -rf /data/etcd\n# 其余两个节点相同操作\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">在所有节点上开始恢复数据</font>\n\n```plain\n[root@k8s-work1 ~]# etcdctl snapshot restore snap.db --name=etcd2 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.11:2380\n{\"level\":\"info\",\"ts\":1679221421.2932272,\"caller\":\"snapshot/v3_snapshot.go:296\",\"msg\":\"restoring snapshot\",\"path\":\"snap.db\",\"wal-dir\":\"/data/etcd/cluster.etcd/member/wal\",\"data-dir\":\"/data/etcd/cluster.etcd\",\"snap-dir\":\"/data/etcd/cluster.etcd/member/snap\"}\n{\"level\":\"info\",\"ts\":1679221421.3019996,\"caller\":\"membership/cluster.go:392\",\"msg\":\"added member\",\"cluster-id\":\"cd30cff36981306b\",\"local-member-id\":\"0\",\"added-peer-id\":\"2e0eda3ad6bc6e1e\",\"added-peer-peer-urls\":[\"http://192.168.10.100:2380\"]}\n{\"level\":\"info\",\"ts\":1679221421.30208,\"caller\":\"membership/cluster.go:392\",\"msg\":\"added member\",\"cluster-id\":\"cd30cff36981306b\",\"local-member-id\":\"0\",\"added-peer-id\":\"5d2c1bd3b22f796f\",\"added-peer-peer-urls\":[\"http://192.168.10.12:2380\"]}\n{\"level\":\"info\",\"ts\":1679221421.3021913,\"caller\":\"membership/cluster.go:392\",\"msg\":\"added member\",\"cluster-id\":\"cd30cff36981306b\",\"local-member-id\":\"0\",\"added-peer-id\":\"bc34c6bd673bdf9f\",\"added-peer-peer-urls\":[\"http://192.168.10.11:2380\"]}\n{\"level\":\"info\",\"ts\":1679221421.3094716,\"caller\":\"snapshot/v3_snapshot.go:309\",\"msg\":\"restored snapshot\",\"path\":\"snap.db\",\"wal-dir\":\"/data/etcd/cluster.etcd/member/wal\",\"data-dir\":\"/data/etcd/cluster.etcd\",\"snap-dir\":\"/data/etcd/cluster.etcd/member/snap\"}\n[root@tiaoban ~]# etcdctl snapshot restore snap.db --name=etcd1 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.100:2380\n[root@k8s-work2 ~]# etcdctl snapshot restore snap.db --name=etcd3 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.12:2380\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">所有节点重启etcd服务</font>\n\n```plain\n[root@tiaoban ~]# systemctl restart etcd\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font>\n\n```plain\n[root@tiaoban ~]# etcdctl get name\nname\ncuiliang\n[root@tiaoban ~]# etcdctl endpoint status -w table\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |\n|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |\n+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重启etcd后，仍能正常获取name的值，并且节点ID未发生改变。</font>\n\n<h2 id=\"7c91fffc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理命令</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd默认是没有开启访问控制的，如果开启外网访问etcd的话就需要考虑访问控制的问题，etcd提供了两种访问控制的方式：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">基于身份验证的访问控制</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">基于证书的访问控制</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从v3.2版本开始，如果使用参数 --client-cert-auth=true 启动etcd服务器，则客户端的TLS证书中的 “通用名称（CN）” 字段将用作 etcd 用户。在这种情况下，公用名将对用户进行身份验证，并且客户端不需要密码。如果同时传递了 --client-cert-auth=true 且客户端提供了 CN，并且客户端提供了用户名和密码，则将优先考虑基于用户名和密码的身份验证。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd有一个特殊用户root和一个特殊角色root：</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">root用户</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：root用户是etcd的超级管理员，拥有etcd的所有权限，在开启角色认证之前为们必须要先建立好root用户</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">root角色</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：具有该root角色的用户既具有全局读写访问权限，具有更新集群的身份验证配置的权限。此外，该root角色还授予常规集群维护的特权，包括修改集群成员资格，对存储进行碎片整理以及拍摄快照。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd的权限资源：</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">Users</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">: user用来设置身份认证(user:passwd)，一个用户可以拥有多个角色，每个角色被分配一定的权限(只读、只写、可读写)，用户分为root用户和非root用户。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">Roles</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">: 角色用来关联权限，角色主要三类：  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">root角色:默认创建root用户时即创建了root角色，该角色拥有所有权限；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">guest角色:默认自动创建，主要用于非认证使用。普通角色，  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">由root用户创建角色，并分配指定权限。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">Permissions</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">: 权限分为只读、只写、可读写三种权限，权限即对指定目录或key的读写权限。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果没有指定任何验证方式，即未显示指定以什么用户进行访问，那么默认会设定为 guest 角色。默认情况下 guest 也是具有全局访问权限的</font>\n\n<h3 id=\"7d94de1c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl user <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">add</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user add < user name or user:password > [options] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">添加新用户</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user delete < user name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">list</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user list [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有用户</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">get</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user get < user name > [options] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户详细信息</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">passwd</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user passwd < user name > [options] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">修改密码</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">grant-role</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user grant-role < user name > < role name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">赋予用户角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-role</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user revoke-role < user name > < role name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户角色</font> |\n\n\n<h3 id=\"3f856ec2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n```plain\netcdctl role <subcommand> [flags]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font>** |\n| --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">add</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role add < role name > [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">添加角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role delete[flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">list</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role list [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">get</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role get[flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">获取角色详情</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">grant-permission</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role grant-permission [options] < role name > < permission type > < key > [endkey] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">把key操作权限授予给一个角色</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-permission</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role revoke-permission < role name > < key > [endkey] [flags]</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">从角色中撤销key操作权限</font> |\n\n\n<h3 id=\"2c28d63a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启身份验证后，注意事项如下所示：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">开启身份验证：所有etcdctl命令操作都需要指定用户参数–user，参数值为用户名:密码</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">开启证书验证：所有etcdctl命令操作都需要添加证书参数–cacert</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证的步骤如下所示：</font>\n\n```plain\n# 添加root 用户，密码为123456\n[root@tiaoban ~]# etcdctl user add root:123456\nUser root created\n# 开启身份验证，开启为enable，取消为disable\n[root@tiaoban ~]# etcdctl auth enable --user=root:123456\nAuthentication Enabled\n# 在开启身份验证后，直接获取键值报错\n[root@tiaoban ~]# etcdctl get name\n{\"level\":\"warn\",\"ts\":\"2023-03-19T19:00:03.922+0800\",\"caller\":\"clientv3/retry_interceptor.go:62\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"endpoint://client-bdd66650-a0b8-4fb4-ab60-47336cfb7523/192.168.10.100:2379\",\"attempt\":0,\"error\":\"rpc error: code = InvalidArgument desc = etcdserver: user name is empty\"}\nError: etcdserver: user name is empty\n# 添加用户信息访问\n[root@tiaoban ~]# etcdctl get name --user=root:123456\nname\ncuiliang\n```\n\n<h3 id=\"debce981\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启了root身份验证后，就可以对普通用户和角色操作了。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">用户增删改查</font>**\n\n```plain\n# 增加普通用户\n[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456\nUser test created\n# 获取用户信息\n[root@tiaoban ~]# etcdctl user get test --user=root:123456\nUser: test\nRoles:\n# 查看所有用户\n[root@tiaoban ~]# etcdctl user list --user=root:123456\nroot\ntest\n# 修改用户密码\n[root@tiaoban ~]# etcdctl user passwd test --user=root:123456\nPassword of test: \nType password of test again for confirmation: \nPassword updated\n# 删除用户\n[root@tiaoban ~]# etcdctl user delete test --user=root:123456\nUser test deleted\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">角色增删改查</font>**\n\n```plain\n# 添加角色\n[root@tiaoban ~]# etcdctl role add test-role --user=root:123456\nRole test-role created\n# 获取角色详细信息\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\nKV Write:\n# 获取所有角色\n[root@tiaoban ~]# etcdctl role list --user=root:123456\nroot\ntest-role\n# 删除角色\n[root@tiaoban ~]# etcdctl role delete test-role --user=root:123456\nRole test-role deleted\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">用户角色绑定</font>**\n\n```plain\n# 增加普通用户\n[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456\nUser test created\n# 添加角色\n[root@tiaoban ~]# etcdctl role add test-role --user=root:123456\nRole test-role created\n# 将角色绑定给指定用户\n[root@tiaoban ~]# etcdctl user grant-role test test-role --user=root:123456\nRole test-role is granted to user test\n# 查看用户信息\n[root@tiaoban ~]# etcdctl user get test --user=root:123456\nUser: test\nRoles: test-role\n\n# 取消用户与角色绑定\n[root@tiaoban ~]# etcdctl user revoke-role test test-role --user=root:123456\nRole test-role is revoked from user test\n# 查看用户信息\n[root@tiaoban ~]# etcdctl user get test --user=root:123456\nUser: test\nRoles:\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">权限分为：只读（read）、只写(write)和读写(readwrite)权限</font>\n\n```plain\n# 使用test用户获取name值会报错，权限拒绝\n[root@tiaoban ~]# etcdctl get name --user=test:123\n{\"level\":\"warn\",\"ts\":\"2023-03-19T19:10:50.515+0800\",\"caller\":\"clientv3/retry_interceptor.go:62\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"endpoint://client-dbe4e470-b1f4-40a1-b48f-71fcab9f32f0/192.168.10.100:2379\",\"attempt\":0,\"error\":\"rpc error: code = PermissionDenied desc = etcdserver: permission denied\"}\nError: etcdserver: permission denied\n\n# 按key进行授权，test-role角色可以读写name\n[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite name  --user=root:123456\nRole test-role updated\n# 查看角色权限详情\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\n        name\nKV Write:\n        name\n\n# 也可以按key的prefix进行授权\n[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite foo --prefix=true --user=root:123456\nRole test-role updated\n# 查看角色权限详情\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\n        [foo, fop) (prefix foo)\n        name\nKV Write:\n        [foo, fop) (prefix foo)\n        name\n\n# 撤消角色授权\n[root@tiaoban ~]# etcdctl role revoke-permission test-role name --user=root:123456\nPermission of key name is revoked from role test-role\n# 查看角色权限详情\n[root@tiaoban ~]# etcdctl role get test-role --user=root:123456\nRole test-role\nKV Read:\n        [foo, fop) (prefix foo)\nKV Write:\n        [foo, fop) (prefix foo)\n```\n\n","slug":"3.ETCD——常用命令","published":1,"updated":"2025-03-30T13:04:26.864Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlo000jtsv13hhh924z","content":"<h2 id=\"dd367c2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群管理命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl是一个</font><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行的客户端</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">，它提供了一些命令，可以方便我们在对服务进行测试或者手动修改数据库内容。etcdctl命令基本用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl [global options] command [command options] [args...]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">具体的命令选项参数可以通过 etcdctl command –help来获取相关帮助</font></p>\n<h3 id=\"3867e350\"><font style=\"background-color:rgba(255, 255, 255, 0);\">环境变量</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果遇到使用了TLS加密的集群，通常每条指令都需要指定证书路径和etcd节点地址，可以把相关命令行参数添加在环境变量中，在**~/.bashrc**添加以下内容：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# cat ~/.bashrc</span><br><span class=\"line\">HOST_1=https://192.168.10.100:2379</span><br><span class=\"line\">HOST_2=https://192.168.10.11:2379</span><br><span class=\"line\">HOST_3=https://192.168.10.12:2379</span><br><span class=\"line\">ENDPOINTS=$&#123;HOST_1&#125;,$&#123;HOST_2&#125;,$&#123;HOST_3&#125;</span><br><span class=\"line\"># 如果需要使用原生命令，在命令开头加一个\\ 例如：\\etcdctl command</span><br><span class=\"line\">alias etcdctl=&quot;etcdctl --endpoints=$&#123;ENDPOINTS&#125; --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem&quot;</span><br><span class=\"line\">alias etcdctljson=&quot;etcdctl --endpoints=$&#123;ENDPOINTS&#125; --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=json&quot;</span><br><span class=\"line\">alias etcdctltable=&quot;etcdctl --endpoints=$&#123;ENDPOINTS&#125; --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=table&quot;</span><br><span class=\"line\">[root@tiaoban etcd]# source ~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"c66c9b5d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd版本</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl version</span><br><span class=\"line\">etcdctl version: 3.4.23</span><br><span class=\"line\">API version: 3.4</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"e65806ec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd集群节点信息</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl member list -w table</span><br><span class=\"line\">+------------------+---------+-------+----------------------------+----------------------------+------------+</span><br><span class=\"line\">|        ID        | STATUS  | NAME  |         PEER ADDRS         |        CLIENT ADDRS        | IS LEARNER |</span><br><span class=\"line\">+------------------+---------+-------+----------------------------+----------------------------+------------+</span><br><span class=\"line\">| 2e0eda3ad6bc6e1e | started | etcd1 | http://192.168.10.100:2380 | http://192.168.10.100:2379 |      false |</span><br><span class=\"line\">| 5d2c1bd3b22f796f | started | etcd3 |  http://192.168.10.12:2380 |  http://192.168.10.12:2379 |      false |</span><br><span class=\"line\">| bc34c6bd673bdf9f | started | etcd2 |  http://192.168.10.11:2380 |  http://192.168.10.11:2379 |      false |</span><br><span class=\"line\">+------------------+---------+-------+----------------------------+----------------------------+------------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"bcf18e5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群健康状态</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint status -w table</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |          9 |                  9 |        |</span><br><span class=\"line\">|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |</span><br><span class=\"line\">|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint health -w table</span><br><span class=\"line\">+---------------------+--------+------------+-------+</span><br><span class=\"line\">|      ENDPOINT       | HEALTH |    TOOK    | ERROR |</span><br><span class=\"line\">+---------------------+--------+------------+-------+</span><br><span class=\"line\">| 192.168.10.100:2379 |   true | 4.391924ms |       |</span><br><span class=\"line\">|  192.168.10.11:2379 |   true | 7.091404ms |       |</span><br><span class=\"line\">|  192.168.10.12:2379 |   true | 7.571706ms |       |</span><br><span class=\"line\">+---------------------+--------+------------+-------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"cd2c454b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看告警事件</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果内部出现问题，会触发告警，可以通过命令查看告警引起原因，命令如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl alarm &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用的子命令主要有两个：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看所有告警</span><br><span class=\"line\">etcdctl alarm list</span><br><span class=\"line\"># 解除所有告警</span><br><span class=\"line\">etcdctl alarm disarm</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"c3514e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当集群部署完成后，后续可能需要进行节点扩缩容，就可以使用member命令管理节点。先查看当前集群信息</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         8 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在启动新的etcd节点前，先向etcd集群声明添加节点的peer-urls和节点名称</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl member add etcd4 --peer-urls=http://192.168.10.100:12380</span><br><span class=\"line\">Member b112a60ec305e42a added to cluster cd30cff36981306b</span><br><span class=\"line\"></span><br><span class=\"line\">ETCD_NAME=&quot;etcd4&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER=&quot;etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:12380,etcd2=http://192.168.10.11:2380&quot;</span><br><span class=\"line\">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.10.100:12380&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER_STATE=&quot;existing&quot;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# mkdir -p /opt/docker/etcd/&#123;conf,data&#125;</span><br><span class=\"line\">[root@tiaoban etcd]# chown -R 1001:1001 /opt/docker/etcd/data/</span><br><span class=\"line\">[root@tiaoban etcd]# cat /opt/docker/etcd/conf/etcd.conf </span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd4&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data&#x27;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.100:12379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.100:12380&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.100:12379&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.100:12380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd2=http://192.168.10.11:2380,etcd4=http://192.168.10.100:12380&quot;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;existing&#x27;</span><br><span class=\"line\">[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf</span><br><span class=\"line\">a142f38c785f2b7c217fb15f01ac62addfeb22eeb44da00363b1f7b5ce398439</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd4启动后，查看集群节点信息：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">| http://192.168.10.100:12379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"8456c2a4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当etcd节点故障，启动etcd时报错</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">**member count is unequal**</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">。如果有保留的数据目录下的文件时，可以通过使用 member update 命令，在保留 etcd 数据的情况下初始化集群数据，重新构建一个新的etcd集群节点。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:12380节点故障，但数据目录文件有备份，启动一个新的节点，地址为：192.168.10.100:22380</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 停用旧节点</span><br><span class=\"line\">[root@tiaoban etcd]# docker stop etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\">[root@tiaoban etcd]# docker rm etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\"></span><br><span class=\"line\"># 更新节点地址</span><br><span class=\"line\">[root@tiaoban etcd]# cat conf/etcd.conf </span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd4&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data&#x27;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.100:22379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.100:22380&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.100:22379&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.100:22380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:22380&quot;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;existing&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动新节点</span><br><span class=\"line\">[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:3.4.23 etcd --config-file /conf/etcd.conf</span><br><span class=\"line\">03c03ac7e6b50a8600cefe443ecafdb03f8f61f153b1a1138029c1726826d74e</span><br><span class=\"line\">[root@tiaoban etcd]# docker ps</span><br><span class=\"line\">CONTAINER ID   IMAGE                 COMMAND                   CREATED         STATUS         PORTS     NAMES</span><br><span class=\"line\">03c03ac7e6b5   bitnami/etcd:3.4.23   &quot;/opt/bitnami/script…&quot;   3 seconds ago   Up 3 seconds             etcd4</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">执行更新member操作，指定新的节点地址。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl member update b112a60ec305e42a --peer-urls=http://192.168.10.100:22380</span><br><span class=\"line\">Member b112a60ec305e42a updated in cluster cd30cff36981306b</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群节点信息，节点信息更新完成。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">| http://192.168.10.100:22379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"93020cb7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl member remove &lt;memberID&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:22379节点下线操作</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# docker stop etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\">[root@tiaoban etcd]# docker rm etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl member remove b112a60ec305e42a</span><br><span class=\"line\">Member b112a60ec305e42a removed from cluster cd30cff36981306b</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f4ce7445\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据库操作命令</font></h2>\n---\n\n<h3 id=\"7b67e8eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">增加(put)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加一个键值，基本用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl put [options] &lt;key&gt; &lt;value&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">输出修改前的键值</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">其中value接受从stdin的输入内容</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果value是以横线-开始，将会被视为flag，如果不希望出现这种情况，可以使用两个横线代替–</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl put name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put location -- -beijing</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put foo1 bar1</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put foo2 bar2</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put foo3 bar3</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"b9026f46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询(get)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查询键值，基本用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl get [options] &lt;key&gt; [range_end] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–hex</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">以十六进制形式输出</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–limit number</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">设置输出结果的最大值</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配key</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–order</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对输出结果进行排序，ASCEND 或 DESCEND</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–sort-by</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">按给定字段排序，CREATE, KEY, MODIFY, VALUE, VERSION</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–print-value-only</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">仅输出value值</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，获取大于等于指定key的结果</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–keys-only</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">仅获取keys</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 获取键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get name</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\"># 只获取值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get location --print-value-only</span><br><span class=\"line\">-beijing</span><br><span class=\"line\"># 批量取从foo1到foo3的值，不包括foo3</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo foo3 --print-value-only</span><br><span class=\"line\">bar1</span><br><span class=\"line\">bar2</span><br><span class=\"line\"># 批量获取前缀为foo的值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only</span><br><span class=\"line\">bar1</span><br><span class=\"line\">bar2</span><br><span class=\"line\">bar3</span><br><span class=\"line\"># 批量获取符合前缀的前两个值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get --prefix --limit=2 foo --print-value-only</span><br><span class=\"line\">bar1</span><br><span class=\"line\">bar2</span><br><span class=\"line\"># 批量获取前缀为foo的值，并排序</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only --order DESCEND</span><br><span class=\"line\">bar3</span><br><span class=\"line\">bar2</span><br><span class=\"line\">bar1</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"800a3375\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除(del)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除键值，基本用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl del [options] &lt;key&gt; [range_end] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配删除</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">输出删除的键值</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，删除大于等于指定key的结果</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 删除name的键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl del name</span><br><span class=\"line\">1</span><br><span class=\"line\"># 删除从foo1到foo3且不包含foo3的键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl del foo1 foo3</span><br><span class=\"line\">2</span><br><span class=\"line\"># 删除前缀为foo的所有键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl del --prefix foo</span><br><span class=\"line\">1</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1e15cca4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新(put覆盖)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加。</font>\n\n<h3 id=\"9634c1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询键历史记录查询</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd在每次键值变更时，都会记录变更信息，便于我们查看键变更记录</font>\n\n<h2 id=\"2c1031f0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">watch是监听键或前缀发生改变的事件流， 主要用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl watch [options] [key or prefix] [range_end] [--] [exec-command arg1 arg2 ...] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 对某个key监听操作，当key1发生改变时，会返回最新值</span><br><span class=\"line\">etcdctl watch name</span><br><span class=\"line\"># 监听key前缀</span><br><span class=\"line\">etcdctl watch name --prefix</span><br><span class=\"line\"># 监听到改变后执行相关操作</span><br><span class=\"line\">etcdctl watch name --  etcdctl get age</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl watch name – etcdctl put name Kevin，如果写成，会不会变成死循环，导致无限监视，尽量避免。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<h3 id=\"beae6e09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听单个键</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 启动监听命令</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\"></span><br><span class=\"line\">#另一个控制台执行新增命令</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\"></span><br><span class=\"line\"># 观察控制台监听输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\"></span><br><span class=\"line\">#另一个控制台执行更新命令</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo bar123</span><br><span class=\"line\">OK</span><br><span class=\"line\"></span><br><span class=\"line\"># 观察控制台监听输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar123</span><br><span class=\"line\"></span><br><span class=\"line\">#另一个控制台执行删除命令</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del foo</span><br><span class=\"line\">1</span><br><span class=\"line\"></span><br><span class=\"line\"># 观察控制台监听输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar123</span><br><span class=\"line\">DELETE</span><br><span class=\"line\">foo</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"8545b8fc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">同时监听多个键</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 监听前缀为foo的键</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch --prefix foo</span><br><span class=\"line\"># 另一个控制台执行操作</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo1 bar1</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo2 bar2</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del foo1</span><br><span class=\"line\">1</span><br><span class=\"line\"># 观察控制台输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch --prefix foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo1</span><br><span class=\"line\">bar1</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo2</span><br><span class=\"line\">bar2</span><br><span class=\"line\">DELETE</span><br><span class=\"line\">foo1</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 监听指定的多个键</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch -i</span><br><span class=\"line\">watch name</span><br><span class=\"line\">watch location</span><br><span class=\"line\"></span><br><span class=\"line\"># 另一个控制台执行操作</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del name</span><br><span class=\"line\">1</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put location beijing</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 观察控制台输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch -i</span><br><span class=\"line\">watch name</span><br><span class=\"line\">watch location</span><br><span class=\"line\">PUT</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\">DELETE</span><br><span class=\"line\">name</span><br><span class=\"line\"></span><br><span class=\"line\">PUT</span><br><span class=\"line\">location</span><br><span class=\"line\">beijing</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"dc4e3ec3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">租约具有生命周期，需要为租约授予一个TTL(time to live)，将租约绑定到一个key上，则key的生命周期与租约一致，可续租，可撤销租约，类似于redis为键设置过期时间。其主要用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"70ab4a10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease grant &lt;ttl&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置60秒后过期时间</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a2b granted with TTL(60s)</span><br><span class=\"line\"># 把foo和租约绑定，设置成60秒后过期</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a29 foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 租约期内查询键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\"># 租约期外查询键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo</span><br><span class=\"line\">返回为空</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"84e9d55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约信息，以便续租或查看租约是否仍然存在或已过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约详情主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease timetolive &lt;leaseID&gt; [options] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加一个50秒的租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 50</span><br><span class=\"line\">lease 6e1e86f4c6512a32 granted with TTL(50s)</span><br><span class=\"line\"># 将name键绑定到6e1e86f4c6512a32租约上</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a32 name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 查看所有租约列表</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease list</span><br><span class=\"line\">found 1 leases</span><br><span class=\"line\">6e1e86f4c6512a32</span><br><span class=\"line\"># 查看租约详情，remaining(6s) 剩余有效时间6秒；--keys 获取租约绑定的 key</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a32</span><br><span class=\"line\">lease 6e1e86f4c6512a32 granted with TTL(50s), remaining(6s), attached keys([name])</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"536b7b10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约续约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过刷新 TTL 值来保持租约的有效，使其不会过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease keep-alive [options] &lt;leaseID&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置60秒后过期租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a36 granted with TTL(60s)</span><br><span class=\"line\"># 把name和租约绑定，设置成 60 秒后过期</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a36 name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 自动定时执行续约，续约成功后每次租约为60秒</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a36</span><br><span class=\"line\">lease 6e1e86f4c6512a36 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a36 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a36 keepalived with TTL(60)</span><br><span class=\"line\">……</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"92a5dd2d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过租约 ID 撤销租约，撤销租约将删除其所有绑定的 key。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease revoke &lt;leaseID&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置600秒后过期租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 600</span><br><span class=\"line\">lease 6e1e86f4c6512a39 granted with TTL(600s)</span><br><span class=\"line\"># 把foo和租约绑定，600秒后过期</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a39 foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 查看租约详情</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39</span><br><span class=\"line\">lease 6e1e86f4c6512a39 granted with TTL(600s), remaining(556s), attached keys([foo])</span><br><span class=\"line\"># 删除租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease revoke 6e1e86f4c6512a39</span><br><span class=\"line\">lease 6e1e86f4c6512a39 revoked</span><br><span class=\"line\"># 查看租约详情</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39</span><br><span class=\"line\">lease 6e1e86f4c6512a39 already expired</span><br><span class=\"line\"># 获取键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo</span><br><span class=\"line\">返回为空</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1f35a899\"><font style=\"background-color:rgba(255, 255, 255, 0);\">多key同一租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">一个租约支持绑定多个 key</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置60秒后过期的租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a3e granted with TTL(60s)</span><br><span class=\"line\"># foo1与租约绑定</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo1 bar1</span><br><span class=\"line\">OK</span><br><span class=\"line\"># foo2与租约绑定</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo2 bar2</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 查看租约详情</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a3e</span><br><span class=\"line\">lease 6e1e86f4c6512a3e granted with TTL(60s), remaining(14s), attached keys([foo1 foo2])</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">租约过期后，所有 key 值都会被删除，因此：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">当租约只绑定了一个 key 时，想删除这个 key，最好的办法是撤销它的租约，而不是直接删除这个 key。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">当租约没有绑定key时，应主动把它撤销掉，单纯删除 key 后，续约操作持续进行，会造成内存泄露。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">直接删除key演示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置租约并绑定 zoo1</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a43 granted with TTL(60s)</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --lease=6e1e86f4c6512a43 put zoo1 val1</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 续约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\"></span><br><span class=\"line\"># 此时在另一个控制台执行删除key操作：</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del zoo1</span><br><span class=\"line\">1</span><br><span class=\"line\"># 单纯删除 key 后，续约操作持续进行，会造成内存泄露</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">撤销key的租约演示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置租约并绑定 zoo1</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 50</span><br><span class=\"line\">lease 32698142c52a1717 granted with TTL(50s)</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --lease=32698142c52a1717 put zoo1 val1</span><br><span class=\"line\">OK</span><br><span class=\"line\"></span><br><span class=\"line\"># 续约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 32698142c52a1717</span><br><span class=\"line\">lease 32698142c52a1717 keepalived with TTL(50)</span><br><span class=\"line\">lease 32698142c52a1717 keepalived with TTL(50)</span><br><span class=\"line\"></span><br><span class=\"line\"># 另一个控制台执行：etcdctl lease revoke 32698142c52a1717</span><br><span class=\"line\"></span><br><span class=\"line\"># 续约撤销并退出</span><br><span class=\"line\">lease 32698142c52a1717 expired or revoked.</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get zoo1</span><br><span class=\"line\"># 返回空</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"17c28d47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用于管理节点的快照，其主要用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"f1184f61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot save &lt;filename&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot save etcd-snapshot.db</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"077a284f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot status &lt;filename&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot status etcd-snapshot.db -w table</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"af357963\"><font style=\"background-color:rgba(255, 255, 255, 0);\">恢复快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot restore &lt;filename&gt; [options] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"0255a4be\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复演示</font></h3>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">新建一个名为name的key</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl put name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint status -w table</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照，创建名为snap.db的备份文件</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# etcdctl snapshot save snap.db</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.5883558,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:119&quot;,&quot;msg&quot;:&quot;created temporary db file&quot;,&quot;path&quot;:&quot;snap.db.part&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2023-03-19T18:12:32.592+0800&quot;,&quot;caller&quot;:&quot;clientv3/maintenance.go:200&quot;,&quot;msg&quot;:&quot;opened snapshot stream; downloading&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.5924425,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:127&quot;,&quot;msg&quot;:&quot;fetching snapshot&quot;,&quot;endpoint&quot;:&quot;127.0.0.1:2379&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2023-03-19T18:12:32.595+0800&quot;,&quot;caller&quot;:&quot;clientv3/maintenance.go:208&quot;,&quot;msg&quot;:&quot;completed snapshot read; closing&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.597161,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:142&quot;,&quot;msg&quot;:&quot;fetched snapshot&quot;,&quot;endpoint&quot;:&quot;127.0.0.1:2379&quot;,&quot;size&quot;:&quot;25 kB&quot;,&quot;took&quot;:0.008507131&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.5973082,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:152&quot;,&quot;msg&quot;:&quot;saved&quot;,&quot;path&quot;:&quot;snap.db&quot;&#125;</span><br><span class=\"line\">Snapshot saved at snap.db</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看备份文件详情</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# ls -lh snap.db </span><br><span class=\"line\">-rw------- 1 root root 25K 3月  19 18:12 snap.db</span><br><span class=\"line\">[root@k8s-work1 ~]# etcdctl snapshot status snap.db -w table</span><br><span class=\"line\">+----------+----------+------------+------------+</span><br><span class=\"line\">|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |</span><br><span class=\"line\">+----------+----------+------------+------------+</span><br><span class=\"line\">| 8f097221 |       39 |         47 |      25 kB |</span><br><span class=\"line\">+----------+----------+------------+------------+</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">把快照文件传到其他节点</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# scp snap.db 192.168.10.100:/root                                                                                                                      100%   24KB   6.9MB/s   00:00    </span><br><span class=\"line\">[root@k8s-work1 ~]# scp snap.db 192.168.10.12:/root</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">停止所有节点的etcd服务，并删除数据目录</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# systemctl stop etcd</span><br><span class=\"line\">[root@k8s-work1 ~]# rm -rf /data/etcd</span><br><span class=\"line\"># 其余两个节点相同操作</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">在所有节点上开始恢复数据</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# etcdctl snapshot restore snap.db --name=etcd2 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.11:2380</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.2932272,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:296&quot;,&quot;msg&quot;:&quot;restoring snapshot&quot;,&quot;path&quot;:&quot;snap.db&quot;,&quot;wal-dir&quot;:&quot;/data/etcd/cluster.etcd/member/wal&quot;,&quot;data-dir&quot;:&quot;/data/etcd/cluster.etcd&quot;,&quot;snap-dir&quot;:&quot;/data/etcd/cluster.etcd/member/snap&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.3019996,&quot;caller&quot;:&quot;membership/cluster.go:392&quot;,&quot;msg&quot;:&quot;added member&quot;,&quot;cluster-id&quot;:&quot;cd30cff36981306b&quot;,&quot;local-member-id&quot;:&quot;0&quot;,&quot;added-peer-id&quot;:&quot;2e0eda3ad6bc6e1e&quot;,&quot;added-peer-peer-urls&quot;:[&quot;http://192.168.10.100:2380&quot;]&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.30208,&quot;caller&quot;:&quot;membership/cluster.go:392&quot;,&quot;msg&quot;:&quot;added member&quot;,&quot;cluster-id&quot;:&quot;cd30cff36981306b&quot;,&quot;local-member-id&quot;:&quot;0&quot;,&quot;added-peer-id&quot;:&quot;5d2c1bd3b22f796f&quot;,&quot;added-peer-peer-urls&quot;:[&quot;http://192.168.10.12:2380&quot;]&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.3021913,&quot;caller&quot;:&quot;membership/cluster.go:392&quot;,&quot;msg&quot;:&quot;added member&quot;,&quot;cluster-id&quot;:&quot;cd30cff36981306b&quot;,&quot;local-member-id&quot;:&quot;0&quot;,&quot;added-peer-id&quot;:&quot;bc34c6bd673bdf9f&quot;,&quot;added-peer-peer-urls&quot;:[&quot;http://192.168.10.11:2380&quot;]&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.3094716,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:309&quot;,&quot;msg&quot;:&quot;restored snapshot&quot;,&quot;path&quot;:&quot;snap.db&quot;,&quot;wal-dir&quot;:&quot;/data/etcd/cluster.etcd/member/wal&quot;,&quot;data-dir&quot;:&quot;/data/etcd/cluster.etcd&quot;,&quot;snap-dir&quot;:&quot;/data/etcd/cluster.etcd/member/snap&quot;&#125;</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl snapshot restore snap.db --name=etcd1 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.100:2380</span><br><span class=\"line\">[root@k8s-work2 ~]# etcdctl snapshot restore snap.db --name=etcd3 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.12:2380</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">所有节点重启etcd服务</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# systemctl restart etcd</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl get name</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint status -w table</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重启etcd后，仍能正常获取name的值，并且节点ID未发生改变。</font></p>\n<h2 id=\"7c91fffc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd默认是没有开启访问控制的，如果开启外网访问etcd的话就需要考虑访问控制的问题，etcd提供了两种访问控制的方式：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">基于身份验证的访问控制</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">基于证书的访问控制</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从v3.2版本开始，如果使用参数 –client-cert-auth&#x3D;true 启动etcd服务器，则客户端的TLS证书中的 “通用名称（CN）” 字段将用作 etcd 用户。在这种情况下，公用名将对用户进行身份验证，并且客户端不需要密码。如果同时传递了 –client-cert-auth&#x3D;true 且客户端提供了 CN，并且客户端提供了用户名和密码，则将优先考虑基于用户名和密码的身份验证。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd有一个特殊用户root和一个特殊角色root：</font></p>\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">root用户</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：root用户是etcd的超级管理员，拥有etcd的所有权限，在开启角色认证之前为们必须要先建立好root用户</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">root角色</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：具有该root角色的用户既具有全局读写访问权限，具有更新集群的身份验证配置的权限。此外，该root角色还授予常规集群维护的特权，包括修改集群成员资格，对存储进行碎片整理以及拍摄快照。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd的权限资源：</font></p>\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Users</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">: user用来设置身份认证(user:passwd)，一个用户可以拥有多个角色，每个角色被分配一定的权限(只读、只写、可读写)，用户分为root用户和非root用户。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Roles</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">: 角色用来关联权限，角色主要三类：<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">root角色:默认创建root用户时即创建了root角色，该角色拥有所有权限；<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">guest角色:默认自动创建，主要用于非认证使用。普通角色，<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">由root用户创建角色，并分配指定权限。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Permissions</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">: 权限分为只读、只写、可读写三种权限，权限即对指定目录或key的读写权限。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果没有指定任何验证方式，即未显示指定以什么用户进行访问，那么默认会设定为 guest 角色。默认情况下 guest 也是具有全局访问权限的</font></p>\n<h3 id=\"7d94de1c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl user &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">add</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user add &lt; user name or user:password &gt; [options] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">添加新用户</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user delete &lt; user name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">list</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user list [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有用户</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">get</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user get &lt; user name &gt; [options] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户详细信息</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">passwd</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user passwd &lt; user name &gt; [options] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">修改密码</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">grant-role</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user grant-role &lt; user name &gt; &lt; role name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">赋予用户角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-role</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user revoke-role &lt; user name &gt; &lt; role name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户角色</font></td>\n</tr>\n</tbody></table>\n<h3 id=\"3f856ec2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl role &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">add</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role add &lt; role name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">添加角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role delete[flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">list</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role list [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">get</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role get[flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">获取角色详情</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">grant-permission</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role grant-permission [options] &lt; role name &gt; &lt; permission type &gt; &lt; key &gt; [endkey] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">把key操作权限授予给一个角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-permission</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role revoke-permission &lt; role name &gt; &lt; key &gt; [endkey] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">从角色中撤销key操作权限</font></td>\n</tr>\n</tbody></table>\n<h3 id=\"2c28d63a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启身份验证后，注意事项如下所示：</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">开启身份验证：所有etcdctl命令操作都需要指定用户参数–user，参数值为用户名:密码</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">开启证书验证：所有etcdctl命令操作都需要添加证书参数–cacert</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证的步骤如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加root 用户，密码为123456</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user add root:123456</span><br><span class=\"line\">User root created</span><br><span class=\"line\"># 开启身份验证，开启为enable，取消为disable</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl auth enable --user=root:123456</span><br><span class=\"line\">Authentication Enabled</span><br><span class=\"line\"># 在开启身份验证后，直接获取键值报错</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-03-19T19:00:03.922+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:62&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;endpoint://client-bdd66650-a0b8-4fb4-ab60-47336cfb7523/192.168.10.100:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = InvalidArgument desc = etcdserver: user name is empty&quot;&#125;</span><br><span class=\"line\">Error: etcdserver: user name is empty</span><br><span class=\"line\"># 添加用户信息访问</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name --user=root:123456</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"debce981\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启了root身份验证后，就可以对普通用户和角色操作了。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">用户增删改查</font>**\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 增加普通用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456</span><br><span class=\"line\">User test created</span><br><span class=\"line\"># 获取用户信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user get test --user=root:123456</span><br><span class=\"line\">User: test</span><br><span class=\"line\">Roles:</span><br><span class=\"line\"># 查看所有用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user list --user=root:123456</span><br><span class=\"line\">root</span><br><span class=\"line\">test</span><br><span class=\"line\"># 修改用户密码</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user passwd test --user=root:123456</span><br><span class=\"line\">Password of test: </span><br><span class=\"line\">Type password of test again for confirmation: </span><br><span class=\"line\">Password updated</span><br><span class=\"line\"># 删除用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user delete test --user=root:123456</span><br><span class=\"line\">User test deleted</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">角色增删改查</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role add test-role --user=root:123456</span><br><span class=\"line\">Role test-role created</span><br><span class=\"line\"># 获取角色详细信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\"># 获取所有角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role list --user=root:123456</span><br><span class=\"line\">root</span><br><span class=\"line\">test-role</span><br><span class=\"line\"># 删除角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role delete test-role --user=root:123456</span><br><span class=\"line\">Role test-role deleted</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">用户角色绑定</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 增加普通用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456</span><br><span class=\"line\">User test created</span><br><span class=\"line\"># 添加角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role add test-role --user=root:123456</span><br><span class=\"line\">Role test-role created</span><br><span class=\"line\"># 将角色绑定给指定用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user grant-role test test-role --user=root:123456</span><br><span class=\"line\">Role test-role is granted to user test</span><br><span class=\"line\"># 查看用户信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user get test --user=root:123456</span><br><span class=\"line\">User: test</span><br><span class=\"line\">Roles: test-role</span><br><span class=\"line\"></span><br><span class=\"line\"># 取消用户与角色绑定</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user revoke-role test test-role --user=root:123456</span><br><span class=\"line\">Role test-role is revoked from user test</span><br><span class=\"line\"># 查看用户信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user get test --user=root:123456</span><br><span class=\"line\">User: test</span><br><span class=\"line\">Roles:</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">权限分为：只读（read）、只写(write)和读写(readwrite)权限</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 使用test用户获取name值会报错，权限拒绝</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name --user=test:123</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-03-19T19:10:50.515+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:62&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;endpoint://client-dbe4e470-b1f4-40a1-b48f-71fcab9f32f0/192.168.10.100:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = PermissionDenied desc = etcdserver: permission denied&quot;&#125;</span><br><span class=\"line\">Error: etcdserver: permission denied</span><br><span class=\"line\"></span><br><span class=\"line\"># 按key进行授权，test-role角色可以读写name</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite name  --user=root:123456</span><br><span class=\"line\">Role test-role updated</span><br><span class=\"line\"># 查看角色权限详情</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">        name</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\">        name</span><br><span class=\"line\"></span><br><span class=\"line\"># 也可以按key的prefix进行授权</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite foo --prefix=true --user=root:123456</span><br><span class=\"line\">Role test-role updated</span><br><span class=\"line\"># 查看角色权限详情</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br><span class=\"line\">        name</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br><span class=\"line\">        name</span><br><span class=\"line\"></span><br><span class=\"line\"># 撤消角色授权</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role revoke-permission test-role name --user=root:123456</span><br><span class=\"line\">Permission of key name is revoked from role test-role</span><br><span class=\"line\"># 查看角色权限详情</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<h2 id=\"dd367c2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群管理命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl是一个</font><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行的客户端</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">，它提供了一些命令，可以方便我们在对服务进行测试或者手动修改数据库内容。etcdctl命令基本用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl [global options] command [command options] [args...]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">具体的命令选项参数可以通过 etcdctl command –help来获取相关帮助</font></p>\n<h3 id=\"3867e350\"><font style=\"background-color:rgba(255, 255, 255, 0);\">环境变量</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果遇到使用了TLS加密的集群，通常每条指令都需要指定证书路径和etcd节点地址，可以把相关命令行参数添加在环境变量中，在**~/.bashrc**添加以下内容：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# cat ~/.bashrc</span><br><span class=\"line\">HOST_1=https://192.168.10.100:2379</span><br><span class=\"line\">HOST_2=https://192.168.10.11:2379</span><br><span class=\"line\">HOST_3=https://192.168.10.12:2379</span><br><span class=\"line\">ENDPOINTS=$&#123;HOST_1&#125;,$&#123;HOST_2&#125;,$&#123;HOST_3&#125;</span><br><span class=\"line\"># 如果需要使用原生命令，在命令开头加一个\\ 例如：\\etcdctl command</span><br><span class=\"line\">alias etcdctl=&quot;etcdctl --endpoints=$&#123;ENDPOINTS&#125; --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem&quot;</span><br><span class=\"line\">alias etcdctljson=&quot;etcdctl --endpoints=$&#123;ENDPOINTS&#125; --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=json&quot;</span><br><span class=\"line\">alias etcdctltable=&quot;etcdctl --endpoints=$&#123;ENDPOINTS&#125; --cacert=/root/cfssl/etcd/ca.pem --cert=/root/cfssl/etcd/client.pem --key=/root/cfssl/etcd/client-key.pem --write-out=table&quot;</span><br><span class=\"line\">[root@tiaoban etcd]# source ~/.bashrc</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"c66c9b5d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd版本</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl version</span><br><span class=\"line\">etcdctl version: 3.4.23</span><br><span class=\"line\">API version: 3.4</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"e65806ec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看etcd集群节点信息</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl member list -w table</span><br><span class=\"line\">+------------------+---------+-------+----------------------------+----------------------------+------------+</span><br><span class=\"line\">|        ID        | STATUS  | NAME  |         PEER ADDRS         |        CLIENT ADDRS        | IS LEARNER |</span><br><span class=\"line\">+------------------+---------+-------+----------------------------+----------------------------+------------+</span><br><span class=\"line\">| 2e0eda3ad6bc6e1e | started | etcd1 | http://192.168.10.100:2380 | http://192.168.10.100:2379 |      false |</span><br><span class=\"line\">| 5d2c1bd3b22f796f | started | etcd3 |  http://192.168.10.12:2380 |  http://192.168.10.12:2379 |      false |</span><br><span class=\"line\">| bc34c6bd673bdf9f | started | etcd2 |  http://192.168.10.11:2380 |  http://192.168.10.11:2379 |      false |</span><br><span class=\"line\">+------------------+---------+-------+----------------------------+----------------------------+------------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"bcf18e5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群健康状态</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint status -w table</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |          9 |                  9 |        |</span><br><span class=\"line\">|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |</span><br><span class=\"line\">|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |          9 |                  9 |        |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint health -w table</span><br><span class=\"line\">+---------------------+--------+------------+-------+</span><br><span class=\"line\">|      ENDPOINT       | HEALTH |    TOOK    | ERROR |</span><br><span class=\"line\">+---------------------+--------+------------+-------+</span><br><span class=\"line\">| 192.168.10.100:2379 |   true | 4.391924ms |       |</span><br><span class=\"line\">|  192.168.10.11:2379 |   true | 7.091404ms |       |</span><br><span class=\"line\">|  192.168.10.12:2379 |   true | 7.571706ms |       |</span><br><span class=\"line\">+---------------------+--------+------------+-------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"cd2c454b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看告警事件</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果内部出现问题，会触发告警，可以通过命令查看告警引起原因，命令如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl alarm &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用的子命令主要有两个：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看所有告警</span><br><span class=\"line\">etcdctl alarm list</span><br><span class=\"line\"># 解除所有告警</span><br><span class=\"line\">etcdctl alarm disarm</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"c3514e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当集群部署完成后，后续可能需要进行节点扩缩容，就可以使用member命令管理节点。先查看当前集群信息</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         8 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         8 |         16 |                 16 |        |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在启动新的etcd节点前，先向etcd集群声明添加节点的peer-urls和节点名称</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl member add etcd4 --peer-urls=http://192.168.10.100:12380</span><br><span class=\"line\">Member b112a60ec305e42a added to cluster cd30cff36981306b</span><br><span class=\"line\"></span><br><span class=\"line\">ETCD_NAME=&quot;etcd4&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER=&quot;etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:12380,etcd2=http://192.168.10.11:2380&quot;</span><br><span class=\"line\">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.10.100:12380&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER_STATE=&quot;existing&quot;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# mkdir -p /opt/docker/etcd/&#123;conf,data&#125;</span><br><span class=\"line\">[root@tiaoban etcd]# chown -R 1001:1001 /opt/docker/etcd/data/</span><br><span class=\"line\">[root@tiaoban etcd]# cat /opt/docker/etcd/conf/etcd.conf </span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd4&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data&#x27;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.100:12379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.100:12380&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.100:12379&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.100:12380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd3=http://192.168.10.12:2380,etcd2=http://192.168.10.11:2380,etcd4=http://192.168.10.100:12380&quot;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;existing&#x27;</span><br><span class=\"line\">[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:latest etcd --config-file /conf/etcd.conf</span><br><span class=\"line\">a142f38c785f2b7c217fb15f01ac62addfeb22eeb44da00363b1f7b5ce398439</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd4启动后，查看集群节点信息：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">| http://192.168.10.100:12379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         11 |                 11 |        |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"8456c2a4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">当etcd节点故障，启动etcd时报错</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">**member count is unequal**</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">。如果有保留的数据目录下的文件时，可以通过使用 member update 命令，在保留 etcd 数据的情况下初始化集群数据，重新构建一个新的etcd集群节点。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:12380节点故障，但数据目录文件有备份，启动一个新的节点，地址为：192.168.10.100:22380</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 停用旧节点</span><br><span class=\"line\">[root@tiaoban etcd]# docker stop etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\">[root@tiaoban etcd]# docker rm etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\"></span><br><span class=\"line\"># 更新节点地址</span><br><span class=\"line\">[root@tiaoban etcd]# cat conf/etcd.conf </span><br><span class=\"line\"># 节点名称</span><br><span class=\"line\">name: &#x27;etcd4&#x27;</span><br><span class=\"line\"># 指定节点的数据存储目录</span><br><span class=\"line\">data-dir: &#x27;/data&#x27;</span><br><span class=\"line\"># 监听客户端请求的地址列表</span><br><span class=\"line\">listen-client-urls: &quot;http://192.168.10.100:22379&quot;</span><br><span class=\"line\"># 监听URL，用于节点之间通信监听地址</span><br><span class=\"line\">listen-peer-urls: &quot;http://192.168.10.100:22380&quot;</span><br><span class=\"line\"># 对外公告的该节点客户端监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">advertise-client-urls: &quot;http://192.168.10.100:22379&quot;</span><br><span class=\"line\"># 服务端之间通讯使用的地址列表,该节点同伴监听地址，这个值会告诉集群中其他节点</span><br><span class=\"line\">initial-advertise-peer-urls: &quot;http://192.168.10.100:22380&quot;</span><br><span class=\"line\"># etcd启动时，etcd集群的节点地址列表</span><br><span class=\"line\">initial-cluster: &quot;etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380,etcd4=http://192.168.10.100:22380&quot;</span><br><span class=\"line\"># etcd集群初始化的状态，new代表新建集群，existing表示加入现有集群</span><br><span class=\"line\">initial-cluster-state: &#x27;existing&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\"># 启动新节点</span><br><span class=\"line\">[root@tiaoban etcd]# docker run --name=etcd4 --net=host -d -v /opt/docker/etcd/data:/data -v /opt/docker/etcd/conf:/conf bitnami/etcd:3.4.23 etcd --config-file /conf/etcd.conf</span><br><span class=\"line\">03c03ac7e6b50a8600cefe443ecafdb03f8f61f153b1a1138029c1726826d74e</span><br><span class=\"line\">[root@tiaoban etcd]# docker ps</span><br><span class=\"line\">CONTAINER ID   IMAGE                 COMMAND                   CREATED         STATUS         PORTS     NAMES</span><br><span class=\"line\">03c03ac7e6b5   bitnami/etcd:3.4.23   &quot;/opt/bitnami/script…&quot;   3 seconds ago   Up 3 seconds             etcd4</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">执行更新member操作，指定新的节点地址。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl member update b112a60ec305e42a --peer-urls=http://192.168.10.100:22380</span><br><span class=\"line\">Member b112a60ec305e42a updated in cluster cd30cff36981306b</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群节点信息，节点信息更新完成。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|  http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">|   http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">| http://192.168.10.100:22379 | b112a60ec305e42a |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">|   http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         14 |                 14 |        |</span><br><span class=\"line\">+-----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"93020cb7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除成员</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl member remove &lt;memberID&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">模拟192.168.10.100:22379节点下线操作</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# docker stop etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\">[root@tiaoban etcd]# docker rm etcd4</span><br><span class=\"line\">etcd4</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl member remove b112a60ec305e42a</span><br><span class=\"line\">Member b112a60ec305e42a removed from cluster cd30cff36981306b</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl endpoint status --cluster -w table</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|          ENDPOINT          |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| http://192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         6 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |</span><br><span class=\"line\">|  http://192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         6 |         16 |                 16 |        |</span><br><span class=\"line\">+----------------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f4ce7445\"><font style=\"background-color:rgba(255, 255, 255, 0);\">数据库操作命令</font></h2>\n---\n\n<h3 id=\"7b67e8eb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">增加(put)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加一个键值，基本用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl put [options] &lt;key&gt; &lt;value&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">输出修改前的键值</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">注意事项：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">其中value接受从stdin的输入内容</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果value是以横线-开始，将会被视为flag，如果不希望出现这种情况，可以使用两个横线代替–</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban etcd]# etcdctl put name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put location -- -beijing</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put foo1 bar1</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put foo2 bar2</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put foo3 bar3</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"b9026f46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询(get)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查询键值，基本用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl get [options] &lt;key&gt; [range_end] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–hex</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">以十六进制形式输出</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–limit number</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">设置输出结果的最大值</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配key</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–order</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对输出结果进行排序，ASCEND 或 DESCEND</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–sort-by</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">按给定字段排序，CREATE, KEY, MODIFY, VALUE, VERSION</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–print-value-only</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">仅输出value值</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，获取大于等于指定key的结果</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–keys-only</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">仅获取keys</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 获取键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get name</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\"># 只获取值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get location --print-value-only</span><br><span class=\"line\">-beijing</span><br><span class=\"line\"># 批量取从foo1到foo3的值，不包括foo3</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo foo3 --print-value-only</span><br><span class=\"line\">bar1</span><br><span class=\"line\">bar2</span><br><span class=\"line\"># 批量获取前缀为foo的值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only</span><br><span class=\"line\">bar1</span><br><span class=\"line\">bar2</span><br><span class=\"line\">bar3</span><br><span class=\"line\"># 批量获取符合前缀的前两个值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get --prefix --limit=2 foo --print-value-only</span><br><span class=\"line\">bar1</span><br><span class=\"line\">bar2</span><br><span class=\"line\"># 批量获取前缀为foo的值，并排序</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get --prefix foo --print-value-only --order DESCEND</span><br><span class=\"line\">bar3</span><br><span class=\"line\">bar2</span><br><span class=\"line\">bar1</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"800a3375\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除(del)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除键值，基本用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl del [options] &lt;key&gt; [range_end] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">常用参数如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">参数</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prefix</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">根据prefix进行匹配删除</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–prev-kv</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">输出删除的键值</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">–from-key</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">按byte进行比较，删除大于等于指定key的结果</font></td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 删除name的键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl del name</span><br><span class=\"line\">1</span><br><span class=\"line\"># 删除从foo1到foo3且不包含foo3的键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl del foo1 foo3</span><br><span class=\"line\">2</span><br><span class=\"line\"># 删除前缀为foo的所有键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl del --prefix foo</span><br><span class=\"line\">1</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1e15cca4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">更新(put覆盖)</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">若键已经存在，则进行更新并覆盖原有值，若不存在，则进行添加。</font>\n\n<h3 id=\"9634c1ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查询键历史记录查询</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">etcd在每次键值变更时，都会记录变更信息，便于我们查看键变更记录</font>\n\n<h2 id=\"2c1031f0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">watch是监听键或前缀发生改变的事件流， 主要用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl watch [options] [key or prefix] [range_end] [--] [exec-command arg1 arg2 ...] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 对某个key监听操作，当key1发生改变时，会返回最新值</span><br><span class=\"line\">etcdctl watch name</span><br><span class=\"line\"># 监听key前缀</span><br><span class=\"line\">etcdctl watch name --prefix</span><br><span class=\"line\"># 监听到改变后执行相关操作</span><br><span class=\"line\">etcdctl watch name --  etcdctl get age</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl watch name – etcdctl put name Kevin，如果写成，会不会变成死循环，导致无限监视，尽量避免。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">示例</font></p>\n<h3 id=\"beae6e09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">监听单个键</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 启动监听命令</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\"></span><br><span class=\"line\">#另一个控制台执行新增命令</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\"></span><br><span class=\"line\"># 观察控制台监听输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\"></span><br><span class=\"line\">#另一个控制台执行更新命令</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo bar123</span><br><span class=\"line\">OK</span><br><span class=\"line\"></span><br><span class=\"line\"># 观察控制台监听输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar123</span><br><span class=\"line\"></span><br><span class=\"line\">#另一个控制台执行删除命令</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del foo</span><br><span class=\"line\">1</span><br><span class=\"line\"></span><br><span class=\"line\"># 观察控制台监听输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar123</span><br><span class=\"line\">DELETE</span><br><span class=\"line\">foo</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"8545b8fc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">同时监听多个键</font></h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 监听前缀为foo的键</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch --prefix foo</span><br><span class=\"line\"># 另一个控制台执行操作</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo1 bar1</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put foo2 bar2</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del foo1</span><br><span class=\"line\">1</span><br><span class=\"line\"># 观察控制台输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch --prefix foo</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo1</span><br><span class=\"line\">bar1</span><br><span class=\"line\">PUT</span><br><span class=\"line\">foo2</span><br><span class=\"line\">bar2</span><br><span class=\"line\">DELETE</span><br><span class=\"line\">foo1</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 监听指定的多个键</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch -i</span><br><span class=\"line\">watch name</span><br><span class=\"line\">watch location</span><br><span class=\"line\"></span><br><span class=\"line\"># 另一个控制台执行操作</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del name</span><br><span class=\"line\">1</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl put location beijing</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 观察控制台输出</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl watch -i</span><br><span class=\"line\">watch name</span><br><span class=\"line\">watch location</span><br><span class=\"line\">PUT</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\">DELETE</span><br><span class=\"line\">name</span><br><span class=\"line\"></span><br><span class=\"line\">PUT</span><br><span class=\"line\">location</span><br><span class=\"line\">beijing</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"dc4e3ec3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">租约具有生命周期，需要为租约授予一个TTL(time to live)，将租约绑定到一个key上，则key的生命周期与租约一致，可续租，可撤销租约，类似于redis为键设置过期时间。其主要用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"70ab4a10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">添加租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease grant &lt;ttl&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置60秒后过期时间</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a2b granted with TTL(60s)</span><br><span class=\"line\"># 把foo和租约绑定，设置成60秒后过期</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a29 foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 租约期内查询键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo</span><br><span class=\"line\">foo</span><br><span class=\"line\">bar</span><br><span class=\"line\"># 租约期外查询键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo</span><br><span class=\"line\">返回为空</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"84e9d55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约信息，以便续租或查看租约是否仍然存在或已过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查看租约详情主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease timetolive &lt;leaseID&gt; [options] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加一个50秒的租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 50</span><br><span class=\"line\">lease 6e1e86f4c6512a32 granted with TTL(50s)</span><br><span class=\"line\"># 将name键绑定到6e1e86f4c6512a32租约上</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a32 name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 查看所有租约列表</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease list</span><br><span class=\"line\">found 1 leases</span><br><span class=\"line\">6e1e86f4c6512a32</span><br><span class=\"line\"># 查看租约详情，remaining(6s) 剩余有效时间6秒；--keys 获取租约绑定的 key</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a32</span><br><span class=\"line\">lease 6e1e86f4c6512a32 granted with TTL(50s), remaining(6s), attached keys([name])</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"536b7b10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">租约续约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过刷新 TTL 值来保持租约的有效，使其不会过期。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease keep-alive [options] &lt;leaseID&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置60秒后过期租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a36 granted with TTL(60s)</span><br><span class=\"line\"># 把name和租约绑定，设置成 60 秒后过期</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a36 name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 自动定时执行续约，续约成功后每次租约为60秒</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a36</span><br><span class=\"line\">lease 6e1e86f4c6512a36 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a36 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a36 keepalived with TTL(60)</span><br><span class=\"line\">……</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"92a5dd2d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">删除租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过租约 ID 撤销租约，撤销租约将删除其所有绑定的 key。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl lease revoke &lt;leaseID&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置600秒后过期租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 600</span><br><span class=\"line\">lease 6e1e86f4c6512a39 granted with TTL(600s)</span><br><span class=\"line\"># 把foo和租约绑定，600秒后过期</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a39 foo bar</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 查看租约详情</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39</span><br><span class=\"line\">lease 6e1e86f4c6512a39 granted with TTL(600s), remaining(556s), attached keys([foo])</span><br><span class=\"line\"># 删除租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease revoke 6e1e86f4c6512a39</span><br><span class=\"line\">lease 6e1e86f4c6512a39 revoked</span><br><span class=\"line\"># 查看租约详情</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a39</span><br><span class=\"line\">lease 6e1e86f4c6512a39 already expired</span><br><span class=\"line\"># 获取键值</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get foo</span><br><span class=\"line\">返回为空</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"1f35a899\"><font style=\"background-color:rgba(255, 255, 255, 0);\">多key同一租约</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">一个租约支持绑定多个 key</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置60秒后过期的租约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a3e granted with TTL(60s)</span><br><span class=\"line\"># foo1与租约绑定</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo1 bar1</span><br><span class=\"line\">OK</span><br><span class=\"line\"># foo2与租约绑定</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl put --lease=6e1e86f4c6512a3e foo2 bar2</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 查看租约详情</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease timetolive --keys 6e1e86f4c6512a3e</span><br><span class=\"line\">lease 6e1e86f4c6512a3e granted with TTL(60s), remaining(14s), attached keys([foo1 foo2])</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">租约过期后，所有 key 值都会被删除，因此：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">当租约只绑定了一个 key 时，想删除这个 key，最好的办法是撤销它的租约，而不是直接删除这个 key。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">当租约没有绑定key时，应主动把它撤销掉，单纯删除 key 后，续约操作持续进行，会造成内存泄露。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">直接删除key演示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置租约并绑定 zoo1</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 60</span><br><span class=\"line\">lease 6e1e86f4c6512a43 granted with TTL(60s)</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --lease=6e1e86f4c6512a43 put zoo1 val1</span><br><span class=\"line\">OK</span><br><span class=\"line\"># 续约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\"></span><br><span class=\"line\"># 此时在另一个控制台执行删除key操作：</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl del zoo1</span><br><span class=\"line\">1</span><br><span class=\"line\"># 单纯删除 key 后，续约操作持续进行，会造成内存泄露</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 6e1e86f4c6512a43</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\">lease 6e1e86f4c6512a43 keepalived with TTL(60)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">撤销key的租约演示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置租约并绑定 zoo1</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease grant 50</span><br><span class=\"line\">lease 32698142c52a1717 granted with TTL(50s)</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl --lease=32698142c52a1717 put zoo1 val1</span><br><span class=\"line\">OK</span><br><span class=\"line\"></span><br><span class=\"line\"># 续约</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl lease keep-alive 32698142c52a1717</span><br><span class=\"line\">lease 32698142c52a1717 keepalived with TTL(50)</span><br><span class=\"line\">lease 32698142c52a1717 keepalived with TTL(50)</span><br><span class=\"line\"></span><br><span class=\"line\"># 另一个控制台执行：etcdctl lease revoke 32698142c52a1717</span><br><span class=\"line\"></span><br><span class=\"line\"># 续约撤销并退出</span><br><span class=\"line\">lease 32698142c52a1717 expired or revoked.</span><br><span class=\"line\">[root@tiaoban etcd]# etcdctl get zoo1</span><br><span class=\"line\"># 返回空</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"17c28d47\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">主要用于管理节点的快照，其主要用法如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"f1184f61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot save &lt;filename&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot save etcd-snapshot.db</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"077a284f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot status &lt;filename&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">示例如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot status etcd-snapshot.db -w table</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"af357963\"><font style=\"background-color:rgba(255, 255, 255, 0);\">恢复快照</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl snapshot restore &lt;filename&gt; [options] [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h3 id=\"0255a4be\"><font style=\"background-color:rgba(255, 255, 255, 0);\">备份恢复演示</font></h3>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">新建一个名为name的key</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl put name cuiliang</span><br><span class=\"line\">OK</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint status -w table</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">生成快照，创建名为snap.db的备份文件</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# etcdctl snapshot save snap.db</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.5883558,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:119&quot;,&quot;msg&quot;:&quot;created temporary db file&quot;,&quot;path&quot;:&quot;snap.db.part&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2023-03-19T18:12:32.592+0800&quot;,&quot;caller&quot;:&quot;clientv3/maintenance.go:200&quot;,&quot;msg&quot;:&quot;opened snapshot stream; downloading&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.5924425,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:127&quot;,&quot;msg&quot;:&quot;fetching snapshot&quot;,&quot;endpoint&quot;:&quot;127.0.0.1:2379&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2023-03-19T18:12:32.595+0800&quot;,&quot;caller&quot;:&quot;clientv3/maintenance.go:208&quot;,&quot;msg&quot;:&quot;completed snapshot read; closing&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.597161,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:142&quot;,&quot;msg&quot;:&quot;fetched snapshot&quot;,&quot;endpoint&quot;:&quot;127.0.0.1:2379&quot;,&quot;size&quot;:&quot;25 kB&quot;,&quot;took&quot;:0.008507131&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679220752.5973082,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:152&quot;,&quot;msg&quot;:&quot;saved&quot;,&quot;path&quot;:&quot;snap.db&quot;&#125;</span><br><span class=\"line\">Snapshot saved at snap.db</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看备份文件详情</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# ls -lh snap.db </span><br><span class=\"line\">-rw------- 1 root root 25K 3月  19 18:12 snap.db</span><br><span class=\"line\">[root@k8s-work1 ~]# etcdctl snapshot status snap.db -w table</span><br><span class=\"line\">+----------+----------+------------+------------+</span><br><span class=\"line\">|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |</span><br><span class=\"line\">+----------+----------+------------+------------+</span><br><span class=\"line\">| 8f097221 |       39 |         47 |      25 kB |</span><br><span class=\"line\">+----------+----------+------------+------------+</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">把快照文件传到其他节点</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# scp snap.db 192.168.10.100:/root                                                                                                                      100%   24KB   6.9MB/s   00:00    </span><br><span class=\"line\">[root@k8s-work1 ~]# scp snap.db 192.168.10.12:/root</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">停止所有节点的etcd服务，并删除数据目录</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# systemctl stop etcd</span><br><span class=\"line\">[root@k8s-work1 ~]# rm -rf /data/etcd</span><br><span class=\"line\"># 其余两个节点相同操作</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">在所有节点上开始恢复数据</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# etcdctl snapshot restore snap.db --name=etcd2 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.11:2380</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.2932272,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:296&quot;,&quot;msg&quot;:&quot;restoring snapshot&quot;,&quot;path&quot;:&quot;snap.db&quot;,&quot;wal-dir&quot;:&quot;/data/etcd/cluster.etcd/member/wal&quot;,&quot;data-dir&quot;:&quot;/data/etcd/cluster.etcd&quot;,&quot;snap-dir&quot;:&quot;/data/etcd/cluster.etcd/member/snap&quot;&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.3019996,&quot;caller&quot;:&quot;membership/cluster.go:392&quot;,&quot;msg&quot;:&quot;added member&quot;,&quot;cluster-id&quot;:&quot;cd30cff36981306b&quot;,&quot;local-member-id&quot;:&quot;0&quot;,&quot;added-peer-id&quot;:&quot;2e0eda3ad6bc6e1e&quot;,&quot;added-peer-peer-urls&quot;:[&quot;http://192.168.10.100:2380&quot;]&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.30208,&quot;caller&quot;:&quot;membership/cluster.go:392&quot;,&quot;msg&quot;:&quot;added member&quot;,&quot;cluster-id&quot;:&quot;cd30cff36981306b&quot;,&quot;local-member-id&quot;:&quot;0&quot;,&quot;added-peer-id&quot;:&quot;5d2c1bd3b22f796f&quot;,&quot;added-peer-peer-urls&quot;:[&quot;http://192.168.10.12:2380&quot;]&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.3021913,&quot;caller&quot;:&quot;membership/cluster.go:392&quot;,&quot;msg&quot;:&quot;added member&quot;,&quot;cluster-id&quot;:&quot;cd30cff36981306b&quot;,&quot;local-member-id&quot;:&quot;0&quot;,&quot;added-peer-id&quot;:&quot;bc34c6bd673bdf9f&quot;,&quot;added-peer-peer-urls&quot;:[&quot;http://192.168.10.11:2380&quot;]&#125;</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1679221421.3094716,&quot;caller&quot;:&quot;snapshot/v3_snapshot.go:309&quot;,&quot;msg&quot;:&quot;restored snapshot&quot;,&quot;path&quot;:&quot;snap.db&quot;,&quot;wal-dir&quot;:&quot;/data/etcd/cluster.etcd/member/wal&quot;,&quot;data-dir&quot;:&quot;/data/etcd/cluster.etcd&quot;,&quot;snap-dir&quot;:&quot;/data/etcd/cluster.etcd/member/snap&quot;&#125;</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl snapshot restore snap.db --name=etcd1 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.100:2380</span><br><span class=\"line\">[root@k8s-work2 ~]# etcdctl snapshot restore snap.db --name=etcd3 --data-dir=/data/etcd/cluster.etcd --initial-cluster=etcd1=http://192.168.10.100:2380,etcd2=http://192.168.10.11:2380,etcd3=http://192.168.10.12:2380 --initial-advertise-peer-urls=http://192.168.10.12:2380</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">所有节点重启etcd服务</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# systemctl restart etcd</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">查看验证</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl get name</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl endpoint status -w table</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">|      ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br><span class=\"line\">| 192.168.10.100:2379 | 2e0eda3ad6bc6e1e |  3.4.23 |   20 kB |      true |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.11:2379 | bc34c6bd673bdf9f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">|  192.168.10.12:2379 | 5d2c1bd3b22f796f |  3.4.23 |   20 kB |     false |      false |         4 |         10 |                 10 |        |</span><br><span class=\"line\">+---------------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重启etcd后，仍能正常获取name的值，并且节点ID未发生改变。</font></p>\n<h2 id=\"7c91fffc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理命令</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd默认是没有开启访问控制的，如果开启外网访问etcd的话就需要考虑访问控制的问题，etcd提供了两种访问控制的方式：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">基于身份验证的访问控制</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">基于证书的访问控制</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从v3.2版本开始，如果使用参数 –client-cert-auth&#x3D;true 启动etcd服务器，则客户端的TLS证书中的 “通用名称（CN）” 字段将用作 etcd 用户。在这种情况下，公用名将对用户进行身份验证，并且客户端不需要密码。如果同时传递了 –client-cert-auth&#x3D;true 且客户端提供了 CN，并且客户端提供了用户名和密码，则将优先考虑基于用户名和密码的身份验证。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd有一个特殊用户root和一个特殊角色root：</font></p>\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">root用户</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：root用户是etcd的超级管理员，拥有etcd的所有权限，在开启角色认证之前为们必须要先建立好root用户</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">root角色</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：具有该root角色的用户既具有全局读写访问权限，具有更新集群的身份验证配置的权限。此外，该root角色还授予常规集群维护的特权，包括修改集群成员资格，对存储进行碎片整理以及拍摄快照。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">etcd的权限资源：</font></p>\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Users</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">: user用来设置身份认证(user:passwd)，一个用户可以拥有多个角色，每个角色被分配一定的权限(只读、只写、可读写)，用户分为root用户和非root用户。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Roles</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">: 角色用来关联权限，角色主要三类：<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">root角色:默认创建root用户时即创建了root角色，该角色拥有所有权限；<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">guest角色:默认自动创建，主要用于非认证使用。普通角色，<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">由root用户创建角色，并分配指定权限。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">Permissions</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">: 权限分为只读、只写、可读写三种权限，权限即对指定目录或key的读写权限。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果没有指定任何验证方式，即未显示指定以什么用户进行访问，那么默认会设定为 guest 角色。默认情况下 guest 也是具有全局访问权限的</font></p>\n<h3 id=\"7d94de1c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">用户管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl user &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">add</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user add &lt; user name or user:password &gt; [options] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">添加新用户</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user delete &lt; user name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">list</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user list [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有用户</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">get</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user get &lt; user name &gt; [options] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户详细信息</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">passwd</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user passwd &lt; user name &gt; [options] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">修改密码</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">grant-role</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user grant-role &lt; user name &gt; &lt; role name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">赋予用户角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-role</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl user revoke-role &lt; user name &gt; &lt; role name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除用户角色</font></td>\n</tr>\n</tbody></table>\n<h3 id=\"3f856ec2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色管理</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其主要用法如下所示：</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcdctl role &lt;subcommand&gt; [flags]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其主要子命令主要如下所示：</font></p>\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">子命令</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">常用用法</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能描述</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">add</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role add &lt; role name &gt; [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">添加角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">delete</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role delete[flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">list</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role list [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">列出所有角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">get</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role get[flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">获取角色详情</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">grant-permission</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role grant-permission [options] &lt; role name &gt; &lt; permission type &gt; &lt; key &gt; [endkey] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">把key操作权限授予给一个角色</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">revoke-permission</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">etcdctl role revoke-permission &lt; role name &gt; &lt; key &gt; [endkey] [flags]</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">从角色中撤销key操作权限</font></td>\n</tr>\n</tbody></table>\n<h3 id=\"2c28d63a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启身份验证后，注意事项如下所示：</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">开启身份验证：所有etcdctl命令操作都需要指定用户参数–user，参数值为用户名:密码</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">开启证书验证：所有etcdctl命令操作都需要添加证书参数–cacert</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">开启root身份验证的步骤如下所示：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加root 用户，密码为123456</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user add root:123456</span><br><span class=\"line\">User root created</span><br><span class=\"line\"># 开启身份验证，开启为enable，取消为disable</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl auth enable --user=root:123456</span><br><span class=\"line\">Authentication Enabled</span><br><span class=\"line\"># 在开启身份验证后，直接获取键值报错</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-03-19T19:00:03.922+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:62&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;endpoint://client-bdd66650-a0b8-4fb4-ab60-47336cfb7523/192.168.10.100:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = InvalidArgument desc = etcdserver: user name is empty&quot;&#125;</span><br><span class=\"line\">Error: etcdserver: user name is empty</span><br><span class=\"line\"># 添加用户信息访问</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name --user=root:123456</span><br><span class=\"line\">name</span><br><span class=\"line\">cuiliang</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"debce981\"><font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在开启了root身份验证后，就可以对普通用户和角色操作了。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">用户增删改查</font>**\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 增加普通用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456</span><br><span class=\"line\">User test created</span><br><span class=\"line\"># 获取用户信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user get test --user=root:123456</span><br><span class=\"line\">User: test</span><br><span class=\"line\">Roles:</span><br><span class=\"line\"># 查看所有用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user list --user=root:123456</span><br><span class=\"line\">root</span><br><span class=\"line\">test</span><br><span class=\"line\"># 修改用户密码</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user passwd test --user=root:123456</span><br><span class=\"line\">Password of test: </span><br><span class=\"line\">Type password of test again for confirmation: </span><br><span class=\"line\">Password updated</span><br><span class=\"line\"># 删除用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user delete test --user=root:123456</span><br><span class=\"line\">User test deleted</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">角色增删改查</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role add test-role --user=root:123456</span><br><span class=\"line\">Role test-role created</span><br><span class=\"line\"># 获取角色详细信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\"># 获取所有角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role list --user=root:123456</span><br><span class=\"line\">root</span><br><span class=\"line\">test-role</span><br><span class=\"line\"># 删除角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role delete test-role --user=root:123456</span><br><span class=\"line\">Role test-role deleted</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">用户角色绑定</font></strong></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 增加普通用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user add test:123 --user=root:123456</span><br><span class=\"line\">User test created</span><br><span class=\"line\"># 添加角色</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role add test-role --user=root:123456</span><br><span class=\"line\">Role test-role created</span><br><span class=\"line\"># 将角色绑定给指定用户</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user grant-role test test-role --user=root:123456</span><br><span class=\"line\">Role test-role is granted to user test</span><br><span class=\"line\"># 查看用户信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user get test --user=root:123456</span><br><span class=\"line\">User: test</span><br><span class=\"line\">Roles: test-role</span><br><span class=\"line\"></span><br><span class=\"line\"># 取消用户与角色绑定</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user revoke-role test test-role --user=root:123456</span><br><span class=\"line\">Role test-role is revoked from user test</span><br><span class=\"line\"># 查看用户信息</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl user get test --user=root:123456</span><br><span class=\"line\">User: test</span><br><span class=\"line\">Roles:</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">角色授权</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">权限分为：只读（read）、只写(write)和读写(readwrite)权限</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 使用test用户获取name值会报错，权限拒绝</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl get name --user=test:123</span><br><span class=\"line\">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-03-19T19:10:50.515+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:62&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;endpoint://client-dbe4e470-b1f4-40a1-b48f-71fcab9f32f0/192.168.10.100:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = PermissionDenied desc = etcdserver: permission denied&quot;&#125;</span><br><span class=\"line\">Error: etcdserver: permission denied</span><br><span class=\"line\"></span><br><span class=\"line\"># 按key进行授权，test-role角色可以读写name</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite name  --user=root:123456</span><br><span class=\"line\">Role test-role updated</span><br><span class=\"line\"># 查看角色权限详情</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">        name</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\">        name</span><br><span class=\"line\"></span><br><span class=\"line\"># 也可以按key的prefix进行授权</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role grant-permission test-role readwrite foo --prefix=true --user=root:123456</span><br><span class=\"line\">Role test-role updated</span><br><span class=\"line\"># 查看角色权限详情</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br><span class=\"line\">        name</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br><span class=\"line\">        name</span><br><span class=\"line\"></span><br><span class=\"line\"># 撤消角色授权</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role revoke-permission test-role name --user=root:123456</span><br><span class=\"line\">Permission of key name is revoked from role test-role</span><br><span class=\"line\"># 查看角色权限详情</span><br><span class=\"line\">[root@tiaoban ~]# etcdctl role get test-role --user=root:123456</span><br><span class=\"line\">Role test-role</span><br><span class=\"line\">KV Read:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br><span class=\"line\">KV Write:</span><br><span class=\"line\">        [foo, fop) (prefix foo)</span><br></pre></td></tr></table></figure>\n\n"},{"title":"安装容器运行时(Containerd)","date":"2025-03-11T10:00:00.000Z","_content":"> <font style=\"background-color:rgba(255, 255, 255, 0);\">从Kubernetes 1.20版本开始官方不推荐使用Docker，1.24版本将完全弃用docker。如果安装1.22以上版本的k8s，官方推荐使用containerd，docker支持k8s版本最高为1.23.16。</font>\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的Containerd版本范围，具体参考官方文档</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font>](https://github.com/kubernetes/kubernetes/releases)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以1.24.X为例，查看</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md</font>](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800976689-0ad68850-7c7c-4556-873c-d01f7eb564a2.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的最低版本Containerd为1.4.12</font>\n\n<h1 id=\"e3833a08\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装container</font></h1>\n---\n\n<h2 id=\"rhel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL</font></h2>\n---\n\n```shell\n# 安装依赖\n[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2\n# 添加yum源\n[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n# 查看可安装的containerd版本\n[root@k8s-master ~]# yum list containerd.io.x86_64 --showduplicates | sort -r\n# 安装1.6.4版本containerd\n[root@k8s-master ~]# yum install -y containerd.io-1.6.4-3.1.el8.x86_64\n[root@k8s-master ~]# containerd -v\ncontainerd containerd.io 1.6.4 212e8b6fa2f44b9c21b2798135fc6fb7c53efc16\n```\n\n<h2 id=\"debian\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian</font></h2>\n---\n\n```shell\n# step 1: 安装必要的一些系统工具\nroot@k8s-master:~# apt-get update && apt-get -y install apt-transport-https ca-certificates curl software-properties-common\n# step 2: 安装GPG证书\nroot@k8s-master:~# curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add -\n# Step 3: 写入软件源信息\nroot@k8s-master:~# add-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\n# Step 4: 更新并安装containerd\nroot@k8s-master:~# apt-get -y update && apt-cache madison containerd.io | sort -V\nroot@k8s-master:~# apt-get -y install containerd.io=1.5.11-1\n# 验证\nroot@k8s-master:~# containerd -v\n```\n\n<h1 id=\"362c48f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改container配置</font></h1>\n---\n\n<h2 id=\"405b4c46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font></h2>\n---\n\n```shell\n[root@k8s-master ~]# containerd config default > /etc/containerd/config.toml\n```\n\n<h2 id=\"4799a358\"><font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。</font><font style=\"background-color:rgba(255, 255, 255, 0);\">把sandbox_image = \"k8s.gcr.io/pause:3.6\"修改为：sandbox_image=“registry.aliyuncs.com/google_containers/pause:3.6”</font>\n\n```shell\n[root@k8s-master ~]# sed -i 's/sandbox_image\\ =.*/sandbox_image\\ =\\ \"registry.aliyuncs.com\\/google_containers\\/pause:3.6\"/g' /etc/containerd/config.toml|grep sandbox_image\n```\n\n<h2 id=\"6cc5ad61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">cgroup</font><font style=\"background-color:rgba(255, 255, 255, 0);\">驱动器</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 </font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和容器运行时需使用相同的 cgroup 驱动</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">并且采用相同的配置。</font>\n\n```shell\n[root@k8s-master ~]# sed -i 's/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g' /etc/containerd/config.toml\n```\n\n<h2 id=\"840c5742\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">与我们之前配置docker镜像源的做法类似，在国内使用containerd依然需要更换成国内的镜像源。但是这里有一些问题需要说明一下：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">配置的镜像仓库在使用crictl工具调用或者kubernetes调用时才会生效，如果使用ctr命令拉取镜像是不生效的。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Docker 只支持为 Docker Hub 配置 mirror，而 Containerd 支持为任意镜像仓库配置 mirror</font>\n\n```shell\n# 修改container配置，指定registry配置从文件读取\n[root@k8s-master ~]# vim /etc/containerd/config.toml\n    [plugins.\"io.containerd.grpc.v1.cri\".registry]\n      config_path = \"/etc/containerd/certs.d\" # 添加配置文件地址\n\n# 创建配置文件目录\n[root@k8s-master ~]# mkdir -p /etc/containerd/certs.d/docker.io\n\n# 新增加速配置\n[root@k8s-master ~]# cat > /etc/containerd/certs.d/docker.io/hosts.toml << EOF\nserver = \"https://docker.io\"\n[host.\"https://registry-1.docker.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n\n[host.\"https://934du3yi.mirror.aliyuncs.com\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从配置文件里面我们看到的</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">server表示需要配置的mirror的镜像仓库，例如：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://docker.io</font>](https://docker.io/)<font style=\"background-color:rgba(255, 255, 255, 0);\">表示配置的是docker.io的mirror，这是最基本的镜像。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">host：表示提供的mirror的镜像加速服务，可以使用中国科技大学的，也可以使用阿里云的镜像。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images</font>](https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images)\n\n<h1 id=\"1446f09b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 containerd 服务</font></h1>\n---\n\n```shell\n[root@k8s-master ~]# systemctl daemon-reload\n[root@k8s-master ~]# systemctl enable containerd\n[root@k8s-master ~]# systemctl start containerd\n```\n\n<h1 id=\"17e08cf7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时</font></h1>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用containerd作为容器运行时，需要指定kubelet的容器运行时，如果使用docker作为容器运行时，则无需操作下面的步骤。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl安装参考containerd进阶使用。</font>\n\n```shell\n[root@k8s-master ~]# crictl config runtime-endpoint /run/containerd/containerd.sock\n[root@k8s-master ~]# systemctl daemon-reload\n[root@k8s-master ~]# systemctl restart kubelet\n```\n\n","source":"_posts/3.安装容器运行时(Containerd) 副本.md","raw":"---\ntitle: 安装容器运行时(Containerd) \ndate: 2025-03-11 18:00:00\n---\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">从Kubernetes 1.20版本开始官方不推荐使用Docker，1.24版本将完全弃用docker。如果安装1.22以上版本的k8s，官方推荐使用containerd，docker支持k8s版本最高为1.23.16。</font>\n>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的Containerd版本范围，具体参考官方文档</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font>](https://github.com/kubernetes/kubernetes/releases)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以1.24.X为例，查看</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md</font>](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800976689-0ad68850-7c7c-4556-873c-d01f7eb564a2.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的最低版本Containerd为1.4.12</font>\n\n<h1 id=\"e3833a08\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装container</font></h1>\n---\n\n<h2 id=\"rhel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL</font></h2>\n---\n\n```shell\n# 安装依赖\n[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2\n# 添加yum源\n[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n# 查看可安装的containerd版本\n[root@k8s-master ~]# yum list containerd.io.x86_64 --showduplicates | sort -r\n# 安装1.6.4版本containerd\n[root@k8s-master ~]# yum install -y containerd.io-1.6.4-3.1.el8.x86_64\n[root@k8s-master ~]# containerd -v\ncontainerd containerd.io 1.6.4 212e8b6fa2f44b9c21b2798135fc6fb7c53efc16\n```\n\n<h2 id=\"debian\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian</font></h2>\n---\n\n```shell\n# step 1: 安装必要的一些系统工具\nroot@k8s-master:~# apt-get update && apt-get -y install apt-transport-https ca-certificates curl software-properties-common\n# step 2: 安装GPG证书\nroot@k8s-master:~# curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add -\n# Step 3: 写入软件源信息\nroot@k8s-master:~# add-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"\n# Step 4: 更新并安装containerd\nroot@k8s-master:~# apt-get -y update && apt-cache madison containerd.io | sort -V\nroot@k8s-master:~# apt-get -y install containerd.io=1.5.11-1\n# 验证\nroot@k8s-master:~# containerd -v\n```\n\n<h1 id=\"362c48f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改container配置</font></h1>\n---\n\n<h2 id=\"405b4c46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font></h2>\n---\n\n```shell\n[root@k8s-master ~]# containerd config default > /etc/containerd/config.toml\n```\n\n<h2 id=\"4799a358\"><font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。</font><font style=\"background-color:rgba(255, 255, 255, 0);\">把sandbox_image = \"k8s.gcr.io/pause:3.6\"修改为：sandbox_image=“registry.aliyuncs.com/google_containers/pause:3.6”</font>\n\n```shell\n[root@k8s-master ~]# sed -i 's/sandbox_image\\ =.*/sandbox_image\\ =\\ \"registry.aliyuncs.com\\/google_containers\\/pause:3.6\"/g' /etc/containerd/config.toml|grep sandbox_image\n```\n\n<h2 id=\"6cc5ad61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">cgroup</font><font style=\"background-color:rgba(255, 255, 255, 0);\">驱动器</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 </font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和容器运行时需使用相同的 cgroup 驱动</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">并且采用相同的配置。</font>\n\n```shell\n[root@k8s-master ~]# sed -i 's/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g' /etc/containerd/config.toml\n```\n\n<h2 id=\"840c5742\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">与我们之前配置docker镜像源的做法类似，在国内使用containerd依然需要更换成国内的镜像源。但是这里有一些问题需要说明一下：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">配置的镜像仓库在使用crictl工具调用或者kubernetes调用时才会生效，如果使用ctr命令拉取镜像是不生效的。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Docker 只支持为 Docker Hub 配置 mirror，而 Containerd 支持为任意镜像仓库配置 mirror</font>\n\n```shell\n# 修改container配置，指定registry配置从文件读取\n[root@k8s-master ~]# vim /etc/containerd/config.toml\n    [plugins.\"io.containerd.grpc.v1.cri\".registry]\n      config_path = \"/etc/containerd/certs.d\" # 添加配置文件地址\n\n# 创建配置文件目录\n[root@k8s-master ~]# mkdir -p /etc/containerd/certs.d/docker.io\n\n# 新增加速配置\n[root@k8s-master ~]# cat > /etc/containerd/certs.d/docker.io/hosts.toml << EOF\nserver = \"https://docker.io\"\n[host.\"https://registry-1.docker.io\"]\n  capabilities = [\"pull\", \"resolve\"]\n\n[host.\"https://934du3yi.mirror.aliyuncs.com\"]\n  capabilities = [\"pull\", \"resolve\"]\nEOF\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从配置文件里面我们看到的</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">server表示需要配置的mirror的镜像仓库，例如：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://docker.io</font>](https://docker.io/)<font style=\"background-color:rgba(255, 255, 255, 0);\">表示配置的是docker.io的mirror，这是最基本的镜像。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">host：表示提供的mirror的镜像加速服务，可以使用中国科技大学的，也可以使用阿里云的镜像。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images</font>](https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images)\n\n<h1 id=\"1446f09b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 containerd 服务</font></h1>\n---\n\n```shell\n[root@k8s-master ~]# systemctl daemon-reload\n[root@k8s-master ~]# systemctl enable containerd\n[root@k8s-master ~]# systemctl start containerd\n```\n\n<h1 id=\"17e08cf7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时</font></h1>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用containerd作为容器运行时，需要指定kubelet的容器运行时，如果使用docker作为容器运行时，则无需操作下面的步骤。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl安装参考containerd进阶使用。</font>\n\n```shell\n[root@k8s-master ~]# crictl config runtime-endpoint /run/containerd/containerd.sock\n[root@k8s-master ~]# systemctl daemon-reload\n[root@k8s-master ~]# systemctl restart kubelet\n```\n\n","slug":"3.安装容器运行时(Containerd) 副本","published":1,"updated":"2025-03-30T13:10:55.103Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlp000ktsv194gc4sg7","content":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从Kubernetes 1.20版本开始官方不推荐使用Docker，1.24版本将完全弃用docker。如果安装1.22以上版本的k8s，官方推荐使用containerd，docker支持k8s版本最高为1.23.16。</font></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的Containerd版本范围，具体参考官方文档</font><a href=\"https://github.com/kubernetes/kubernetes/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以1.24.X为例，查看</font><a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md</font></a></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800976689-0ad68850-7c7c-4556-873c-d01f7eb564a2.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的最低版本Containerd为1.4.12</font></p>\n<h1 id=\"e3833a08\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装container</font></h1>\n---\n\n<h2 id=\"rhel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装依赖</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">添加yum源</span></span><br><span class=\"line\">[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看可安装的containerd版本</span></span><br><span class=\"line\">[root@k8s-master ~]# yum list containerd.io.x86_64 --showduplicates | sort -r</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装1.6.4版本containerd</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y containerd.io-1.6.4-3.1.el8.x86_64</span><br><span class=\"line\">[root@k8s-master ~]# containerd -v</span><br><span class=\"line\">containerd containerd.io 1.6.4 212e8b6fa2f44b9c21b2798135fc6fb7c53efc16</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"debian\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">step 1: 安装必要的一些系统工具</span></span><br><span class=\"line\">root@k8s-master:~# apt-get update &amp;&amp; apt-get -y install apt-transport-https ca-certificates curl software-properties-common</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">step 2: 安装GPG证书</span></span><br><span class=\"line\">root@k8s-master:~# curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add -</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Step 3: 写入软件源信息</span></span><br><span class=\"line\">root@k8s-master:~# add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Step 4: 更新并安装containerd</span></span><br><span class=\"line\">root@k8s-master:~# apt-get -y update &amp;&amp; apt-cache madison containerd.io | sort -V</span><br><span class=\"line\">root@k8s-master:~# apt-get -y install containerd.io=1.5.11-1</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">验证</span></span><br><span class=\"line\">root@k8s-master:~# containerd -v</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"362c48f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改container配置</font></h1>\n---\n\n<h2 id=\"405b4c46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# containerd config default &gt; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4799a358\"><font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。</font><font style=\"background-color:rgba(255, 255, 255, 0);\">把sandbox_image &#x3D; “k8s.gcr.io&#x2F;pause:3.6”修改为：sandbox_image&#x3D;“registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.6”</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# sed -i &#x27;s/sandbox_image\\ =.*/sandbox_image\\ =\\ &quot;registry.aliyuncs.com\\/google_containers\\/pause:3.6&quot;/g&#x27; /etc/containerd/config.toml|grep sandbox_image</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6cc5ad61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">cgroup</font><font style=\"background-color:rgba(255, 255, 255, 0);\">驱动器</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 </font><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和容器运行时需使用相同的 cgroup 驱动</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">并且采用相同的配置。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# sed -i &#x27;s/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g&#x27; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"840c5742\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">与我们之前配置docker镜像源的做法类似，在国内使用containerd依然需要更换成国内的镜像源。但是这里有一些问题需要说明一下：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">配置的镜像仓库在使用crictl工具调用或者kubernetes调用时才会生效，如果使用ctr命令拉取镜像是不生效的。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Docker 只支持为 Docker Hub 配置 mirror，而 Containerd 支持为任意镜像仓库配置 mirror</font></li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">修改container配置，指定registry配置从文件读取</span></span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/containerd/config.toml</span><br><span class=\"line\">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]</span><br><span class=\"line\">      config_path = &quot;/etc/containerd/certs.d&quot; # 添加配置文件地址</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">创建配置文件目录</span></span><br><span class=\"line\">[root@k8s-master ~]# mkdir -p /etc/containerd/certs.d/docker.io</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">新增加速配置</span></span><br><span class=\"line\">[root@k8s-master ~]# cat &gt; /etc/containerd/certs.d/docker.io/hosts.toml &lt;&lt; EOF</span><br><span class=\"line\">server = &quot;https://docker.io&quot;</span><br><span class=\"line\">[host.&quot;https://registry-1.docker.io&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">[host.&quot;https://934du3yi.mirror.aliyuncs.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从配置文件里面我们看到的</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">server表示需要配置的mirror的镜像仓库，例如：</font><a href=\"https://docker.io/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://docker.io</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">表示配置的是docker.io的mirror，这是最基本的镜像。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">host：表示提供的mirror的镜像加速服务，可以使用中国科技大学的，也可以使用阿里云的镜像。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font><a href=\"https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images</font></a></p>\n<h1 id=\"1446f09b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 containerd 服务</font></h1>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# systemctl daemon-reload</span><br><span class=\"line\">[root@k8s-master ~]# systemctl enable containerd</span><br><span class=\"line\">[root@k8s-master ~]# systemctl start containerd</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"17e08cf7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时</font></h1>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用containerd作为容器运行时，需要指定kubelet的容器运行时，如果使用docker作为容器运行时，则无需操作下面的步骤。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">crictl安装参考containerd进阶使用。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# crictl config runtime-endpoint /run/containerd/containerd.sock</span><br><span class=\"line\">[root@k8s-master ~]# systemctl daemon-reload</span><br><span class=\"line\">[root@k8s-master ~]# systemctl restart kubelet</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从Kubernetes 1.20版本开始官方不推荐使用Docker，1.24版本将完全弃用docker。如果安装1.22以上版本的k8s，官方推荐使用containerd，docker支持k8s版本最高为1.23.16。</font></p>\n</blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h1 id=\"139b964f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">版本选择</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">每个k8s版本都有对应的Containerd版本范围，具体参考官方文档</font><a href=\"https://github.com/kubernetes/kubernetes/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/releases</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以1.24.X为例，查看</font><a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.24.md</font></a></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737800976689-0ad68850-7c7c-4556-873c-d01f7eb564a2.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由更新日志可知，支持的最低版本Containerd为1.4.12</font></p>\n<h1 id=\"e3833a08\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装container</font></h1>\n---\n\n<h2 id=\"rhel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">RHEL</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装依赖</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">添加yum源</span></span><br><span class=\"line\">[root@k8s-master ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">查看可安装的containerd版本</span></span><br><span class=\"line\">[root@k8s-master ~]# yum list containerd.io.x86_64 --showduplicates | sort -r</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">安装1.6.4版本containerd</span></span><br><span class=\"line\">[root@k8s-master ~]# yum install -y containerd.io-1.6.4-3.1.el8.x86_64</span><br><span class=\"line\">[root@k8s-master ~]# containerd -v</span><br><span class=\"line\">containerd containerd.io 1.6.4 212e8b6fa2f44b9c21b2798135fc6fb7c53efc16</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"debian\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Debian</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">step 1: 安装必要的一些系统工具</span></span><br><span class=\"line\">root@k8s-master:~# apt-get update &amp;&amp; apt-get -y install apt-transport-https ca-certificates curl software-properties-common</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">step 2: 安装GPG证书</span></span><br><span class=\"line\">root@k8s-master:~# curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | apt-key add -</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Step 3: 写入软件源信息</span></span><br><span class=\"line\">root@k8s-master:~# add-apt-repository &quot;deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">Step 4: 更新并安装containerd</span></span><br><span class=\"line\">root@k8s-master:~# apt-get -y update &amp;&amp; apt-cache madison containerd.io | sort -V</span><br><span class=\"line\">root@k8s-master:~# apt-get -y install containerd.io=1.5.11-1</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">验证</span></span><br><span class=\"line\">root@k8s-master:~# containerd -v</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"362c48f1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改container配置</font></h1>\n---\n\n<h2 id=\"405b4c46\"><font style=\"background-color:rgba(255, 255, 255, 0);\">生成默认配置文件</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# containerd config default &gt; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4799a358\"><font style=\"background-color:rgba(255, 255, 255, 0);\">替换镜像源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由于国内环境原因我们需要将 sandbox_image 镜像源设置为阿里云google_containers镜像源。</font><font style=\"background-color:rgba(255, 255, 255, 0);\">把sandbox_image &#x3D; “k8s.gcr.io&#x2F;pause:3.6”修改为：sandbox_image&#x3D;“registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.6”</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# sed -i &#x27;s/sandbox_image\\ =.*/sandbox_image\\ =\\ &quot;registry.aliyuncs.com\\/google_containers\\/pause:3.6&quot;/g&#x27; /etc/containerd/config.toml|grep sandbox_image</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6cc5ad61\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置</font><font style=\"background-color:rgba(255, 255, 255, 0);\">cgroup</font><font style=\"background-color:rgba(255, 255, 255, 0);\">驱动器</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">在 Linux 上，控制组（CGroup）用于限制分配给进程的资源。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和底层容器运行时都需要对接控制组 为 Pod 和容器管理资源 ，如 CPU、内存这类资源设置请求和限制。 若要对接控制组（CGroup），kubelet 和容器运行时需要使用一个 cgroup 驱动。 关键的一点是 </font><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">kubelet 和容器运行时需使用相同的 cgroup 驱动</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">并且采用相同的配置。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# sed -i &#x27;s/SystemdCgroup\\ =\\ false/SystemdCgroup\\ =\\ true/g&#x27; /etc/containerd/config.toml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"840c5742\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置国内镜像加速</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">与我们之前配置docker镜像源的做法类似，在国内使用containerd依然需要更换成国内的镜像源。但是这里有一些问题需要说明一下：</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">配置的镜像仓库在使用crictl工具调用或者kubernetes调用时才会生效，如果使用ctr命令拉取镜像是不生效的。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Docker 只支持为 Docker Hub 配置 mirror，而 Containerd 支持为任意镜像仓库配置 mirror</font></li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">修改container配置，指定registry配置从文件读取</span></span><br><span class=\"line\">[root@k8s-master ~]# vim /etc/containerd/config.toml</span><br><span class=\"line\">    [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry]</span><br><span class=\"line\">      config_path = &quot;/etc/containerd/certs.d&quot; # 添加配置文件地址</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">创建配置文件目录</span></span><br><span class=\"line\">[root@k8s-master ~]# mkdir -p /etc/containerd/certs.d/docker.io</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">新增加速配置</span></span><br><span class=\"line\">[root@k8s-master ~]# cat &gt; /etc/containerd/certs.d/docker.io/hosts.toml &lt;&lt; EOF</span><br><span class=\"line\">server = &quot;https://docker.io&quot;</span><br><span class=\"line\">[host.&quot;https://registry-1.docker.io&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">[host.&quot;https://934du3yi.mirror.aliyuncs.com&quot;]</span><br><span class=\"line\">  capabilities = [&quot;pull&quot;, &quot;resolve&quot;]</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从配置文件里面我们看到的</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">server表示需要配置的mirror的镜像仓库，例如：</font><a href=\"https://docker.io/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://docker.io</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">表示配置的是docker.io的mirror，这是最基本的镜像。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">host：表示提供的mirror的镜像加速服务，可以使用中国科技大学的，也可以使用阿里云的镜像。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font><a href=\"https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://help.aliyun.com/zh/acr/user-guide/accelerate-the-pulls-of-docker-official-images</font></a></p>\n<h1 id=\"1446f09b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动 containerd 服务</font></h1>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# systemctl daemon-reload</span><br><span class=\"line\">[root@k8s-master ~]# systemctl enable containerd</span><br><span class=\"line\">[root@k8s-master ~]# systemctl start containerd</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"17e08cf7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">指定kubelet的容器运行时</font></h1>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果使用containerd作为容器运行时，需要指定kubelet的容器运行时，如果使用docker作为容器运行时，则无需操作下面的步骤。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">crictl安装参考containerd进阶使用。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# crictl config runtime-endpoint /run/containerd/containerd.sock</span><br><span class=\"line\">[root@k8s-master ~]# systemctl daemon-reload</span><br><span class=\"line\">[root@k8s-master ~]# systemctl restart kubelet</span><br></pre></td></tr></table></figure>\n\n"},{"title":"ETCD--confd配置管理","date":"2025-03-05T11:08:06.000Z","_content":"<h1 id=\"800f2ad9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd简介</font></h1>\n---\n\n<h2 id=\"b2847d5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是confd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Confd是一个轻量级的配置管理工具。通过查询后端存储，结合配置模板引擎，保持本地配置最新，同时具备定期探测机制，配置变更自动reload。对应的后端存储可以是etcd，redis、zookeeper等。</font>\n\n<h2 id=\"3ed06af0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd用途</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着上线的服务越来越多，配置文件和配置项越来越复杂，管理和变更维护配置文件逐渐成为一件麻烦的事情。在这时候，就需要一套集中化的配置文件管理系统。一方面实现配置文件的统一管理，版本回溯，另一方面提供配置文件的批量自动下发，已经动态加载重启服务。而confd+etcd就是为解决上述问题提出的一种解决思路。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176432-60ddfdb2-8731-4b7d-9a66-7beb7b76d57b.jpeg)\n\n<h2 id=\"818c70a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd工作原理</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176339-9480cbeb-90fb-49b3-a4c2-bcc4f20a3b62.jpeg)\n\n<h1 id=\"97f01f3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用confd</font></h1>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">confd配置文件默认在/etc/confd中，可以通过参数-confdir指定。目录中包含两个子目录，分别是：conf.d templates。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">confd会先读取conf.d目录中的配置文件(toml格式)，然后根据文件指定的模板路径去渲染模板，再执行<reload_cmd>。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">接下来以NGINX配置为例，通过监听etcd存储变化，动态的修改NGINX主页。</font>\n\n<h2 id=\"2ea05453\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装confd</font></h2>\n```plain\n[root@tiaoban ~]# wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64\n[root@tiaoban ~]# mv confd-0.16.0-linux-amd64 /usr/local/bin/confd\n[root@tiaoban ~]# chmod +x /usr/local/bin/confd\n[root@tiaoban ~]# confd -version\nconfd 0.16.0 (Git SHA: 7217b0ca, Go Version: go1.10.2)\n```\n\n<h2 id=\"d0c40ddb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建nginx资源文件</font></h2>\n```plain\n[root@tiaoban ~]# dnf -y install nginx \n[root@tiaoban ~]# systemctl start nginx\n# 准备两个html文件目录\n[root@tiaoban nginx]# pwd\n/usr/share/nginx\n[root@tiaoban nginx]# tree .\n.\n├── html\n│   ├── 404.html\n│   ├── 50x.html\n│   ├── index.html\n│   ├── nginx-logo.png\n│   └── poweredby.png\n├── modules\n│   ├── mod-http-image-filter.conf\n│   ├── mod-http-perl.conf\n│   ├── mod-http-xslt-filter.conf\n│   ├── mod-mail.conf\n│   └── mod-stream.conf\n├── v1\n│   └── index.html\n└── v2\n    └── index.html\n\n4 directories, 12 files\n[root@tiaoban nginx]# cat v1/index.html \n<!DOCTYPE html>\n<html>\n\t<head>\n\t\t<title>nginx-v1</title>\n\t\t</head>\n\t<body>\n\t\t<h1>hello nginx v1</h1>\n\t</body>\n</html>\n[root@tiaoban nginx]# cat v2/index.html \n<!DOCTYPE html>\n<html>\n  <head>\n  \t<title>nginx-v2</title>\n\t</head>\n\t<body>\n\t\t<h1>hello nginx v2</h1>\n\t</body>\n</html>\n```\n\n<h2 id=\"0d3a828b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置目录</font></h2>\n```plain\n[root@tiaoban ~]# mkdir -p /etc/confd/{conf.d,templates}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">confd目录主要使用两个核心的目录</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">conf.d：主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">templates：配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。</font>\n\n<h2 id=\"fb90c475\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建模板文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Template定义了单一应用配置的模板，默认存储在/etc/confd/templates目录下，模板文件符合Go的text/template格式。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模板文件常用函数有base，get，gets，lsdir，json等。具体可参考</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kelseyhightower/confd/blob/master/docs/templates.md</font>](https://github.com/kelseyhightower/confd/blob/master/docs/templates.md)<font style=\"background-color:rgba(255, 255, 255, 0);\">。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">此处的逻辑是使用root_dir变量，动态更新nginx的root文件目录，如果root_dir这个key不存在，则默认值为/usr/share/nginx/html。</font>\n\n```plain\n[root@tiaoban ~]# cd /etc/confd/templates\n[root@tiaoban templates]# cat nginx.tmpl\nserver {\n        listen       80;\n        server_name  ~^.*$;\n        location / {\n            root  {{getv \"/root_dir\" \"/usr/share/nginx/html\"}};\n            index  index.html index.htm;\n        }\n    }\n```\n\n<h2 id=\"bba0d682\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">模板源配置文件是TOML格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在/etc/confd/conf.d。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">必要参数</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">dest：目标文件（字符串类型）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">keys ： 键数组（字符串数组）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">src ：配置模板的相对路径（字符串）</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">可选参数</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">gid：应该拥有该文件的gid。默认为有效的gid（整数）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">mode：文件的权限模式（字符串）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">uid：应该拥有该文件的uid。默认为有效的uid（整数）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">reload_cmd：重新加载配置的命令（字符串）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">check_cmd：检查配置的命令（字符串）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">prefix：键前缀的字符串（字符串）</font>\n\n```plain\n[root@tiaoban confd]# cat /etc/confd/conf.d/myapp-nginx.toml \n[template]\nprefix = \"/nginx\" # 指定字符串前缀，便于区分不同confd项目\nsrc = \"nginx.tmpl\" #配置模板相对路径\ndest = \"/etc/nginx/conf.d/myapp.conf\" # 目标路径\nmode = \"0644\" # 文件权限\nkeys = [\n  \"/root_dir\"\n] # 键数组，与模板使用的键对应\ncheck_cmd = \"/usr/sbin/nginx -t\" # 配置检查命令\nreload_cmd = \"/usr/sbin/nginx -s reload\" # 重新加载配置命令\n```\n\n<h2 id=\"fc5cef98\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化etcd中的数据</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">先在etcd中创建一个名为/nginx/root_dir的键，值为/usr/share/nginx/v1。需要注意的是如果在配置文件中指定前缀，那么在创建键时键名为前缀+keys。</font>\n\n```plain\n[root@tiaoban ~]# etcdctl put /nginx/root_dir '/usr/share/nginx/v1'\nOK\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h2 id=\"32874e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动confd的服务</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">confd支持以daemon或者onetime两种模式运行</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">onetime模式：只会生成一次配置，之后key无论变化不会再生成，一般很少使用这种模式。</font>\n\n```plain\n[root@tiaoban ~]# confd -onetime -backend etcd -node http://127.0.0.1:2379\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">daemon模式：confd会监听后端存储的配置变化，根据配置模板动态生成目标配置文件。</font>\n\n```plain\n[root@tiaoban ~]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend set to etcdv3\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Starting confd\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend source(s) set to http://192.168.10.100:2379\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由日志可知，已经成功根据模板文件和etcd的key生成了配置文件。</font>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看生成的nginx配置文件</font>\n\n```plain\n[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf \nserver {\n        listen       80;\n        server_name  ~^.*$;\n        location / {\n            root  /usr/share/nginx/v1;\n            index  index.html index.htm;\n        }\n    }\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问nginx服务，查看页面</font>\n\n```plain\n[root@tiaoban ~]# curl 127.0.0.1/\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>nginx-v1</title>\n  </head>\n  <body>\n    <h1>hello nginx v1</h1>\n  </body>\n</html>\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">ok，v1版本的nginx服务访问正常，接下来我们更新/nginx/root_dir，模拟版本更新操作</font>\n\n```plain\n[root@tiaoban ~]# etcdctl put /nginx/root_dir '/usr/share/nginx/v2'\nOK\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">观察confd日志，有检测到了etcd键值变化，并触发了自动更新操作</font>\n\n```plain\n[root@tiaoban confd]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend set to etcdv3\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Starting confd\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend source(s) set to http://192.168.10.100:2379\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated\n2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO /etc/nginx/conf.d/myapp.conf has md5sum 86f04524c0f5e58d81f86649b6feef79 should be 47da5e695a2c5ad1e5561bec683a920c\n2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync\n2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看新生成的nginx配置文件，并访问验证</font>\n\n```plain\n[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf \nserver {\n        listen       80;\n        server_name  ~^.*$;\n        location / {\n            root  /usr/share/nginx/v2;\n            index  index.html index.htm;\n        }\n    }\n[root@tiaoban ~]# curl 127.0.0.1/\n<!DOCTYPE html>\n<html>\n<head>\n<title>nginx-v2</title>\n</head>\n<body>\n<h1>hello nginx v2</h1>\n</body>\n</html>\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由此可见，confd实时监听/nginx/root_dir这个key的值变化，当键的值更新时，自动渲染模板文件，生成了新的nginx配置，并自动执行了nginx -t和nginx -s reload操作。</font>\n\n","source":"_posts/4.ETCD——confd配置管理.md","raw":"---\ntitle: ETCD--confd配置管理\ndate: 2025-03-05 19:08:06\n---\n<h1 id=\"800f2ad9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd简介</font></h1>\n---\n\n<h2 id=\"b2847d5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是confd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Confd是一个轻量级的配置管理工具。通过查询后端存储，结合配置模板引擎，保持本地配置最新，同时具备定期探测机制，配置变更自动reload。对应的后端存储可以是etcd，redis、zookeeper等。</font>\n\n<h2 id=\"3ed06af0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd用途</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着上线的服务越来越多，配置文件和配置项越来越复杂，管理和变更维护配置文件逐渐成为一件麻烦的事情。在这时候，就需要一套集中化的配置文件管理系统。一方面实现配置文件的统一管理，版本回溯，另一方面提供配置文件的批量自动下发，已经动态加载重启服务。而confd+etcd就是为解决上述问题提出的一种解决思路。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176432-60ddfdb2-8731-4b7d-9a66-7beb7b76d57b.jpeg)\n\n<h2 id=\"818c70a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd工作原理</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176339-9480cbeb-90fb-49b3-a4c2-bcc4f20a3b62.jpeg)\n\n<h1 id=\"97f01f3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用confd</font></h1>\n---\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">confd配置文件默认在/etc/confd中，可以通过参数-confdir指定。目录中包含两个子目录，分别是：conf.d templates。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">confd会先读取conf.d目录中的配置文件(toml格式)，然后根据文件指定的模板路径去渲染模板，再执行<reload_cmd>。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">接下来以NGINX配置为例，通过监听etcd存储变化，动态的修改NGINX主页。</font>\n\n<h2 id=\"2ea05453\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装confd</font></h2>\n```plain\n[root@tiaoban ~]# wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64\n[root@tiaoban ~]# mv confd-0.16.0-linux-amd64 /usr/local/bin/confd\n[root@tiaoban ~]# chmod +x /usr/local/bin/confd\n[root@tiaoban ~]# confd -version\nconfd 0.16.0 (Git SHA: 7217b0ca, Go Version: go1.10.2)\n```\n\n<h2 id=\"d0c40ddb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建nginx资源文件</font></h2>\n```plain\n[root@tiaoban ~]# dnf -y install nginx \n[root@tiaoban ~]# systemctl start nginx\n# 准备两个html文件目录\n[root@tiaoban nginx]# pwd\n/usr/share/nginx\n[root@tiaoban nginx]# tree .\n.\n├── html\n│   ├── 404.html\n│   ├── 50x.html\n│   ├── index.html\n│   ├── nginx-logo.png\n│   └── poweredby.png\n├── modules\n│   ├── mod-http-image-filter.conf\n│   ├── mod-http-perl.conf\n│   ├── mod-http-xslt-filter.conf\n│   ├── mod-mail.conf\n│   └── mod-stream.conf\n├── v1\n│   └── index.html\n└── v2\n    └── index.html\n\n4 directories, 12 files\n[root@tiaoban nginx]# cat v1/index.html \n<!DOCTYPE html>\n<html>\n\t<head>\n\t\t<title>nginx-v1</title>\n\t\t</head>\n\t<body>\n\t\t<h1>hello nginx v1</h1>\n\t</body>\n</html>\n[root@tiaoban nginx]# cat v2/index.html \n<!DOCTYPE html>\n<html>\n  <head>\n  \t<title>nginx-v2</title>\n\t</head>\n\t<body>\n\t\t<h1>hello nginx v2</h1>\n\t</body>\n</html>\n```\n\n<h2 id=\"0d3a828b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置目录</font></h2>\n```plain\n[root@tiaoban ~]# mkdir -p /etc/confd/{conf.d,templates}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">confd目录主要使用两个核心的目录</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">conf.d：主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">templates：配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。</font>\n\n<h2 id=\"fb90c475\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建模板文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Template定义了单一应用配置的模板，默认存储在/etc/confd/templates目录下，模板文件符合Go的text/template格式。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模板文件常用函数有base，get，gets，lsdir，json等。具体可参考</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kelseyhightower/confd/blob/master/docs/templates.md</font>](https://github.com/kelseyhightower/confd/blob/master/docs/templates.md)<font style=\"background-color:rgba(255, 255, 255, 0);\">。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">此处的逻辑是使用root_dir变量，动态更新nginx的root文件目录，如果root_dir这个key不存在，则默认值为/usr/share/nginx/html。</font>\n\n```plain\n[root@tiaoban ~]# cd /etc/confd/templates\n[root@tiaoban templates]# cat nginx.tmpl\nserver {\n        listen       80;\n        server_name  ~^.*$;\n        location / {\n            root  {{getv \"/root_dir\" \"/usr/share/nginx/html\"}};\n            index  index.html index.htm;\n        }\n    }\n```\n\n<h2 id=\"bba0d682\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">模板源配置文件是TOML格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在/etc/confd/conf.d。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">必要参数</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">dest：目标文件（字符串类型）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">keys ： 键数组（字符串数组）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">src ：配置模板的相对路径（字符串）</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">可选参数</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">gid：应该拥有该文件的gid。默认为有效的gid（整数）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">mode：文件的权限模式（字符串）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">uid：应该拥有该文件的uid。默认为有效的uid（整数）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">reload_cmd：重新加载配置的命令（字符串）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">check_cmd：检查配置的命令（字符串）  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">prefix：键前缀的字符串（字符串）</font>\n\n```plain\n[root@tiaoban confd]# cat /etc/confd/conf.d/myapp-nginx.toml \n[template]\nprefix = \"/nginx\" # 指定字符串前缀，便于区分不同confd项目\nsrc = \"nginx.tmpl\" #配置模板相对路径\ndest = \"/etc/nginx/conf.d/myapp.conf\" # 目标路径\nmode = \"0644\" # 文件权限\nkeys = [\n  \"/root_dir\"\n] # 键数组，与模板使用的键对应\ncheck_cmd = \"/usr/sbin/nginx -t\" # 配置检查命令\nreload_cmd = \"/usr/sbin/nginx -s reload\" # 重新加载配置命令\n```\n\n<h2 id=\"fc5cef98\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化etcd中的数据</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">先在etcd中创建一个名为/nginx/root_dir的键，值为/usr/share/nginx/v1。需要注意的是如果在配置文件中指定前缀，那么在创建键时键名为前缀+keys。</font>\n\n```plain\n[root@tiaoban ~]# etcdctl put /nginx/root_dir '/usr/share/nginx/v1'\nOK\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h2 id=\"32874e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动confd的服务</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">confd支持以daemon或者onetime两种模式运行</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">onetime模式：只会生成一次配置，之后key无论变化不会再生成，一般很少使用这种模式。</font>\n\n```plain\n[root@tiaoban ~]# confd -onetime -backend etcd -node http://127.0.0.1:2379\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">daemon模式：confd会监听后端存储的配置变化，根据配置模板动态生成目标配置文件。</font>\n\n```plain\n[root@tiaoban ~]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend set to etcdv3\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Starting confd\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend source(s) set to http://192.168.10.100:2379\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync\n2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由日志可知，已经成功根据模板文件和etcd的key生成了配置文件。</font>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看生成的nginx配置文件</font>\n\n```plain\n[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf \nserver {\n        listen       80;\n        server_name  ~^.*$;\n        location / {\n            root  /usr/share/nginx/v1;\n            index  index.html index.htm;\n        }\n    }\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问nginx服务，查看页面</font>\n\n```plain\n[root@tiaoban ~]# curl 127.0.0.1/\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>nginx-v1</title>\n  </head>\n  <body>\n    <h1>hello nginx v1</h1>\n  </body>\n</html>\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">ok，v1版本的nginx服务访问正常，接下来我们更新/nginx/root_dir，模拟版本更新操作</font>\n\n```plain\n[root@tiaoban ~]# etcdctl put /nginx/root_dir '/usr/share/nginx/v2'\nOK\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">观察confd日志，有检测到了etcd键值变化，并触发了自动更新操作</font>\n\n```plain\n[root@tiaoban confd]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend set to etcdv3\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Starting confd\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend source(s) set to http://192.168.10.100:2379\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync\n2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated\n2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO /etc/nginx/conf.d/myapp.conf has md5sum 86f04524c0f5e58d81f86649b6feef79 should be 47da5e695a2c5ad1e5561bec683a920c\n2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync\n2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看新生成的nginx配置文件，并访问验证</font>\n\n```plain\n[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf \nserver {\n        listen       80;\n        server_name  ~^.*$;\n        location / {\n            root  /usr/share/nginx/v2;\n            index  index.html index.htm;\n        }\n    }\n[root@tiaoban ~]# curl 127.0.0.1/\n<!DOCTYPE html>\n<html>\n<head>\n<title>nginx-v2</title>\n</head>\n<body>\n<h1>hello nginx v2</h1>\n</body>\n</html>\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">由此可见，confd实时监听/nginx/root_dir这个key的值变化，当键的值更新时，自动渲染模板文件，生成了新的nginx配置，并自动执行了nginx -t和nginx -s reload操作。</font>\n\n","slug":"4.ETCD——confd配置管理","published":1,"updated":"2025-03-30T13:04:47.125Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlp000ltsv116oz0vjy","content":"<h1 id=\"800f2ad9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd简介</font></h1>\n---\n\n<h2 id=\"b2847d5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是confd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Confd是一个轻量级的配置管理工具。通过查询后端存储，结合配置模板引擎，保持本地配置最新，同时具备定期探测机制，配置变更自动reload。对应的后端存储可以是etcd，redis、zookeeper等。</font>\n\n<h2 id=\"3ed06af0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd用途</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着上线的服务越来越多，配置文件和配置项越来越复杂，管理和变更维护配置文件逐渐成为一件麻烦的事情。在这时候，就需要一套集中化的配置文件管理系统。一方面实现配置文件的统一管理，版本回溯，另一方面提供配置文件的批量自动下发，已经动态加载重启服务。而confd+etcd就是为解决上述问题提出的一种解决思路。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176432-60ddfdb2-8731-4b7d-9a66-7beb7b76d57b.jpeg)\n\n<h2 id=\"818c70a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd工作原理</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176339-9480cbeb-90fb-49b3-a4c2-bcc4f20a3b62.jpeg)\n\n<h1 id=\"97f01f3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用confd</font></h1>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">confd配置文件默认在&#x2F;etc&#x2F;confd中，可以通过参数-confdir指定。目录中包含两个子目录，分别是：conf.d templates。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">confd会先读取conf.d目录中的配置文件(toml格式)，然后根据文件指定的模板路径去渲染模板，再执行<reload_cmd>。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">接下来以NGINX配置为例，通过监听etcd存储变化，动态的修改NGINX主页。</font></p>\n<h2 id=\"2ea05453\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装confd</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64</span><br><span class=\"line\">[root@tiaoban ~]# mv confd-0.16.0-linux-amd64 /usr/local/bin/confd</span><br><span class=\"line\">[root@tiaoban ~]# chmod +x /usr/local/bin/confd</span><br><span class=\"line\">[root@tiaoban ~]# confd -version</span><br><span class=\"line\">confd 0.16.0 (Git SHA: 7217b0ca, Go Version: go1.10.2)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"d0c40ddb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建nginx资源文件</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# dnf -y install nginx </span><br><span class=\"line\">[root@tiaoban ~]# systemctl start nginx</span><br><span class=\"line\"># 准备两个html文件目录</span><br><span class=\"line\">[root@tiaoban nginx]# pwd</span><br><span class=\"line\">/usr/share/nginx</span><br><span class=\"line\">[root@tiaoban nginx]# tree .</span><br><span class=\"line\">.</span><br><span class=\"line\">├── html</span><br><span class=\"line\">│   ├── 404.html</span><br><span class=\"line\">│   ├── 50x.html</span><br><span class=\"line\">│   ├── index.html</span><br><span class=\"line\">│   ├── nginx-logo.png</span><br><span class=\"line\">│   └── poweredby.png</span><br><span class=\"line\">├── modules</span><br><span class=\"line\">│   ├── mod-http-image-filter.conf</span><br><span class=\"line\">│   ├── mod-http-perl.conf</span><br><span class=\"line\">│   ├── mod-http-xslt-filter.conf</span><br><span class=\"line\">│   ├── mod-mail.conf</span><br><span class=\"line\">│   └── mod-stream.conf</span><br><span class=\"line\">├── v1</span><br><span class=\"line\">│   └── index.html</span><br><span class=\"line\">└── v2</span><br><span class=\"line\">    └── index.html</span><br><span class=\"line\"></span><br><span class=\"line\">4 directories, 12 files</span><br><span class=\"line\">[root@tiaoban nginx]# cat v1/index.html </span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">\t&lt;head&gt;</span><br><span class=\"line\">\t\t&lt;title&gt;nginx-v1&lt;/title&gt;</span><br><span class=\"line\">\t\t&lt;/head&gt;</span><br><span class=\"line\">\t&lt;body&gt;</span><br><span class=\"line\">\t\t&lt;h1&gt;hello nginx v1&lt;/h1&gt;</span><br><span class=\"line\">\t&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br><span class=\"line\">[root@tiaoban nginx]# cat v2/index.html </span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">  &lt;head&gt;</span><br><span class=\"line\">  \t&lt;title&gt;nginx-v2&lt;/title&gt;</span><br><span class=\"line\">\t&lt;/head&gt;</span><br><span class=\"line\">\t&lt;body&gt;</span><br><span class=\"line\">\t\t&lt;h1&gt;hello nginx v2&lt;/h1&gt;</span><br><span class=\"line\">\t&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"0d3a828b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置目录</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# mkdir -p /etc/confd/&#123;conf.d,templates&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">confd目录主要使用两个核心的目录</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">conf.d：主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">templates：配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。</font></li>\n</ul>\n<h2 id=\"fb90c475\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建模板文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Template定义了单一应用配置的模板，默认存储在/etc/confd/templates目录下，模板文件符合Go的text/template格式。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模板文件常用函数有base，get，gets，lsdir，json等。具体可参考</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kelseyhightower/confd/blob/master/docs/templates.md</font>](https://github.com/kelseyhightower/confd/blob/master/docs/templates.md)<font style=\"background-color:rgba(255, 255, 255, 0);\">。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">此处的逻辑是使用root_dir变量，动态更新nginx的root文件目录，如果root_dir这个key不存在，则默认值为/usr/share/nginx/html。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cd /etc/confd/templates</span><br><span class=\"line\">[root@tiaoban templates]# cat nginx.tmpl</span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen       80;</span><br><span class=\"line\">        server_name  ~^.*$;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root  &#123;&#123;getv &quot;/root_dir&quot; &quot;/usr/share/nginx/html&quot;&#125;&#125;;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"bba0d682\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">模板源配置文件是TOML格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在/etc/confd/conf.d。</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">必要参数</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">dest：目标文件（字符串类型）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">keys ： 键数组（字符串数组）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">src ：配置模板的相对路径（字符串）</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">可选参数</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">gid：应该拥有该文件的gid。默认为有效的gid（整数）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">mode：文件的权限模式（字符串）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">uid：应该拥有该文件的uid。默认为有效的uid（整数）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">reload_cmd：重新加载配置的命令（字符串）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">check_cmd：检查配置的命令（字符串）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">prefix：键前缀的字符串（字符串）</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban confd]# cat /etc/confd/conf.d/myapp-nginx.toml </span><br><span class=\"line\">[template]</span><br><span class=\"line\">prefix = &quot;/nginx&quot; # 指定字符串前缀，便于区分不同confd项目</span><br><span class=\"line\">src = &quot;nginx.tmpl&quot; #配置模板相对路径</span><br><span class=\"line\">dest = &quot;/etc/nginx/conf.d/myapp.conf&quot; # 目标路径</span><br><span class=\"line\">mode = &quot;0644&quot; # 文件权限</span><br><span class=\"line\">keys = [</span><br><span class=\"line\">  &quot;/root_dir&quot;</span><br><span class=\"line\">] # 键数组，与模板使用的键对应</span><br><span class=\"line\">check_cmd = &quot;/usr/sbin/nginx -t&quot; # 配置检查命令</span><br><span class=\"line\">reload_cmd = &quot;/usr/sbin/nginx -s reload&quot; # 重新加载配置命令</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fc5cef98\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化etcd中的数据</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">先在etcd中创建一个名为/nginx/root_dir的键，值为/usr/share/nginx/v1。需要注意的是如果在配置文件中指定前缀，那么在创建键时键名为前缀+keys。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl put /nginx/root_dir &#x27;/usr/share/nginx/v1&#x27;</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h2 id=\"32874e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动confd的服务</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">confd支持以daemon或者onetime两种模式运行</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">onetime模式：只会生成一次配置，之后key无论变化不会再生成，一般很少使用这种模式。</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# confd -onetime -backend etcd -node http://127.0.0.1:2379</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">daemon模式：confd会监听后端存储的配置变化，根据配置模板动态生成目标配置文件。</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend set to etcdv3</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Starting confd</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend source(s) set to http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由日志可知，已经成功根据模板文件和etcd的key生成了配置文件。</font></p>\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看生成的nginx配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf </span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen       80;</span><br><span class=\"line\">        server_name  ~^.*$;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root  /usr/share/nginx/v1;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问nginx服务，查看页面</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# curl 127.0.0.1/</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">  &lt;head&gt;</span><br><span class=\"line\">    &lt;title&gt;nginx-v1&lt;/title&gt;</span><br><span class=\"line\">  &lt;/head&gt;</span><br><span class=\"line\">  &lt;body&gt;</span><br><span class=\"line\">    &lt;h1&gt;hello nginx v1&lt;/h1&gt;</span><br><span class=\"line\">  &lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ok，v1版本的nginx服务访问正常，接下来我们更新&#x2F;nginx&#x2F;root_dir，模拟版本更新操作</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl put /nginx/root_dir &#x27;/usr/share/nginx/v2&#x27;</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">观察confd日志，有检测到了etcd键值变化，并触发了自动更新操作</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban confd]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend set to etcdv3</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Starting confd</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend source(s) set to http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated</span><br><span class=\"line\">2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO /etc/nginx/conf.d/myapp.conf has md5sum 86f04524c0f5e58d81f86649b6feef79 should be 47da5e695a2c5ad1e5561bec683a920c</span><br><span class=\"line\">2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync</span><br><span class=\"line\">2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看新生成的nginx配置文件，并访问验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf </span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen       80;</span><br><span class=\"line\">        server_name  ~^.*$;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root  /usr/share/nginx/v2;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">[root@tiaoban ~]# curl 127.0.0.1/</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;title&gt;nginx-v2&lt;/title&gt;</span><br><span class=\"line\">&lt;/head&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;h1&gt;hello nginx v2&lt;/h1&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由此可见，confd实时监听&#x2F;nginx&#x2F;root_dir这个key的值变化，当键的值更新时，自动渲染模板文件，生成了新的nginx配置，并自动执行了nginx -t和nginx -s reload操作。</font></p>\n","excerpt":"","more":"<h1 id=\"800f2ad9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd简介</font></h1>\n---\n\n<h2 id=\"b2847d5c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是confd</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Confd是一个轻量级的配置管理工具。通过查询后端存储，结合配置模板引擎，保持本地配置最新，同时具备定期探测机制，配置变更自动reload。对应的后端存储可以是etcd，redis、zookeeper等。</font>\n\n<h2 id=\"3ed06af0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd用途</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着上线的服务越来越多，配置文件和配置项越来越复杂，管理和变更维护配置文件逐渐成为一件麻烦的事情。在这时候，就需要一套集中化的配置文件管理系统。一方面实现配置文件的统一管理，版本回溯，另一方面提供配置文件的批量自动下发，已经动态加载重启服务。而confd+etcd就是为解决上述问题提出的一种解决思路。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176432-60ddfdb2-8731-4b7d-9a66-7beb7b76d57b.jpeg)\n\n<h2 id=\"818c70a3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">confd工作原理</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738851176339-9480cbeb-90fb-49b3-a4c2-bcc4f20a3b62.jpeg)\n\n<h1 id=\"97f01f3c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用confd</font></h1>\n---\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">confd配置文件默认在&#x2F;etc&#x2F;confd中，可以通过参数-confdir指定。目录中包含两个子目录，分别是：conf.d templates。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">confd会先读取conf.d目录中的配置文件(toml格式)，然后根据文件指定的模板路径去渲染模板，再执行<reload_cmd>。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">接下来以NGINX配置为例，通过监听etcd存储变化，动态的修改NGINX主页。</font></p>\n<h2 id=\"2ea05453\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装confd</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64</span><br><span class=\"line\">[root@tiaoban ~]# mv confd-0.16.0-linux-amd64 /usr/local/bin/confd</span><br><span class=\"line\">[root@tiaoban ~]# chmod +x /usr/local/bin/confd</span><br><span class=\"line\">[root@tiaoban ~]# confd -version</span><br><span class=\"line\">confd 0.16.0 (Git SHA: 7217b0ca, Go Version: go1.10.2)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"d0c40ddb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建nginx资源文件</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# dnf -y install nginx </span><br><span class=\"line\">[root@tiaoban ~]# systemctl start nginx</span><br><span class=\"line\"># 准备两个html文件目录</span><br><span class=\"line\">[root@tiaoban nginx]# pwd</span><br><span class=\"line\">/usr/share/nginx</span><br><span class=\"line\">[root@tiaoban nginx]# tree .</span><br><span class=\"line\">.</span><br><span class=\"line\">├── html</span><br><span class=\"line\">│   ├── 404.html</span><br><span class=\"line\">│   ├── 50x.html</span><br><span class=\"line\">│   ├── index.html</span><br><span class=\"line\">│   ├── nginx-logo.png</span><br><span class=\"line\">│   └── poweredby.png</span><br><span class=\"line\">├── modules</span><br><span class=\"line\">│   ├── mod-http-image-filter.conf</span><br><span class=\"line\">│   ├── mod-http-perl.conf</span><br><span class=\"line\">│   ├── mod-http-xslt-filter.conf</span><br><span class=\"line\">│   ├── mod-mail.conf</span><br><span class=\"line\">│   └── mod-stream.conf</span><br><span class=\"line\">├── v1</span><br><span class=\"line\">│   └── index.html</span><br><span class=\"line\">└── v2</span><br><span class=\"line\">    └── index.html</span><br><span class=\"line\"></span><br><span class=\"line\">4 directories, 12 files</span><br><span class=\"line\">[root@tiaoban nginx]# cat v1/index.html </span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">\t&lt;head&gt;</span><br><span class=\"line\">\t\t&lt;title&gt;nginx-v1&lt;/title&gt;</span><br><span class=\"line\">\t\t&lt;/head&gt;</span><br><span class=\"line\">\t&lt;body&gt;</span><br><span class=\"line\">\t\t&lt;h1&gt;hello nginx v1&lt;/h1&gt;</span><br><span class=\"line\">\t&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br><span class=\"line\">[root@tiaoban nginx]# cat v2/index.html </span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">  &lt;head&gt;</span><br><span class=\"line\">  \t&lt;title&gt;nginx-v2&lt;/title&gt;</span><br><span class=\"line\">\t&lt;/head&gt;</span><br><span class=\"line\">\t&lt;body&gt;</span><br><span class=\"line\">\t\t&lt;h1&gt;hello nginx v2&lt;/h1&gt;</span><br><span class=\"line\">\t&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"0d3a828b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置目录</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# mkdir -p /etc/confd/&#123;conf.d,templates&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">confd目录主要使用两个核心的目录</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">conf.d：主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">templates：配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。</font></li>\n</ul>\n<h2 id=\"fb90c475\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建模板文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Template定义了单一应用配置的模板，默认存储在/etc/confd/templates目录下，模板文件符合Go的text/template格式。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">模板文件常用函数有base，get，gets，lsdir，json等。具体可参考</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kelseyhightower/confd/blob/master/docs/templates.md</font>](https://github.com/kelseyhightower/confd/blob/master/docs/templates.md)<font style=\"background-color:rgba(255, 255, 255, 0);\">。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">此处的逻辑是使用root_dir变量，动态更新nginx的root文件目录，如果root_dir这个key不存在，则默认值为/usr/share/nginx/html。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cd /etc/confd/templates</span><br><span class=\"line\">[root@tiaoban templates]# cat nginx.tmpl</span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen       80;</span><br><span class=\"line\">        server_name  ~^.*$;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root  &#123;&#123;getv &quot;/root_dir&quot; &quot;/usr/share/nginx/html&quot;&#125;&#125;;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"bba0d682\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">模板源配置文件是TOML格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在/etc/confd/conf.d。</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">必要参数</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">dest：目标文件（字符串类型）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">keys ： 键数组（字符串数组）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">src ：配置模板的相对路径（字符串）</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">可选参数</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">gid：应该拥有该文件的gid。默认为有效的gid（整数）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">mode：文件的权限模式（字符串）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">uid：应该拥有该文件的uid。默认为有效的uid（整数）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">reload_cmd：重新加载配置的命令（字符串）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">check_cmd：检查配置的命令（字符串）<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">prefix：键前缀的字符串（字符串）</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban confd]# cat /etc/confd/conf.d/myapp-nginx.toml </span><br><span class=\"line\">[template]</span><br><span class=\"line\">prefix = &quot;/nginx&quot; # 指定字符串前缀，便于区分不同confd项目</span><br><span class=\"line\">src = &quot;nginx.tmpl&quot; #配置模板相对路径</span><br><span class=\"line\">dest = &quot;/etc/nginx/conf.d/myapp.conf&quot; # 目标路径</span><br><span class=\"line\">mode = &quot;0644&quot; # 文件权限</span><br><span class=\"line\">keys = [</span><br><span class=\"line\">  &quot;/root_dir&quot;</span><br><span class=\"line\">] # 键数组，与模板使用的键对应</span><br><span class=\"line\">check_cmd = &quot;/usr/sbin/nginx -t&quot; # 配置检查命令</span><br><span class=\"line\">reload_cmd = &quot;/usr/sbin/nginx -s reload&quot; # 重新加载配置命令</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"fc5cef98\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化etcd中的数据</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">先在etcd中创建一个名为/nginx/root_dir的键，值为/usr/share/nginx/v1。需要注意的是如果在配置文件中指定前缀，那么在创建键时键名为前缀+keys。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl put /nginx/root_dir &#x27;/usr/share/nginx/v1&#x27;</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h2 id=\"32874e94\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动confd的服务</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">confd支持以daemon或者onetime两种模式运行</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">onetime模式：只会生成一次配置，之后key无论变化不会再生成，一般很少使用这种模式。</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# confd -onetime -backend etcd -node http://127.0.0.1:2379</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">daemon模式：confd会监听后端存储的配置变化，根据配置模板动态生成目标配置文件。</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend set to etcdv3</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Starting confd</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Backend source(s) set to http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync</span><br><span class=\"line\">2023-03-22T22:04:55+08:00 tiaoban confd[5312]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由日志可知，已经成功根据模板文件和etcd的key生成了配置文件。</font></p>\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看生成的nginx配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf </span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen       80;</span><br><span class=\"line\">        server_name  ~^.*$;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root  /usr/share/nginx/v1;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问nginx服务，查看页面</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# curl 127.0.0.1/</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">  &lt;head&gt;</span><br><span class=\"line\">    &lt;title&gt;nginx-v1&lt;/title&gt;</span><br><span class=\"line\">  &lt;/head&gt;</span><br><span class=\"line\">  &lt;body&gt;</span><br><span class=\"line\">    &lt;h1&gt;hello nginx v1&lt;/h1&gt;</span><br><span class=\"line\">  &lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ok，v1版本的nginx服务访问正常，接下来我们更新&#x2F;nginx&#x2F;root_dir，模拟版本更新操作</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# etcdctl put /nginx/root_dir &#x27;/usr/share/nginx/v2&#x27;</span><br><span class=\"line\">OK</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">观察confd日志，有检测到了etcd键值变化，并触发了自动更新操作</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban confd]# confd -watch -backend etcdv3 -node http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend set to etcdv3</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Starting confd</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Backend source(s) set to http://192.168.10.100:2379</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync</span><br><span class=\"line\">2023-03-22T22:06:06+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated</span><br><span class=\"line\">2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO /etc/nginx/conf.d/myapp.conf has md5sum 86f04524c0f5e58d81f86649b6feef79 should be 47da5e695a2c5ad1e5561bec683a920c</span><br><span class=\"line\">2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf out of sync</span><br><span class=\"line\">2023-03-22T22:09:25+08:00 tiaoban confd[5344]: INFO Target config /etc/nginx/conf.d/myapp.conf has been updated</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看新生成的nginx配置文件，并访问验证</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat /etc/nginx/conf.d/myapp.conf </span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen       80;</span><br><span class=\"line\">        server_name  ~^.*$;</span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">            root  /usr/share/nginx/v2;</span><br><span class=\"line\">            index  index.html index.htm;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">[root@tiaoban ~]# curl 127.0.0.1/</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;title&gt;nginx-v2&lt;/title&gt;</span><br><span class=\"line\">&lt;/head&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;h1&gt;hello nginx v2&lt;/h1&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">由此可见，confd实时监听&#x2F;nginx&#x2F;root_dir这个key的值变化，当键的值更新时，自动渲染模板文件，生成了新的nginx配置，并自动执行了nginx -t和nginx -s reload操作。</font></p>\n"},{"title":"Containerd进阶使用","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"Wu324\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr命令使用</font></h1>\n---\n\n<h2 id=\"jWZEX\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd 中也支持命名空间的概念，比如查看命名空间：</font>\n\n```shell\n[root@work3 ~]# ctr ns ls\nNAME    LABELS \ndefault        \nk8s.io         \nmoby \n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果不指定，ctr 默认使用的是 default 空间。同样也可以使用 ns create 命令创建一个命名空间：</font>\n\n```shell\n[root@work3 ~]# ctr ns create test\n[root@work3 ~]# ctr ns ls\nNAME    LABELS \ndefault        \nk8s.io         \nmoby           \ntest\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用 remove 或者 rm 可以删除 namespace：</font>\n\n```shell\n[root@work3 ~]# ctr ns rm test\ntest\n[root@work3 ~]# ctr ns ls\nNAME    LABELS \ndefault        \nk8s.io         \nmoby \n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">指定命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">有了命名空间后就可以在操作资源的时候指定 namespace，比如查看 test 命名空间的镜像，可以在操作命令后面加上 -n test 选项：</font>\n\n```shell\n➜  ~ ctr -n test image ls\nREF TYPE DIGEST SIZE PLATFORMS LABELS\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们知道 Docker 其实也是默认调用的 containerd，事实上 Docker 使用的 containerd 下面的命名空间默认是 moby，而不是 default，所以假如我们有用 docker 启动容器，那么我们也可以通过 ctr -n moby 来定位下面的容器：</font>\n\n```shell\n➜  ~ ctr -n moby container ls\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">同样 Kubernetes 下使用的 containerd 默认命名空间是 k8s.io，所以我们可以使用 ctr -n k8s.io 来查看 Kubernetes 下面创建的容器。</font>\n\n<h2 id=\"vPuiL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像操作</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr image命令完成，也可以简化为ctr i命令操作</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像可以使用 ctr image pull 来完成，比如拉取 Docker Hub 官方镜像 nginx:alpine，需要注意的是镜像地址需要加上 docker.io Host 地址</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n```shell\n[root@work3 ~]# ctr image pull docker.io/library/nginx:alpine\ndocker.io/library/nginx:alpine:                                                   resolved       |++++++++++++++++++++++++++++++++++++++| \nindex-sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c:    exists         |++++++++++++++++++++++++++++++++++++++| \nmanifest-sha256:ccf066d2cfec0cfe57a63cf26f4b7cabbea80e11ab5b7f1cc11a1b5efd65ea0b: exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9398808236ffac29e60c04ec906d8d409af7fa19dc57d8c65ad167e9c4967006:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:e6a5b569446606ea05a88fc5be4097b4982fc4bc8aeae0818385fe13b8b6066e:    done           |++++++++++++++++++++++++++++++++++++++| \nconfig-sha256:414132ff3b076936528928c823b4f3d1e1178b2692ae04defc8f8fdfd0a83a03:   exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:7b8bdebbb770eb9a7ceaecd729a82d21052fcdb9915873a67d5834960944fcf2:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:a2a4fe64baa08a5a04c1acd107b0026f81a72c7e35cdb3647e164f3b87871d09:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:0777b518fc6e4d42454db10fd2da40eb3f2e9086aa2529066ce6b314c2ec08cb:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:63f4060a8ef34058494aefc8ef63522d21056a40f00255d0c5d92ab51212e4c2:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:48703ecfcf806f280f159af73a1688374148f4860c52d016646a40a1a84853ec:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9cbe387ec693ef1d8ece08c1ab2d510ac31d0745c157fbf948cacac343b47c34:    exists         |++++++++++++++++++++++++++++++++++++++| \nelapsed: 164.1s                                                                   total:  11.0 M (68.6 KiB/s)                                      \nunpacking linux/amd64 sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c...\ndone: 1.656214028s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">列出本地镜像</font>\n\n```shell\n# 列出镜像列表\n[root@work3 ~]# ctr image ls\nREF                                         TYPE                                                      DIGEST                                                                  SIZE      PLATFORMS                                                                                                                          LABELS \ndocker.io/library/nginx:alpine              application/vnd.docker.distribution.manifest.list.v2+json sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c 16.2 MiB  linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x                                           -      \n# 只查看镜像名称标签\n[root@work3 ~]# ctr image ls -q\ndocker.io/flannel/flannel-cni-plugin:v1.2.0\ndocker.io/flannel/flannel:v0.22.1\ndocker.io/library/busybox:latest\ndocker.io/library/nginx:alpine\nghcr.io/kube-vip/kube-vip:v0.6.0\nharbor.local.com/library/busybox:latest\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重新打标签</font>\n\n```shell\n[root@work3 ~]# ctr image tag docker.io/library/nginx:alpine harbor.local.com/library/nginx:alpine\nharbor.local.com/library/nginx:alpine\n[root@work3 ~]# ctr image ls -q\ndocker.io/library/nginx:alpine\nharbor.local.com/library/nginx:alpine\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除镜像</font>\n\n```shell\n[root@work3 ~]# ctr image rm harbor.local.com/library/nginx:alpine\nharbor.local.com/library/nginx:alpine\n[root@work3 ~]# ctr image ls -q\ndocker.io/library/nginx:alpine\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">将镜像导出为压缩包</font>\n\n```shell\n[root@work3 ~]# ctr image export nginx.tar docker.io/library/nginx:alpine\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从压缩包导入镜像</font>\n\n```shell\n[root@work2 ~]# ctr image import nginx.tar \n```\n\n<h2 id=\"SmLyN\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器操作</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr container命令完成，也可以简化为ctr c命令操作</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这里要解释一个概念 containers 和 task ，在docker里面 container 概念被弱化 ，将containers 和 task 整在一起 形成了docker中的 container。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 containers 是镜像实例化的一个虚拟环境，提供一个磁盘，模拟空间，就好比你电脑处于关机状态一样。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 tasks 是将容器运行起来，电脑开机了 ，初始化进程等 ，task就是的这么个形式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font>\n\n```shell\n[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">列出容器</font>\n\n```shell\n[root@work3 ~]# ctr container ls\nCONTAINER    IMAGE                             RUNTIME                  \nnginx        docker.io/library/nginx:alpine    io.containerd.runc.v2    \n[root@work3 ~]# ctr container ls -q\nnginx\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看容器详情</font>\n\n```shell\n[root@work3 ~]# ctr container info nginx\n{\n    \"ID\": \"nginx\",\n    \"Labels\": {\n        \"io.containerd.image.config.stop-signal\": \"SIGQUIT\",\n        \"maintainer\": \"NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e\"\n    },\n    \"Image\": \"docker.io/library/nginx:alpine\",\n    \"Runtime\": {\n        \"Name\": \"io.containerd.runc.v2\",\n        \"Options\": {\n            \"type_url\": \"containerd.runc.v1.Options\"\n        }\n    }\n    ……\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font>\n\n```shell\n[root@work3 ~]# ctr container rm nginx\n[root@work3 ~]# ctr container ls\nCONTAINER    IMAGE    RUNTIME \n```\n\n<h2 id=\"P5mQT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">任务操作</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">上面我们通过 container create 命令创建的容器，并没有处于运行状态，只是一个静态的容器。一个 container 对象只是包含了运行一个容器所需的资源及相关配置数据，表示 namespaces、rootfs 和容器的配置都已经初始化成功了，只是用户进程还没有启动。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">一个容器真正运行起来是由 Task 任务实现的，Task 可以为容器设置网卡，还可以配置工具来对容器进行监控等。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font>\n\n```shell\n[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx\n[root@work3 ~]# ctr task start -d nginx\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看正在运行的容器</font>\n\n```shell\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    RUNNING\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器信息</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task metrics 命令用来获取容器的内存、CPU 和 PID 的限额与使用量。</font>\n\n```shell\n[root@work3 ~]# ctr task metrics nginx\nID       TIMESTAMP                                  \nnginx    2023-08-13 04:42:31.648754469 +0000 UTC    \n\nMETRIC                   VALUE                                                                                                                                                                                                                                                                                          \nmemory.usage_in_bytes    5226496                                                                                                                                                                                                                                                                                        \nmemory.limit_in_bytes    9223372036854771712                                                                                                                                                                                                                                                                            \nmemory.stat.cache        155648                                                                                                                                                                                                                                                                                         \ncpuacct.usage            74124077                                                                                                                                                                                                                                                                                       \ncpuacct.usage_percpu     [32560123 27605021 7821698 6137235 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]    \npids.current             5                                                                                                                                                                                                                                                                                              \npids.limit               0\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器PID</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task ps 命令查看容器中所有进程在宿主机中的 PID：</font>\n\n```shell\n[root@work3 ~]# ctr task ps nginx\nPID      INFO\n62925    -\n62954    -\n62955    -\n62956    -\n62957    -\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    62925    RUNNING\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其中第一个 PID 3984 就是我们容器中的 1 号进程。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">进入容器进行操作</font>\n\n```shell\n[root@work3 ~]# ctr task exec --exec-id 0 -t nginx sh\n/ # ls\nbin                   docker-entrypoint.sh  lib \n# 指定用户进入\n[root@work3 ~]# ctr task exec --exec-id 0 --user 65534 -t nginx sh\n$ whoami\nnobody\n$ exit\n[root@work3 ~]# ctr task exec --exec-id 0 --user 0 -t nginx sh\n# whoami\nroot\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">不过这里需要注意必须要指定 --exec-id 参数，这个 id 可以随便写，只要唯一就行。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">暂停容器</font>\n\n```shell\n[root@work3 ~]# ctr task pause nginx\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    PAUSED\n# 暂停后容器状态变成了 PAUSED\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">恢复容器</font>\n\n```shell\n[root@work3 ~]# ctr task resume nginx\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    RUNNING\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">不过需要注意 ctr 没有 stop 容器的功能，只能暂停或者杀死容器。杀死容器可以使用 task kill 命令:</font>\n\n```shell\n[root@work3 ~]# ctr task kill nginx\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    STOPPED\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">杀掉容器后可以看到容器的状态变成了 STOPPED。同样也可以通过 task rm 命令删除 Task：</font>\n\n```shell\n[root@work3 ~]# ctr task rm nginx\n[root@work3 ~]# ctr task ls\nTASK    PID    STATUS\n```\n\n<h1 id=\"oZwBQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h1>\n---\n\n<h2 id=\"AJFk1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装crictl</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：https://github.com/kubernetes-sigs/cri-tools/releases，例如安装1.30.6版本的k8s，此处安装的crictl就是1.30.1。</font>\n\n```shell\nLoading...# 下载\n[root@k8s-master ~]# wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.30.1/crictl-v1.30.1-linux-amd64.tar.gz\n# 解压\n[root@k8s-master ~]# tar -zxvf crictl-v1.30.1-linux-amd64.tar.gz -C /usr/local/bin\n# 配置\n[root@k8s-master ~]# cat > /etc/crictl.yaml << EOF\nruntime-endpoint: \"unix:///run/containerd/containerd.sock\"\nimage-endpoint: \"unix:///run/containerd/containerd.sock\"\ntimeout: 0\ndebug: false\npull-image-on-create: false\ndisable-pull-on-run: false\nEOF\n[root@k8s-master ~]# crictl version\nVersion:  0.1.0\nRuntimeName:  containerd\nRuntimeVersion:  1.6.4\nRuntimeApiVersion:  v1\n```\n\n<h2 id=\"VUGBB\"><font style=\"background-color:rgba(255, 255, 255, 0);\">打印清单</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打印 Pod 清单</font>\n\n```shell\n# 打印所有 Pod 的清单\n$ crictl pods\nPOD ID              CREATED              STATE               NAME                         NAMESPACE           ATTEMPT\n926f1b5a1d33a       About a minute ago   Ready               sh-84d7dcf559-4r2gq          default             0\n4dccb216c4adb       About a minute ago   Ready               nginx-65899c769f-wv2gp       default             0\na86316e96fa89       17 hours ago         Ready               kube-proxy-gblk4             kube-system         0\n919630b8f81f1       17 hours ago         Ready               nvidia-device-plugin-zgbbv   kube-system         0\n\n# 根据名称打印 Pod 清单：\n$ crictl pods --name nginx-65899c769f-wv2gp\nPOD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT\n4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0\n\n# 根据标签打印 Pod 清单\n$ crictl pods --label run=nginx\nPOD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT\n4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打印镜像清单</font>\n\n```shell\n# 打印所有镜像清单\n$ crictl images\nIMAGE                                     TAG                 IMAGE ID            SIZE\nbusybox                                   latest              8c811b4aec35f       1.15MB\nk8s-gcrio.azureedge.net/hyperkube-amd64   v1.10.3             e179bbfe5d238       665MB\nk8s-gcrio.azureedge.net/pause-amd64       3.1                 da86e6ba6ca19       742kB\nnginx                                     latest              cd5239a0906a6       109MB\n\n# 根据仓库打印镜像清单\n$ crictl images nginx\nIMAGE               TAG                 IMAGE ID            SIZE\nnginx               latest              cd5239a0906a6       109MB\n\n# 只打印镜像 ID\n$ crictl images -q\nsha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a\nsha256:e179bbfe5d238de6069f3b03fccbecc3fb4f2019af741bfff1233c4d7b2970c5\nsha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e\nsha256:cd5239a0906a6ccf0562354852fae04bc5b52d72a2aff9a871ddb6bd57553569\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打印容器清单</font>\n\n```shell\n# 打印所有容器清单\n$ crictl ps -a\nCONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT\n1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   7 minutes ago       Running             sh                         1\n9c5951df22c78       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   8 minutes ago       Exited              sh                         0\n87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     8 minutes ago       Running             nginx                      0\n1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   18 hours ago        Running             kube-proxy                 0\n\n# 打印正在运行的容器清单\n$ crictl ps\nCONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT\n1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   6 minutes ago       Running             sh                         1\n87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     7 minutes ago       Running             nginx                      0\n1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   17 hours ago        Running             kube-proxy                 0\n\n```\n\n<h2 id=\"UOaNL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器执行命令</font></h2>\n---\n\n```shell\n$ crictl exec -i -t 1f73f2d81bf98 ls\nbin   dev   etc   home  proc  root  sys   tmp   usr   var\n```\n\n<h2 id=\"DC2UT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器日志</font></h2>\n---\n\n```shell\n# 获取容器的所有日志\n$ crictl logs 87d3992f84f74\n10.240.0.96 - - [06/Jun/2018:02:45:49 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n10.240.0.96 - - [06/Jun/2018:02:45:50 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n\n# 获取最近的 N 行日志\n$ crictl logs --tail=1 87d3992f84f74\n10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n```\n\n<h2 id=\"zgG3P\"><font style=\"background-color:rgba(255, 255, 255, 0);\">运行 Pod 沙盒</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 运行 Pod 沙盒对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机地被 kubelet 停止和删除。</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">编写下面的 JSON 文件：</font>\n\n```plain\n{\n    \"metadata\": {\n        \"name\": \"nginx-sandbox\",\n        \"namespace\": \"default\",\n        \"attempt\": 1,\n        \"uid\": \"hdishd83djaidwnduwk28bcsb\"\n    },\n    \"logDirectory\": \"/tmp\",\n    \"linux\": {\n    }\n}\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">使用 crictl runp 命令应用 JSON 文件并运行沙盒。</font>\n\n```plain\n$ crictl runp pod-config.json\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">返回了沙盒的 ID。</font>\n\n<h2 id=\"rQW1l\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 创建容器对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机的被 kubelet 停止和删除。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取 busybox 镜像</font>\n\n```plain\n$ crictl pull busybox\nImage is up to date for busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建 Pod 配置</font>\n\n```plain\n{\n    \"metadata\": {\n        \"name\": \"nginx-sandbox\",\n        \"namespace\": \"default\",\n        \"attempt\": 1,\n        \"uid\": \"hdishd83djaidwnduwk28bcsb\"\n    },\n    \"log_directory\": \"/tmp\",\n    \"linux\": {\n    }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器配置</font>\n\n```plain\n{\n  \"metadata\": {\n      \"name\": \"busybox\"\n  },\n  \"image\":{\n      \"image\": \"busybox\"\n  },\n  \"command\": [\n      \"top\"\n  ],\n  \"log_path\":\"busybox.log\",\n  \"linux\": {\n  }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器，传递先前创建的 Pod 的 ID、容器配置文件和 Pod 配置文件。返回容器的 ID。</font>\n\n```plain\n$ crictl create f84dd361f8dc51518ed291fbadd6db537b0496536c1d2d6c05ff943ce8c9a54f container-config.json pod-config.json\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查询所有容器并确认新创建的容器状态为 Created。</font>\n\n```plain\nCONTAINER ID        IMAGE               CREATED             STATE               NAME                ATTEMPT\n3e025dd50a72d       busybox             32 seconds ago      Created             busybox             0\n```\n\n---\n\n<h2 id=\"TS3x9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">要启动容器，要将容器 ID 传给 crictl start：</font>\n\n```plain\n$ crictl start 3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60\n3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">确认容器的状态为 Running。</font>\n\n```plain\n$ crictl ps\nCONTAINER ID        IMAGE               CREATED              STATE               NAME                ATTEMPT\n3e025dd50a72d       busybox             About a minute ago   Running             busybox             0\n```\n\n<h1 id=\"jllch\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装与使用nerdctl</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font>\n\n<h2 id=\"Ehxpa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装nerdctl</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/containerd/nerdctl/releases</font>](https://github.com/containerd/nerdctl/releases)\n\n```plain\n# 下载\n[root@k8s-master ~]# wget https://github.com/containerd/nerdctl/releases/download/v2.0.0-rc.3/nerdctl-2.0.0-rc.3-linux-amd64.tar.gz\n# 解压\n[root@k8s-master ~]# tar -zxvf nerdctl-2.0.0-rc.3-linux-amd64.tar.gz\nnerdctl\ncontainerd-rootless-setuptool.sh\ncontainerd-rootless.sh\n# 复制文件\n[root@k8s-master ~]# mv nerdctl /usr/bin/\n# 配置 nerdctl 参数自动补齐\n[root@k8s-master ~]# echo 'source <(nerdctl completion bash)' >> /etc/profile\n[root@k8s-master ~]# source /etc/profile\n# 验证\n[root@k8s-master ~]# nerdctl -v\nnerdctl version 2.0.0-rc.2\n```\n\n<h2 id=\"BXi4y\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这个和K8s的名字空间不是一回事，其中default就是containerd的默认名字空间，</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://k8s.io</font>](http://k8s.io/)<font style=\"background-color:rgba(255, 255, 255, 0);\">是K8s的名字空间</font>\n\n```plain\n# 查看命名空间\n[root@k8s-master ~]# nerdctl ns ls\nNAME         CONTAINERS    IMAGES    VOLUMES    LABELS\ndefault      0             2         0              \ndocker.io    0             1         0              \nk8s.io       18            51        0              \nmoby         0             0         0\n# 创建命名空间\n[root@k8s-master ~]# nerdctl ns create test\n# 删除命名空间\n[root@k8s-master ~]# nerdctl ns remove test\ntest\n# 查看名称空间详情\n[root@k8s-master ~]# nerdctl ns inspect k8s.io\n[\n    {\n        \"Name\": \"k8s.io\",\n        \"Labels\": null\n    }\n]\n```\n\n<h2 id=\"sU4R0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像</font></h2>\n---\n\n```plain\n# 查看镜像\n[root@k8s-master ~]# nerdctl -n k8s.io images\nREPOSITORY                                                         TAG         IMAGE ID        CREATED         PLATFORM       SIZE         BLOB SIZE\nregistry.aliyuncs.com/google_containers/coredns                    v1.8.6      5b6ec0d6de9b    5 days ago      linux/amd64    44.7 MiB     13.0 MiB\nregistry.aliyuncs.com/google_containers/etcd                       3.5.6-0     dd75ec974b0a    5 days ago      linux/amd64    289.0 MiB    97.8 MiB\n# 拉取镜像\n[root@k8s-master ~]# nerdctl -n test pull nginx:alpine\n# 构建镜像\n[root@k8s-master ~]# cat Dockerfile \nFROM     debian\nRUN apt-get install -y --force-yes locales\nRUN echo \"LC_ALL=\\\"zh_CN.UTF-8\\\"\" >> /etc/default/locale\nRUN locale-gen \"zh_CN.UTF-8\"\n[root@k8s-master ~]# nerdctl -n test build -t abc.com/debian .\n# 上传镜像\n[root@k8s-master ~]# nerdctl -n test push abc.com/debian\n# 导出镜像\n[root@k8s-master ~]# nerdctl -n test save -o debian.tar abc.com/debian\n# 导入镜像\n[root@k8s-master ~]# nerdctl -n test load -i debian.tar\n```\n\n<h2 id=\"tX7Xc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器</font></h2>\n---\n\n```plain\n# 查看容器\n[root@k8s-master ~]# nerdctl -n k8s.io ps \nCONTAINER ID    IMAGE                                                                      COMMAND                   CREATED         STATUS    PORTS    NAMES\n05be77648e0c    registry.aliyuncs.com/google_containers/kube-proxy:v1.25.0                 \"/usr/local/bin/kube…\"    13 hours ago    Up                 k8s://kube-system/kube-proxy-qd2dg/kube-proxy\n240c8fdfb7dd    registry.aliyuncs.com/google_containers/pause:3.6                          \"/pause\"                  13 hours ago    Up                 k8s://kube-system/kube-apiserver-k8s-master\n24728a2d2f1b    docker.io/flannel/flannel:v0.21.5                                          \"/opt/bin/flanneld -…\"    17 hours ago    Up                 k8s://kube-flannel/kube-flannel-ds-45rxr/kube-flannel\n# 启动容器\n[root@k8s-master ~]# nerdctl -n test run -d -p 80:80 --name web nginx:alpine\n# 进入容器\n[root@k8s-master ~]# nerdctl -n test exec -it web sh\n/ # \n# 停止容器\n[root@k8s-master ~]# nerdctl -n test stop web\nweb\n# 删除容器\n[root@k8s-master ~]# nerdctl -n test rm web\nweb\n```\n\n<h2 id=\"JfIJj\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他操作</font></h2>\n---\n\n```plain\n# 查看网络信息\n[root@k8s-master ~]# nerdctl network ls\nNETWORK ID      NAME      FILE\n                cbr0      /etc/cni/net.d/10-flannel.conflist\n17f29b073143    bridge    /etc/cni/net.d/nerdctl-bridge.conflist\n                host      \n                none\n# 查看系统信息\n[root@k8s-master ~]# nerdctl system info\nClient:\n Namespace:     default\n Debug Mode:    false\n\nServer:\n Server Version: 1.6.4\n Storage Driver: overlayfs\n Logging Driver: json-file\n Cgroup Driver: cgroupfs\n Cgroup Version: 1\n Plugins:\n  Log: fluentd journald json-file syslog\n  Storage: native overlayfs\n Security Options:\n  seccomp\n   Profile: default\n Kernel Version: 4.18.0-425.13.1.el8_7.x86_64\n Operating System: Rocky Linux 8.7 (Green Obsidian)\n OSType: linux\n Architecture: x86_64\n CPUs: 2\n Total Memory: 3.618GiB\n Name: k8s-master\n ID: d2b76909-9552-4be5-a12a-00b955f756f2\n# 清理数据，它不是和Docker那样只是把标签为\"none\"的镜像清理掉，而是把所有没有\"正在使用\"的镜像清理了\n[root@k8s-master ~]# nerdctl system prune -h\n```\n\n<h1 id=\"we2x0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl替代docker-compose</font></h1>\n---\n\n<h2 id=\"zEQJn\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装bridge插件</font></h2>\n---\n\n```plain\n[root@tiaoban ~]# mkdir -p /opt/cni/bin\n[root@tiaoban ~]# cd /opt/cni/bin\n[root@tiaoban ~]# wget https://github.com/containernetworking/plugins/releases/download/v1.4.1/cni-plugins-linux-amd64-v1.4.1.tgz\n[root@tiaoban ~]# tar -zxvf cni-plugins-linux-amd64-v1.4.1.tgz\n```\n\n<h2 id=\"r8sMZ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">管理compose</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以Harbor为例演示，启动容器</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl compose up -d\nINFO[0000] Creating network harbor_harbor               \nINFO[0000] Creating network harbor_default \n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看启动的容器</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl ps\nCONTAINER ID    IMAGE                                            COMMAND                   CREATED           STATUS    PORTS                                          NAMES\n276a4f6a92e5    docker.io/goharbor/harbor-jobservice:v2.10.1     \"/harbor/entrypoint.…\"    32 seconds ago    Up                                                       harbor-jobservice\n7c3699c62fc7    docker.io/goharbor/redis-photon:v2.10.1          \"redis-server /etc/r…\"    35 seconds ago    Up                                                       redis\n810fbb8229c1    docker.io/goharbor/harbor-core:v2.10.1           \"/harbor/entrypoint.…\"    35 seconds ago    Up                                                       harbor-core\n9a6237f63aeb    docker.io/goharbor/nginx-photon:v2.10.1          \"nginx -g daemon off;\"    33 seconds ago    Up        0.0.0.0:80->8080/tcp, 0.0.0.0:443->8443/tcp    nginx\na0198a493795    docker.io/goharbor/harbor-db:v2.10.1             \"/docker-entrypoint.…\"    36 seconds ago    Up                                                       harbor-db\nb4c2c4a1f934    docker.io/goharbor/harbor-log:v2.10.1            \"/bin/sh -c /usr/loc…\"    37 seconds ago    Up        127.0.0.1:1514->10514/tcp                      harbor-log\nd9ec21d50e55    docker.io/goharbor/harbor-portal:v2.10.1         \"nginx -g daemon off;\"    34 seconds ago    Up                                                       harbor-portal\nf1e6c92a6000    docker.io/goharbor/harbor-registryctl:v2.10.1    \"/home/harbor/start.…\"    33 seconds ago    Up                                                       registryctl\nf2f383e2a191    docker.io/goharbor/registry-photon:v2.10.1       \"/home/harbor/entryp…\"    36 seconds ago    Up                                                       registry\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看日志</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl compose logs\ndb          |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nportal      |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nredis       |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nregistry    |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nnginx       |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\ncore        |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\njobservice  |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nregistryctl |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl compose down\n```\n\n<h1 id=\"5339e56b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl+buildkitd构建镜像</font></h1>\n---\n\n<h2 id=\"4abe89d9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit介绍</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit 从Docker公司的开源的镜像构建工具包，支持OCI标准的镜像构建</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd组成部分：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd（服务端），目前支持runc和containerd作为镜像构建环境，默认是runc，可以更换containerd。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildctl（客户端），负责解析Dockerfile文件、并向服务端buildkitd发出构建请求。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并推送至Harbor为例，整个服务调用过程如下：</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802396681-1f579c7b-2837-4924-8113-97dbba5607e3.jpeg)\n\n<h2 id=\"c992adf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装buildkit</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">软件包下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/moby/buildkit/releases</font>](https://github.com/moby/buildkit/releases)\n\n```plain\n[root@master ~]# wget https://github.com/moby/buildkit/releases/download/v0.13.2/buildkit-v0.13.2.linux-amd64.tar.gz\n[root@master ~]# tar -zxvf buildkit-v0.13.2.linux-amd64.tar.gz \nbin/\nbin/buildctl\nbin/buildkit-cni-bridge\nbin/buildkit-cni-firewall\nbin/buildkit-cni-host-local\nbin/buildkit-cni-loopback\nbin/buildkit-qemu-aarch64\nbin/buildkit-qemu-arm\nbin/buildkit-qemu-i386\nbin/buildkit-qemu-mips64\nbin/buildkit-qemu-mips64el\nbin/buildkit-qemu-ppc64le\nbin/buildkit-qemu-riscv64\nbin/buildkit-qemu-s390x\nbin/buildkit-runc\nbin/buildkitd\n[root@master ~]# cd bin/\n[root@master bin]# cp * /usr/local/bin/\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建service脚本</font>\n\n```plain\n[root@master bin]# cat /etc/systemd/system/buildkitd.service\n[Unit]\nDescription=BuildKit\nDocumentation=https://github.com/moby/buildkit\n\n[Service]\nExecStart=/usr/local/bin/buildkitd --oci-worker=false --containerd-worker=true\n\n[Install]\nWantedBy=multi-user.target\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">新增buildkitd配置文件，添加镜像仓库使用http访问</font>\n\n```plain\n[root@master bin]# vim /etc/buildkit/buildkitd.toml\n[registry.\"harbor.local.com\"]\n  http = false\n  insecure = true\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动buildkitd</font>\n\n```plain\n[root@master bin]# systemctl daemon-reload\n[root@master bin]# systemctl start buildkitd\n[root@master bin]# systemctl enable buildkitd\n```\n\n<h2 id=\"5b4ab044\"><font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并测试</font></h2>\n---\n\n```plain\n[root@master ~]# cat Dockerfile \nFROM busybox\nCMD [\"echo\",\"hello\",\"container\"]\n[root@master ~]# nerdctl build -t busybox:v1 .\n[root@master ~]# nerdctl images\nREPOSITORY    TAG    IMAGE ID        CREATED               PLATFORM       SIZE       BLOB SIZE\nbusybox       v1     fb6a2dfc7899    About a minute ago    linux/amd64    4.1 MiB    2.1 MiB\n[root@master ~]# nerdctl run busybox:v1\nhello container\n```\n\n<h2 id=\"6d4c46c7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">推送至Harbor仓库</font></h2>\n---\n\n```plain\n[root@master ~]# nerdctl tag busybox:v1 harbor.local.com/app/busybox:v1\n[root@master ~]# nerdctl push harbor.local.com/app/busybox:v1\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">此时查看Harbor仓库发现已经推送成功</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802523651-b6549a67-9710-41ff-9ee6-4903e44ffd04.jpeg)\n\n","source":"_posts/4.Containerd进阶使用 副本.md","raw":"---\ntitle: Containerd进阶使用 \ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"Wu324\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr命令使用</font></h1>\n---\n\n<h2 id=\"jWZEX\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd 中也支持命名空间的概念，比如查看命名空间：</font>\n\n```shell\n[root@work3 ~]# ctr ns ls\nNAME    LABELS \ndefault        \nk8s.io         \nmoby \n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果不指定，ctr 默认使用的是 default 空间。同样也可以使用 ns create 命令创建一个命名空间：</font>\n\n```shell\n[root@work3 ~]# ctr ns create test\n[root@work3 ~]# ctr ns ls\nNAME    LABELS \ndefault        \nk8s.io         \nmoby           \ntest\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用 remove 或者 rm 可以删除 namespace：</font>\n\n```shell\n[root@work3 ~]# ctr ns rm test\ntest\n[root@work3 ~]# ctr ns ls\nNAME    LABELS \ndefault        \nk8s.io         \nmoby \n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">指定命名空间</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">有了命名空间后就可以在操作资源的时候指定 namespace，比如查看 test 命名空间的镜像，可以在操作命令后面加上 -n test 选项：</font>\n\n```shell\n➜  ~ ctr -n test image ls\nREF TYPE DIGEST SIZE PLATFORMS LABELS\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们知道 Docker 其实也是默认调用的 containerd，事实上 Docker 使用的 containerd 下面的命名空间默认是 moby，而不是 default，所以假如我们有用 docker 启动容器，那么我们也可以通过 ctr -n moby 来定位下面的容器：</font>\n\n```shell\n➜  ~ ctr -n moby container ls\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">同样 Kubernetes 下使用的 containerd 默认命名空间是 k8s.io，所以我们可以使用 ctr -n k8s.io 来查看 Kubernetes 下面创建的容器。</font>\n\n<h2 id=\"vPuiL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像操作</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr image命令完成，也可以简化为ctr i命令操作</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像可以使用 ctr image pull 来完成，比如拉取 Docker Hub 官方镜像 nginx:alpine，需要注意的是镜像地址需要加上 docker.io Host 地址</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n```shell\n[root@work3 ~]# ctr image pull docker.io/library/nginx:alpine\ndocker.io/library/nginx:alpine:                                                   resolved       |++++++++++++++++++++++++++++++++++++++| \nindex-sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c:    exists         |++++++++++++++++++++++++++++++++++++++| \nmanifest-sha256:ccf066d2cfec0cfe57a63cf26f4b7cabbea80e11ab5b7f1cc11a1b5efd65ea0b: exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9398808236ffac29e60c04ec906d8d409af7fa19dc57d8c65ad167e9c4967006:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:e6a5b569446606ea05a88fc5be4097b4982fc4bc8aeae0818385fe13b8b6066e:    done           |++++++++++++++++++++++++++++++++++++++| \nconfig-sha256:414132ff3b076936528928c823b4f3d1e1178b2692ae04defc8f8fdfd0a83a03:   exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:7b8bdebbb770eb9a7ceaecd729a82d21052fcdb9915873a67d5834960944fcf2:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:a2a4fe64baa08a5a04c1acd107b0026f81a72c7e35cdb3647e164f3b87871d09:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:0777b518fc6e4d42454db10fd2da40eb3f2e9086aa2529066ce6b314c2ec08cb:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:63f4060a8ef34058494aefc8ef63522d21056a40f00255d0c5d92ab51212e4c2:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:48703ecfcf806f280f159af73a1688374148f4860c52d016646a40a1a84853ec:    exists         |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9cbe387ec693ef1d8ece08c1ab2d510ac31d0745c157fbf948cacac343b47c34:    exists         |++++++++++++++++++++++++++++++++++++++| \nelapsed: 164.1s                                                                   total:  11.0 M (68.6 KiB/s)                                      \nunpacking linux/amd64 sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c...\ndone: 1.656214028s\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">列出本地镜像</font>\n\n```shell\n# 列出镜像列表\n[root@work3 ~]# ctr image ls\nREF                                         TYPE                                                      DIGEST                                                                  SIZE      PLATFORMS                                                                                                                          LABELS \ndocker.io/library/nginx:alpine              application/vnd.docker.distribution.manifest.list.v2+json sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c 16.2 MiB  linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x                                           -      \n# 只查看镜像名称标签\n[root@work3 ~]# ctr image ls -q\ndocker.io/flannel/flannel-cni-plugin:v1.2.0\ndocker.io/flannel/flannel:v0.22.1\ndocker.io/library/busybox:latest\ndocker.io/library/nginx:alpine\nghcr.io/kube-vip/kube-vip:v0.6.0\nharbor.local.com/library/busybox:latest\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重新打标签</font>\n\n```shell\n[root@work3 ~]# ctr image tag docker.io/library/nginx:alpine harbor.local.com/library/nginx:alpine\nharbor.local.com/library/nginx:alpine\n[root@work3 ~]# ctr image ls -q\ndocker.io/library/nginx:alpine\nharbor.local.com/library/nginx:alpine\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除镜像</font>\n\n```shell\n[root@work3 ~]# ctr image rm harbor.local.com/library/nginx:alpine\nharbor.local.com/library/nginx:alpine\n[root@work3 ~]# ctr image ls -q\ndocker.io/library/nginx:alpine\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">将镜像导出为压缩包</font>\n\n```shell\n[root@work3 ~]# ctr image export nginx.tar docker.io/library/nginx:alpine\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从压缩包导入镜像</font>\n\n```shell\n[root@work2 ~]# ctr image import nginx.tar \n```\n\n<h2 id=\"SmLyN\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器操作</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr container命令完成，也可以简化为ctr c命令操作</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这里要解释一个概念 containers 和 task ，在docker里面 container 概念被弱化 ，将containers 和 task 整在一起 形成了docker中的 container。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 containers 是镜像实例化的一个虚拟环境，提供一个磁盘，模拟空间，就好比你电脑处于关机状态一样。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 tasks 是将容器运行起来，电脑开机了 ，初始化进程等 ，task就是的这么个形式。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font>\n\n```shell\n[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">列出容器</font>\n\n```shell\n[root@work3 ~]# ctr container ls\nCONTAINER    IMAGE                             RUNTIME                  \nnginx        docker.io/library/nginx:alpine    io.containerd.runc.v2    \n[root@work3 ~]# ctr container ls -q\nnginx\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看容器详情</font>\n\n```shell\n[root@work3 ~]# ctr container info nginx\n{\n    \"ID\": \"nginx\",\n    \"Labels\": {\n        \"io.containerd.image.config.stop-signal\": \"SIGQUIT\",\n        \"maintainer\": \"NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e\"\n    },\n    \"Image\": \"docker.io/library/nginx:alpine\",\n    \"Runtime\": {\n        \"Name\": \"io.containerd.runc.v2\",\n        \"Options\": {\n            \"type_url\": \"containerd.runc.v1.Options\"\n        }\n    }\n    ……\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font>\n\n```shell\n[root@work3 ~]# ctr container rm nginx\n[root@work3 ~]# ctr container ls\nCONTAINER    IMAGE    RUNTIME \n```\n\n<h2 id=\"P5mQT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">任务操作</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">上面我们通过 container create 命令创建的容器，并没有处于运行状态，只是一个静态的容器。一个 container 对象只是包含了运行一个容器所需的资源及相关配置数据，表示 namespaces、rootfs 和容器的配置都已经初始化成功了，只是用户进程还没有启动。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">一个容器真正运行起来是由 Task 任务实现的，Task 可以为容器设置网卡，还可以配置工具来对容器进行监控等。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font>\n\n```shell\n[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx\n[root@work3 ~]# ctr task start -d nginx\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看正在运行的容器</font>\n\n```shell\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    RUNNING\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器信息</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task metrics 命令用来获取容器的内存、CPU 和 PID 的限额与使用量。</font>\n\n```shell\n[root@work3 ~]# ctr task metrics nginx\nID       TIMESTAMP                                  \nnginx    2023-08-13 04:42:31.648754469 +0000 UTC    \n\nMETRIC                   VALUE                                                                                                                                                                                                                                                                                          \nmemory.usage_in_bytes    5226496                                                                                                                                                                                                                                                                                        \nmemory.limit_in_bytes    9223372036854771712                                                                                                                                                                                                                                                                            \nmemory.stat.cache        155648                                                                                                                                                                                                                                                                                         \ncpuacct.usage            74124077                                                                                                                                                                                                                                                                                       \ncpuacct.usage_percpu     [32560123 27605021 7821698 6137235 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]    \npids.current             5                                                                                                                                                                                                                                                                                              \npids.limit               0\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器PID</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task ps 命令查看容器中所有进程在宿主机中的 PID：</font>\n\n```shell\n[root@work3 ~]# ctr task ps nginx\nPID      INFO\n62925    -\n62954    -\n62955    -\n62956    -\n62957    -\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    62925    RUNNING\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">其中第一个 PID 3984 就是我们容器中的 1 号进程。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">进入容器进行操作</font>\n\n```shell\n[root@work3 ~]# ctr task exec --exec-id 0 -t nginx sh\n/ # ls\nbin                   docker-entrypoint.sh  lib \n# 指定用户进入\n[root@work3 ~]# ctr task exec --exec-id 0 --user 65534 -t nginx sh\n$ whoami\nnobody\n$ exit\n[root@work3 ~]# ctr task exec --exec-id 0 --user 0 -t nginx sh\n# whoami\nroot\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">不过这里需要注意必须要指定 --exec-id 参数，这个 id 可以随便写，只要唯一就行。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">暂停容器</font>\n\n```shell\n[root@work3 ~]# ctr task pause nginx\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    PAUSED\n# 暂停后容器状态变成了 PAUSED\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">恢复容器</font>\n\n```shell\n[root@work3 ~]# ctr task resume nginx\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    RUNNING\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">不过需要注意 ctr 没有 stop 容器的功能，只能暂停或者杀死容器。杀死容器可以使用 task kill 命令:</font>\n\n```shell\n[root@work3 ~]# ctr task kill nginx\n[root@work3 ~]# ctr task ls\nTASK     PID      STATUS    \nnginx    60394    STOPPED\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">杀掉容器后可以看到容器的状态变成了 STOPPED。同样也可以通过 task rm 命令删除 Task：</font>\n\n```shell\n[root@work3 ~]# ctr task rm nginx\n[root@work3 ~]# ctr task ls\nTASK    PID    STATUS\n```\n\n<h1 id=\"oZwBQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h1>\n---\n\n<h2 id=\"AJFk1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装crictl</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：https://github.com/kubernetes-sigs/cri-tools/releases，例如安装1.30.6版本的k8s，此处安装的crictl就是1.30.1。</font>\n\n```shell\nLoading...# 下载\n[root@k8s-master ~]# wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.30.1/crictl-v1.30.1-linux-amd64.tar.gz\n# 解压\n[root@k8s-master ~]# tar -zxvf crictl-v1.30.1-linux-amd64.tar.gz -C /usr/local/bin\n# 配置\n[root@k8s-master ~]# cat > /etc/crictl.yaml << EOF\nruntime-endpoint: \"unix:///run/containerd/containerd.sock\"\nimage-endpoint: \"unix:///run/containerd/containerd.sock\"\ntimeout: 0\ndebug: false\npull-image-on-create: false\ndisable-pull-on-run: false\nEOF\n[root@k8s-master ~]# crictl version\nVersion:  0.1.0\nRuntimeName:  containerd\nRuntimeVersion:  1.6.4\nRuntimeApiVersion:  v1\n```\n\n<h2 id=\"VUGBB\"><font style=\"background-color:rgba(255, 255, 255, 0);\">打印清单</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打印 Pod 清单</font>\n\n```shell\n# 打印所有 Pod 的清单\n$ crictl pods\nPOD ID              CREATED              STATE               NAME                         NAMESPACE           ATTEMPT\n926f1b5a1d33a       About a minute ago   Ready               sh-84d7dcf559-4r2gq          default             0\n4dccb216c4adb       About a minute ago   Ready               nginx-65899c769f-wv2gp       default             0\na86316e96fa89       17 hours ago         Ready               kube-proxy-gblk4             kube-system         0\n919630b8f81f1       17 hours ago         Ready               nvidia-device-plugin-zgbbv   kube-system         0\n\n# 根据名称打印 Pod 清单：\n$ crictl pods --name nginx-65899c769f-wv2gp\nPOD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT\n4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0\n\n# 根据标签打印 Pod 清单\n$ crictl pods --label run=nginx\nPOD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT\n4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打印镜像清单</font>\n\n```shell\n# 打印所有镜像清单\n$ crictl images\nIMAGE                                     TAG                 IMAGE ID            SIZE\nbusybox                                   latest              8c811b4aec35f       1.15MB\nk8s-gcrio.azureedge.net/hyperkube-amd64   v1.10.3             e179bbfe5d238       665MB\nk8s-gcrio.azureedge.net/pause-amd64       3.1                 da86e6ba6ca19       742kB\nnginx                                     latest              cd5239a0906a6       109MB\n\n# 根据仓库打印镜像清单\n$ crictl images nginx\nIMAGE               TAG                 IMAGE ID            SIZE\nnginx               latest              cd5239a0906a6       109MB\n\n# 只打印镜像 ID\n$ crictl images -q\nsha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a\nsha256:e179bbfe5d238de6069f3b03fccbecc3fb4f2019af741bfff1233c4d7b2970c5\nsha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e\nsha256:cd5239a0906a6ccf0562354852fae04bc5b52d72a2aff9a871ddb6bd57553569\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打印容器清单</font>\n\n```shell\n# 打印所有容器清单\n$ crictl ps -a\nCONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT\n1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   7 minutes ago       Running             sh                         1\n9c5951df22c78       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   8 minutes ago       Exited              sh                         0\n87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     8 minutes ago       Running             nginx                      0\n1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   18 hours ago        Running             kube-proxy                 0\n\n# 打印正在运行的容器清单\n$ crictl ps\nCONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT\n1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   6 minutes ago       Running             sh                         1\n87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     7 minutes ago       Running             nginx                      0\n1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   17 hours ago        Running             kube-proxy                 0\n\n```\n\n<h2 id=\"UOaNL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器执行命令</font></h2>\n---\n\n```shell\n$ crictl exec -i -t 1f73f2d81bf98 ls\nbin   dev   etc   home  proc  root  sys   tmp   usr   var\n```\n\n<h2 id=\"DC2UT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器日志</font></h2>\n---\n\n```shell\n# 获取容器的所有日志\n$ crictl logs 87d3992f84f74\n10.240.0.96 - - [06/Jun/2018:02:45:49 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n10.240.0.96 - - [06/Jun/2018:02:45:50 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n\n# 获取最近的 N 行日志\n$ crictl logs --tail=1 87d3992f84f74\n10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.47.0\" \"-\"\n```\n\n<h2 id=\"zgG3P\"><font style=\"background-color:rgba(255, 255, 255, 0);\">运行 Pod 沙盒</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 运行 Pod 沙盒对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机地被 kubelet 停止和删除。</font>\n\n1. <font style=\"background-color:rgba(255, 255, 255, 0);\">编写下面的 JSON 文件：</font>\n\n```plain\n{\n    \"metadata\": {\n        \"name\": \"nginx-sandbox\",\n        \"namespace\": \"default\",\n        \"attempt\": 1,\n        \"uid\": \"hdishd83djaidwnduwk28bcsb\"\n    },\n    \"logDirectory\": \"/tmp\",\n    \"linux\": {\n    }\n}\n```\n\n2. <font style=\"background-color:rgba(255, 255, 255, 0);\">使用 crictl runp 命令应用 JSON 文件并运行沙盒。</font>\n\n```plain\n$ crictl runp pod-config.json\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">返回了沙盒的 ID。</font>\n\n<h2 id=\"rQW1l\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 创建容器对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机的被 kubelet 停止和删除。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取 busybox 镜像</font>\n\n```plain\n$ crictl pull busybox\nImage is up to date for busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建 Pod 配置</font>\n\n```plain\n{\n    \"metadata\": {\n        \"name\": \"nginx-sandbox\",\n        \"namespace\": \"default\",\n        \"attempt\": 1,\n        \"uid\": \"hdishd83djaidwnduwk28bcsb\"\n    },\n    \"log_directory\": \"/tmp\",\n    \"linux\": {\n    }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器配置</font>\n\n```plain\n{\n  \"metadata\": {\n      \"name\": \"busybox\"\n  },\n  \"image\":{\n      \"image\": \"busybox\"\n  },\n  \"command\": [\n      \"top\"\n  ],\n  \"log_path\":\"busybox.log\",\n  \"linux\": {\n  }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器，传递先前创建的 Pod 的 ID、容器配置文件和 Pod 配置文件。返回容器的 ID。</font>\n\n```plain\n$ crictl create f84dd361f8dc51518ed291fbadd6db537b0496536c1d2d6c05ff943ce8c9a54f container-config.json pod-config.json\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查询所有容器并确认新创建的容器状态为 Created。</font>\n\n```plain\nCONTAINER ID        IMAGE               CREATED             STATE               NAME                ATTEMPT\n3e025dd50a72d       busybox             32 seconds ago      Created             busybox             0\n```\n\n---\n\n<h2 id=\"TS3x9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">要启动容器，要将容器 ID 传给 crictl start：</font>\n\n```plain\n$ crictl start 3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60\n3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">确认容器的状态为 Running。</font>\n\n```plain\n$ crictl ps\nCONTAINER ID        IMAGE               CREATED              STATE               NAME                ATTEMPT\n3e025dd50a72d       busybox             About a minute ago   Running             busybox             0\n```\n\n<h1 id=\"jllch\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装与使用nerdctl</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font>\n\n<h2 id=\"Ehxpa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装nerdctl</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/containerd/nerdctl/releases</font>](https://github.com/containerd/nerdctl/releases)\n\n```plain\n# 下载\n[root@k8s-master ~]# wget https://github.com/containerd/nerdctl/releases/download/v2.0.0-rc.3/nerdctl-2.0.0-rc.3-linux-amd64.tar.gz\n# 解压\n[root@k8s-master ~]# tar -zxvf nerdctl-2.0.0-rc.3-linux-amd64.tar.gz\nnerdctl\ncontainerd-rootless-setuptool.sh\ncontainerd-rootless.sh\n# 复制文件\n[root@k8s-master ~]# mv nerdctl /usr/bin/\n# 配置 nerdctl 参数自动补齐\n[root@k8s-master ~]# echo 'source <(nerdctl completion bash)' >> /etc/profile\n[root@k8s-master ~]# source /etc/profile\n# 验证\n[root@k8s-master ~]# nerdctl -v\nnerdctl version 2.0.0-rc.2\n```\n\n<h2 id=\"BXi4y\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这个和K8s的名字空间不是一回事，其中default就是containerd的默认名字空间，</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://k8s.io</font>](http://k8s.io/)<font style=\"background-color:rgba(255, 255, 255, 0);\">是K8s的名字空间</font>\n\n```plain\n# 查看命名空间\n[root@k8s-master ~]# nerdctl ns ls\nNAME         CONTAINERS    IMAGES    VOLUMES    LABELS\ndefault      0             2         0              \ndocker.io    0             1         0              \nk8s.io       18            51        0              \nmoby         0             0         0\n# 创建命名空间\n[root@k8s-master ~]# nerdctl ns create test\n# 删除命名空间\n[root@k8s-master ~]# nerdctl ns remove test\ntest\n# 查看名称空间详情\n[root@k8s-master ~]# nerdctl ns inspect k8s.io\n[\n    {\n        \"Name\": \"k8s.io\",\n        \"Labels\": null\n    }\n]\n```\n\n<h2 id=\"sU4R0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像</font></h2>\n---\n\n```plain\n# 查看镜像\n[root@k8s-master ~]# nerdctl -n k8s.io images\nREPOSITORY                                                         TAG         IMAGE ID        CREATED         PLATFORM       SIZE         BLOB SIZE\nregistry.aliyuncs.com/google_containers/coredns                    v1.8.6      5b6ec0d6de9b    5 days ago      linux/amd64    44.7 MiB     13.0 MiB\nregistry.aliyuncs.com/google_containers/etcd                       3.5.6-0     dd75ec974b0a    5 days ago      linux/amd64    289.0 MiB    97.8 MiB\n# 拉取镜像\n[root@k8s-master ~]# nerdctl -n test pull nginx:alpine\n# 构建镜像\n[root@k8s-master ~]# cat Dockerfile \nFROM     debian\nRUN apt-get install -y --force-yes locales\nRUN echo \"LC_ALL=\\\"zh_CN.UTF-8\\\"\" >> /etc/default/locale\nRUN locale-gen \"zh_CN.UTF-8\"\n[root@k8s-master ~]# nerdctl -n test build -t abc.com/debian .\n# 上传镜像\n[root@k8s-master ~]# nerdctl -n test push abc.com/debian\n# 导出镜像\n[root@k8s-master ~]# nerdctl -n test save -o debian.tar abc.com/debian\n# 导入镜像\n[root@k8s-master ~]# nerdctl -n test load -i debian.tar\n```\n\n<h2 id=\"tX7Xc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器</font></h2>\n---\n\n```plain\n# 查看容器\n[root@k8s-master ~]# nerdctl -n k8s.io ps \nCONTAINER ID    IMAGE                                                                      COMMAND                   CREATED         STATUS    PORTS    NAMES\n05be77648e0c    registry.aliyuncs.com/google_containers/kube-proxy:v1.25.0                 \"/usr/local/bin/kube…\"    13 hours ago    Up                 k8s://kube-system/kube-proxy-qd2dg/kube-proxy\n240c8fdfb7dd    registry.aliyuncs.com/google_containers/pause:3.6                          \"/pause\"                  13 hours ago    Up                 k8s://kube-system/kube-apiserver-k8s-master\n24728a2d2f1b    docker.io/flannel/flannel:v0.21.5                                          \"/opt/bin/flanneld -…\"    17 hours ago    Up                 k8s://kube-flannel/kube-flannel-ds-45rxr/kube-flannel\n# 启动容器\n[root@k8s-master ~]# nerdctl -n test run -d -p 80:80 --name web nginx:alpine\n# 进入容器\n[root@k8s-master ~]# nerdctl -n test exec -it web sh\n/ # \n# 停止容器\n[root@k8s-master ~]# nerdctl -n test stop web\nweb\n# 删除容器\n[root@k8s-master ~]# nerdctl -n test rm web\nweb\n```\n\n<h2 id=\"JfIJj\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他操作</font></h2>\n---\n\n```plain\n# 查看网络信息\n[root@k8s-master ~]# nerdctl network ls\nNETWORK ID      NAME      FILE\n                cbr0      /etc/cni/net.d/10-flannel.conflist\n17f29b073143    bridge    /etc/cni/net.d/nerdctl-bridge.conflist\n                host      \n                none\n# 查看系统信息\n[root@k8s-master ~]# nerdctl system info\nClient:\n Namespace:     default\n Debug Mode:    false\n\nServer:\n Server Version: 1.6.4\n Storage Driver: overlayfs\n Logging Driver: json-file\n Cgroup Driver: cgroupfs\n Cgroup Version: 1\n Plugins:\n  Log: fluentd journald json-file syslog\n  Storage: native overlayfs\n Security Options:\n  seccomp\n   Profile: default\n Kernel Version: 4.18.0-425.13.1.el8_7.x86_64\n Operating System: Rocky Linux 8.7 (Green Obsidian)\n OSType: linux\n Architecture: x86_64\n CPUs: 2\n Total Memory: 3.618GiB\n Name: k8s-master\n ID: d2b76909-9552-4be5-a12a-00b955f756f2\n# 清理数据，它不是和Docker那样只是把标签为\"none\"的镜像清理掉，而是把所有没有\"正在使用\"的镜像清理了\n[root@k8s-master ~]# nerdctl system prune -h\n```\n\n<h1 id=\"we2x0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl替代docker-compose</font></h1>\n---\n\n<h2 id=\"zEQJn\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装bridge插件</font></h2>\n---\n\n```plain\n[root@tiaoban ~]# mkdir -p /opt/cni/bin\n[root@tiaoban ~]# cd /opt/cni/bin\n[root@tiaoban ~]# wget https://github.com/containernetworking/plugins/releases/download/v1.4.1/cni-plugins-linux-amd64-v1.4.1.tgz\n[root@tiaoban ~]# tar -zxvf cni-plugins-linux-amd64-v1.4.1.tgz\n```\n\n<h2 id=\"r8sMZ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">管理compose</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以Harbor为例演示，启动容器</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl compose up -d\nINFO[0000] Creating network harbor_harbor               \nINFO[0000] Creating network harbor_default \n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看启动的容器</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl ps\nCONTAINER ID    IMAGE                                            COMMAND                   CREATED           STATUS    PORTS                                          NAMES\n276a4f6a92e5    docker.io/goharbor/harbor-jobservice:v2.10.1     \"/harbor/entrypoint.…\"    32 seconds ago    Up                                                       harbor-jobservice\n7c3699c62fc7    docker.io/goharbor/redis-photon:v2.10.1          \"redis-server /etc/r…\"    35 seconds ago    Up                                                       redis\n810fbb8229c1    docker.io/goharbor/harbor-core:v2.10.1           \"/harbor/entrypoint.…\"    35 seconds ago    Up                                                       harbor-core\n9a6237f63aeb    docker.io/goharbor/nginx-photon:v2.10.1          \"nginx -g daemon off;\"    33 seconds ago    Up        0.0.0.0:80->8080/tcp, 0.0.0.0:443->8443/tcp    nginx\na0198a493795    docker.io/goharbor/harbor-db:v2.10.1             \"/docker-entrypoint.…\"    36 seconds ago    Up                                                       harbor-db\nb4c2c4a1f934    docker.io/goharbor/harbor-log:v2.10.1            \"/bin/sh -c /usr/loc…\"    37 seconds ago    Up        127.0.0.1:1514->10514/tcp                      harbor-log\nd9ec21d50e55    docker.io/goharbor/harbor-portal:v2.10.1         \"nginx -g daemon off;\"    34 seconds ago    Up                                                       harbor-portal\nf1e6c92a6000    docker.io/goharbor/harbor-registryctl:v2.10.1    \"/home/harbor/start.…\"    33 seconds ago    Up                                                       registryctl\nf2f383e2a191    docker.io/goharbor/registry-photon:v2.10.1       \"/home/harbor/entryp…\"    36 seconds ago    Up                                                       registry\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看日志</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl compose logs\ndb          |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nportal      |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nredis       |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nregistry    |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nnginx       |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\ncore        |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\njobservice  |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\nregistryctl |time=\"2024-04-26T20:39:54+08:00\" level=fatal msg=\"no log viewer type registered for logging driver \\\"syslog\\\"\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font>\n\n```plain\n[root@tiaoban harbor]# nerdctl compose down\n```\n\n<h1 id=\"5339e56b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl+buildkitd构建镜像</font></h1>\n---\n\n<h2 id=\"4abe89d9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit介绍</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit 从Docker公司的开源的镜像构建工具包，支持OCI标准的镜像构建</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd组成部分：</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd（服务端），目前支持runc和containerd作为镜像构建环境，默认是runc，可以更换containerd。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">buildctl（客户端），负责解析Dockerfile文件、并向服务端buildkitd发出构建请求。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并推送至Harbor为例，整个服务调用过程如下：</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802396681-1f579c7b-2837-4924-8113-97dbba5607e3.jpeg)\n\n<h2 id=\"c992adf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装buildkit</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">软件包下载地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/moby/buildkit/releases</font>](https://github.com/moby/buildkit/releases)\n\n```plain\n[root@master ~]# wget https://github.com/moby/buildkit/releases/download/v0.13.2/buildkit-v0.13.2.linux-amd64.tar.gz\n[root@master ~]# tar -zxvf buildkit-v0.13.2.linux-amd64.tar.gz \nbin/\nbin/buildctl\nbin/buildkit-cni-bridge\nbin/buildkit-cni-firewall\nbin/buildkit-cni-host-local\nbin/buildkit-cni-loopback\nbin/buildkit-qemu-aarch64\nbin/buildkit-qemu-arm\nbin/buildkit-qemu-i386\nbin/buildkit-qemu-mips64\nbin/buildkit-qemu-mips64el\nbin/buildkit-qemu-ppc64le\nbin/buildkit-qemu-riscv64\nbin/buildkit-qemu-s390x\nbin/buildkit-runc\nbin/buildkitd\n[root@master ~]# cd bin/\n[root@master bin]# cp * /usr/local/bin/\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建service脚本</font>\n\n```plain\n[root@master bin]# cat /etc/systemd/system/buildkitd.service\n[Unit]\nDescription=BuildKit\nDocumentation=https://github.com/moby/buildkit\n\n[Service]\nExecStart=/usr/local/bin/buildkitd --oci-worker=false --containerd-worker=true\n\n[Install]\nWantedBy=multi-user.target\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">新增buildkitd配置文件，添加镜像仓库使用http访问</font>\n\n```plain\n[root@master bin]# vim /etc/buildkit/buildkitd.toml\n[registry.\"harbor.local.com\"]\n  http = false\n  insecure = true\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动buildkitd</font>\n\n```plain\n[root@master bin]# systemctl daemon-reload\n[root@master bin]# systemctl start buildkitd\n[root@master bin]# systemctl enable buildkitd\n```\n\n<h2 id=\"5b4ab044\"><font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并测试</font></h2>\n---\n\n```plain\n[root@master ~]# cat Dockerfile \nFROM busybox\nCMD [\"echo\",\"hello\",\"container\"]\n[root@master ~]# nerdctl build -t busybox:v1 .\n[root@master ~]# nerdctl images\nREPOSITORY    TAG    IMAGE ID        CREATED               PLATFORM       SIZE       BLOB SIZE\nbusybox       v1     fb6a2dfc7899    About a minute ago    linux/amd64    4.1 MiB    2.1 MiB\n[root@master ~]# nerdctl run busybox:v1\nhello container\n```\n\n<h2 id=\"6d4c46c7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">推送至Harbor仓库</font></h2>\n---\n\n```plain\n[root@master ~]# nerdctl tag busybox:v1 harbor.local.com/app/busybox:v1\n[root@master ~]# nerdctl push harbor.local.com/app/busybox:v1\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">此时查看Harbor仓库发现已经推送成功</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802523651-b6549a67-9710-41ff-9ee6-4903e44ffd04.jpeg)\n\n","slug":"4.Containerd进阶使用 副本","published":1,"updated":"2025-03-30T13:11:27.640Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlq000mtsv18kvuhtfb","content":"<h1 id=\"Wu324\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr命令使用</font></h1>\n---\n\n<h2 id=\"jWZEX\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看命名空间</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd 中也支持命名空间的概念，比如查看命名空间：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr ns ls</span><br><span class=\"line\">NAME    LABELS </span><br><span class=\"line\">default        </span><br><span class=\"line\">k8s.io         </span><br><span class=\"line\">moby </span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建命名空间</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果不指定，ctr 默认使用的是 default 空间。同样也可以使用 ns create 命令创建一个命名空间：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr ns create test</span><br><span class=\"line\">[root@work3 ~]# ctr ns ls</span><br><span class=\"line\">NAME    LABELS </span><br><span class=\"line\">default        </span><br><span class=\"line\">k8s.io         </span><br><span class=\"line\">moby           </span><br><span class=\"line\">test</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除命名空间</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 remove 或者 rm 可以删除 namespace：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr ns rm test</span><br><span class=\"line\">test</span><br><span class=\"line\">[root@work3 ~]# ctr ns ls</span><br><span class=\"line\">NAME    LABELS </span><br><span class=\"line\">default        </span><br><span class=\"line\">k8s.io         </span><br><span class=\"line\">moby </span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">指定命名空间</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">有了命名空间后就可以在操作资源的时候指定 namespace，比如查看 test 命名空间的镜像，可以在操作命令后面加上 -n test 选项：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ ctr -n test image ls</span><br><span class=\"line\">REF TYPE DIGEST SIZE PLATFORMS LABELS</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们知道 Docker 其实也是默认调用的 containerd，事实上 Docker 使用的 containerd 下面的命名空间默认是 moby，而不是 default，所以假如我们有用 docker 启动容器，那么我们也可以通过 ctr -n moby 来定位下面的容器：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ ctr -n moby container ls</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">同样 Kubernetes 下使用的 containerd 默认命名空间是 k8s.io，所以我们可以使用 ctr -n k8s.io 来查看 Kubernetes 下面创建的容器。</font></p>\n<h2 id=\"vPuiL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像操作</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr image命令完成，也可以简化为ctr i命令操作</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像可以使用 ctr image pull 来完成，比如拉取 Docker Hub 官方镜像 nginx:alpine，需要注意的是镜像地址需要加上 docker.io Host 地址</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image pull docker.io/library/nginx:alpine</span><br><span class=\"line\">docker.io/library/nginx:alpine:                                                   resolved       |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">index-sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">manifest-sha256:ccf066d2cfec0cfe57a63cf26f4b7cabbea80e11ab5b7f1cc11a1b5efd65ea0b: exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:9398808236ffac29e60c04ec906d8d409af7fa19dc57d8c65ad167e9c4967006:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:e6a5b569446606ea05a88fc5be4097b4982fc4bc8aeae0818385fe13b8b6066e:    done           |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">config-sha256:414132ff3b076936528928c823b4f3d1e1178b2692ae04defc8f8fdfd0a83a03:   exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:7b8bdebbb770eb9a7ceaecd729a82d21052fcdb9915873a67d5834960944fcf2:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:a2a4fe64baa08a5a04c1acd107b0026f81a72c7e35cdb3647e164f3b87871d09:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:0777b518fc6e4d42454db10fd2da40eb3f2e9086aa2529066ce6b314c2ec08cb:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:63f4060a8ef34058494aefc8ef63522d21056a40f00255d0c5d92ab51212e4c2:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:48703ecfcf806f280f159af73a1688374148f4860c52d016646a40a1a84853ec:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:9cbe387ec693ef1d8ece08c1ab2d510ac31d0745c157fbf948cacac343b47c34:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">elapsed: 164.1s                                                                   total:  11.0 M (68.6 KiB/s)                                      </span><br><span class=\"line\">unpacking linux/amd64 sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c...</span><br><span class=\"line\">done: 1.656214028s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">列出本地镜像</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">列出镜像列表</span></span><br><span class=\"line\">[root@work3 ~]# ctr image ls</span><br><span class=\"line\">REF                                         TYPE                                                      DIGEST                                                                  SIZE      PLATFORMS                                                                                                                          LABELS </span><br><span class=\"line\">docker.io/library/nginx:alpine              application/vnd.docker.distribution.manifest.list.v2+json sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c 16.2 MiB  linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x                                           -      </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">只查看镜像名称标签</span></span><br><span class=\"line\">[root@work3 ~]# ctr image ls -q</span><br><span class=\"line\">docker.io/flannel/flannel-cni-plugin:v1.2.0</span><br><span class=\"line\">docker.io/flannel/flannel:v0.22.1</span><br><span class=\"line\">docker.io/library/busybox:latest</span><br><span class=\"line\">docker.io/library/nginx:alpine</span><br><span class=\"line\">ghcr.io/kube-vip/kube-vip:v0.6.0</span><br><span class=\"line\">harbor.local.com/library/busybox:latest</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重新打标签</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image tag docker.io/library/nginx:alpine harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">[root@work3 ~]# ctr image ls -q</span><br><span class=\"line\">docker.io/library/nginx:alpine</span><br><span class=\"line\">harbor.local.com/library/nginx:alpine</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除镜像</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image rm harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">[root@work3 ~]# ctr image ls -q</span><br><span class=\"line\">docker.io/library/nginx:alpine</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">将镜像导出为压缩包</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image export nginx.tar docker.io/library/nginx:alpine</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从压缩包导入镜像</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work2 ~]# ctr image import nginx.tar </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"SmLyN\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器操作</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr container命令完成，也可以简化为ctr c命令操作</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这里要解释一个概念 containers 和 task ，在docker里面 container 概念被弱化 ，将containers 和 task 整在一起 形成了docker中的 container。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 containers 是镜像实例化的一个虚拟环境，提供一个磁盘，模拟空间，就好比你电脑处于关机状态一样。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 tasks 是将容器运行起来，电脑开机了 ，初始化进程等 ，task就是的这么个形式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">列出容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container ls</span><br><span class=\"line\">CONTAINER    IMAGE                             RUNTIME                  </span><br><span class=\"line\">nginx        docker.io/library/nginx:alpine    io.containerd.runc.v2    </span><br><span class=\"line\">[root@work3 ~]# ctr container ls -q</span><br><span class=\"line\">nginx</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看容器详情</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container info nginx</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;ID&quot;: &quot;nginx&quot;,</span><br><span class=\"line\">    &quot;Labels&quot;: &#123;</span><br><span class=\"line\">        &quot;io.containerd.image.config.stop-signal&quot;: &quot;SIGQUIT&quot;,</span><br><span class=\"line\">        &quot;maintainer&quot;: &quot;NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;Image&quot;: &quot;docker.io/library/nginx:alpine&quot;,</span><br><span class=\"line\">    &quot;Runtime&quot;: &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;io.containerd.runc.v2&quot;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;type_url&quot;: &quot;containerd.runc.v1.Options&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ……</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container rm nginx</span><br><span class=\"line\">[root@work3 ~]# ctr container ls</span><br><span class=\"line\">CONTAINER    IMAGE    RUNTIME </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"P5mQT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">任务操作</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">上面我们通过 container create 命令创建的容器，并没有处于运行状态，只是一个静态的容器。一个 container 对象只是包含了运行一个容器所需的资源及相关配置数据，表示 namespaces、rootfs 和容器的配置都已经初始化成功了，只是用户进程还没有启动。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">一个容器真正运行起来是由 Task 任务实现的，Task 可以为容器设置网卡，还可以配置工具来对容器进行监控等。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task start -d nginx</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看正在运行的容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    RUNNING</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器信息</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task metrics 命令用来获取容器的内存、CPU 和 PID 的限额与使用量。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task metrics nginx</span><br><span class=\"line\">ID       TIMESTAMP                                  </span><br><span class=\"line\">nginx    2023-08-13 04:42:31.648754469 +0000 UTC    </span><br><span class=\"line\"></span><br><span class=\"line\">METRIC                   VALUE                                                                                                                                                                                                                                                                                          </span><br><span class=\"line\">memory.usage_in_bytes    5226496                                                                                                                                                                                                                                                                                        </span><br><span class=\"line\">memory.limit_in_bytes    9223372036854771712                                                                                                                                                                                                                                                                            </span><br><span class=\"line\">memory.stat.cache        155648                                                                                                                                                                                                                                                                                         </span><br><span class=\"line\">cpuacct.usage            74124077                                                                                                                                                                                                                                                                                       </span><br><span class=\"line\">cpuacct.usage_percpu     [32560123 27605021 7821698 6137235 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]    </span><br><span class=\"line\">pids.current             5                                                                                                                                                                                                                                                                                              </span><br><span class=\"line\">pids.limit               0</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器PID</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task ps 命令查看容器中所有进程在宿主机中的 PID：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task ps nginx</span><br><span class=\"line\">PID      INFO</span><br><span class=\"line\">62925    -</span><br><span class=\"line\">62954    -</span><br><span class=\"line\">62955    -</span><br><span class=\"line\">62956    -</span><br><span class=\"line\">62957    -</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    62925    RUNNING</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其中第一个 PID 3984 就是我们容器中的 1 号进程。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">进入容器进行操作</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task exec --exec-id 0 -t nginx sh</span><br><span class=\"line\">/ # ls</span><br><span class=\"line\">bin                   docker-entrypoint.sh  lib </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">指定用户进入</span></span><br><span class=\"line\">[root@work3 ~]# ctr task exec --exec-id 0 --user 65534 -t nginx sh</span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\"><span class=\"built_in\">whoami</span></span></span><br><span class=\"line\">nobody</span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\"><span class=\"built_in\">exit</span></span></span><br><span class=\"line\">[root@work3 ~]# ctr task exec --exec-id 0 --user 0 -t nginx sh</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">whoami</span></span></span><br><span class=\"line\">root</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">不过这里需要注意必须要指定 –exec-id 参数，这个 id 可以随便写，只要唯一就行。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">暂停容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task pause nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    PAUSED</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">暂停后容器状态变成了 PAUSED</span></span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">恢复容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task resume nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    RUNNING</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">不过需要注意 ctr 没有 stop 容器的功能，只能暂停或者杀死容器。杀死容器可以使用 task kill 命令:</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task kill nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    STOPPED</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">杀掉容器后可以看到容器的状态变成了 STOPPED。同样也可以通过 task rm 命令删除 Task：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task rm nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK    PID    STATUS</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"oZwBQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h1>\n---\n\n<h2 id=\"AJFk1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装crictl</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：<a href=\"https://github.com/kubernetes-sigs/cri-tools/releases%EF%BC%8C%E4%BE%8B%E5%A6%82%E5%AE%89%E8%A3%851.30.6%E7%89%88%E6%9C%AC%E7%9A%84k8s%EF%BC%8C%E6%AD%A4%E5%A4%84%E5%AE%89%E8%A3%85%E7%9A%84crictl%E5%B0%B1%E6%98%AF1.30.1%E3%80%82\">https://github.com/kubernetes-sigs/cri-tools/releases，例如安装1.30.6版本的k8s，此处安装的crictl就是1.30.1。</a></font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Loading...# 下载</span><br><span class=\"line\">[root@k8s-master ~]# wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.30.1/crictl-v1.30.1-linux-amd64.tar.gz</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">解压</span></span><br><span class=\"line\">[root@k8s-master ~]# tar -zxvf crictl-v1.30.1-linux-amd64.tar.gz -C /usr/local/bin</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">配置</span></span><br><span class=\"line\">[root@k8s-master ~]# cat &gt; /etc/crictl.yaml &lt;&lt; EOF</span><br><span class=\"line\">runtime-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">image-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">timeout: 0</span><br><span class=\"line\">debug: false</span><br><span class=\"line\">pull-image-on-create: false</span><br><span class=\"line\">disable-pull-on-run: false</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master ~]# crictl version</span><br><span class=\"line\">Version:  0.1.0</span><br><span class=\"line\">RuntimeName:  containerd</span><br><span class=\"line\">RuntimeVersion:  1.6.4</span><br><span class=\"line\">RuntimeApiVersion:  v1</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"VUGBB\"><font style=\"background-color:rgba(255, 255, 255, 0);\">打印清单</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打印 Pod 清单</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印所有 Pod 的清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl pods</span></span><br><span class=\"line\">POD ID              CREATED              STATE               NAME                         NAMESPACE           ATTEMPT</span><br><span class=\"line\">926f1b5a1d33a       About a minute ago   Ready               sh-84d7dcf559-4r2gq          default             0</span><br><span class=\"line\">4dccb216c4adb       About a minute ago   Ready               nginx-65899c769f-wv2gp       default             0</span><br><span class=\"line\">a86316e96fa89       17 hours ago         Ready               kube-proxy-gblk4             kube-system         0</span><br><span class=\"line\">919630b8f81f1       17 hours ago         Ready               nvidia-device-plugin-zgbbv   kube-system         0</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">根据名称打印 Pod 清单：</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl pods --name nginx-65899c769f-wv2gp</span></span><br><span class=\"line\">POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT</span><br><span class=\"line\">4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">根据标签打印 Pod 清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl pods --label run=nginx</span></span><br><span class=\"line\">POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT</span><br><span class=\"line\">4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打印镜像清单</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印所有镜像清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl images</span></span><br><span class=\"line\">IMAGE                                     TAG                 IMAGE ID            SIZE</span><br><span class=\"line\">busybox                                   latest              8c811b4aec35f       1.15MB</span><br><span class=\"line\">k8s-gcrio.azureedge.net/hyperkube-amd64   v1.10.3             e179bbfe5d238       665MB</span><br><span class=\"line\">k8s-gcrio.azureedge.net/pause-amd64       3.1                 da86e6ba6ca19       742kB</span><br><span class=\"line\">nginx                                     latest              cd5239a0906a6       109MB</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">根据仓库打印镜像清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl images nginx</span></span><br><span class=\"line\">IMAGE               TAG                 IMAGE ID            SIZE</span><br><span class=\"line\">nginx               latest              cd5239a0906a6       109MB</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">只打印镜像 ID</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl images -q</span></span><br><span class=\"line\">sha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a</span><br><span class=\"line\">sha256:e179bbfe5d238de6069f3b03fccbecc3fb4f2019af741bfff1233c4d7b2970c5</span><br><span class=\"line\">sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e</span><br><span class=\"line\">sha256:cd5239a0906a6ccf0562354852fae04bc5b52d72a2aff9a871ddb6bd57553569</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打印容器清单</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印所有容器清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl ps -a</span></span><br><span class=\"line\">CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT</span><br><span class=\"line\">1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   7 minutes ago       Running             sh                         1</span><br><span class=\"line\">9c5951df22c78       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   8 minutes ago       Exited              sh                         0</span><br><span class=\"line\">87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     8 minutes ago       Running             nginx                      0</span><br><span class=\"line\">1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   18 hours ago        Running             kube-proxy                 0</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印正在运行的容器清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl ps</span></span><br><span class=\"line\">CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT</span><br><span class=\"line\">1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   6 minutes ago       Running             sh                         1</span><br><span class=\"line\">87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     7 minutes ago       Running             nginx                      0</span><br><span class=\"line\">1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   17 hours ago        Running             kube-proxy                 0</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"UOaNL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器执行命令</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl <span class=\"built_in\">exec</span> -i -t 1f73f2d81bf98 <span class=\"built_in\">ls</span></span></span><br><span class=\"line\">bin   dev   etc   home  proc  root  sys   tmp   usr   var</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"DC2UT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器日志</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">获取容器的所有日志</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl logs 87d3992f84f74</span></span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:49 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:50 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">获取最近的 N 行日志</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl logs --<span class=\"built_in\">tail</span>=1 87d3992f84f74</span></span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"zgG3P\"><font style=\"background-color:rgba(255, 255, 255, 0);\">运行 Pod 沙盒</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 运行 Pod 沙盒对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机地被 kubelet 停止和删除。</font>\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">编写下面的 JSON 文件：</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;metadata&quot;: &#123;</span><br><span class=\"line\">        &quot;name&quot;: &quot;nginx-sandbox&quot;,</span><br><span class=\"line\">        &quot;namespace&quot;: &quot;default&quot;,</span><br><span class=\"line\">        &quot;attempt&quot;: 1,</span><br><span class=\"line\">        &quot;uid&quot;: &quot;hdishd83djaidwnduwk28bcsb&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;logDirectory&quot;: &quot;/tmp&quot;,</span><br><span class=\"line\">    &quot;linux&quot;: &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 crictl runp 命令应用 JSON 文件并运行沙盒。</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl runp pod-config.json</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">返回了沙盒的 ID。</font></p>\n<h2 id=\"rQW1l\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 创建容器对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机的被 kubelet 停止和删除。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取 busybox 镜像</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl pull busybox</span><br><span class=\"line\">Image is up to date for busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建 Pod 配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;metadata&quot;: &#123;</span><br><span class=\"line\">        &quot;name&quot;: &quot;nginx-sandbox&quot;,</span><br><span class=\"line\">        &quot;namespace&quot;: &quot;default&quot;,</span><br><span class=\"line\">        &quot;attempt&quot;: 1,</span><br><span class=\"line\">        &quot;uid&quot;: &quot;hdishd83djaidwnduwk28bcsb&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;log_directory&quot;: &quot;/tmp&quot;,</span><br><span class=\"line\">    &quot;linux&quot;: &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;metadata&quot;: &#123;</span><br><span class=\"line\">      &quot;name&quot;: &quot;busybox&quot;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;image&quot;:&#123;</span><br><span class=\"line\">      &quot;image&quot;: &quot;busybox&quot;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;command&quot;: [</span><br><span class=\"line\">      &quot;top&quot;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  &quot;log_path&quot;:&quot;busybox.log&quot;,</span><br><span class=\"line\">  &quot;linux&quot;: &#123;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器，传递先前创建的 Pod 的 ID、容器配置文件和 Pod 配置文件。返回容器的 ID。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl create f84dd361f8dc51518ed291fbadd6db537b0496536c1d2d6c05ff943ce8c9a54f container-config.json pod-config.json</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查询所有容器并确认新创建的容器状态为 Created。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CONTAINER ID        IMAGE               CREATED             STATE               NAME                ATTEMPT</span><br><span class=\"line\">3e025dd50a72d       busybox             32 seconds ago      Created             busybox             0</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"TS3x9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">要启动容器，要将容器 ID 传给 crictl start：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl start 3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60</span><br><span class=\"line\">3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">确认容器的状态为 Running。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               CREATED              STATE               NAME                ATTEMPT</span><br><span class=\"line\">3e025dd50a72d       busybox             About a minute ago   Running             busybox             0</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"jllch\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装与使用nerdctl</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font></p>\n<h2 id=\"Ehxpa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装nerdctl</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font><a href=\"https://github.com/containerd/nerdctl/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/containerd/nerdctl/releases</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载</span><br><span class=\"line\">[root@k8s-master ~]# wget https://github.com/containerd/nerdctl/releases/download/v2.0.0-rc.3/nerdctl-2.0.0-rc.3-linux-amd64.tar.gz</span><br><span class=\"line\"># 解压</span><br><span class=\"line\">[root@k8s-master ~]# tar -zxvf nerdctl-2.0.0-rc.3-linux-amd64.tar.gz</span><br><span class=\"line\">nerdctl</span><br><span class=\"line\">containerd-rootless-setuptool.sh</span><br><span class=\"line\">containerd-rootless.sh</span><br><span class=\"line\"># 复制文件</span><br><span class=\"line\">[root@k8s-master ~]# mv nerdctl /usr/bin/</span><br><span class=\"line\"># 配置 nerdctl 参数自动补齐</span><br><span class=\"line\">[root@k8s-master ~]# echo &#x27;source &lt;(nerdctl completion bash)&#x27; &gt;&gt; /etc/profile</span><br><span class=\"line\">[root@k8s-master ~]# source /etc/profile</span><br><span class=\"line\"># 验证</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -v</span><br><span class=\"line\">nerdctl version 2.0.0-rc.2</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"BXi4y\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这个和K8s的名字空间不是一回事，其中default就是containerd的默认名字空间，</font><a href=\"http://k8s.io/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://k8s.io</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">是K8s的名字空间</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看命名空间</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns ls</span><br><span class=\"line\">NAME         CONTAINERS    IMAGES    VOLUMES    LABELS</span><br><span class=\"line\">default      0             2         0              </span><br><span class=\"line\">docker.io    0             1         0              </span><br><span class=\"line\">k8s.io       18            51        0              </span><br><span class=\"line\">moby         0             0         0</span><br><span class=\"line\"># 创建命名空间</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns create test</span><br><span class=\"line\"># 删除命名空间</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns remove test</span><br><span class=\"line\">test</span><br><span class=\"line\"># 查看名称空间详情</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns inspect k8s.io</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;k8s.io&quot;,</span><br><span class=\"line\">        &quot;Labels&quot;: null</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"sU4R0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n k8s.io images</span><br><span class=\"line\">REPOSITORY                                                         TAG         IMAGE ID        CREATED         PLATFORM       SIZE         BLOB SIZE</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/coredns                    v1.8.6      5b6ec0d6de9b    5 days ago      linux/amd64    44.7 MiB     13.0 MiB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/etcd                       3.5.6-0     dd75ec974b0a    5 days ago      linux/amd64    289.0 MiB    97.8 MiB</span><br><span class=\"line\"># 拉取镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test pull nginx:alpine</span><br><span class=\"line\"># 构建镜像</span><br><span class=\"line\">[root@k8s-master ~]# cat Dockerfile </span><br><span class=\"line\">FROM     debian</span><br><span class=\"line\">RUN apt-get install -y --force-yes locales</span><br><span class=\"line\">RUN echo &quot;LC_ALL=\\&quot;zh_CN.UTF-8\\&quot;&quot; &gt;&gt; /etc/default/locale</span><br><span class=\"line\">RUN locale-gen &quot;zh_CN.UTF-8&quot;</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test build -t abc.com/debian .</span><br><span class=\"line\"># 上传镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test push abc.com/debian</span><br><span class=\"line\"># 导出镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test save -o debian.tar abc.com/debian</span><br><span class=\"line\"># 导入镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test load -i debian.tar</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"tX7Xc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n k8s.io ps </span><br><span class=\"line\">CONTAINER ID    IMAGE                                                                      COMMAND                   CREATED         STATUS    PORTS    NAMES</span><br><span class=\"line\">05be77648e0c    registry.aliyuncs.com/google_containers/kube-proxy:v1.25.0                 &quot;/usr/local/bin/kube…&quot;    13 hours ago    Up                 k8s://kube-system/kube-proxy-qd2dg/kube-proxy</span><br><span class=\"line\">240c8fdfb7dd    registry.aliyuncs.com/google_containers/pause:3.6                          &quot;/pause&quot;                  13 hours ago    Up                 k8s://kube-system/kube-apiserver-k8s-master</span><br><span class=\"line\">24728a2d2f1b    docker.io/flannel/flannel:v0.21.5                                          &quot;/opt/bin/flanneld -…&quot;    17 hours ago    Up                 k8s://kube-flannel/kube-flannel-ds-45rxr/kube-flannel</span><br><span class=\"line\"># 启动容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test run -d -p 80:80 --name web nginx:alpine</span><br><span class=\"line\"># 进入容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test exec -it web sh</span><br><span class=\"line\">/ # </span><br><span class=\"line\"># 停止容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test stop web</span><br><span class=\"line\">web</span><br><span class=\"line\"># 删除容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test rm web</span><br><span class=\"line\">web</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"JfIJj\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看网络信息</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl network ls</span><br><span class=\"line\">NETWORK ID      NAME      FILE</span><br><span class=\"line\">                cbr0      /etc/cni/net.d/10-flannel.conflist</span><br><span class=\"line\">17f29b073143    bridge    /etc/cni/net.d/nerdctl-bridge.conflist</span><br><span class=\"line\">                host      </span><br><span class=\"line\">                none</span><br><span class=\"line\"># 查看系统信息</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl system info</span><br><span class=\"line\">Client:</span><br><span class=\"line\"> Namespace:     default</span><br><span class=\"line\"> Debug Mode:    false</span><br><span class=\"line\"></span><br><span class=\"line\">Server:</span><br><span class=\"line\"> Server Version: 1.6.4</span><br><span class=\"line\"> Storage Driver: overlayfs</span><br><span class=\"line\"> Logging Driver: json-file</span><br><span class=\"line\"> Cgroup Driver: cgroupfs</span><br><span class=\"line\"> Cgroup Version: 1</span><br><span class=\"line\"> Plugins:</span><br><span class=\"line\">  Log: fluentd journald json-file syslog</span><br><span class=\"line\">  Storage: native overlayfs</span><br><span class=\"line\"> Security Options:</span><br><span class=\"line\">  seccomp</span><br><span class=\"line\">   Profile: default</span><br><span class=\"line\"> Kernel Version: 4.18.0-425.13.1.el8_7.x86_64</span><br><span class=\"line\"> Operating System: Rocky Linux 8.7 (Green Obsidian)</span><br><span class=\"line\"> OSType: linux</span><br><span class=\"line\"> Architecture: x86_64</span><br><span class=\"line\"> CPUs: 2</span><br><span class=\"line\"> Total Memory: 3.618GiB</span><br><span class=\"line\"> Name: k8s-master</span><br><span class=\"line\"> ID: d2b76909-9552-4be5-a12a-00b955f756f2</span><br><span class=\"line\"># 清理数据，它不是和Docker那样只是把标签为&quot;none&quot;的镜像清理掉，而是把所有没有&quot;正在使用&quot;的镜像清理了</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl system prune -h</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"we2x0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl替代docker-compose</font></h1>\n---\n\n<h2 id=\"zEQJn\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装bridge插件</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# mkdir -p /opt/cni/bin</span><br><span class=\"line\">[root@tiaoban ~]# cd /opt/cni/bin</span><br><span class=\"line\">[root@tiaoban ~]# wget https://github.com/containernetworking/plugins/releases/download/v1.4.1/cni-plugins-linux-amd64-v1.4.1.tgz</span><br><span class=\"line\">[root@tiaoban ~]# tar -zxvf cni-plugins-linux-amd64-v1.4.1.tgz</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"r8sMZ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">管理compose</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以Harbor为例演示，启动容器</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl compose up -d</span><br><span class=\"line\">INFO[0000] Creating network harbor_harbor               </span><br><span class=\"line\">INFO[0000] Creating network harbor_default </span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看启动的容器</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl ps</span><br><span class=\"line\">CONTAINER ID    IMAGE                                            COMMAND                   CREATED           STATUS    PORTS                                          NAMES</span><br><span class=\"line\">276a4f6a92e5    docker.io/goharbor/harbor-jobservice:v2.10.1     &quot;/harbor/entrypoint.…&quot;    32 seconds ago    Up                                                       harbor-jobservice</span><br><span class=\"line\">7c3699c62fc7    docker.io/goharbor/redis-photon:v2.10.1          &quot;redis-server /etc/r…&quot;    35 seconds ago    Up                                                       redis</span><br><span class=\"line\">810fbb8229c1    docker.io/goharbor/harbor-core:v2.10.1           &quot;/harbor/entrypoint.…&quot;    35 seconds ago    Up                                                       harbor-core</span><br><span class=\"line\">9a6237f63aeb    docker.io/goharbor/nginx-photon:v2.10.1          &quot;nginx -g daemon off;&quot;    33 seconds ago    Up        0.0.0.0:80-&gt;8080/tcp, 0.0.0.0:443-&gt;8443/tcp    nginx</span><br><span class=\"line\">a0198a493795    docker.io/goharbor/harbor-db:v2.10.1             &quot;/docker-entrypoint.…&quot;    36 seconds ago    Up                                                       harbor-db</span><br><span class=\"line\">b4c2c4a1f934    docker.io/goharbor/harbor-log:v2.10.1            &quot;/bin/sh -c /usr/loc…&quot;    37 seconds ago    Up        127.0.0.1:1514-&gt;10514/tcp                      harbor-log</span><br><span class=\"line\">d9ec21d50e55    docker.io/goharbor/harbor-portal:v2.10.1         &quot;nginx -g daemon off;&quot;    34 seconds ago    Up                                                       harbor-portal</span><br><span class=\"line\">f1e6c92a6000    docker.io/goharbor/harbor-registryctl:v2.10.1    &quot;/home/harbor/start.…&quot;    33 seconds ago    Up                                                       registryctl</span><br><span class=\"line\">f2f383e2a191    docker.io/goharbor/registry-photon:v2.10.1       &quot;/home/harbor/entryp…&quot;    36 seconds ago    Up                                                       registry</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看日志</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl compose logs</span><br><span class=\"line\">db          |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">portal      |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">redis       |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">registry    |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">nginx       |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">core        |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">jobservice  |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">registryctl |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl compose down</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"5339e56b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl+buildkitd构建镜像</font></h1>\n---\n\n<h2 id=\"4abe89d9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit介绍</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit 从Docker公司的开源的镜像构建工具包，支持OCI标准的镜像构建</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd组成部分：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd（服务端），目前支持runc和containerd作为镜像构建环境，默认是runc，可以更换containerd。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildctl（客户端），负责解析Dockerfile文件、并向服务端buildkitd发出构建请求。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并推送至Harbor为例，整个服务调用过程如下：</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802396681-1f579c7b-2837-4924-8113-97dbba5607e3.jpeg\"></p>\n<h2 id=\"c992adf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装buildkit</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">软件包下载地址：</font><a href=\"https://github.com/moby/buildkit/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/moby/buildkit/releases</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# wget https://github.com/moby/buildkit/releases/download/v0.13.2/buildkit-v0.13.2.linux-amd64.tar.gz</span><br><span class=\"line\">[root@master ~]# tar -zxvf buildkit-v0.13.2.linux-amd64.tar.gz </span><br><span class=\"line\">bin/</span><br><span class=\"line\">bin/buildctl</span><br><span class=\"line\">bin/buildkit-cni-bridge</span><br><span class=\"line\">bin/buildkit-cni-firewall</span><br><span class=\"line\">bin/buildkit-cni-host-local</span><br><span class=\"line\">bin/buildkit-cni-loopback</span><br><span class=\"line\">bin/buildkit-qemu-aarch64</span><br><span class=\"line\">bin/buildkit-qemu-arm</span><br><span class=\"line\">bin/buildkit-qemu-i386</span><br><span class=\"line\">bin/buildkit-qemu-mips64</span><br><span class=\"line\">bin/buildkit-qemu-mips64el</span><br><span class=\"line\">bin/buildkit-qemu-ppc64le</span><br><span class=\"line\">bin/buildkit-qemu-riscv64</span><br><span class=\"line\">bin/buildkit-qemu-s390x</span><br><span class=\"line\">bin/buildkit-runc</span><br><span class=\"line\">bin/buildkitd</span><br><span class=\"line\">[root@master ~]# cd bin/</span><br><span class=\"line\">[root@master bin]# cp * /usr/local/bin/</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建service脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]# cat /etc/systemd/system/buildkitd.service</span><br><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=BuildKit</span><br><span class=\"line\">Documentation=https://github.com/moby/buildkit</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">ExecStart=/usr/local/bin/buildkitd --oci-worker=false --containerd-worker=true</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">新增buildkitd配置文件，添加镜像仓库使用http访问</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]# vim /etc/buildkit/buildkitd.toml</span><br><span class=\"line\">[registry.&quot;harbor.local.com&quot;]</span><br><span class=\"line\">  http = false</span><br><span class=\"line\">  insecure = true</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动buildkitd</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]# systemctl daemon-reload</span><br><span class=\"line\">[root@master bin]# systemctl start buildkitd</span><br><span class=\"line\">[root@master bin]# systemctl enable buildkitd</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5b4ab044\"><font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并测试</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# cat Dockerfile </span><br><span class=\"line\">FROM busybox</span><br><span class=\"line\">CMD [&quot;echo&quot;,&quot;hello&quot;,&quot;container&quot;]</span><br><span class=\"line\">[root@master ~]# nerdctl build -t busybox:v1 .</span><br><span class=\"line\">[root@master ~]# nerdctl images</span><br><span class=\"line\">REPOSITORY    TAG    IMAGE ID        CREATED               PLATFORM       SIZE       BLOB SIZE</span><br><span class=\"line\">busybox       v1     fb6a2dfc7899    About a minute ago    linux/amd64    4.1 MiB    2.1 MiB</span><br><span class=\"line\">[root@master ~]# nerdctl run busybox:v1</span><br><span class=\"line\">hello container</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6d4c46c7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">推送至Harbor仓库</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# nerdctl tag busybox:v1 harbor.local.com/app/busybox:v1</span><br><span class=\"line\">[root@master ~]# nerdctl push harbor.local.com/app/busybox:v1</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">此时查看Harbor仓库发现已经推送成功</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802523651-b6549a67-9710-41ff-9ee6-4903e44ffd04.jpeg\"></p>\n","excerpt":"","more":"<h1 id=\"Wu324\"><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr命令使用</font></h1>\n---\n\n<h2 id=\"jWZEX\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看命名空间</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Containerd 中也支持命名空间的概念，比如查看命名空间：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr ns ls</span><br><span class=\"line\">NAME    LABELS </span><br><span class=\"line\">default        </span><br><span class=\"line\">k8s.io         </span><br><span class=\"line\">moby </span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建命名空间</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果不指定，ctr 默认使用的是 default 空间。同样也可以使用 ns create 命令创建一个命名空间：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr ns create test</span><br><span class=\"line\">[root@work3 ~]# ctr ns ls</span><br><span class=\"line\">NAME    LABELS </span><br><span class=\"line\">default        </span><br><span class=\"line\">k8s.io         </span><br><span class=\"line\">moby           </span><br><span class=\"line\">test</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除命名空间</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 remove 或者 rm 可以删除 namespace：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr ns rm test</span><br><span class=\"line\">test</span><br><span class=\"line\">[root@work3 ~]# ctr ns ls</span><br><span class=\"line\">NAME    LABELS </span><br><span class=\"line\">default        </span><br><span class=\"line\">k8s.io         </span><br><span class=\"line\">moby </span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">指定命名空间</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">有了命名空间后就可以在操作资源的时候指定 namespace，比如查看 test 命名空间的镜像，可以在操作命令后面加上 -n test 选项：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ ctr -n test image ls</span><br><span class=\"line\">REF TYPE DIGEST SIZE PLATFORMS LABELS</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们知道 Docker 其实也是默认调用的 containerd，事实上 Docker 使用的 containerd 下面的命名空间默认是 moby，而不是 default，所以假如我们有用 docker 启动容器，那么我们也可以通过 ctr -n moby 来定位下面的容器：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">➜  ~ ctr -n moby container ls</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">同样 Kubernetes 下使用的 containerd 默认命名空间是 k8s.io，所以我们可以使用 ctr -n k8s.io 来查看 Kubernetes 下面创建的容器。</font></p>\n<h2 id=\"vPuiL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像操作</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr image命令完成，也可以简化为ctr i命令操作</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取镜像可以使用 ctr image pull 来完成，比如拉取 Docker Hub 官方镜像 nginx:alpine，需要注意的是镜像地址需要加上 docker.io Host 地址</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image pull docker.io/library/nginx:alpine</span><br><span class=\"line\">docker.io/library/nginx:alpine:                                                   resolved       |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">index-sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">manifest-sha256:ccf066d2cfec0cfe57a63cf26f4b7cabbea80e11ab5b7f1cc11a1b5efd65ea0b: exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:9398808236ffac29e60c04ec906d8d409af7fa19dc57d8c65ad167e9c4967006:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:e6a5b569446606ea05a88fc5be4097b4982fc4bc8aeae0818385fe13b8b6066e:    done           |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">config-sha256:414132ff3b076936528928c823b4f3d1e1178b2692ae04defc8f8fdfd0a83a03:   exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:7b8bdebbb770eb9a7ceaecd729a82d21052fcdb9915873a67d5834960944fcf2:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:a2a4fe64baa08a5a04c1acd107b0026f81a72c7e35cdb3647e164f3b87871d09:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:0777b518fc6e4d42454db10fd2da40eb3f2e9086aa2529066ce6b314c2ec08cb:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:63f4060a8ef34058494aefc8ef63522d21056a40f00255d0c5d92ab51212e4c2:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:48703ecfcf806f280f159af73a1688374148f4860c52d016646a40a1a84853ec:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">layer-sha256:9cbe387ec693ef1d8ece08c1ab2d510ac31d0745c157fbf948cacac343b47c34:    exists         |++++++++++++++++++++++++++++++++++++++| </span><br><span class=\"line\">elapsed: 164.1s                                                                   total:  11.0 M (68.6 KiB/s)                                      </span><br><span class=\"line\">unpacking linux/amd64 sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c...</span><br><span class=\"line\">done: 1.656214028s</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">列出本地镜像</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">列出镜像列表</span></span><br><span class=\"line\">[root@work3 ~]# ctr image ls</span><br><span class=\"line\">REF                                         TYPE                                                      DIGEST                                                                  SIZE      PLATFORMS                                                                                                                          LABELS </span><br><span class=\"line\">docker.io/library/nginx:alpine              application/vnd.docker.distribution.manifest.list.v2+json sha256:647c5c83418c19eef0cddc647b9899326e3081576390c4c7baa4fce545123b6c 16.2 MiB  linux/386,linux/amd64,linux/arm/v6,linux/arm/v7,linux/arm64/v8,linux/ppc64le,linux/s390x                                           -      </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">只查看镜像名称标签</span></span><br><span class=\"line\">[root@work3 ~]# ctr image ls -q</span><br><span class=\"line\">docker.io/flannel/flannel-cni-plugin:v1.2.0</span><br><span class=\"line\">docker.io/flannel/flannel:v0.22.1</span><br><span class=\"line\">docker.io/library/busybox:latest</span><br><span class=\"line\">docker.io/library/nginx:alpine</span><br><span class=\"line\">ghcr.io/kube-vip/kube-vip:v0.6.0</span><br><span class=\"line\">harbor.local.com/library/busybox:latest</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重新打标签</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image tag docker.io/library/nginx:alpine harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">[root@work3 ~]# ctr image ls -q</span><br><span class=\"line\">docker.io/library/nginx:alpine</span><br><span class=\"line\">harbor.local.com/library/nginx:alpine</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除镜像</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image rm harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">harbor.local.com/library/nginx:alpine</span><br><span class=\"line\">[root@work3 ~]# ctr image ls -q</span><br><span class=\"line\">docker.io/library/nginx:alpine</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">将镜像导出为压缩包</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr image export nginx.tar docker.io/library/nginx:alpine</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从压缩包导入镜像</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work2 ~]# ctr image import nginx.tar </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"SmLyN\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器操作</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">通过ctr container命令完成，也可以简化为ctr c命令操作</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这里要解释一个概念 containers 和 task ，在docker里面 container 概念被弱化 ，将containers 和 task 整在一起 形成了docker中的 container。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 containers 是镜像实例化的一个虚拟环境，提供一个磁盘，模拟空间，就好比你电脑处于关机状态一样。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ctr中 tasks 是将容器运行起来，电脑开机了 ，初始化进程等 ，task就是的这么个形式。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">列出容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container ls</span><br><span class=\"line\">CONTAINER    IMAGE                             RUNTIME                  </span><br><span class=\"line\">nginx        docker.io/library/nginx:alpine    io.containerd.runc.v2    </span><br><span class=\"line\">[root@work3 ~]# ctr container ls -q</span><br><span class=\"line\">nginx</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看容器详情</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container info nginx</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;ID&quot;: &quot;nginx&quot;,</span><br><span class=\"line\">    &quot;Labels&quot;: &#123;</span><br><span class=\"line\">        &quot;io.containerd.image.config.stop-signal&quot;: &quot;SIGQUIT&quot;,</span><br><span class=\"line\">        &quot;maintainer&quot;: &quot;NGINX Docker Maintainers \\u003cdocker-maint@nginx.com\\u003e&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;Image&quot;: &quot;docker.io/library/nginx:alpine&quot;,</span><br><span class=\"line\">    &quot;Runtime&quot;: &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;io.containerd.runc.v2&quot;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;type_url&quot;: &quot;containerd.runc.v1.Options&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ……</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container rm nginx</span><br><span class=\"line\">[root@work3 ~]# ctr container ls</span><br><span class=\"line\">CONTAINER    IMAGE    RUNTIME </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"P5mQT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">任务操作</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">上面我们通过 container create 命令创建的容器，并没有处于运行状态，只是一个静态的容器。一个 container 对象只是包含了运行一个容器所需的资源及相关配置数据，表示 namespaces、rootfs 和容器的配置都已经初始化成功了，只是用户进程还没有启动。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">一个容器真正运行起来是由 Task 任务实现的，Task 可以为容器设置网卡，还可以配置工具来对容器进行监控等。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr container create docker.io/library/nginx:alpine nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task start -d nginx</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看正在运行的容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    RUNNING</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器信息</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task metrics 命令用来获取容器的内存、CPU 和 PID 的限额与使用量。</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task metrics nginx</span><br><span class=\"line\">ID       TIMESTAMP                                  </span><br><span class=\"line\">nginx    2023-08-13 04:42:31.648754469 +0000 UTC    </span><br><span class=\"line\"></span><br><span class=\"line\">METRIC                   VALUE                                                                                                                                                                                                                                                                                          </span><br><span class=\"line\">memory.usage_in_bytes    5226496                                                                                                                                                                                                                                                                                        </span><br><span class=\"line\">memory.limit_in_bytes    9223372036854771712                                                                                                                                                                                                                                                                            </span><br><span class=\"line\">memory.stat.cache        155648                                                                                                                                                                                                                                                                                         </span><br><span class=\"line\">cpuacct.usage            74124077                                                                                                                                                                                                                                                                                       </span><br><span class=\"line\">cpuacct.usage_percpu     [32560123 27605021 7821698 6137235 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]    </span><br><span class=\"line\">pids.current             5                                                                                                                                                                                                                                                                                              </span><br><span class=\"line\">pids.limit               0</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器PID</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 task ps 命令查看容器中所有进程在宿主机中的 PID：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task ps nginx</span><br><span class=\"line\">PID      INFO</span><br><span class=\"line\">62925    -</span><br><span class=\"line\">62954    -</span><br><span class=\"line\">62955    -</span><br><span class=\"line\">62956    -</span><br><span class=\"line\">62957    -</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    62925    RUNNING</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">其中第一个 PID 3984 就是我们容器中的 1 号进程。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">进入容器进行操作</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task exec --exec-id 0 -t nginx sh</span><br><span class=\"line\">/ # ls</span><br><span class=\"line\">bin                   docker-entrypoint.sh  lib </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">指定用户进入</span></span><br><span class=\"line\">[root@work3 ~]# ctr task exec --exec-id 0 --user 65534 -t nginx sh</span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\"><span class=\"built_in\">whoami</span></span></span><br><span class=\"line\">nobody</span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\"><span class=\"built_in\">exit</span></span></span><br><span class=\"line\">[root@work3 ~]# ctr task exec --exec-id 0 --user 0 -t nginx sh</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\"><span class=\"built_in\">whoami</span></span></span><br><span class=\"line\">root</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">不过这里需要注意必须要指定 –exec-id 参数，这个 id 可以随便写，只要唯一就行。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">暂停容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task pause nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    PAUSED</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">暂停后容器状态变成了 PAUSED</span></span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">恢复容器</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task resume nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    RUNNING</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">不过需要注意 ctr 没有 stop 容器的功能，只能暂停或者杀死容器。杀死容器可以使用 task kill 命令:</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task kill nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK     PID      STATUS    </span><br><span class=\"line\">nginx    60394    STOPPED</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除容器</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">杀掉容器后可以看到容器的状态变成了 STOPPED。同样也可以通过 task rm 命令删除 Task：</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@work3 ~]# ctr task rm nginx</span><br><span class=\"line\">[root@work3 ~]# ctr task ls</span><br><span class=\"line\">TASK    PID    STATUS</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"oZwBQ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装配置crictl</font></h1>\n---\n\n<h2 id=\"AJFk1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装crictl</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">crictl 是 CRI 兼容的容器运行时命令行接口，和containerd无关，由Kubernetes提供，可以使用它来检查和调试 k8s 节点上的容器运行时和应用程序。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：<a href=\"https://github.com/kubernetes-sigs/cri-tools/releases%EF%BC%8C%E4%BE%8B%E5%A6%82%E5%AE%89%E8%A3%851.30.6%E7%89%88%E6%9C%AC%E7%9A%84k8s%EF%BC%8C%E6%AD%A4%E5%A4%84%E5%AE%89%E8%A3%85%E7%9A%84crictl%E5%B0%B1%E6%98%AF1.30.1%E3%80%82\">https://github.com/kubernetes-sigs/cri-tools/releases，例如安装1.30.6版本的k8s，此处安装的crictl就是1.30.1。</a></font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Loading...# 下载</span><br><span class=\"line\">[root@k8s-master ~]# wget https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.30.1/crictl-v1.30.1-linux-amd64.tar.gz</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">解压</span></span><br><span class=\"line\">[root@k8s-master ~]# tar -zxvf crictl-v1.30.1-linux-amd64.tar.gz -C /usr/local/bin</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">配置</span></span><br><span class=\"line\">[root@k8s-master ~]# cat &gt; /etc/crictl.yaml &lt;&lt; EOF</span><br><span class=\"line\">runtime-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">image-endpoint: &quot;unix:///run/containerd/containerd.sock&quot;</span><br><span class=\"line\">timeout: 0</span><br><span class=\"line\">debug: false</span><br><span class=\"line\">pull-image-on-create: false</span><br><span class=\"line\">disable-pull-on-run: false</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master ~]# crictl version</span><br><span class=\"line\">Version:  0.1.0</span><br><span class=\"line\">RuntimeName:  containerd</span><br><span class=\"line\">RuntimeVersion:  1.6.4</span><br><span class=\"line\">RuntimeApiVersion:  v1</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"VUGBB\"><font style=\"background-color:rgba(255, 255, 255, 0);\">打印清单</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打印 Pod 清单</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印所有 Pod 的清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl pods</span></span><br><span class=\"line\">POD ID              CREATED              STATE               NAME                         NAMESPACE           ATTEMPT</span><br><span class=\"line\">926f1b5a1d33a       About a minute ago   Ready               sh-84d7dcf559-4r2gq          default             0</span><br><span class=\"line\">4dccb216c4adb       About a minute ago   Ready               nginx-65899c769f-wv2gp       default             0</span><br><span class=\"line\">a86316e96fa89       17 hours ago         Ready               kube-proxy-gblk4             kube-system         0</span><br><span class=\"line\">919630b8f81f1       17 hours ago         Ready               nvidia-device-plugin-zgbbv   kube-system         0</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">根据名称打印 Pod 清单：</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl pods --name nginx-65899c769f-wv2gp</span></span><br><span class=\"line\">POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT</span><br><span class=\"line\">4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">根据标签打印 Pod 清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl pods --label run=nginx</span></span><br><span class=\"line\">POD ID              CREATED             STATE               NAME                     NAMESPACE           ATTEMPT</span><br><span class=\"line\">4dccb216c4adb       2 minutes ago       Ready               nginx-65899c769f-wv2gp   default             0</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打印镜像清单</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印所有镜像清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl images</span></span><br><span class=\"line\">IMAGE                                     TAG                 IMAGE ID            SIZE</span><br><span class=\"line\">busybox                                   latest              8c811b4aec35f       1.15MB</span><br><span class=\"line\">k8s-gcrio.azureedge.net/hyperkube-amd64   v1.10.3             e179bbfe5d238       665MB</span><br><span class=\"line\">k8s-gcrio.azureedge.net/pause-amd64       3.1                 da86e6ba6ca19       742kB</span><br><span class=\"line\">nginx                                     latest              cd5239a0906a6       109MB</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">根据仓库打印镜像清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl images nginx</span></span><br><span class=\"line\">IMAGE               TAG                 IMAGE ID            SIZE</span><br><span class=\"line\">nginx               latest              cd5239a0906a6       109MB</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">只打印镜像 ID</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl images -q</span></span><br><span class=\"line\">sha256:8c811b4aec35f259572d0f79207bc0678df4c736eeec50bc9fec37ed936a472a</span><br><span class=\"line\">sha256:e179bbfe5d238de6069f3b03fccbecc3fb4f2019af741bfff1233c4d7b2970c5</span><br><span class=\"line\">sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e</span><br><span class=\"line\">sha256:cd5239a0906a6ccf0562354852fae04bc5b52d72a2aff9a871ddb6bd57553569</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打印容器清单</font></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印所有容器清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl ps -a</span></span><br><span class=\"line\">CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT</span><br><span class=\"line\">1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   7 minutes ago       Running             sh                         1</span><br><span class=\"line\">9c5951df22c78       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   8 minutes ago       Exited              sh                         0</span><br><span class=\"line\">87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     8 minutes ago       Running             nginx                      0</span><br><span class=\"line\">1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   18 hours ago        Running             kube-proxy                 0</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">打印正在运行的容器清单</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl ps</span></span><br><span class=\"line\">CONTAINER ID        IMAGE                                                                                                             CREATED             STATE               NAME                       ATTEMPT</span><br><span class=\"line\">1f73f2d81bf98       busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47                                   6 minutes ago       Running             sh                         1</span><br><span class=\"line\">87d3992f84f74       nginx@sha256:d0a8828cccb73397acb0073bf34f4d7d8aa315263f1e7806bf8c55d8ac139d5f                                     7 minutes ago       Running             nginx                      0</span><br><span class=\"line\">1941fb4da154f       k8s-gcrio.azureedge.net/hyperkube-amd64@sha256:00d814b1f7763f4ab5be80c58e98140dfc69df107f253d7fdd714b30a714260a   17 hours ago        Running             kube-proxy                 0</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"UOaNL\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器执行命令</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl <span class=\"built_in\">exec</span> -i -t 1f73f2d81bf98 <span class=\"built_in\">ls</span></span></span><br><span class=\"line\">bin   dev   etc   home  proc  root  sys   tmp   usr   var</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"DC2UT\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取容器日志</font></h2>\n---\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">获取容器的所有日志</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl logs 87d3992f84f74</span></span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:49 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:50 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br><span class=\"line\"><span class=\"meta prompt_\"></span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">获取最近的 N 行日志</span></span><br><span class=\"line\"><span class=\"meta prompt_\">$ </span><span class=\"language-bash\">crictl logs --<span class=\"built_in\">tail</span>=1 87d3992f84f74</span></span><br><span class=\"line\">10.240.0.96 - - [06/Jun/2018:02:45:51 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;curl/7.47.0&quot; &quot;-&quot;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"zgG3P\"><font style=\"background-color:rgba(255, 255, 255, 0);\">运行 Pod 沙盒</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 运行 Pod 沙盒对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机地被 kubelet 停止和删除。</font>\n\n<ol>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">编写下面的 JSON 文件：</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;metadata&quot;: &#123;</span><br><span class=\"line\">        &quot;name&quot;: &quot;nginx-sandbox&quot;,</span><br><span class=\"line\">        &quot;namespace&quot;: &quot;default&quot;,</span><br><span class=\"line\">        &quot;attempt&quot;: 1,</span><br><span class=\"line\">        &quot;uid&quot;: &quot;hdishd83djaidwnduwk28bcsb&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;logDirectory&quot;: &quot;/tmp&quot;,</span><br><span class=\"line\">    &quot;linux&quot;: &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">使用 crictl runp 命令应用 JSON 文件并运行沙盒。</font></li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl runp pod-config.json</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">返回了沙盒的 ID。</font></p>\n<h2 id=\"rQW1l\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">用 crictl 创建容器对容器运行时排错很有帮助。 在运行的 Kubernetes 集群中，沙盒会随机的被 kubelet 停止和删除。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取 busybox 镜像</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl pull busybox</span><br><span class=\"line\">Image is up to date for busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建 Pod 配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;metadata&quot;: &#123;</span><br><span class=\"line\">        &quot;name&quot;: &quot;nginx-sandbox&quot;,</span><br><span class=\"line\">        &quot;namespace&quot;: &quot;default&quot;,</span><br><span class=\"line\">        &quot;attempt&quot;: 1,</span><br><span class=\"line\">        &quot;uid&quot;: &quot;hdishd83djaidwnduwk28bcsb&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;log_directory&quot;: &quot;/tmp&quot;,</span><br><span class=\"line\">    &quot;linux&quot;: &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;metadata&quot;: &#123;</span><br><span class=\"line\">      &quot;name&quot;: &quot;busybox&quot;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;image&quot;:&#123;</span><br><span class=\"line\">      &quot;image&quot;: &quot;busybox&quot;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;command&quot;: [</span><br><span class=\"line\">      &quot;top&quot;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  &quot;log_path&quot;:&quot;busybox.log&quot;,</span><br><span class=\"line\">  &quot;linux&quot;: &#123;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建容器，传递先前创建的 Pod 的 ID、容器配置文件和 Pod 配置文件。返回容器的 ID。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl create f84dd361f8dc51518ed291fbadd6db537b0496536c1d2d6c05ff943ce8c9a54f container-config.json pod-config.json</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查询所有容器并确认新创建的容器状态为 Created。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CONTAINER ID        IMAGE               CREATED             STATE               NAME                ATTEMPT</span><br><span class=\"line\">3e025dd50a72d       busybox             32 seconds ago      Created             busybox             0</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"TS3x9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启动容器</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">要启动容器，要将容器 ID 传给 crictl start：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl start 3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60</span><br><span class=\"line\">3e025dd50a72d956c4f14881fbb5b1080c9275674e95fb67f965f6478a957d60</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">确认容器的状态为 Running。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ crictl ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               CREATED              STATE               NAME                ATTEMPT</span><br><span class=\"line\">3e025dd50a72d       busybox             About a minute ago   Running             busybox             0</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"jllch\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装与使用nerdctl</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">containerd虽然可直接提供给终端用户直接使用，也提供了命令行工具(ctr)，但并不是很友好，所以nerdctl应运而生，它也是containerd的命令行工具，支持docker cli关于容器生命周期管理的所有命令，并且支持docker compose (nerdctl compose up)</font></p>\n<h2 id=\"Ehxpa\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装nerdctl</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载地址：</font><a href=\"https://github.com/containerd/nerdctl/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/containerd/nerdctl/releases</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 下载</span><br><span class=\"line\">[root@k8s-master ~]# wget https://github.com/containerd/nerdctl/releases/download/v2.0.0-rc.3/nerdctl-2.0.0-rc.3-linux-amd64.tar.gz</span><br><span class=\"line\"># 解压</span><br><span class=\"line\">[root@k8s-master ~]# tar -zxvf nerdctl-2.0.0-rc.3-linux-amd64.tar.gz</span><br><span class=\"line\">nerdctl</span><br><span class=\"line\">containerd-rootless-setuptool.sh</span><br><span class=\"line\">containerd-rootless.sh</span><br><span class=\"line\"># 复制文件</span><br><span class=\"line\">[root@k8s-master ~]# mv nerdctl /usr/bin/</span><br><span class=\"line\"># 配置 nerdctl 参数自动补齐</span><br><span class=\"line\">[root@k8s-master ~]# echo &#x27;source &lt;(nerdctl completion bash)&#x27; &gt;&gt; /etc/profile</span><br><span class=\"line\">[root@k8s-master ~]# source /etc/profile</span><br><span class=\"line\"># 验证</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -v</span><br><span class=\"line\">nerdctl version 2.0.0-rc.2</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"BXi4y\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命名空间</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这个和K8s的名字空间不是一回事，其中default就是containerd的默认名字空间，</font><a href=\"http://k8s.io/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">http://k8s.io</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">是K8s的名字空间</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看命名空间</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns ls</span><br><span class=\"line\">NAME         CONTAINERS    IMAGES    VOLUMES    LABELS</span><br><span class=\"line\">default      0             2         0              </span><br><span class=\"line\">docker.io    0             1         0              </span><br><span class=\"line\">k8s.io       18            51        0              </span><br><span class=\"line\">moby         0             0         0</span><br><span class=\"line\"># 创建命名空间</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns create test</span><br><span class=\"line\"># 删除命名空间</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns remove test</span><br><span class=\"line\">test</span><br><span class=\"line\"># 查看名称空间详情</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl ns inspect k8s.io</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;k8s.io&quot;,</span><br><span class=\"line\">        &quot;Labels&quot;: null</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"sU4R0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">镜像</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n k8s.io images</span><br><span class=\"line\">REPOSITORY                                                         TAG         IMAGE ID        CREATED         PLATFORM       SIZE         BLOB SIZE</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/coredns                    v1.8.6      5b6ec0d6de9b    5 days ago      linux/amd64    44.7 MiB     13.0 MiB</span><br><span class=\"line\">registry.aliyuncs.com/google_containers/etcd                       3.5.6-0     dd75ec974b0a    5 days ago      linux/amd64    289.0 MiB    97.8 MiB</span><br><span class=\"line\"># 拉取镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test pull nginx:alpine</span><br><span class=\"line\"># 构建镜像</span><br><span class=\"line\">[root@k8s-master ~]# cat Dockerfile </span><br><span class=\"line\">FROM     debian</span><br><span class=\"line\">RUN apt-get install -y --force-yes locales</span><br><span class=\"line\">RUN echo &quot;LC_ALL=\\&quot;zh_CN.UTF-8\\&quot;&quot; &gt;&gt; /etc/default/locale</span><br><span class=\"line\">RUN locale-gen &quot;zh_CN.UTF-8&quot;</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test build -t abc.com/debian .</span><br><span class=\"line\"># 上传镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test push abc.com/debian</span><br><span class=\"line\"># 导出镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test save -o debian.tar abc.com/debian</span><br><span class=\"line\"># 导入镜像</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test load -i debian.tar</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"tX7Xc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">容器</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n k8s.io ps </span><br><span class=\"line\">CONTAINER ID    IMAGE                                                                      COMMAND                   CREATED         STATUS    PORTS    NAMES</span><br><span class=\"line\">05be77648e0c    registry.aliyuncs.com/google_containers/kube-proxy:v1.25.0                 &quot;/usr/local/bin/kube…&quot;    13 hours ago    Up                 k8s://kube-system/kube-proxy-qd2dg/kube-proxy</span><br><span class=\"line\">240c8fdfb7dd    registry.aliyuncs.com/google_containers/pause:3.6                          &quot;/pause&quot;                  13 hours ago    Up                 k8s://kube-system/kube-apiserver-k8s-master</span><br><span class=\"line\">24728a2d2f1b    docker.io/flannel/flannel:v0.21.5                                          &quot;/opt/bin/flanneld -…&quot;    17 hours ago    Up                 k8s://kube-flannel/kube-flannel-ds-45rxr/kube-flannel</span><br><span class=\"line\"># 启动容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test run -d -p 80:80 --name web nginx:alpine</span><br><span class=\"line\"># 进入容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test exec -it web sh</span><br><span class=\"line\">/ # </span><br><span class=\"line\"># 停止容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test stop web</span><br><span class=\"line\">web</span><br><span class=\"line\"># 删除容器</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl -n test rm web</span><br><span class=\"line\">web</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"JfIJj\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看网络信息</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl network ls</span><br><span class=\"line\">NETWORK ID      NAME      FILE</span><br><span class=\"line\">                cbr0      /etc/cni/net.d/10-flannel.conflist</span><br><span class=\"line\">17f29b073143    bridge    /etc/cni/net.d/nerdctl-bridge.conflist</span><br><span class=\"line\">                host      </span><br><span class=\"line\">                none</span><br><span class=\"line\"># 查看系统信息</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl system info</span><br><span class=\"line\">Client:</span><br><span class=\"line\"> Namespace:     default</span><br><span class=\"line\"> Debug Mode:    false</span><br><span class=\"line\"></span><br><span class=\"line\">Server:</span><br><span class=\"line\"> Server Version: 1.6.4</span><br><span class=\"line\"> Storage Driver: overlayfs</span><br><span class=\"line\"> Logging Driver: json-file</span><br><span class=\"line\"> Cgroup Driver: cgroupfs</span><br><span class=\"line\"> Cgroup Version: 1</span><br><span class=\"line\"> Plugins:</span><br><span class=\"line\">  Log: fluentd journald json-file syslog</span><br><span class=\"line\">  Storage: native overlayfs</span><br><span class=\"line\"> Security Options:</span><br><span class=\"line\">  seccomp</span><br><span class=\"line\">   Profile: default</span><br><span class=\"line\"> Kernel Version: 4.18.0-425.13.1.el8_7.x86_64</span><br><span class=\"line\"> Operating System: Rocky Linux 8.7 (Green Obsidian)</span><br><span class=\"line\"> OSType: linux</span><br><span class=\"line\"> Architecture: x86_64</span><br><span class=\"line\"> CPUs: 2</span><br><span class=\"line\"> Total Memory: 3.618GiB</span><br><span class=\"line\"> Name: k8s-master</span><br><span class=\"line\"> ID: d2b76909-9552-4be5-a12a-00b955f756f2</span><br><span class=\"line\"># 清理数据，它不是和Docker那样只是把标签为&quot;none&quot;的镜像清理掉，而是把所有没有&quot;正在使用&quot;的镜像清理了</span><br><span class=\"line\">[root@k8s-master ~]# nerdctl system prune -h</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"we2x0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl替代docker-compose</font></h1>\n---\n\n<h2 id=\"zEQJn\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装bridge插件</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# mkdir -p /opt/cni/bin</span><br><span class=\"line\">[root@tiaoban ~]# cd /opt/cni/bin</span><br><span class=\"line\">[root@tiaoban ~]# wget https://github.com/containernetworking/plugins/releases/download/v1.4.1/cni-plugins-linux-amd64-v1.4.1.tgz</span><br><span class=\"line\">[root@tiaoban ~]# tar -zxvf cni-plugins-linux-amd64-v1.4.1.tgz</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"r8sMZ\"><font style=\"background-color:rgba(255, 255, 255, 0);\">管理compose</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以Harbor为例演示，启动容器</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl compose up -d</span><br><span class=\"line\">INFO[0000] Creating network harbor_harbor               </span><br><span class=\"line\">INFO[0000] Creating network harbor_default </span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看启动的容器</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl ps</span><br><span class=\"line\">CONTAINER ID    IMAGE                                            COMMAND                   CREATED           STATUS    PORTS                                          NAMES</span><br><span class=\"line\">276a4f6a92e5    docker.io/goharbor/harbor-jobservice:v2.10.1     &quot;/harbor/entrypoint.…&quot;    32 seconds ago    Up                                                       harbor-jobservice</span><br><span class=\"line\">7c3699c62fc7    docker.io/goharbor/redis-photon:v2.10.1          &quot;redis-server /etc/r…&quot;    35 seconds ago    Up                                                       redis</span><br><span class=\"line\">810fbb8229c1    docker.io/goharbor/harbor-core:v2.10.1           &quot;/harbor/entrypoint.…&quot;    35 seconds ago    Up                                                       harbor-core</span><br><span class=\"line\">9a6237f63aeb    docker.io/goharbor/nginx-photon:v2.10.1          &quot;nginx -g daemon off;&quot;    33 seconds ago    Up        0.0.0.0:80-&gt;8080/tcp, 0.0.0.0:443-&gt;8443/tcp    nginx</span><br><span class=\"line\">a0198a493795    docker.io/goharbor/harbor-db:v2.10.1             &quot;/docker-entrypoint.…&quot;    36 seconds ago    Up                                                       harbor-db</span><br><span class=\"line\">b4c2c4a1f934    docker.io/goharbor/harbor-log:v2.10.1            &quot;/bin/sh -c /usr/loc…&quot;    37 seconds ago    Up        127.0.0.1:1514-&gt;10514/tcp                      harbor-log</span><br><span class=\"line\">d9ec21d50e55    docker.io/goharbor/harbor-portal:v2.10.1         &quot;nginx -g daemon off;&quot;    34 seconds ago    Up                                                       harbor-portal</span><br><span class=\"line\">f1e6c92a6000    docker.io/goharbor/harbor-registryctl:v2.10.1    &quot;/home/harbor/start.…&quot;    33 seconds ago    Up                                                       registryctl</span><br><span class=\"line\">f2f383e2a191    docker.io/goharbor/registry-photon:v2.10.1       &quot;/home/harbor/entryp…&quot;    36 seconds ago    Up                                                       registry</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看日志</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl compose logs</span><br><span class=\"line\">db          |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">portal      |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">redis       |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">registry    |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">nginx       |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">core        |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">jobservice  |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br><span class=\"line\">registryctl |time=&quot;2024-04-26T20:39:54+08:00&quot; level=fatal msg=&quot;no log viewer type registered for logging driver \\&quot;syslog\\&quot;&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">停止容器</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban harbor]# nerdctl compose down</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"5339e56b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">nerdctl+buildkitd构建镜像</font></h1>\n---\n\n<h2 id=\"4abe89d9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit介绍</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkit 从Docker公司的开源的镜像构建工具包，支持OCI标准的镜像构建</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd组成部分：</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildkitd（服务端），目前支持runc和containerd作为镜像构建环境，默认是runc，可以更换containerd。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">buildctl（客户端），负责解析Dockerfile文件、并向服务端buildkitd发出构建请求。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并推送至Harbor为例，整个服务调用过程如下：</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802396681-1f579c7b-2837-4924-8113-97dbba5607e3.jpeg\"></p>\n<h2 id=\"c992adf1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装buildkit</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">软件包下载地址：</font><a href=\"https://github.com/moby/buildkit/releases\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/moby/buildkit/releases</font></a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# wget https://github.com/moby/buildkit/releases/download/v0.13.2/buildkit-v0.13.2.linux-amd64.tar.gz</span><br><span class=\"line\">[root@master ~]# tar -zxvf buildkit-v0.13.2.linux-amd64.tar.gz </span><br><span class=\"line\">bin/</span><br><span class=\"line\">bin/buildctl</span><br><span class=\"line\">bin/buildkit-cni-bridge</span><br><span class=\"line\">bin/buildkit-cni-firewall</span><br><span class=\"line\">bin/buildkit-cni-host-local</span><br><span class=\"line\">bin/buildkit-cni-loopback</span><br><span class=\"line\">bin/buildkit-qemu-aarch64</span><br><span class=\"line\">bin/buildkit-qemu-arm</span><br><span class=\"line\">bin/buildkit-qemu-i386</span><br><span class=\"line\">bin/buildkit-qemu-mips64</span><br><span class=\"line\">bin/buildkit-qemu-mips64el</span><br><span class=\"line\">bin/buildkit-qemu-ppc64le</span><br><span class=\"line\">bin/buildkit-qemu-riscv64</span><br><span class=\"line\">bin/buildkit-qemu-s390x</span><br><span class=\"line\">bin/buildkit-runc</span><br><span class=\"line\">bin/buildkitd</span><br><span class=\"line\">[root@master ~]# cd bin/</span><br><span class=\"line\">[root@master bin]# cp * /usr/local/bin/</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建service脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]# cat /etc/systemd/system/buildkitd.service</span><br><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=BuildKit</span><br><span class=\"line\">Documentation=https://github.com/moby/buildkit</span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">ExecStart=/usr/local/bin/buildkitd --oci-worker=false --containerd-worker=true</span><br><span class=\"line\"></span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">新增buildkitd配置文件，添加镜像仓库使用http访问</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]# vim /etc/buildkit/buildkitd.toml</span><br><span class=\"line\">[registry.&quot;harbor.local.com&quot;]</span><br><span class=\"line\">  http = false</span><br><span class=\"line\">  insecure = true</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动buildkitd</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]# systemctl daemon-reload</span><br><span class=\"line\">[root@master bin]# systemctl start buildkitd</span><br><span class=\"line\">[root@master bin]# systemctl enable buildkitd</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5b4ab044\"><font style=\"background-color:rgba(255, 255, 255, 0);\">构建镜像并测试</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# cat Dockerfile </span><br><span class=\"line\">FROM busybox</span><br><span class=\"line\">CMD [&quot;echo&quot;,&quot;hello&quot;,&quot;container&quot;]</span><br><span class=\"line\">[root@master ~]# nerdctl build -t busybox:v1 .</span><br><span class=\"line\">[root@master ~]# nerdctl images</span><br><span class=\"line\">REPOSITORY    TAG    IMAGE ID        CREATED               PLATFORM       SIZE       BLOB SIZE</span><br><span class=\"line\">busybox       v1     fb6a2dfc7899    About a minute ago    linux/amd64    4.1 MiB    2.1 MiB</span><br><span class=\"line\">[root@master ~]# nerdctl run busybox:v1</span><br><span class=\"line\">hello container</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6d4c46c7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">推送至Harbor仓库</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# nerdctl tag busybox:v1 harbor.local.com/app/busybox:v1</span><br><span class=\"line\">[root@master ~]# nerdctl push harbor.local.com/app/busybox:v1</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">此时查看Harbor仓库发现已经推送成功</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737802523651-b6549a67-9710-41ff-9ee6-4903e44ffd04.jpeg\"></p>\n"},{"title":"安装Kubernets集群","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"eb5fd3ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之前)</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master节点执行\t</font>\n>\n\n<h2 id=\"lEFpw\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件创建集群</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># kubeadm config print init-defaults > kubeadm-conf.yaml</font>`\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">配置kubeadm-conf.yaml初始化文件</font>\n\n```plain\napiVersion: kubeadm.k8s.io/v1beta2\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.10.10 # master节点ip地址，如果 Master 有多个interface，建议明确指定，\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /var/run/dockershim.sock\n  name: k8s-master # master节点主机名\n  taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io/master\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta2\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns:\n  type: CoreDNS\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: k8s.gcr.io\nkind: ClusterConfiguration\nkubernetesVersion: v1.19.16 # k8s安装版本\nimageRepository: \"registry.aliyuncs.com/google_containers\" # 将其指定为阿里云镜像地址\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: \"10.244.0.0/16\" #Kubernetes 支持多种网络方案，而且不同网络方案对--pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nfeatureGates:\n  SupportIPVSProxyMode: true\nmode: ipvs\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">指定配置文件创建k8s集群</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm init --config=kubeadm-conf.yaml</font>`\n\n<h2 id=\"f21393df\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建k8s集群</font></h2>\n---\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@master ~]# kubeadm init --apiserver-advertise-address=192.168.10.100 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.15 --pod-network-cidr=10.244.0.0/16</font>`\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–apiserver-advertise-address  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的interface。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–pod-network-cidr  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对–pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–image-repository  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问gcr.io，在1.13版本中我们可以增加–image-repository参数，默认值是k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–kubernetes-version=v1.19.15  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭版本探测，因为它的默认值是stable-1，会导致从</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://dl.k8s.io/release/stable-1.txt</font>](https://dl.k8s.io/release/stable-1.txt)<font style=\"background-color:rgba(255, 255, 255, 0);\">下载最新的版本号</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">执行完毕后控制台打印以下信息：</font>\n\n```plain\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\nhttps://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef \\\n--discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 \n```\n\n<h2 id=\"7a2aabc6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示初始化kubectl</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# mkdir -p $HOME/.kube\n[root@k8s-master k8s-install]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n[root@k8s-master k8s-install]# chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n<h2 id=\"c58c9c6b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用 kubectl 命令自动补全功能</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# yum -y install bash-completion\n[root@k8s-master k8s-install]# echo \"source <(kubectl completion bash)\" >> ~/.bash_profile \n[root@k8s-master k8s-install]# source ~/.bash_profile \n```\n\n<h2 id=\"f722bf53\"><font style=\"background-color:rgba(255, 255, 255, 0);\">测试kubectl</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# kubectl get node\nNAME         STATUS     ROLES                  AGE   VERSION\nk8s-master   NotReady   control-plane,master   46s   v1.19.16\n```\n\n<h1 id=\"26b442b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之后)</font></h1>\n---\n\n<h2 id=\"5adf0bd8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">变化说明</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从1.20开始，开启ipvs配置字段发生了变化，访问官方查看最新版本ipvs开启的正确配置,通过</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md</font>](https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md)<font style=\"background-color:rgba(255, 255, 255, 0);\">可以看到官方说明</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从1.22开始，推荐使用containerd作为容器运行时。</font>\n\n<h2 id=\"a2e6d0cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">init配置文件</font></h2>\n---\n\n```plain\n# cat kubeadm-conf.yaml \napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.10.10  #修改为控制节点IP（VIP）\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///run/containerd/containerd.sock  #使用containerd为容器运行时\n\t# criSocket: /var/run/dockershim.sock  #使用docker为容器运行时\n  imagePullPolicy: IfNotPresent\n  name: k8s-master     #修改为控制节点主机名\n  taints: null\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers  #修改为阿里镜像地址\nkind: ClusterConfiguration\nkubernetesVersion: 1.24.13  #版本\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16   #指定Pod网段\n  serviceSubnet: 10.96.0.0/12  #指定Service网段\nscheduler: {}\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind:  KubeProxyConfiguration\nmode: ipvs\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\ncgroupDriver: systemd\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果初始化时出现以下报错，先停止master节点的kubelet</font>\n\n```plain\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n        [ERROR Port-10250]: Port 10250 is in use\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@k8s-master k8s-install]# systemctl stop kubelet</font>\n\n<h1 id=\"86e19ab6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化失败解决</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果因为配置文件异常导致集群初始化失败，可执行如下命令</font>\n\n```plain\n# kubeadm reset \n# rm -rf $HOME/.kube/config\n```\n\n<h1 id=\"a5188f63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用基于flannel的Pod网络</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/flannel-io/flannel</font>](https://github.com/flannel-io/flannel)\n\n<h2 id=\"1616c281\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载配置文件</font></h2>\n---\n\n```plain\n[root@master ~]# wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml \n```\n\n<h2 id=\"c3f7e4cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用flannel</font></h2>\n---\n\n```plain\n[root@master ~]# kubectl apply -f kube-flannel.yml  \n# 如果机器有多块物理网卡，需要指定网卡名称\ncontainers:\n- name: kube-flannel\n    - args:\n    - --ip-masq\n    - --kube-subnet-mgr\n    - --iface=bond0 # 添加这行\n```\n\n<h2 id=\"5655008a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证操作</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# kubectl get pods -A\nNAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE\nkube-flannel   kube-flannel-ds-5tjkb                1/1     Running   0          9m1s\nkube-system    coredns-6d56c8448f-vnrqf             1/1     Running   0          19m\nkube-system    coredns-6d56c8448f-x9q75             1/1     Running   0          19m\nkube-system    etcd-k8s-master                      1/1     Running   0          20m\nkube-system    kube-apiserver-k8s-master            1/1     Running   0          20m\nkube-system    kube-controller-manager-k8s-master   1/1     Running   0          20m\nkube-system    kube-proxy-9df97                     1/1     Running   0          19m\nkube-system    kube-scheduler-k8s-master            1/1     Running   0          20m\n```\n\n<h1 id=\"598a8888\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他node节点加入集群</font></h1>\n---\n\n<h2 id=\"b7eec277\"><font style=\"background-color:rgba(255, 255, 255, 0);\">将节点加入到集群</font></h2>\n---\n\n```plain\n[root@k8s-work1 ~]# kubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 \n```\n\n<h2 id=\"e1dc7e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群信息</font></h2>\n---\n\n```plain\n[root@k8s-master ~]# kubectl get node\nNAME         STATUS   ROLES                  AGE     VERSION\nk8s-master   Ready    control-plane,master   5m26s   v1.24.13\nk8s-work1    Ready    <none>                 3m39s   v1.24.13\nk8s-work2    Ready    <none>                 3m48s   v1.24.13\n[root@k8s-master ~]# kubectl get pod -A\nNAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE\nkube-flannel   kube-flannel-ds-22hrr                1/1     Running   2          17m\nkube-flannel   kube-flannel-ds-5tjkb                1/1     Running   2          36m\nkube-flannel   kube-flannel-ds-kmtnk                1/1     Running   0          84s\nkube-system    coredns-6d56c8448f-vnrqf             1/1     Running   3          47m\nkube-system    coredns-6d56c8448f-x9q75             1/1     Running   2          47m\nkube-system    etcd-k8s-master                      1/1     Running   2          47m\nkube-system    kube-apiserver-k8s-master            1/1     Running   2          47m\nkube-system    kube-controller-manager-k8s-master   1/1     Running   2          47m\nkube-system    kube-proxy-6wmsl                     1/1     Running   2          17m\nkube-system    kube-proxy-9df97                     1/1     Running   2          47m\nkube-system    kube-proxy-fkkm6                     1/1     Running   0          84s\nkube-system    kube-scheduler-k8s-master            1/1     Running   2          47m\n```\n\n","source":"_posts/5.安装Kubernets集群.md","raw":"---\ntitle: 安装Kubernets集群\ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"eb5fd3ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之前)</font></h1>\n---\n\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master节点执行\t</font>\n>\n\n<h2 id=\"lEFpw\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件创建集群</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\"># kubeadm config print init-defaults > kubeadm-conf.yaml</font>`\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">配置kubeadm-conf.yaml初始化文件</font>\n\n```plain\napiVersion: kubeadm.k8s.io/v1beta2\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.10.10 # master节点ip地址，如果 Master 有多个interface，建议明确指定，\n  bindPort: 6443\nnodeRegistration:\n  criSocket: /var/run/dockershim.sock\n  name: k8s-master # master节点主机名\n  taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io/master\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta2\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns:\n  type: CoreDNS\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: k8s.gcr.io\nkind: ClusterConfiguration\nkubernetesVersion: v1.19.16 # k8s安装版本\nimageRepository: \"registry.aliyuncs.com/google_containers\" # 将其指定为阿里云镜像地址\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: \"10.244.0.0/16\" #Kubernetes 支持多种网络方案，而且不同网络方案对--pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。\n  serviceSubnet: 10.96.0.0/12\nscheduler: {}\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nfeatureGates:\n  SupportIPVSProxyMode: true\nmode: ipvs\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">指定配置文件创建k8s集群</font>\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm init --config=kubeadm-conf.yaml</font>`\n\n<h2 id=\"f21393df\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建k8s集群</font></h2>\n---\n\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@master ~]# kubeadm init --apiserver-advertise-address=192.168.10.100 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.15 --pod-network-cidr=10.244.0.0/16</font>`\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–apiserver-advertise-address  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的interface。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–pod-network-cidr  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对–pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–image-repository  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问gcr.io，在1.13版本中我们可以增加–image-repository参数，默认值是k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com/google_containers。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">–kubernetes-version=v1.19.15  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭版本探测，因为它的默认值是stable-1，会导致从</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://dl.k8s.io/release/stable-1.txt</font>](https://dl.k8s.io/release/stable-1.txt)<font style=\"background-color:rgba(255, 255, 255, 0);\">下载最新的版本号</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">执行完毕后控制台打印以下信息：</font>\n\n```plain\nYour Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\nhttps://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef \\\n--discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 \n```\n\n<h2 id=\"7a2aabc6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示初始化kubectl</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# mkdir -p $HOME/.kube\n[root@k8s-master k8s-install]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n[root@k8s-master k8s-install]# chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n<h2 id=\"c58c9c6b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用 kubectl 命令自动补全功能</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# yum -y install bash-completion\n[root@k8s-master k8s-install]# echo \"source <(kubectl completion bash)\" >> ~/.bash_profile \n[root@k8s-master k8s-install]# source ~/.bash_profile \n```\n\n<h2 id=\"f722bf53\"><font style=\"background-color:rgba(255, 255, 255, 0);\">测试kubectl</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# kubectl get node\nNAME         STATUS     ROLES                  AGE   VERSION\nk8s-master   NotReady   control-plane,master   46s   v1.19.16\n```\n\n<h1 id=\"26b442b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之后)</font></h1>\n---\n\n<h2 id=\"5adf0bd8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">变化说明</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从1.20开始，开启ipvs配置字段发生了变化，访问官方查看最新版本ipvs开启的正确配置,通过</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md</font>](https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md)<font style=\"background-color:rgba(255, 255, 255, 0);\">可以看到官方说明</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">从1.22开始，推荐使用containerd作为容器运行时。</font>\n\n<h2 id=\"a2e6d0cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">init配置文件</font></h2>\n---\n\n```plain\n# cat kubeadm-conf.yaml \napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: abcdef.0123456789abcdef\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.10.10  #修改为控制节点IP（VIP）\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///run/containerd/containerd.sock  #使用containerd为容器运行时\n\t# criSocket: /var/run/dockershim.sock  #使用docker为容器运行时\n  imagePullPolicy: IfNotPresent\n  name: k8s-master     #修改为控制节点主机名\n  taints: null\n---\napiServer:\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrollerManager: {}\ndns: {}\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.aliyuncs.com/google_containers  #修改为阿里镜像地址\nkind: ClusterConfiguration\nkubernetesVersion: 1.24.13  #版本\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 10.244.0.0/16   #指定Pod网段\n  serviceSubnet: 10.96.0.0/12  #指定Service网段\nscheduler: {}\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind:  KubeProxyConfiguration\nmode: ipvs\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\ncgroupDriver: systemd\n```\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">如果初始化时出现以下报错，先停止master节点的kubelet</font>\n\n```plain\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n        [ERROR Port-10250]: Port 10250 is in use\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">[root@k8s-master k8s-install]# systemctl stop kubelet</font>\n\n<h1 id=\"86e19ab6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化失败解决</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果因为配置文件异常导致集群初始化失败，可执行如下命令</font>\n\n```plain\n# kubeadm reset \n# rm -rf $HOME/.kube/config\n```\n\n<h1 id=\"a5188f63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用基于flannel的Pod网络</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/flannel-io/flannel</font>](https://github.com/flannel-io/flannel)\n\n<h2 id=\"1616c281\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载配置文件</font></h2>\n---\n\n```plain\n[root@master ~]# wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml \n```\n\n<h2 id=\"c3f7e4cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用flannel</font></h2>\n---\n\n```plain\n[root@master ~]# kubectl apply -f kube-flannel.yml  \n# 如果机器有多块物理网卡，需要指定网卡名称\ncontainers:\n- name: kube-flannel\n    - args:\n    - --ip-masq\n    - --kube-subnet-mgr\n    - --iface=bond0 # 添加这行\n```\n\n<h2 id=\"5655008a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证操作</font></h2>\n---\n\n```plain\n[root@k8s-master k8s-install]# kubectl get pods -A\nNAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE\nkube-flannel   kube-flannel-ds-5tjkb                1/1     Running   0          9m1s\nkube-system    coredns-6d56c8448f-vnrqf             1/1     Running   0          19m\nkube-system    coredns-6d56c8448f-x9q75             1/1     Running   0          19m\nkube-system    etcd-k8s-master                      1/1     Running   0          20m\nkube-system    kube-apiserver-k8s-master            1/1     Running   0          20m\nkube-system    kube-controller-manager-k8s-master   1/1     Running   0          20m\nkube-system    kube-proxy-9df97                     1/1     Running   0          19m\nkube-system    kube-scheduler-k8s-master            1/1     Running   0          20m\n```\n\n<h1 id=\"598a8888\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他node节点加入集群</font></h1>\n---\n\n<h2 id=\"b7eec277\"><font style=\"background-color:rgba(255, 255, 255, 0);\">将节点加入到集群</font></h2>\n---\n\n```plain\n[root@k8s-work1 ~]# kubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 \n```\n\n<h2 id=\"e1dc7e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群信息</font></h2>\n---\n\n```plain\n[root@k8s-master ~]# kubectl get node\nNAME         STATUS   ROLES                  AGE     VERSION\nk8s-master   Ready    control-plane,master   5m26s   v1.24.13\nk8s-work1    Ready    <none>                 3m39s   v1.24.13\nk8s-work2    Ready    <none>                 3m48s   v1.24.13\n[root@k8s-master ~]# kubectl get pod -A\nNAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE\nkube-flannel   kube-flannel-ds-22hrr                1/1     Running   2          17m\nkube-flannel   kube-flannel-ds-5tjkb                1/1     Running   2          36m\nkube-flannel   kube-flannel-ds-kmtnk                1/1     Running   0          84s\nkube-system    coredns-6d56c8448f-vnrqf             1/1     Running   3          47m\nkube-system    coredns-6d56c8448f-x9q75             1/1     Running   2          47m\nkube-system    etcd-k8s-master                      1/1     Running   2          47m\nkube-system    kube-apiserver-k8s-master            1/1     Running   2          47m\nkube-system    kube-controller-manager-k8s-master   1/1     Running   2          47m\nkube-system    kube-proxy-6wmsl                     1/1     Running   2          17m\nkube-system    kube-proxy-9df97                     1/1     Running   2          47m\nkube-system    kube-proxy-fkkm6                     1/1     Running   0          84s\nkube-system    kube-scheduler-k8s-master            1/1     Running   2          47m\n```\n\n","slug":"5.安装Kubernets集群","published":1,"updated":"2025-03-30T13:11:56.526Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlq000ntsv1422s23d8","content":"<h1 id=\"eb5fd3ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之前)</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master节点执行\t</font></p>\n</blockquote>\n<h2 id=\"lEFpw\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件创建集群</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font>\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# kubeadm config print init-defaults &gt; kubeadm-conf.yaml&lt;/font&gt;</code></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">配置kubeadm-conf.yaml初始化文件</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 192.168.10.10 # master节点ip地址，如果 Master 有多个interface，建议明确指定，</span><br><span class=\"line\">  bindPort: 6443</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: /var/run/dockershim.sock</span><br><span class=\"line\">  name: k8s-master # master节点主机名</span><br><span class=\"line\">  taints:</span><br><span class=\"line\">  - effect: NoSchedule</span><br><span class=\"line\">    key: node-role.kubernetes.io/master</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns:</span><br><span class=\"line\">  type: CoreDNS</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: k8s.gcr.io</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: v1.19.16 # k8s安装版本</span><br><span class=\"line\">imageRepository: &quot;registry.aliyuncs.com/google_containers&quot; # 将其指定为阿里云镜像地址</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  podSubnet: &quot;10.244.0.0/16&quot; #Kubernetes 支持多种网络方案，而且不同网络方案对--pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class=\"line\">kind: KubeProxyConfiguration</span><br><span class=\"line\">featureGates:</span><br><span class=\"line\">  SupportIPVSProxyMode: true</span><br><span class=\"line\">mode: ipvs</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">指定配置文件创建k8s集群</font></li>\n</ul>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubeadm init --config=kubeadm-conf.yaml&lt;/font&gt;</code></p>\n<h2 id=\"f21393df\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建k8s集群</font></h2>\n---\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;[root@master ~]# kubeadm init --apiserver-advertise-address=192.168.10.100 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.15 --pod-network-cidr=10.244.0.0/16&lt;/font&gt;</code></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–apiserver-advertise-address<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的interface。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–pod-network-cidr<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对–pod-network-cidr 有自己的要求，这里设置为 10.244.0.0&#x2F;16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–image-repository<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问gcr.io，在1.13版本中我们可以增加–image-repository参数，默认值是k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com&#x2F;google_containers。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–kubernetes-version&#x3D;v1.19.15<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭版本探测，因为它的默认值是stable-1，会导致从</font><a href=\"https://dl.k8s.io/release/stable-1.txt\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://dl.k8s.io/release/stable-1.txt</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">下载最新的版本号</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">执行完毕后控制台打印以下信息：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Your Kubernetes control-plane has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">mkdir -p $HOME/.kube</span><br><span class=\"line\">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">kubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">--discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7a2aabc6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示初始化kubectl</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# mkdir -p $HOME/.kube</span><br><span class=\"line\">[root@k8s-master k8s-install]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">[root@k8s-master k8s-install]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c58c9c6b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用 kubectl 命令自动补全功能</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# yum -y install bash-completion</span><br><span class=\"line\">[root@k8s-master k8s-install]# echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profile </span><br><span class=\"line\">[root@k8s-master k8s-install]# source ~/.bash_profile </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f722bf53\"><font style=\"background-color:rgba(255, 255, 255, 0);\">测试kubectl</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# kubectl get node</span><br><span class=\"line\">NAME         STATUS     ROLES                  AGE   VERSION</span><br><span class=\"line\">k8s-master   NotReady   control-plane,master   46s   v1.19.16</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"26b442b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之后)</font></h1>\n---\n\n<h2 id=\"5adf0bd8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">变化说明</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从1.20开始，开启ipvs配置字段发生了变化，访问官方查看最新版本ipvs开启的正确配置,通过</font><a href=\"https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">可以看到官方说明</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从1.22开始，推荐使用containerd作为容器运行时。</font></p>\n<h2 id=\"a2e6d0cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">init配置文件</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cat kubeadm-conf.yaml </span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 192.168.10.10  #修改为控制节点IP（VIP）</span><br><span class=\"line\">  bindPort: 6443</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: unix:///run/containerd/containerd.sock  #使用containerd为容器运行时</span><br><span class=\"line\">\t# criSocket: /var/run/dockershim.sock  #使用docker为容器运行时</span><br><span class=\"line\">  imagePullPolicy: IfNotPresent</span><br><span class=\"line\">  name: k8s-master     #修改为控制节点主机名</span><br><span class=\"line\">  taints: null</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns: &#123;&#125;</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers  #修改为阿里镜像地址</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: 1.24.13  #版本</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  podSubnet: 10.244.0.0/16   #指定Pod网段</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12  #指定Service网段</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class=\"line\">kind:  KubeProxyConfiguration</span><br><span class=\"line\">mode: ipvs</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class=\"line\">kind: KubeletConfiguration</span><br><span class=\"line\">cgroupDriver: systemd</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果初始化时出现以下报错，先停止master节点的kubelet</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class=\"line\">        [ERROR Port-10250]: Port 10250 is in use</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">[root@k8s-master k8s-install]# systemctl stop kubelet</font></p>\n<h1 id=\"86e19ab6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化失败解决</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果因为配置文件异常导致集群初始化失败，可执行如下命令</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubeadm reset </span><br><span class=\"line\"># rm -rf $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"a5188f63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用基于flannel的Pod网络</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font><a href=\"https://github.com/flannel-io/flannel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/flannel-io/flannel</font></a></p>\n<h2 id=\"1616c281\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载配置文件</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c3f7e4cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用flannel</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# kubectl apply -f kube-flannel.yml  </span><br><span class=\"line\"># 如果机器有多块物理网卡，需要指定网卡名称</span><br><span class=\"line\">containers:</span><br><span class=\"line\">- name: kube-flannel</span><br><span class=\"line\">    - args:</span><br><span class=\"line\">    - --ip-masq</span><br><span class=\"line\">    - --kube-subnet-mgr</span><br><span class=\"line\">    - --iface=bond0 # 添加这行</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5655008a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# kubectl get pods -A</span><br><span class=\"line\">NAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-5tjkb                1/1     Running   0          9m1s</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-vnrqf             1/1     Running   0          19m</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-x9q75             1/1     Running   0          19m</span><br><span class=\"line\">kube-system    etcd-k8s-master                      1/1     Running   0          20m</span><br><span class=\"line\">kube-system    kube-apiserver-k8s-master            1/1     Running   0          20m</span><br><span class=\"line\">kube-system    kube-controller-manager-k8s-master   1/1     Running   0          20m</span><br><span class=\"line\">kube-system    kube-proxy-9df97                     1/1     Running   0          19m</span><br><span class=\"line\">kube-system    kube-scheduler-k8s-master            1/1     Running   0          20m</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"598a8888\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他node节点加入集群</font></h1>\n---\n\n<h2 id=\"b7eec277\"><font style=\"background-color:rgba(255, 255, 255, 0);\">将节点加入到集群</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# kubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e1dc7e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# kubectl get node</span><br><span class=\"line\">NAME         STATUS   ROLES                  AGE     VERSION</span><br><span class=\"line\">k8s-master   Ready    control-plane,master   5m26s   v1.24.13</span><br><span class=\"line\">k8s-work1    Ready    &lt;none&gt;                 3m39s   v1.24.13</span><br><span class=\"line\">k8s-work2    Ready    &lt;none&gt;                 3m48s   v1.24.13</span><br><span class=\"line\">[root@k8s-master ~]# kubectl get pod -A</span><br><span class=\"line\">NAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-22hrr                1/1     Running   2          17m</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-5tjkb                1/1     Running   2          36m</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-kmtnk                1/1     Running   0          84s</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-vnrqf             1/1     Running   3          47m</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-x9q75             1/1     Running   2          47m</span><br><span class=\"line\">kube-system    etcd-k8s-master                      1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-apiserver-k8s-master            1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-controller-manager-k8s-master   1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-proxy-6wmsl                     1/1     Running   2          17m</span><br><span class=\"line\">kube-system    kube-proxy-9df97                     1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-proxy-fkkm6                     1/1     Running   0          84s</span><br><span class=\"line\">kube-system    kube-scheduler-k8s-master            1/1     Running   2          47m</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<h1 id=\"eb5fd3ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之前)</font></h1>\n---\n\n<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作在master节点执行\t</font></p>\n</blockquote>\n<h2 id=\"lEFpw\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件创建集群</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">获取默认的初始化参数文件</font>\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;# kubeadm config print init-defaults &gt; kubeadm-conf.yaml&lt;/font&gt;</code></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">配置kubeadm-conf.yaml初始化文件</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 192.168.10.10 # master节点ip地址，如果 Master 有多个interface，建议明确指定，</span><br><span class=\"line\">  bindPort: 6443</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: /var/run/dockershim.sock</span><br><span class=\"line\">  name: k8s-master # master节点主机名</span><br><span class=\"line\">  taints:</span><br><span class=\"line\">  - effect: NoSchedule</span><br><span class=\"line\">    key: node-role.kubernetes.io/master</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns:</span><br><span class=\"line\">  type: CoreDNS</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: k8s.gcr.io</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: v1.19.16 # k8s安装版本</span><br><span class=\"line\">imageRepository: &quot;registry.aliyuncs.com/google_containers&quot; # 将其指定为阿里云镜像地址</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  podSubnet: &quot;10.244.0.0/16&quot; #Kubernetes 支持多种网络方案，而且不同网络方案对--pod-network-cidr 有自己的要求，这里设置为 10.244.0.0/16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class=\"line\">kind: KubeProxyConfiguration</span><br><span class=\"line\">featureGates:</span><br><span class=\"line\">  SupportIPVSProxyMode: true</span><br><span class=\"line\">mode: ipvs</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">指定配置文件创建k8s集群</font></li>\n</ul>\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubeadm init --config=kubeadm-conf.yaml&lt;/font&gt;</code></p>\n<h2 id=\"f21393df\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建k8s集群</font></h2>\n---\n\n<p><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;[root@master ~]# kubeadm init --apiserver-advertise-address=192.168.10.100 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.15 --pod-network-cidr=10.244.0.0/16&lt;/font&gt;</code></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–apiserver-advertise-address<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">指明用 Master 的哪个 interface 与 Cluster 的其他节点通信。如果 Master 有多个interface，建议明确指定，如果不指定，kubeadm 会自动选择有默认网关的interface。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–pod-network-cidr<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">指定 Pod 网络的范围。Kubernetes 支持多种网络方案，而且不同网络方案对–pod-network-cidr 有自己的要求，这里设置为 10.244.0.0&#x2F;16 是因为我们将使用flannel 网络方案，必须设置成这个 CIDR。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–image-repository<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubenetes默认Registries地址是 k8s.gcr.io，在国内并不能访问gcr.io，在1.13版本中我们可以增加–image-repository参数，默认值是k8s.gcr.io，将其指定为阿里云镜像地址：registry.aliyuncs.com&#x2F;google_containers。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">–kubernetes-version&#x3D;v1.19.15<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">关闭版本探测，因为它的默认值是stable-1，会导致从</font><a href=\"https://dl.k8s.io/release/stable-1.txt\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://dl.k8s.io/release/stable-1.txt</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">下载最新的版本号</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">执行完毕后控制台打印以下信息：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Your Kubernetes control-plane has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">mkdir -p $HOME/.kube</span><br><span class=\"line\">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class=\"line\"></span><br><span class=\"line\">kubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef \\</span><br><span class=\"line\">--discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7a2aabc6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">根据提示初始化kubectl</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# mkdir -p $HOME/.kube</span><br><span class=\"line\">[root@k8s-master k8s-install]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">[root@k8s-master k8s-install]# chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c58c9c6b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用 kubectl 命令自动补全功能</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# yum -y install bash-completion</span><br><span class=\"line\">[root@k8s-master k8s-install]# echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bash_profile </span><br><span class=\"line\">[root@k8s-master k8s-install]# source ~/.bash_profile </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"f722bf53\"><font style=\"background-color:rgba(255, 255, 255, 0);\">测试kubectl</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# kubectl get node</span><br><span class=\"line\">NAME         STATUS     ROLES                  AGE   VERSION</span><br><span class=\"line\">k8s-master   NotReady   control-plane,master   46s   v1.19.16</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"26b442b7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">kubeadm部署集群(1.20之后)</font></h1>\n---\n\n<h2 id=\"5adf0bd8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">变化说明</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从1.20开始，开启ipvs配置字段发生了变化，访问官方查看最新版本ipvs开启的正确配置,通过</font><a href=\"https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">可以看到官方说明</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">从1.22开始，推荐使用containerd作为容器运行时。</font></p>\n<h2 id=\"a2e6d0cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">init配置文件</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cat kubeadm-conf.yaml </span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">bootstrapTokens:</span><br><span class=\"line\">- groups:</span><br><span class=\"line\">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class=\"line\">  token: abcdef.0123456789abcdef</span><br><span class=\"line\">  ttl: 24h0m0s</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - signing</span><br><span class=\"line\">  - authentication</span><br><span class=\"line\">kind: InitConfiguration</span><br><span class=\"line\">localAPIEndpoint:</span><br><span class=\"line\">  advertiseAddress: 192.168.10.10  #修改为控制节点IP（VIP）</span><br><span class=\"line\">  bindPort: 6443</span><br><span class=\"line\">nodeRegistration:</span><br><span class=\"line\">  criSocket: unix:///run/containerd/containerd.sock  #使用containerd为容器运行时</span><br><span class=\"line\">\t# criSocket: /var/run/dockershim.sock  #使用docker为容器运行时</span><br><span class=\"line\">  imagePullPolicy: IfNotPresent</span><br><span class=\"line\">  name: k8s-master     #修改为控制节点主机名</span><br><span class=\"line\">  taints: null</span><br><span class=\"line\">---</span><br><span class=\"line\">apiServer:</span><br><span class=\"line\">  timeoutForControlPlane: 4m0s</span><br><span class=\"line\">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class=\"line\">certificatesDir: /etc/kubernetes/pki</span><br><span class=\"line\">clusterName: kubernetes</span><br><span class=\"line\">controllerManager: &#123;&#125;</span><br><span class=\"line\">dns: &#123;&#125;</span><br><span class=\"line\">etcd:</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    dataDir: /var/lib/etcd</span><br><span class=\"line\">imageRepository: registry.aliyuncs.com/google_containers  #修改为阿里镜像地址</span><br><span class=\"line\">kind: ClusterConfiguration</span><br><span class=\"line\">kubernetesVersion: 1.24.13  #版本</span><br><span class=\"line\">networking:</span><br><span class=\"line\">  dnsDomain: cluster.local</span><br><span class=\"line\">  podSubnet: 10.244.0.0/16   #指定Pod网段</span><br><span class=\"line\">  serviceSubnet: 10.96.0.0/12  #指定Service网段</span><br><span class=\"line\">scheduler: &#123;&#125;</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class=\"line\">kind:  KubeProxyConfiguration</span><br><span class=\"line\">mode: ipvs</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class=\"line\">kind: KubeletConfiguration</span><br><span class=\"line\">cgroupDriver: systemd</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">如果初始化时出现以下报错，先停止master节点的kubelet</font></li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class=\"line\">        [ERROR Port-10250]: Port 10250 is in use</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">[root@k8s-master k8s-install]# systemctl stop kubelet</font></p>\n<h1 id=\"86e19ab6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">初始化失败解决</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果因为配置文件异常导致集群初始化失败，可执行如下命令</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubeadm reset </span><br><span class=\"line\"># rm -rf $HOME/.kube/config</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"a5188f63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用基于flannel的Pod网络</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">项目地址：</font><a href=\"https://github.com/flannel-io/flannel\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/flannel-io/flannel</font></a></p>\n<h2 id=\"1616c281\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载配置文件</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# wget https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"c3f7e4cd\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用flannel</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# kubectl apply -f kube-flannel.yml  </span><br><span class=\"line\"># 如果机器有多块物理网卡，需要指定网卡名称</span><br><span class=\"line\">containers:</span><br><span class=\"line\">- name: kube-flannel</span><br><span class=\"line\">    - args:</span><br><span class=\"line\">    - --ip-masq</span><br><span class=\"line\">    - --kube-subnet-mgr</span><br><span class=\"line\">    - --iface=bond0 # 添加这行</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"5655008a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">验证操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master k8s-install]# kubectl get pods -A</span><br><span class=\"line\">NAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-5tjkb                1/1     Running   0          9m1s</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-vnrqf             1/1     Running   0          19m</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-x9q75             1/1     Running   0          19m</span><br><span class=\"line\">kube-system    etcd-k8s-master                      1/1     Running   0          20m</span><br><span class=\"line\">kube-system    kube-apiserver-k8s-master            1/1     Running   0          20m</span><br><span class=\"line\">kube-system    kube-controller-manager-k8s-master   1/1     Running   0          20m</span><br><span class=\"line\">kube-system    kube-proxy-9df97                     1/1     Running   0          19m</span><br><span class=\"line\">kube-system    kube-scheduler-k8s-master            1/1     Running   0          20m</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"598a8888\"><font style=\"background-color:rgba(255, 255, 255, 0);\">其他node节点加入集群</font></h1>\n---\n\n<h2 id=\"b7eec277\"><font style=\"background-color:rgba(255, 255, 255, 0);\">将节点加入到集群</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-work1 ~]# kubeadm join 192.168.10.10:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:1f0931588ac578637042e96ebede6c086a36105ceb4cdb65399b6f315650b996 </span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e1dc7e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看集群信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# kubectl get node</span><br><span class=\"line\">NAME         STATUS   ROLES                  AGE     VERSION</span><br><span class=\"line\">k8s-master   Ready    control-plane,master   5m26s   v1.24.13</span><br><span class=\"line\">k8s-work1    Ready    &lt;none&gt;                 3m39s   v1.24.13</span><br><span class=\"line\">k8s-work2    Ready    &lt;none&gt;                 3m48s   v1.24.13</span><br><span class=\"line\">[root@k8s-master ~]# kubectl get pod -A</span><br><span class=\"line\">NAMESPACE      NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-22hrr                1/1     Running   2          17m</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-5tjkb                1/1     Running   2          36m</span><br><span class=\"line\">kube-flannel   kube-flannel-ds-kmtnk                1/1     Running   0          84s</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-vnrqf             1/1     Running   3          47m</span><br><span class=\"line\">kube-system    coredns-6d56c8448f-x9q75             1/1     Running   2          47m</span><br><span class=\"line\">kube-system    etcd-k8s-master                      1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-apiserver-k8s-master            1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-controller-manager-k8s-master   1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-proxy-6wmsl                     1/1     Running   2          17m</span><br><span class=\"line\">kube-system    kube-proxy-9df97                     1/1     Running   2          47m</span><br><span class=\"line\">kube-system    kube-proxy-fkkm6                     1/1     Running   0          84s</span><br><span class=\"line\">kube-system    kube-scheduler-k8s-master            1/1     Running   2          47m</span><br></pre></td></tr></table></figure>\n\n"},{"title":"部署traefik代理","date":"2025-03-11T10:00:00.000Z","_content":"> <font style=\"background-color:rgba(255, 255, 255, 0);\">ingress-NGINX和traefik二选一</font>\n>\n\n<h1 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://doc.traefik.io/traefik/getting-started/install-traefik/</font>](https://doc.traefik.io/traefik/getting-started/install-traefik/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">gtihub地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/traefik/traefik-helm-chart</font>](https://github.com/traefik/traefik-helm-chart)\n\n<h1 id=\"aae74ee4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">必要条件</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes版本1.14+</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Helm版本3+</font>\n\n<h1 id=\"7cc71933\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装traefik</font></h1>\n---\n\n```plain\n# 添加repo\n[root@k8s-master ~]# helm repo add traefik https://helm.traefik.io/traefik\n# 更新repo仓库资源\n[root@k8s-master ~]# helm repo update\n# 查看repo仓库traefik\n[root@k8s-master ~]# helm search repo traefik                                    \nNAME                    CHART VERSION   APP VERSION     DESCRIPTION                                       \ntraefik/traefik         29.0.1          v3.0.4          A Traefik based Kubernetes ingress controller     \ntraefik/traefik-hub     4.2.0           v2.11.0         Traefik Hub Ingress Controller                    \ntraefik/traefik-mesh    4.1.1           v1.4.8          Traefik Mesh - Simpler Service Mesh               \ntraefik/traefikee       4.0.1           v2.11.3         Traefik Enterprise is a unified cloud-native ne...\ntraefik/maesh           2.1.2           v1.3.2          Maesh - Simpler Service Mesh[root@k8s-master ~]# kubectl create ns traefik\n# 拉取helm包\n[root@k8s-master ~]# helm pull traefik/traefik --untar\n# 修改配置\n[root@k8s-master ~]# cd traefik/\n[root@k8s-master traefik]# vim values.yaml \ndeployment:\n  replicas: 1 # master节点数\n\ningressRoute:\n  dashboard:\n    enabled: false  # 禁用helm中渲染的dashboard，traefik默认使用LoadBalancer暴露服务配置较为麻烦\n\n# Configure ports\nports:\n  traefik:\n    port: 9000\n    hostPort: 9000 # 使用 hostport 模式\n  web:\n    port: 8000\n    hostPort: 80  # 使用 hostport 模式\n  websecure:\n    port: 8443\n    hostPort: 443  # 使用 hostport 模式\n\n# Options for the main traefik service, where the entrypoints traffic comes\n# from.\nservice:  # 使用 hostport 模式就不需要Service了\n  enabled: false\n\n# Logs\n# https://docs.traefik.io/observability/logs/\nlogs:\n  general:\n    level: DEBUG\n    \ntolerations:   # kubeadm 安装的集群默认情况下master是有污点，需要容忍这个污点才可以部署\n- key: \"node-role.kubernetes.io/master\"\n  operator: \"Equal\"\n  effect: \"NoSchedule\"\n\nnodeSelector:   # 固定到master1节点（该节点才可以访问外网）\n  kubernetes.io/hostname: \"k8s-master\"\n\nmetrics:\n  service:\n    enabled: true # 开启metrics指标暴露\nlogs:\n  access:\n    enabled: true # 启用access访问日志记录\n  fields:\n    headers:\n      defaultmode: keep # 保留请求头信息\n# 安装\n[root@k8s-master traefik]# helm install traefik -n traefik . -f values.yaml\nNAME: traefik\nLAST DEPLOYED: Mon Aug 14 13:11:04 2023\nNAMESPACE: traefik\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nTraefik Proxy v2.10.4 has been deployed successfully on traefik namespace !\n\n# 查看helm列表\n[root@k8s-master traefik]# helm list -n traefik\nNAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION\ntraefik traefik         1               2023-08-14 13:11:04.879891529 +0800 CST deployed        traefik-24.0.0  v2.10.4    \n# 查看pod资源信息\n[root@k8s-master traefik]# kubectl get pod -n traefik\nNAME                       READY   STATUS    RESTARTS   AGE\ntraefik-5bfc574f88-vz4zr   1/1     Running   0          65s\n```\n\n<h1 id=\"6ddaaaec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">域名访问dashboard服务</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加dashboard的IngressRoute资源：</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl apply -f dashboard.yaml</font>`\n\n```plain\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\n  namespace: traefik\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`traefik.local.com`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果是traefik3以上版本，ingress资源如下</font>\n\n```plain\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\n  namespace: traefik\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`traefik.local.com`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">接下来使用集群外部机器访问，添加hosts解析</font>\n\n```plain\n192.168.10.100 traefik.local.com\n```\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810865713-743745e2-5843-48fd-83b9-c6fec38fbb1d.jpeg)\n\n","source":"_posts/4.部署traefik代理.md","raw":"---\ntitle: 部署traefik代理\ndate: 2025-03-11 18:00:00\n---\n> <font style=\"background-color:rgba(255, 255, 255, 0);\">ingress-NGINX和traefik二选一</font>\n>\n\n<h1 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://doc.traefik.io/traefik/getting-started/install-traefik/</font>](https://doc.traefik.io/traefik/getting-started/install-traefik/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">gtihub地址：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/traefik/traefik-helm-chart</font>](https://github.com/traefik/traefik-helm-chart)\n\n<h1 id=\"aae74ee4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">必要条件</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes版本1.14+</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Helm版本3+</font>\n\n<h1 id=\"7cc71933\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装traefik</font></h1>\n---\n\n```plain\n# 添加repo\n[root@k8s-master ~]# helm repo add traefik https://helm.traefik.io/traefik\n# 更新repo仓库资源\n[root@k8s-master ~]# helm repo update\n# 查看repo仓库traefik\n[root@k8s-master ~]# helm search repo traefik                                    \nNAME                    CHART VERSION   APP VERSION     DESCRIPTION                                       \ntraefik/traefik         29.0.1          v3.0.4          A Traefik based Kubernetes ingress controller     \ntraefik/traefik-hub     4.2.0           v2.11.0         Traefik Hub Ingress Controller                    \ntraefik/traefik-mesh    4.1.1           v1.4.8          Traefik Mesh - Simpler Service Mesh               \ntraefik/traefikee       4.0.1           v2.11.3         Traefik Enterprise is a unified cloud-native ne...\ntraefik/maesh           2.1.2           v1.3.2          Maesh - Simpler Service Mesh[root@k8s-master ~]# kubectl create ns traefik\n# 拉取helm包\n[root@k8s-master ~]# helm pull traefik/traefik --untar\n# 修改配置\n[root@k8s-master ~]# cd traefik/\n[root@k8s-master traefik]# vim values.yaml \ndeployment:\n  replicas: 1 # master节点数\n\ningressRoute:\n  dashboard:\n    enabled: false  # 禁用helm中渲染的dashboard，traefik默认使用LoadBalancer暴露服务配置较为麻烦\n\n# Configure ports\nports:\n  traefik:\n    port: 9000\n    hostPort: 9000 # 使用 hostport 模式\n  web:\n    port: 8000\n    hostPort: 80  # 使用 hostport 模式\n  websecure:\n    port: 8443\n    hostPort: 443  # 使用 hostport 模式\n\n# Options for the main traefik service, where the entrypoints traffic comes\n# from.\nservice:  # 使用 hostport 模式就不需要Service了\n  enabled: false\n\n# Logs\n# https://docs.traefik.io/observability/logs/\nlogs:\n  general:\n    level: DEBUG\n    \ntolerations:   # kubeadm 安装的集群默认情况下master是有污点，需要容忍这个污点才可以部署\n- key: \"node-role.kubernetes.io/master\"\n  operator: \"Equal\"\n  effect: \"NoSchedule\"\n\nnodeSelector:   # 固定到master1节点（该节点才可以访问外网）\n  kubernetes.io/hostname: \"k8s-master\"\n\nmetrics:\n  service:\n    enabled: true # 开启metrics指标暴露\nlogs:\n  access:\n    enabled: true # 启用access访问日志记录\n  fields:\n    headers:\n      defaultmode: keep # 保留请求头信息\n# 安装\n[root@k8s-master traefik]# helm install traefik -n traefik . -f values.yaml\nNAME: traefik\nLAST DEPLOYED: Mon Aug 14 13:11:04 2023\nNAMESPACE: traefik\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nTraefik Proxy v2.10.4 has been deployed successfully on traefik namespace !\n\n# 查看helm列表\n[root@k8s-master traefik]# helm list -n traefik\nNAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION\ntraefik traefik         1               2023-08-14 13:11:04.879891529 +0800 CST deployed        traefik-24.0.0  v2.10.4    \n# 查看pod资源信息\n[root@k8s-master traefik]# kubectl get pod -n traefik\nNAME                       READY   STATUS    RESTARTS   AGE\ntraefik-5bfc574f88-vz4zr   1/1     Running   0          65s\n```\n\n<h1 id=\"6ddaaaec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">域名访问dashboard服务</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加dashboard的IngressRoute资源：</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">kubectl apply -f dashboard.yaml</font>`\n\n```plain\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\n  namespace: traefik\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`traefik.local.com`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">如果是traefik3以上版本，ingress资源如下</font>\n\n```plain\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: dashboard\n  namespace: traefik\nspec:\n  entryPoints:\n    - web\n  routes:\n    - match: Host(`traefik.local.com`)\n      kind: Rule\n      services:\n        - name: api@internal\n          kind: TraefikService\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">接下来使用集群外部机器访问，添加hosts解析</font>\n\n```plain\n192.168.10.100 traefik.local.com\n```\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810865713-743745e2-5843-48fd-83b9-c6fec38fbb1d.jpeg)\n\n","slug":"4.部署traefik代理","published":1,"updated":"2025-03-30T13:13:40.029Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlr000otsv13t3gg4et","content":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ingress-NGINX和traefik二选一</font></p>\n</blockquote>\n<h1 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档：</font><a href=\"https://doc.traefik.io/traefik/getting-started/install-traefik/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://doc.traefik.io/traefik/getting-started/install-traefik/</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">gtihub地址：</font><a href=\"https://github.com/traefik/traefik-helm-chart\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/traefik/traefik-helm-chart</font></a></p>\n<h1 id=\"aae74ee4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">必要条件</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes版本1.14+</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm版本3+</font></p>\n<h1 id=\"7cc71933\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装traefik</font></h1>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加repo</span><br><span class=\"line\">[root@k8s-master ~]# helm repo add traefik https://helm.traefik.io/traefik</span><br><span class=\"line\"># 更新repo仓库资源</span><br><span class=\"line\">[root@k8s-master ~]# helm repo update</span><br><span class=\"line\"># 查看repo仓库traefik</span><br><span class=\"line\">[root@k8s-master ~]# helm search repo traefik                                    </span><br><span class=\"line\">NAME                    CHART VERSION   APP VERSION     DESCRIPTION                                       </span><br><span class=\"line\">traefik/traefik         29.0.1          v3.0.4          A Traefik based Kubernetes ingress controller     </span><br><span class=\"line\">traefik/traefik-hub     4.2.0           v2.11.0         Traefik Hub Ingress Controller                    </span><br><span class=\"line\">traefik/traefik-mesh    4.1.1           v1.4.8          Traefik Mesh - Simpler Service Mesh               </span><br><span class=\"line\">traefik/traefikee       4.0.1           v2.11.3         Traefik Enterprise is a unified cloud-native ne...</span><br><span class=\"line\">traefik/maesh           2.1.2           v1.3.2          Maesh - Simpler Service Mesh[root@k8s-master ~]# kubectl create ns traefik</span><br><span class=\"line\"># 拉取helm包</span><br><span class=\"line\">[root@k8s-master ~]# helm pull traefik/traefik --untar</span><br><span class=\"line\"># 修改配置</span><br><span class=\"line\">[root@k8s-master ~]# cd traefik/</span><br><span class=\"line\">[root@k8s-master traefik]# vim values.yaml </span><br><span class=\"line\">deployment:</span><br><span class=\"line\">  replicas: 1 # master节点数</span><br><span class=\"line\"></span><br><span class=\"line\">ingressRoute:</span><br><span class=\"line\">  dashboard:</span><br><span class=\"line\">    enabled: false  # 禁用helm中渲染的dashboard，traefik默认使用LoadBalancer暴露服务配置较为麻烦</span><br><span class=\"line\"></span><br><span class=\"line\"># Configure ports</span><br><span class=\"line\">ports:</span><br><span class=\"line\">  traefik:</span><br><span class=\"line\">    port: 9000</span><br><span class=\"line\">    hostPort: 9000 # 使用 hostport 模式</span><br><span class=\"line\">  web:</span><br><span class=\"line\">    port: 8000</span><br><span class=\"line\">    hostPort: 80  # 使用 hostport 模式</span><br><span class=\"line\">  websecure:</span><br><span class=\"line\">    port: 8443</span><br><span class=\"line\">    hostPort: 443  # 使用 hostport 模式</span><br><span class=\"line\"></span><br><span class=\"line\"># Options for the main traefik service, where the entrypoints traffic comes</span><br><span class=\"line\"># from.</span><br><span class=\"line\">service:  # 使用 hostport 模式就不需要Service了</span><br><span class=\"line\">  enabled: false</span><br><span class=\"line\"></span><br><span class=\"line\"># Logs</span><br><span class=\"line\"># https://docs.traefik.io/observability/logs/</span><br><span class=\"line\">logs:</span><br><span class=\"line\">  general:</span><br><span class=\"line\">    level: DEBUG</span><br><span class=\"line\">    </span><br><span class=\"line\">tolerations:   # kubeadm 安装的集群默认情况下master是有污点，需要容忍这个污点才可以部署</span><br><span class=\"line\">- key: &quot;node-role.kubernetes.io/master&quot;</span><br><span class=\"line\">  operator: &quot;Equal&quot;</span><br><span class=\"line\">  effect: &quot;NoSchedule&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">nodeSelector:   # 固定到master1节点（该节点才可以访问外网）</span><br><span class=\"line\">  kubernetes.io/hostname: &quot;k8s-master&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">metrics:</span><br><span class=\"line\">  service:</span><br><span class=\"line\">    enabled: true # 开启metrics指标暴露</span><br><span class=\"line\">logs:</span><br><span class=\"line\">  access:</span><br><span class=\"line\">    enabled: true # 启用access访问日志记录</span><br><span class=\"line\">  fields:</span><br><span class=\"line\">    headers:</span><br><span class=\"line\">      defaultmode: keep # 保留请求头信息</span><br><span class=\"line\"># 安装</span><br><span class=\"line\">[root@k8s-master traefik]# helm install traefik -n traefik . -f values.yaml</span><br><span class=\"line\">NAME: traefik</span><br><span class=\"line\">LAST DEPLOYED: Mon Aug 14 13:11:04 2023</span><br><span class=\"line\">NAMESPACE: traefik</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Traefik Proxy v2.10.4 has been deployed successfully on traefik namespace !</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看helm列表</span><br><span class=\"line\">[root@k8s-master traefik]# helm list -n traefik</span><br><span class=\"line\">NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span><br><span class=\"line\">traefik traefik         1               2023-08-14 13:11:04.879891529 +0800 CST deployed        traefik-24.0.0  v2.10.4    </span><br><span class=\"line\"># 查看pod资源信息</span><br><span class=\"line\">[root@k8s-master traefik]# kubectl get pod -n traefik</span><br><span class=\"line\">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">traefik-5bfc574f88-vz4zr   1/1     Running   0          65s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6ddaaaec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">域名访问dashboard服务</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加dashboard的IngressRoute资源：</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubectl apply -f dashboard.yaml&lt;/font&gt;</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard</span><br><span class=\"line\">  namespace: traefik</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">    - match: Host(`traefik.local.com`)</span><br><span class=\"line\">      kind: Rule</span><br><span class=\"line\">      services:</span><br><span class=\"line\">        - name: api@internal</span><br><span class=\"line\">          kind: TraefikService</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果是traefik3以上版本，ingress资源如下</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard</span><br><span class=\"line\">  namespace: traefik</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">    - match: Host(`traefik.local.com`)</span><br><span class=\"line\">      kind: Rule</span><br><span class=\"line\">      services:</span><br><span class=\"line\">        - name: api@internal</span><br><span class=\"line\">          kind: TraefikService</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">接下来使用集群外部机器访问，添加hosts解析</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">192.168.10.100 traefik.local.com</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810865713-743745e2-5843-48fd-83b9-c6fec38fbb1d.jpeg\"></p>\n","excerpt":"","more":"<blockquote>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">ingress-NGINX和traefik二选一</font></p>\n</blockquote>\n<h1 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">官方文档：</font><a href=\"https://doc.traefik.io/traefik/getting-started/install-traefik/\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://doc.traefik.io/traefik/getting-started/install-traefik/</font></a></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">gtihub地址：</font><a href=\"https://github.com/traefik/traefik-helm-chart\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://github.com/traefik/traefik-helm-chart</font></a></p>\n<h1 id=\"aae74ee4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">必要条件</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Kubernetes版本1.14+</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Helm版本3+</font></p>\n<h1 id=\"7cc71933\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装traefik</font></h1>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加repo</span><br><span class=\"line\">[root@k8s-master ~]# helm repo add traefik https://helm.traefik.io/traefik</span><br><span class=\"line\"># 更新repo仓库资源</span><br><span class=\"line\">[root@k8s-master ~]# helm repo update</span><br><span class=\"line\"># 查看repo仓库traefik</span><br><span class=\"line\">[root@k8s-master ~]# helm search repo traefik                                    </span><br><span class=\"line\">NAME                    CHART VERSION   APP VERSION     DESCRIPTION                                       </span><br><span class=\"line\">traefik/traefik         29.0.1          v3.0.4          A Traefik based Kubernetes ingress controller     </span><br><span class=\"line\">traefik/traefik-hub     4.2.0           v2.11.0         Traefik Hub Ingress Controller                    </span><br><span class=\"line\">traefik/traefik-mesh    4.1.1           v1.4.8          Traefik Mesh - Simpler Service Mesh               </span><br><span class=\"line\">traefik/traefikee       4.0.1           v2.11.3         Traefik Enterprise is a unified cloud-native ne...</span><br><span class=\"line\">traefik/maesh           2.1.2           v1.3.2          Maesh - Simpler Service Mesh[root@k8s-master ~]# kubectl create ns traefik</span><br><span class=\"line\"># 拉取helm包</span><br><span class=\"line\">[root@k8s-master ~]# helm pull traefik/traefik --untar</span><br><span class=\"line\"># 修改配置</span><br><span class=\"line\">[root@k8s-master ~]# cd traefik/</span><br><span class=\"line\">[root@k8s-master traefik]# vim values.yaml </span><br><span class=\"line\">deployment:</span><br><span class=\"line\">  replicas: 1 # master节点数</span><br><span class=\"line\"></span><br><span class=\"line\">ingressRoute:</span><br><span class=\"line\">  dashboard:</span><br><span class=\"line\">    enabled: false  # 禁用helm中渲染的dashboard，traefik默认使用LoadBalancer暴露服务配置较为麻烦</span><br><span class=\"line\"></span><br><span class=\"line\"># Configure ports</span><br><span class=\"line\">ports:</span><br><span class=\"line\">  traefik:</span><br><span class=\"line\">    port: 9000</span><br><span class=\"line\">    hostPort: 9000 # 使用 hostport 模式</span><br><span class=\"line\">  web:</span><br><span class=\"line\">    port: 8000</span><br><span class=\"line\">    hostPort: 80  # 使用 hostport 模式</span><br><span class=\"line\">  websecure:</span><br><span class=\"line\">    port: 8443</span><br><span class=\"line\">    hostPort: 443  # 使用 hostport 模式</span><br><span class=\"line\"></span><br><span class=\"line\"># Options for the main traefik service, where the entrypoints traffic comes</span><br><span class=\"line\"># from.</span><br><span class=\"line\">service:  # 使用 hostport 模式就不需要Service了</span><br><span class=\"line\">  enabled: false</span><br><span class=\"line\"></span><br><span class=\"line\"># Logs</span><br><span class=\"line\"># https://docs.traefik.io/observability/logs/</span><br><span class=\"line\">logs:</span><br><span class=\"line\">  general:</span><br><span class=\"line\">    level: DEBUG</span><br><span class=\"line\">    </span><br><span class=\"line\">tolerations:   # kubeadm 安装的集群默认情况下master是有污点，需要容忍这个污点才可以部署</span><br><span class=\"line\">- key: &quot;node-role.kubernetes.io/master&quot;</span><br><span class=\"line\">  operator: &quot;Equal&quot;</span><br><span class=\"line\">  effect: &quot;NoSchedule&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">nodeSelector:   # 固定到master1节点（该节点才可以访问外网）</span><br><span class=\"line\">  kubernetes.io/hostname: &quot;k8s-master&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">metrics:</span><br><span class=\"line\">  service:</span><br><span class=\"line\">    enabled: true # 开启metrics指标暴露</span><br><span class=\"line\">logs:</span><br><span class=\"line\">  access:</span><br><span class=\"line\">    enabled: true # 启用access访问日志记录</span><br><span class=\"line\">  fields:</span><br><span class=\"line\">    headers:</span><br><span class=\"line\">      defaultmode: keep # 保留请求头信息</span><br><span class=\"line\"># 安装</span><br><span class=\"line\">[root@k8s-master traefik]# helm install traefik -n traefik . -f values.yaml</span><br><span class=\"line\">NAME: traefik</span><br><span class=\"line\">LAST DEPLOYED: Mon Aug 14 13:11:04 2023</span><br><span class=\"line\">NAMESPACE: traefik</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">Traefik Proxy v2.10.4 has been deployed successfully on traefik namespace !</span><br><span class=\"line\"></span><br><span class=\"line\"># 查看helm列表</span><br><span class=\"line\">[root@k8s-master traefik]# helm list -n traefik</span><br><span class=\"line\">NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span><br><span class=\"line\">traefik traefik         1               2023-08-14 13:11:04.879891529 +0800 CST deployed        traefik-24.0.0  v2.10.4    </span><br><span class=\"line\"># 查看pod资源信息</span><br><span class=\"line\">[root@k8s-master traefik]# kubectl get pod -n traefik</span><br><span class=\"line\">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">traefik-5bfc574f88-vz4zr   1/1     Running   0          65s</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6ddaaaec\"><font style=\"background-color:rgba(255, 255, 255, 0);\">域名访问dashboard服务</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加dashboard的IngressRoute资源：</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;kubectl apply -f dashboard.yaml&lt;/font&gt;</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard</span><br><span class=\"line\">  namespace: traefik</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">    - match: Host(`traefik.local.com`)</span><br><span class=\"line\">      kind: Rule</span><br><span class=\"line\">      services:</span><br><span class=\"line\">        - name: api@internal</span><br><span class=\"line\">          kind: TraefikService</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">如果是traefik3以上版本，ingress资源如下</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard</span><br><span class=\"line\">  namespace: traefik</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">    - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">    - match: Host(`traefik.local.com`)</span><br><span class=\"line\">      kind: Rule</span><br><span class=\"line\">      services:</span><br><span class=\"line\">        - name: api@internal</span><br><span class=\"line\">          kind: TraefikService</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">接下来使用集群外部机器访问，添加hosts解析</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">192.168.10.100 traefik.local.com</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737810865713-743745e2-5843-48fd-83b9-c6fec38fbb1d.jpeg\"></p>\n"},{"title":"Istio Basic 部署","date":"2025-03-05T11:08:06.000Z","_content":"<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font>\n\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif)\n\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font>\n\n```bash\n$ curl -L https://istio.io/downloadIstio | sh -\n# 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3\n\n$ cd istio-1.7.3/\n# 输出环境变量, 以便直接使用\n$ export PATH=$PWD/bin:$PATH\n# 添加自动补全功能(需要子命令时按下TAB键激活)\n$ cp ./tools/istioctl.bash ~ && source ~/istioctl.bash\n# 安装demo配置\n$ istioctl manifest install --set profile=demo\n# 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：\n$ kubectl get svc -n istio-system\n# 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running\n$ kubectl get pods -n istio-system\n\n# 卸载\n$ istioctl manifest generate --set profile=demo | kubectl delete -f -\n```\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n","source":"_posts/Istio Basic.md","raw":"---\ntitle: Istio Basic 部署\ndate: 2025-03-05 19:08:06\n---\n<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font>\n\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif)\n\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font>\n\n```bash\n$ curl -L https://istio.io/downloadIstio | sh -\n# 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3\n\n$ cd istio-1.7.3/\n# 输出环境变量, 以便直接使用\n$ export PATH=$PWD/bin:$PATH\n# 添加自动补全功能(需要子命令时按下TAB键激活)\n$ cp ./tools/istioctl.bash ~ && source ~/istioctl.bash\n# 安装demo配置\n$ istioctl manifest install --set profile=demo\n# 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：\n$ kubectl get svc -n istio-system\n# 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running\n$ kubectl get pods -n istio-system\n\n# 卸载\n$ istioctl manifest generate --set profile=demo | kubectl delete -f -\n```\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n","slug":"Istio Basic","published":1,"updated":"2025-03-30T13:19:38.081Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlr000ptsv15jpg1mfa","content":"<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font></li>\n</ul>\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif\"></p>\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -L https://istio.io/downloadIstio | sh -</span><br><span class=\"line\"><span class=\"comment\"># 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> istio-1.7.3/</span><br><span class=\"line\"><span class=\"comment\"># 输出环境变量, 以便直接使用</span></span><br><span class=\"line\">$ <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PWD</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"comment\"># 添加自动补全功能(需要子命令时按下TAB键激活)</span></span><br><span class=\"line\">$ <span class=\"built_in\">cp</span> ./tools/istioctl.bash ~ &amp;&amp; <span class=\"built_in\">source</span> ~/istioctl.bash</span><br><span class=\"line\"><span class=\"comment\"># 安装demo配置</span></span><br><span class=\"line\">$ istioctl manifest install --<span class=\"built_in\">set</span> profile=demo</span><br><span class=\"line\"><span class=\"comment\"># 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：</span></span><br><span class=\"line\">$ kubectl get svc -n istio-system</span><br><span class=\"line\"><span class=\"comment\"># 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running</span></span><br><span class=\"line\">$ kubectl get pods -n istio-system</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 卸载</span></span><br><span class=\"line\">$ istioctl manifest generate --<span class=\"built_in\">set</span> profile=demo | kubectl delete -f -</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><a href=\"https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font></a></p>\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n","excerpt":"","more":"<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font></li>\n</ul>\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif\"></p>\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -L https://istio.io/downloadIstio | sh -</span><br><span class=\"line\"><span class=\"comment\"># 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> istio-1.7.3/</span><br><span class=\"line\"><span class=\"comment\"># 输出环境变量, 以便直接使用</span></span><br><span class=\"line\">$ <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PWD</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"comment\"># 添加自动补全功能(需要子命令时按下TAB键激活)</span></span><br><span class=\"line\">$ <span class=\"built_in\">cp</span> ./tools/istioctl.bash ~ &amp;&amp; <span class=\"built_in\">source</span> ~/istioctl.bash</span><br><span class=\"line\"><span class=\"comment\"># 安装demo配置</span></span><br><span class=\"line\">$ istioctl manifest install --<span class=\"built_in\">set</span> profile=demo</span><br><span class=\"line\"><span class=\"comment\"># 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：</span></span><br><span class=\"line\">$ kubectl get svc -n istio-system</span><br><span class=\"line\"><span class=\"comment\"># 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running</span></span><br><span class=\"line\">$ kubectl get pods -n istio-system</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 卸载</span></span><br><span class=\"line\">$ istioctl manifest generate --<span class=\"built_in\">set</span> profile=demo | kubectl delete -f -</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><a href=\"https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font></a></p>\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n"},{"title":"部署minIO对象存储","date":"2025-03-11T10:00:00.000Z","_content":"<h1 id=\"25b8808d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点部署</font></h1>\n---\n\n<h2 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h2>\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes</font>](http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes)\n\n---\n\n<h2 id=\"8913c985\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n```plain\n[root@k8s-master minio]# cat > minio.yaml << EOF\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: minio-pvc\n  namespace: minio\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: minio\n  name: minio\n  namespace: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: quay.io/minio/minio:latest\n        command:\n        - /bin/bash\n        - -c\n        args: \n        - minio server /data --console-address :9090\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        ports:\n        - containerPort: 9090\n          name: console\n        - containerPort: 9000\n          name: api\n        env:\n        - name: MINIO_ROOT_USER # 指定用户名\n          value: \"admin\" \n        - name: MINIO_ROOT_PASSWORD # 指定密码，最少8位置\n          value: \"minioadmin\"\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: minio-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: minio-service\n  namespace: minio\nspec:\n    type: NodePort \n    selector:     \n      app: minio\n    ports:\n    - name: console\n      port: 9090\n      protocol: TCP\n      targetPort: 9090\n      nodePort: 30300\n    - name: api\n      port: 9000\n      protocol: TCP\n      targetPort: 9000\n      nodePort: 30200\nEOF\n[root@k8s-master minio]# kubectl apply -f minio.yaml \ndeployment.apps/minio created\nservice/minio-service created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用NodePort方式访问web页面</font>\n\n```plain\n[root@k8s-master minio]# kubectl get pod -n minio \nNAME                     READY   STATUS    RESTARTS   AGE\nminio-86577f8755-l65mf   1/1     Running   0          11m\n[root@k8s-master minio]# kubectl get svc -n minio \nNAME            TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE\nminio-service   NodePort   10.102.223.132   <none>        9090:30300/TCP,9000:30200/TCP   10m\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问k8s节点ip:30300，默认用户名密码都是**</font><font style=\"background-color:rgba(255, 255, 255, 0);\">admin</font><font style=\"background-color:rgba(255, 255, 255, 0);\">**</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811336392-f240e346-f3cc-41d9-8b16-5c003a092099.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用ingress方式访问</font>\n\n```plain\n[root@k8s-master minio]# cat minio-ingress.yaml\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-console\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio.test.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio-service  # 与svc的name一致\n        port: 9090           # 与svc的port一致\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-api\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio-api.test.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio-service  # 与svc的name一致\n        port: 9000           # 与svc的port一致\n[root@k8s-master minio]# kubectl apply -f minio-ingress.yaml \ningressroute.traefik.containo.us/minio-console created\ningressroute.traefik.containo.us/minio-api created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts记录</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.10 minio.test.com</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">访问域名即可</font>\n\n<h1 id=\"7f042bda\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">minIO集群方式部署使用operator或者helm均可。如果是一套 k8s 集群部署一套 minio 推荐 shiyonghelm 方式部署，operator 更适合多套 minio 集群多租户场景使用。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://artifacthub.io/packages/helm/bitnami/minio</font>](https://artifacthub.io/packages/helm/bitnami/minio)<font style=\"background-color:rgba(255, 255, 255, 0);\">。</font>\n\n<h2 id=\"afac90af\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群角色规划</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用分布式方式部署高可用的minIO集群时，驱动器总数至少是4 个，以保证纠删码。我们可以在k8s-work1和k8s-work2上的data1和data2路径存放minIO数据，使用local pv方式持久化数据。</font>\n\n```plain\n# 创建数据存放路径\n[root@k8s-work1 ~]# mkdir -p /data1/minio\n[root@k8s-work1 ~]# mkdir -p /data2/minio\n[root@k8s-work2 ~]# mkdir -p /data1/minio\n[root@k8s-work2 ~]# mkdir -p /data2/minio\n```\n\n<h2 id=\"73285e10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载helm包</font></h2>\n---\n\n```plain\n[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami\n[root@k8s-master ~]# helm search repo minio\nNAME                            CHART VERSION   APP VERSION     DESCRIPTION                                       \nbitnami/minio                   14.1.4          2024.3.30       MinIO(R) is an object storage server, compatibl...\n[root@k8s-master ~]# helm pull bitnami/minio --untar \n[root@k8s-master ~]# cd minio\n[root@k8s-master minio]# ls\nChart.lock  charts  Chart.yaml  README.md  templates  values.yaml\n```\n\n<h2 id=\"b19846a6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建sc</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font>\n\n```plain\n[root@k8s-master minio]# cat > storageClass.yaml << EOF\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer\nEOF\n[root@k8s-master minio]# kubectl apply -f storageClass.yaml \nstorageclass.storage.k8s.io/local-storage created\n[root@k8s-master minio]# kubectl get storageclass\nNAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nlocal-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s\n```\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">pvc名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font>** |\n| --- | --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data1/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data2/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data1/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv4</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data2/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n\n\n```plain\n[root@k8s-master minio]# cat > pv.yaml << EOF\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv1\n  labels:\n    app: minio-0\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data1/minio # 本地存储路径\n  nodeAffinity: # 调度至work1节点\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work1\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv2\n  labels:\n    app: minio-1\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage\n  local:\n    path: /data2/minio\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work1\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv3\n  labels:\n    app: minio-2\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage\n  local:\n    path: /data1/minio\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work2\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv4\n  labels:\n    app: minio-3\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage\n  local:\n    path: /data2/minio\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work2\nEOF\n[root@master1 minio]# kubectl apply -f pv.yaml \npersistentvolume/minio-pv1 created\npersistentvolume/minio-pv2 created\npersistentvolume/minio-pv3 created\npersistentvolume/minio-pv4 created\n[root@master1 minio]# kubectl get pv | grep minio\nminio-pv1                                  10Gi       RWO            Delete           Bound    minio/data-minio-1                              local-storage            9s\nminio-pv2                                  10Gi       RWO            Delete           Bound    minio/data-minio-2                              local-storage            9s\nminio-pv3                                  10Gi       RWO            Delete           Bound    minio/data-minio-3                              local-storage            9s\nminio-pv4                                  10Gi       RWO            Delete           Bound    minio/data-minio-0                              local-storage            9s\n```\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 = volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font>\n\n```plain\n[root@master1 minio]# cat > pvc.yaml << EOF\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-0\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-0\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-1\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-1\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-2\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-2\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-3\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-3\nEOF\n[root@tiaoban minio]# kubectl create ns minio\nnamespace/minio created\n[root@tiaoban minio]# kubectl apply -f pvc.yaml \npersistentvolumeclaim/data-minio-0 created\npersistentvolumeclaim/data-minio-1 created\npersistentvolumeclaim/data-minio-2 created\npersistentvolumeclaim/data-minio-3 created\n[root@tiaoban minio]# kubectl get pvc -n minio\nNAME           STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    AGE\ndata-minio-0   Pending                                      local-storage   13s\ndata-minio-1   Pending                                      local-storage   13s\ndata-minio-2   Pending                                      local-storage   13s\ndata-minio-3   Pending                                      local-storage   13s\n```\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置values.yaml</font>\n\n```plain\n68 image:\n69   registry: docker.io\n70   repository: bitnami/minio\n71   tag: 2024.3.30-debian-12-r0\n  \n104 mode: distributed # 集群模式，单节点为standalone，分布式集群为distributed\n\n197 statefulset:\n215  replicaCount: 2 # 节点数\n218   zones: 1 # 区域数，1个即可\n221   drivesPerNode: 2 # 每个节点数据目录数.2节点×2目录组成4节点的mimio集群\n\n558 #podAnnotations: {} # 导出Prometheus指标\n559 podAnnotations:\n560   prometheus.io/scrape: \"true\"\n561   prometheus.io/path: \"/minio/v2/metrics/cluster\"\n562   prometheus.io/port: \"9000\"\n\n1049 persistence:\n1052   enabled: true\n1060   storageClass: \"local-storage\"\n1063   mountPath: /bitnami/minio/data\n1066   accessModes:\n1067     - ReadWriteOnce\n1070   size: 10Gi\n1073   annotations: {}\n1076   existingClaim: \"\"\n```\n\n<h2 id=\"oFNWc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n```plain\n[root@k8s-master minio]# kubectl create ns minio\n[root@k8s-master minio]# helm install minio . -f values.yaml -n minio\nNAME: minio\nLAST DEPLOYED: Tue Apr  2 22:28:03 2024\nNAMESPACE: minio\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCHART NAME: minio\nCHART VERSION: 14.1.4\nAPP VERSION: 2024.3.30\n\n** Please be patient while the chart is being deployed **\n\nMinIO&reg; can be accessed via port  on the following DNS name from within your cluster:\n\n   minio.minio.svc.cluster.local\n\nTo get your credentials run:\n\n   export ROOT_USER=$(kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-user}\" | base64 -d)\n   export ROOT_PASSWORD=$(kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-password}\" | base64 -d)\n\nTo connect to your MinIO&reg; server using a client:\n\n- Run a MinIO&reg; Client pod and append the desired command (e.g. 'admin info'):\n\n   kubectl run --namespace minio minio-client \\\n     --rm --tty -i --restart='Never' \\\n     --env MINIO_SERVER_ROOT_USER=$ROOT_USER \\\n     --env MINIO_SERVER_ROOT_PASSWORD=$ROOT_PASSWORD \\\n     --env MINIO_SERVER_HOST=minio \\\n     --image docker.io/bitnami/minio-client:2024.3.30-debian-12-r0 -- admin info minio\n\nTo access the MinIO&reg; web UI:\n\n- Get the MinIO&reg; URL:\n\n   echo \"MinIO&reg; web URL: http://127.0.0.1:9001/minio\"\n   kubectl port-forward --namespace minio svc/minio 9001:9001\n\nWARNING: There are \"resources\" sections in the chart not set. Using \"resourcesPreset\" is not recommended for production. For production installations, please set the following values according to your workload needs:\n  - resources\n+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n```\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n---\n\n```plain\n[root@master1 minio]# kubectl get all -n minio \nNAME          READY   STATUS    RESTARTS   AGE\npod/minio-0   1/1     Running   0          15s\npod/minio-1   1/1     Running   0          15s\npod/minio-2   1/1     Running   0          15s\npod/minio-3   1/1     Running   0          14s\n\nNAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\nservice/minio            ClusterIP   10.106.74.147   <none>        9000/TCP,9001/TCP   15s\nservice/minio-headless   ClusterIP   None            <none>        9000/TCP,9001/TCP   15s\n\nNAME                     READY   AGE\nstatefulset.apps/minio   4/4     15s\n```\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以ingrss-nginx为例：</font>\n\n```plain\n# cat > ingress.yaml << EOF\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: minio-ingreess\n  namespace: minio\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: minio.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: minio\n            port:\n              number: 9001\nEOF\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例：</font>\n\n```plain\n[root@k8s-master minio]# cat ingress.yaml \napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-console\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio  # 与svc的name一致\n        port: 9001      # 与svc的port一致\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-api\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio-api.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio  # 与svc的name一致\n        port: 9000      # 与svc的port一致\n[root@k8s-master minio]# kubectl apply -f ingress.yaml \ningressroute.traefik.containo.us/minio-console created\ningressroute.traefik.containo.us/minio-api created\n```\n\n<h2 id=\"94d6e340\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户名密码</font></h2>\n```plain\n# 获取用户名和密码\n[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-user}\" | base64 -d\nadmin\n[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-password}\" | base64 -d\nHWLLGMhgkp\n```\n\n<h2 id=\"218f27d6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811583730-920d29c1-0cb8-4123-9787-99a2b32fdade.jpeg)\n\n<h1 id=\"c34d22c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署minIO</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://min.io/docs/minio/kubernetes/upstream/operations/installation.html</font>](https://min.io/docs/minio/kubernetes/upstream/operations/installation.html)\n\n<h2 id=\"5ef4b236\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装operator</font></h2>\n---\n\n```plain\n[root@master1 ~]# helm repo add minio-operator https://operator.min.io\n\"minio-operator\" has been added to your repositories\n[root@master1 ~]# helm search repo minio-operator\nNAME                            CHART VERSION   APP VERSION     DESCRIPTION                    \nminio-operator/minio-operator   4.3.7           v4.3.7          A Helm chart for MinIO Operator\nminio-operator/operator         5.0.14          v5.0.14         A Helm chart for MinIO Operator\nminio-operator/tenant           5.0.14          v5.0.14         A Helm chart for MinIO Operator\n[root@master1 ~]# helm install \\\n--namespace minio-operator \\\n--create-namespace \\\noperator minio-operator/operator\nNAME: operator\nLAST DEPLOYED: Sun Mar 24 21:47:05 2024\nNAMESPACE: minio-operator\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\n1. Get the JWT for logging in to the console:\nkubectl apply -f - <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: console-sa-secret\n  namespace: minio-operator\n  annotations:\n    kubernetes.io/service-account.name: console-sa\ntype: kubernetes.io/service-account-token\nEOF\nkubectl -n minio-operator get secret console-sa-secret -o jsonpath=\"{.data.token}\" | base64 --decode\n\n2. Get the Operator Console URL by running these commands:\n  kubectl --namespace minio-operator port-forward svc/console 9090:9090\n  echo \"Visit the Operator Console at http://127.0.0.1:9090\"\n[root@master1 ~]# kubectl get all -n minio-operator\nNAME                                  READY   STATUS    RESTARTS   AGE\nconsole-658c74c776-mjdq7              1/1     Running   0          3m\nminio-operator-5fb5486696-b494r       1/1     Running   0          3m\nminio-operator-5fb5486696-txds7       1/1     Running   0          3m\n\nNAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\nservice/console    ClusterIP   10.98.101.3     <none>        9090/TCP,9443/TCP   6s\nservice/operator   ClusterIP   10.100.70.152   <none>        4221/TCP            6s\nservice/sts        ClusterIP   10.109.22.187   <none>        4223/TCP            6s\n\nNAME                             READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/console          1/1     1            1           39m\ndeployment.apps/minio-operator   2/2     2            2           39m\n\nNAME                                        DESIRED   CURRENT   READY   AGE\nreplicaset.apps/console-59cbf8fbfb          1         1         1       6s\nreplicaset.apps/minio-operator-6868bf476d   2         2         2       6s\n```\n\n<h2 id=\"4a9f317f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制台</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源，以traefik为例</font>\n\n```plain\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-console\n  namespace: minio-operator\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: console  # 与svc的name一致\n        port: 9090      # 与svc的port一致\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取token</font>\n\n```plain\n[root@tiaoban minio]# kubectl get secret/console-sa-secret -n minio-operator -o json | jq -r \".data.token\" | base64 -d\neyJhbGciOiJSUzI1NiIsImtpZCI6IkJqajJ5XzA1LTdjWmhWWTJhUWdtNW5pMHJsejI4Z0d5MjlsWHg1YjF3NG8ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJtaW5pby1vcGVyYXRvciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjb25zb2xlLXNhLXNlY3JldCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJjb25zb2xlLXNhIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZTA2NmRjOTQtMmI5NS00ODllLTk1MzQtNDdjNTY5MzI0YjQxIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Om1pbmlvLW9wZXJhdG9yOmNvbnNvbGUtc2EifQ.0828UMXxhkESZtTo6xUtJRDqHf8ksVNGUVOZas7dIMCPeF9Z2nLZDySMFXBc4qYUb-qGEw5YT0JYxhz_B82Cy-Lg05RaawCmFWlf4Q5O57xdOZ66sUJffRNprqd4uzLejvirtwgzpD6ddiIg4HVN107VIy--S-A-OTbvbrSWtO95GIu4eNG5pM0YALrYAXPuDbBzRsQ9DHjH9dEoXsJW_yhwmlMoIm4Qi4RR4SSRBuVVRvU38DGvg2eZjveSDDJiozOLuGvw3HTPHuamdneEpdfQzCysMEkUm0eZa_uG-5aoSINd7peB9CBPkSx91tM3aX4E1lyN6Q5SVmr3v7o31w\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">浏览器访问minio</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811639483-67b3a890-3f91-4c28-9417-156359fc770f.jpeg)\n\n<h2 id=\"18531cb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm创建租户</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取helm包</font>\n\n```plain\n[root@master1 ~]# helm pull minio-operator/tenant --untar \n[root@master1 ~]# cd tenant/\n[root@master1 tenant]# ls\nChart.yaml  README.md  templates  values.yaml\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改values.yaml</font>\n\n```plain\n39 tenant:\n44   name: k8s-minio\n\n68   image:\n69     repository: harbor.local.com/minio\n70     tag: RELEASE.2024-03-21T23-13-43Z\n\n91   pools:\n96     - servers: 4            # 服务器数\n102      volumesPerServer: 1   # 每个服务器节点数\n105      size: 10Gi            # 每个节点大小\n112      storageClassName: local-storage\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm</font>\n\n```plain\n[root@master1 tenant]# helm install tenant . -f values.yaml -n minio\nNAME: tenant\nLAST DEPLOYED: Sun Mar 24 23:12:11 2024\nNAMESPACE: minio\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nTo connect to the k8s-minio tenant if it doesn't have a service exposed, you can port-forward to it by running:\n\n  kubectl --namespace minio port-forward svc/k8s-minio-console 9443:9443\n\n  Then visit the MinIO Console at https://127.0.0.1:9443\n```\n\n<h2 id=\"63da7cbb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web页面创建租户</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811692573-08170951-d860-4858-8885-f4f759e1b31b.jpeg)\n\n<h1 id=\"0e6b9bf9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus Operator添加监控</font></h1>\n---\n\n<h2 id=\"23493e2c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问metrics接口验证</font></h2>\n---\n\n```plain\n[root@master1 minio]# kubectl get svc -n minio \nNAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE\nminio            ClusterIP   10.103.75.63   <none>        9000/TCP,9001/TCP   71m\nminio-headless   ClusterIP   None           <none>        9000/TCP,9001/TCP   71m\n[root@rocky /]# curl http://10.103.75.63:9000/minio/v2/metrics/cluster\n# HELP minio_audit_failed_messages Total number of messages that failed to send since start\n# TYPE minio_audit_failed_messages counter\nminio_audit_failed_messages{server=\"minio-0.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_failed_messages{server=\"minio-1.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_failed_messages{server=\"minio-2.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_failed_messages{server=\"minio-3.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\n# HELP minio_audit_target_queue_length Number of unsent messages in queue for target\n# TYPE minio_audit_target_queue_length gauge\nminio_audit_target_queue_length{server=\"minio-0.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_target_queue_length{server=\"minio-1.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_target_queue_length{server=\"minio-2.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_target_queue_length{server=\"minio-3.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\n…………\n```\n\n<h2 id=\"4954f1e7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增svc标签</font></h2>\n---\n\n```plain\n[root@master1 minio]# kubectl edit svc -n minio minio\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    meta.helm.sh/release-name: minio\n    meta.helm.sh/release-namespace: minio\n  creationTimestamp: \"2024-03-24T07:52:49Z\"\n  labels:\n    app: minio # 新增labels标签\n```\n\n<h2 id=\"7c5a5aba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ServiceMonitor</font></h2>\n---\n\n```plain\n[root@master1 minio]# cat ServiceMonitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: minio-exporter  # ServiceMonitor名称\n  namespace: monitoring # ServiceMonitor所在名称空间\nspec:\n  jobLabel: minio # job名称\n  endpoints:  # prometheus所采集Metrics地址配置，endpoints为一个数组，可以创建多个，但是每个endpoints包含三个字段interval、path、port\n    - interval: 30s # prometheus采集数据的周期，单位为秒\n      path: /minio/v2/metrics/cluster # prometheus采集数据的路径\n      port: minio-api # prometheus采集数据的端口，这里为port的name，主要是通过spec.selector中选择对应的svc，在选中的svc中匹配该端口\n      scheme: http # 协议\n  namespaceSelector: # 需要发现svc的范围\n    matchNames:\n    - minio\n  selector:\n    matchLabels:  # 选择svc的标签\n      app: minio\n```\n\n<h2 id=\"13a63e45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus targets验证</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811750733-0d85b71e-0041-4bba-9fdf-8db6370c296f.jpeg)\n\n<h1 id=\"ed9e439c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">minIO使用</font></h1>\n---\n\n<h2 id=\"8f89c55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建bucket</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811763767-c3ad368b-263f-46ce-90c4-40cbe4ccdad8.jpeg)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811768940-3e2cd95f-1090-4378-bde4-a539b48f56b8.jpeg)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811774668-16a9ae87-385a-4bbb-b853-6c4288d3b60c.jpeg)\n\n<h2 id=\"812ce170\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Access Keys</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811794794-53fd8172-ad1f-42ab-8671-ef20cc41f499.jpeg)\n\n<h2 id=\"4abae06c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建访问控制权限</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Minio 的存储桶默认是不跟任何 Acess Key 关联的，不过由于 Minio 支持标准的 S3 协议，我们可以给 Access Key 授予某个 Bucket 存储桶的访问权限，实现 Key 和 Bucket 的绑定。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建policy</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811834692-a48aece0-9058-4cf9-becc-5961c28613b4.jpeg)\n\n```plain\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListAllMyBuckets\",\n                \"s3:ListBucket\",\n                \"s3:GetBucketLocation\",\n                \"s3:GetObject\",\n                \"s3:PutObject\",\n                \"s3:DeleteObject\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::es-backup/*\"\n            ]\n        }\n    ]\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建user</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这里 Access Key 是用户名，Access Secret 是对应的口令。设置时关联上刚才创建的 Policy 即可。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811879724-66f317e4-e8b0-48fa-ba59-f4664e59f4fd.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们就创建了一个新的存储桶，并且给这个存储桶设置了一个用户，同时授权了用户对存储桶的访问，包括列表、上传、下载这几个基本权限。</font>\n\n<h1 id=\"522d049b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端使用</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO Client (mc)为ls，cat，cp，mirror，diff，find等UNIX命令提供了一种替代方案。它支持文件系统和兼容Amazon S3的云存储服务（AWS Signature v2和v4）。</font>\n\n<h2 id=\"e9f10274\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（Linux二进制文件）</font></h2>\n---\n\n```plain\n[root@k8s-master minio]# curl https://dl.min.io/client/mc/release/linux-amd64/mc --create-dirs -o /usr/local/minio-binaries/mc\n[root@k8s-master local]# cd /usr/local/minio-binaries\n[root@k8s-master minio-binaries]# ls\nmc\n[root@k8s-master minio-binaries]# chmod +x mc \n[root@k8s-master minio-binaries]# ./mc --help\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc\nNAME:                                                                              \n  mc - MinIO Client for object storage and filesystems.                            \n                                                                                   \nUSAGE:                                                                             \n  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]\n# 添加环境变量\n[root@k8s-master minio-binaries]# cat /etc/profile\nexport PATH=\"$PATH:/usr/local/minio-binaries\"\n[root@k8s-master minio-binaries]# source /etc/profile\n[root@k8s-master minio-binaries]# mc --help\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc\n  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]\n```\n\n<h2 id=\"2183de63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（docker）</font></h2>\n---\n\n```plain\n[root@tiaoban ~]# docker run -it --rm minio/mc ls play\nmc: Configuration written to `/root/.mc/config.json`. Please update your access credentials.\nmc: Successfully created `/root/.mc/share`.\nmc: Initialized share uploads `/root/.mc/share/uploads.json` file.\nmc: Initialized share downloads `/root/.mc/share/downloads.json` file.\n[2023-04-13 01:39:27 UTC]     0B 64375d4bed2b146c15d5383f-files/\n[2023-03-15 11:55:17 UTC]     0B abc/\n[2023-03-31 18:46:54 UTC]     0B awdkenny/\n```\n\n<h2 id=\"e2e248e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端常用命令</font></h2>\n---\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">命令</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">ls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">列出文件和文件夹。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">mb</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">创建一个存储桶或一个文件夹。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">cat</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">显示文件和对象内容。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">pipe</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">将一个STDIN重定向到一个对象或者文件或者STDOUT。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">share</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">生成用于共享的URL。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">cp</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝文件和对象。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">mirror</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">给存储桶和文件夹做镜像。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">find</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于参数查找文件。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">diff</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对两个文件夹或者存储桶比较差异。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">rm</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除文件和对象。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">events</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">管理对象通知。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">watch</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">监视文件和对象的事件。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">policy</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">管理访问策略。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">config</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">管理mc配置文件。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">update</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">检查软件更新。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">version</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">输出版本信息。</font> |\n\n\n<h2 id=\"d34f7a7e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc连接minIO服务</font></h2>\n---\n\n```plain\n# 添加对象存储服务\n[root@k8s-master minio-binaries]# mc alias set k8s-minio http://10.102.223.132:9000 minioadmin minioadmin\nAdded `k8s-minio` successfully.\n[root@k8s-master minio-binaries]# mc admin info k8s-minio\n●  10.102.223.132:9000\n   Uptime: 41 minutes \n   Version: 2023-04-07T05:28:58Z\n   Network: 1/1 OK \n   Drives: 1/1 OK \n   Pool: 1\n\nPools:\n   1st, Erasure sets: 1, Drives per erasure set: 1\n\n12 MiB Used, 1 Bucket, 2 Objects\n1 drive online, 0 drives offline\n```\n\n<h2 id=\"e67e6265\"><font style=\"background-color:rgba(255, 255, 255, 0);\">bucket操作</font></h2>\n---\n\n```plain\n# 创建bucket\n[root@k8s-master ~]# mc mb k8s-minio/test\nBucket created successfully `k8s-minio/test`.\n# 查看bucket\n[root@k8s-master ~]# mc ls k8s-minio\n[2023-04-13 10:02:02 CST]     0B test/\n\n# 删除没有文件的bucket\n[root@k8s-master ~]# mc rb k8s-minio/demo\n# 删除有文件的bucket\n[root@k8s-master ~]# mc rb k8s-minio/test --force\n```\n\n<h2 id=\"46cb4abb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传下载操作</font></h2>\n---\n\n```plain\n# 上传文件到bucket\n[root@k8s-master ~]# mc cp /etc/hosts k8s-minio/test\n/etc/hosts:                   2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.07 KiB/s 0s[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test\n# 上传目录到bucket\n[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test --recursive\n...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.99 KiB/s 0s\n\n# 下载bucket文件到本地\n[root@k8s-master ~]# mkdir /tmp/download\n[root@k8s-master ~]# mc cp k8s-minio/test/hosts /tmp/download/\n...2.223.132:9000/test/hosts: 2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.18 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/\nhosts\n[root@k8s-master ~]# cat /tmp/download/hosts \n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n# 下载bucket目录到本地\n[root@k8s-master ~]# mc cp k8s-minio/test/yum.repos.d /tmp/download/ --recursive\n...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.10 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/yum.repos.d/\ndocker-ce.repo     epel-testing-modular.repo  Rocky-AppStream.repo\n```\n\n<h2 id=\"52cefcb2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件操作</font></h2>\n---\n\n```plain\n# 查看bucket文件列表\n[root@k8s-master ~]# mc ls k8s-minio/test\n[2023-04-13 10:04:59 CST] 2.1KiB STANDARD hosts\n[2023-04-13 10:10:42 CST]     0B yum.repos.d/\n# 查看bucket目录内容\n[root@k8s-master ~]# mc ls k8s-minio/test/yum.repos.d\n[2023-04-13 10:05:34 CST]   710B STANDARD Rocky-AppStream.repo\n[2023-04-13 10:05:34 CST]   695B STANDARD Rocky-BaseOS.repo\n[2023-04-13 10:05:34 CST] 1.7KiB STANDARD Rocky-Debuginfo.repo\n[2023-04-13 10:05:34 CST]   360B STANDARD Rocky-Devel.repo\n# 查看bucket文件内容\n[root@k8s-master ~]# mc cat k8s-minio/test/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n\n# 删除文件\n[root@k8s-master ~]# mc rm k8s-minio/test/hosts\nRemoved `k8s-minio/test/hosts`.\n# 删除目录\n[root@k8s-master ~]# mc rm k8s-minio/test/yum.repos.d --recursive --force\nRemoved `k8s-minio/test/yum.repos.d/Rocky-AppStream.repo`.\nRemoved `k8s-minio/test/yum.repos.d/Rocky-BaseOS.repo`.\nRemoved `k8s-minio/test/yum.repos.d/Rocky-Debuginfo.repo`.\nRemoved `k8s-minio/test/yum.repos.d/Rocky-Devel.repo`.\n```\n\n<h1 id=\"6506b326\"><font style=\"background-color:rgba(255, 255, 255, 0);\">curl客户端使用</font></h1>\n---\n\n<h2 id=\"a6fc9e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件脚本，按实际情况修改host、s3_key、s3_secret，其中192.168.10.10替换为客户端ip.</font>\n\n```plain\n[root@tiaoban ~]# cat push.sh \n#!/bin/bash\nexport PATH=$PATH:/bin:/usr/bin:/usr/local/bin\nif [ $# != 2 ] ; then \necho \"Usage: `basename $0` my-bucket my-file.zip\" >&2\nexit 1\nfi\nbucket=$1\nfile=$2\nhost=minio-api.test.com\ns3_key=GfuHooI5byVpGf2RGwl3\ns3_secret=YpYqXKKhI4bNUmWWULa3qf5n5WPq3TDedb1uzREc\nresource=\"/${bucket}/${file}\"\ncontent_type=\"application/zstd\"\ndate=`date -R`\n_signature=\"PUT\\n\\n${content_type}\\n${date}\\n${resource}\"\nsignature=`echo -en ${_signature} | openssl sha1 -hmac ${s3_secret} -binary | base64`\n\ncurl -v -X PUT -T \"${file}\" \\\n          -H \"Host: ${host}\" \\\n          -x \"192.168.10.10:80\" \\\n          -H \"Date: ${date}\" \\\n          -H \"Content-Type: ${content_type}\" \\\n          -H \"Authorization: AWS ${s3_key}:${signature}\" \\\n          http://${host}${resource}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font>\n\n```plain\n[root@tiaoban ~]# ls\nanaconda-ks.cfg  cfssl  defaults.ini  es  go  push.sh\n[root@tiaoban ~]# ./push.sh test defaults.ini \n*   Trying 192.168.10.10...\n* TCP_NODELAY set\n* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)\n> PUT http://minio-api.test.com/test/defaults.ini HTTP/1.1\n> Host: minio-api.test.com\n> User-Agent: curl/7.61.1\n> Accept: */*\n> Proxy-Connection: Keep-Alive\n> Date: Sat, 06 May 2023 10:10:07 +0800\n> Content-Type: application/zstd\n> Authorization: AWS bhUsp7nwc6XNPzoI:w2ddmcsQWOijC2BZJSGE4u7DgFc=\n> Content-Length: 55875\n> Expect: 100-continue\n> \n< HTTP/1.1 100 Continue\n* We are completely uploaded and fine\n< HTTP/1.1 200 OK\n< Accept-Ranges: bytes\n< Content-Length: 0\n< Content-Security-Policy: block-all-mixed-content\n< Date: Sat, 06 May 2023 02:10:07 GMT\n< Etag: \"1b0bdd8f4c5f31ef5661380efcaefce5\"\n< Server: MinIO\n< Strict-Transport-Security: max-age=31536000; includeSubDomains\n< Vary: Origin\n< Vary: Accept-Encoding\n< X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n< X-Amz-Request-Id: 175C6BE8ACF79B53\n< X-Content-Type-Options: nosniff\n< X-Xss-Protection: 1; mode=block\n< \n* Connection #0 to host 192.168.10.10 left intact\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看bucket文件</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737812117578-8097118f-4fd4-4847-b9c3-98f82d4e4579.jpeg)\n\n<h2 id=\"5dfd5a78\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件脚本</font>\n\n```plain\n#!/usr/bin/env sh\nif [ $# != 3 ] ; then \necho \"Usage: `basename $0` my-bucket minio-filename localfile\" >&2\necho \"Usage: `basename $0` test-bucket 1.log /tmp/1.log\" >&2\nexit 1\nfi\n# User Minio Vars\nhost=minio-api.test.com\ns3_key=bhUsp7nwc6XNPzoI\ns3_secret=w3KBPxMZ5Nw4apRGZY3uAHON7bkkKprP\nBUCKET=$1\nMINIO_PATH=\"/${BUCKET}/$2\"\nOUT_FILE=$3\n# Static Vars\nDATE=$(date -R)\nCONTENT_TYPE='application/zstd'\nSIG_STRING=\"GET\\n\\n${CONTENT_TYPE}\\n${DATE}\\n${MINIO_PATH}\"\nSIGNATURE=`echo -en ${SIG_STRING} | openssl sha1 -hmac ${s3_secret} -binary | base64`\n\ncurl -v -o \"${OUT_FILE}\" \\\n    -x \"192.168.10.10:80\" \\\n    -H \"Host: $host\" \\\n    -H \"Date: ${DATE}\" \\\n    -H \"Content-Type: ${CONTENT_TYPE}\" \\\n    -H \"Authorization: AWS ${s3_key}:${SIGNATURE}\" \\\n    http://$URL${MINIO_PATH}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font>\n\n```plain\n[root@tiaoban ~]# ./pull.sh test defaults.ini /tmp/defaults.ini\n*   Trying 192.168.10.10...\n* TCP_NODELAY set\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)\n> GET http://minio-api.test.com/test/defaults.ini HTTP/1.1\n> Host: minio-api.test.com\n> User-Agent: curl/7.61.1\n> Accept: */*\n> Proxy-Connection: Keep-Alive\n> Date: Sat, 06 May 2023 10:17:18 +0800\n> Content-Type: application/zstd\n> Authorization: AWS bhUsp7nwc6XNPzoI:sl8feCFiJC4MpaKSKrGU9HlDMLw=\n> \n< HTTP/1.1 200 OK\n< Accept-Ranges: bytes\n< Content-Length: 55875\n< Content-Security-Policy: block-all-mixed-content\n< Content-Type: application/zstd\n< Date: Sat, 06 May 2023 02:17:18 GMT\n< Etag: \"1b0bdd8f4c5f31ef5661380efcaefce5\"\n< Last-Modified: Sat, 06 May 2023 02:10:07 GMT\n< Server: MinIO\n< Strict-Transport-Security: max-age=31536000; includeSubDomains\n< Vary: Origin\n< Vary: Accept-Encoding\n< X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n< X-Amz-Request-Id: 175C6C4CF3EB56C4\n< X-Content-Type-Options: nosniff\n< X-Xss-Protection: 1; mode=block\n< \n{ [3529 bytes data]\n100 55875  100 55875    0     0  1474k      0 --:--:-- --:--:-- --:--:-- 1515k\n* Connection #0 to host 192.168.10.10 left intact\n[root@tiaoban ~]# ls -lh /tmp/defaults.ini \n-rw-r--r-- 1 root root 55K 5月   6 10:17 /tmp/defaults.ini\n```\n\n","source":"_posts/5.部署minIO对象存储 副本.md","raw":"---\ntitle: 部署minIO对象存储 \ndate: 2025-03-11 18:00:00\n---\n<h1 id=\"25b8808d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点部署</font></h1>\n---\n\n<h2 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h2>\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes</font>](http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes)\n\n---\n\n<h2 id=\"8913c985\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font>\n\n```plain\n[root@k8s-master minio]# cat > minio.yaml << EOF\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: minio-pvc\n  namespace: minio\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 50Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: minio\n  name: minio\n  namespace: minio\nspec:\n  selector:\n    matchLabels:\n      app: minio\n  template:\n    metadata:\n      labels:\n        app: minio\n    spec:\n      containers:\n      - name: minio\n        image: quay.io/minio/minio:latest\n        command:\n        - /bin/bash\n        - -c\n        args: \n        - minio server /data --console-address :9090\n        volumeMounts:\n        - mountPath: /data\n          name: data\n        ports:\n        - containerPort: 9090\n          name: console\n        - containerPort: 9000\n          name: api\n        env:\n        - name: MINIO_ROOT_USER # 指定用户名\n          value: \"admin\" \n        - name: MINIO_ROOT_PASSWORD # 指定密码，最少8位置\n          value: \"minioadmin\"\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: minio-pvc\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: minio-service\n  namespace: minio\nspec:\n    type: NodePort \n    selector:     \n      app: minio\n    ports:\n    - name: console\n      port: 9090\n      protocol: TCP\n      targetPort: 9090\n      nodePort: 30300\n    - name: api\n      port: 9000\n      protocol: TCP\n      targetPort: 9000\n      nodePort: 30200\nEOF\n[root@k8s-master minio]# kubectl apply -f minio.yaml \ndeployment.apps/minio created\nservice/minio-service created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用NodePort方式访问web页面</font>\n\n```plain\n[root@k8s-master minio]# kubectl get pod -n minio \nNAME                     READY   STATUS    RESTARTS   AGE\nminio-86577f8755-l65mf   1/1     Running   0          11m\n[root@k8s-master minio]# kubectl get svc -n minio \nNAME            TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE\nminio-service   NodePort   10.102.223.132   <none>        9090:30300/TCP,9000:30200/TCP   10m\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">访问k8s节点ip:30300，默认用户名密码都是**</font><font style=\"background-color:rgba(255, 255, 255, 0);\">admin</font><font style=\"background-color:rgba(255, 255, 255, 0);\">**</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811336392-f240e346-f3cc-41d9-8b16-5c003a092099.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用ingress方式访问</font>\n\n```plain\n[root@k8s-master minio]# cat minio-ingress.yaml\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-console\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio.test.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio-service  # 与svc的name一致\n        port: 9090           # 与svc的port一致\n---\napiVersion: traefik.io/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-api\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio-api.test.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio-service  # 与svc的name一致\n        port: 9000           # 与svc的port一致\n[root@k8s-master minio]# kubectl apply -f minio-ingress.yaml \ningressroute.traefik.containo.us/minio-console created\ningressroute.traefik.containo.us/minio-api created\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts记录</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">192.168.10.10 minio.test.com</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">访问域名即可</font>\n\n<h1 id=\"7f042bda\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO集群</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">minIO集群方式部署使用operator或者helm均可。如果是一套 k8s 集群部署一套 minio 推荐 shiyonghelm 方式部署，operator 更适合多套 minio 集群多租户场景使用。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://artifacthub.io/packages/helm/bitnami/minio</font>](https://artifacthub.io/packages/helm/bitnami/minio)<font style=\"background-color:rgba(255, 255, 255, 0);\">。</font>\n\n<h2 id=\"afac90af\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群角色规划</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">使用分布式方式部署高可用的minIO集群时，驱动器总数至少是4 个，以保证纠删码。我们可以在k8s-work1和k8s-work2上的data1和data2路径存放minIO数据，使用local pv方式持久化数据。</font>\n\n```plain\n# 创建数据存放路径\n[root@k8s-work1 ~]# mkdir -p /data1/minio\n[root@k8s-work1 ~]# mkdir -p /data2/minio\n[root@k8s-work2 ~]# mkdir -p /data1/minio\n[root@k8s-work2 ~]# mkdir -p /data2/minio\n```\n\n<h2 id=\"73285e10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载helm包</font></h2>\n---\n\n```plain\n[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami\n[root@k8s-master ~]# helm search repo minio\nNAME                            CHART VERSION   APP VERSION     DESCRIPTION                                       \nbitnami/minio                   14.1.4          2024.3.30       MinIO(R) is an object storage server, compatibl...\n[root@k8s-master ~]# helm pull bitnami/minio --untar \n[root@k8s-master ~]# cd minio\n[root@k8s-master minio]# ls\nChart.lock  charts  Chart.yaml  README.md  templates  values.yaml\n```\n\n<h2 id=\"b19846a6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建sc</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font>\n\n```plain\n[root@k8s-master minio]# cat > storageClass.yaml << EOF\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: local-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer\nEOF\n[root@k8s-master minio]# kubectl apply -f storageClass.yaml \nstorageclass.storage.k8s.io/local-storage created\n[root@k8s-master minio]# kubectl get storageclass\nNAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\nlocal-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s\n```\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font>\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">pvc名称</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font>** |\n| --- | --- | --- | --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-0</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data1/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data2/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data1/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv4</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-3</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">/data2/minio</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font> |\n\n\n```plain\n[root@k8s-master minio]# cat > pv.yaml << EOF\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv1\n  labels:\n    app: minio-0\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致\n  local:\n    path: /data1/minio # 本地存储路径\n  nodeAffinity: # 调度至work1节点\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work1\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv2\n  labels:\n    app: minio-1\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage\n  local:\n    path: /data2/minio\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work1\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv3\n  labels:\n    app: minio-2\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage\n  local:\n    path: /data1/minio\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work2\n---\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: minio-pv4\n  labels:\n    app: minio-3\nspec:\n  capacity:\n    storage: 10Gi\n  volumeMode: Filesystem\n  accessModes:\n  - ReadWriteOnce\n  storageClassName: local-storage\n  local:\n    path: /data2/minio\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - work2\nEOF\n[root@master1 minio]# kubectl apply -f pv.yaml \npersistentvolume/minio-pv1 created\npersistentvolume/minio-pv2 created\npersistentvolume/minio-pv3 created\npersistentvolume/minio-pv4 created\n[root@master1 minio]# kubectl get pv | grep minio\nminio-pv1                                  10Gi       RWO            Delete           Bound    minio/data-minio-1                              local-storage            9s\nminio-pv2                                  10Gi       RWO            Delete           Bound    minio/data-minio-2                              local-storage            9s\nminio-pv3                                  10Gi       RWO            Delete           Bound    minio/data-minio-3                              local-storage            9s\nminio-pv4                                  10Gi       RWO            Delete           Bound    minio/data-minio-0                              local-storage            9s\n```\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 = volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font>\n\n```plain\n[root@master1 minio]# cat > pvc.yaml << EOF\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-0\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-0\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-1\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-1\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-2\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-2\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-minio-3\n  namespace: minio\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: local-storage\n  selector:\n    matchLabels:\n      app: minio-3\nEOF\n[root@tiaoban minio]# kubectl create ns minio\nnamespace/minio created\n[root@tiaoban minio]# kubectl apply -f pvc.yaml \npersistentvolumeclaim/data-minio-0 created\npersistentvolumeclaim/data-minio-1 created\npersistentvolumeclaim/data-minio-2 created\npersistentvolumeclaim/data-minio-3 created\n[root@tiaoban minio]# kubectl get pvc -n minio\nNAME           STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    AGE\ndata-minio-0   Pending                                      local-storage   13s\ndata-minio-1   Pending                                      local-storage   13s\ndata-minio-2   Pending                                      local-storage   13s\ndata-minio-3   Pending                                      local-storage   13s\n```\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置values.yaml</font>\n\n```plain\n68 image:\n69   registry: docker.io\n70   repository: bitnami/minio\n71   tag: 2024.3.30-debian-12-r0\n  \n104 mode: distributed # 集群模式，单节点为standalone，分布式集群为distributed\n\n197 statefulset:\n215  replicaCount: 2 # 节点数\n218   zones: 1 # 区域数，1个即可\n221   drivesPerNode: 2 # 每个节点数据目录数.2节点×2目录组成4节点的mimio集群\n\n558 #podAnnotations: {} # 导出Prometheus指标\n559 podAnnotations:\n560   prometheus.io/scrape: \"true\"\n561   prometheus.io/path: \"/minio/v2/metrics/cluster\"\n562   prometheus.io/port: \"9000\"\n\n1049 persistence:\n1052   enabled: true\n1060   storageClass: \"local-storage\"\n1063   mountPath: /bitnami/minio/data\n1066   accessModes:\n1067     - ReadWriteOnce\n1070   size: 10Gi\n1073   annotations: {}\n1076   existingClaim: \"\"\n```\n\n<h2 id=\"oFNWc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n```plain\n[root@k8s-master minio]# kubectl create ns minio\n[root@k8s-master minio]# helm install minio . -f values.yaml -n minio\nNAME: minio\nLAST DEPLOYED: Tue Apr  2 22:28:03 2024\nNAMESPACE: minio\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nCHART NAME: minio\nCHART VERSION: 14.1.4\nAPP VERSION: 2024.3.30\n\n** Please be patient while the chart is being deployed **\n\nMinIO&reg; can be accessed via port  on the following DNS name from within your cluster:\n\n   minio.minio.svc.cluster.local\n\nTo get your credentials run:\n\n   export ROOT_USER=$(kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-user}\" | base64 -d)\n   export ROOT_PASSWORD=$(kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-password}\" | base64 -d)\n\nTo connect to your MinIO&reg; server using a client:\n\n- Run a MinIO&reg; Client pod and append the desired command (e.g. 'admin info'):\n\n   kubectl run --namespace minio minio-client \\\n     --rm --tty -i --restart='Never' \\\n     --env MINIO_SERVER_ROOT_USER=$ROOT_USER \\\n     --env MINIO_SERVER_ROOT_PASSWORD=$ROOT_PASSWORD \\\n     --env MINIO_SERVER_HOST=minio \\\n     --image docker.io/bitnami/minio-client:2024.3.30-debian-12-r0 -- admin info minio\n\nTo access the MinIO&reg; web UI:\n\n- Get the MinIO&reg; URL:\n\n   echo \"MinIO&reg; web URL: http://127.0.0.1:9001/minio\"\n   kubectl port-forward --namespace minio svc/minio 9001:9001\n\nWARNING: There are \"resources\" sections in the chart not set. Using \"resourcesPreset\" is not recommended for production. For production installations, please set the following values according to your workload needs:\n  - resources\n+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\n```\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n---\n\n```plain\n[root@master1 minio]# kubectl get all -n minio \nNAME          READY   STATUS    RESTARTS   AGE\npod/minio-0   1/1     Running   0          15s\npod/minio-1   1/1     Running   0          15s\npod/minio-2   1/1     Running   0          15s\npod/minio-3   1/1     Running   0          14s\n\nNAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\nservice/minio            ClusterIP   10.106.74.147   <none>        9000/TCP,9001/TCP   15s\nservice/minio-headless   ClusterIP   None            <none>        9000/TCP,9001/TCP   15s\n\nNAME                     READY   AGE\nstatefulset.apps/minio   4/4     15s\n```\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以ingrss-nginx为例：</font>\n\n```plain\n# cat > ingress.yaml << EOF\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: minio-ingreess\n  namespace: minio\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: minio.local.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: minio\n            port:\n              number: 9001\nEOF\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例：</font>\n\n```plain\n[root@k8s-master minio]# cat ingress.yaml \napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-console\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio  # 与svc的name一致\n        port: 9001      # 与svc的port一致\n---\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-api\n  namespace: minio\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio-api.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: minio  # 与svc的name一致\n        port: 9000      # 与svc的port一致\n[root@k8s-master minio]# kubectl apply -f ingress.yaml \ningressroute.traefik.containo.us/minio-console created\ningressroute.traefik.containo.us/minio-api created\n```\n\n<h2 id=\"94d6e340\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户名密码</font></h2>\n```plain\n# 获取用户名和密码\n[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-user}\" | base64 -d\nadmin\n[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=\"{.data.root-password}\" | base64 -d\nHWLLGMhgkp\n```\n\n<h2 id=\"218f27d6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811583730-920d29c1-0cb8-4123-9787-99a2b32fdade.jpeg)\n\n<h1 id=\"c34d22c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署minIO</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://min.io/docs/minio/kubernetes/upstream/operations/installation.html</font>](https://min.io/docs/minio/kubernetes/upstream/operations/installation.html)\n\n<h2 id=\"5ef4b236\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装operator</font></h2>\n---\n\n```plain\n[root@master1 ~]# helm repo add minio-operator https://operator.min.io\n\"minio-operator\" has been added to your repositories\n[root@master1 ~]# helm search repo minio-operator\nNAME                            CHART VERSION   APP VERSION     DESCRIPTION                    \nminio-operator/minio-operator   4.3.7           v4.3.7          A Helm chart for MinIO Operator\nminio-operator/operator         5.0.14          v5.0.14         A Helm chart for MinIO Operator\nminio-operator/tenant           5.0.14          v5.0.14         A Helm chart for MinIO Operator\n[root@master1 ~]# helm install \\\n--namespace minio-operator \\\n--create-namespace \\\noperator minio-operator/operator\nNAME: operator\nLAST DEPLOYED: Sun Mar 24 21:47:05 2024\nNAMESPACE: minio-operator\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\n1. Get the JWT for logging in to the console:\nkubectl apply -f - <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: console-sa-secret\n  namespace: minio-operator\n  annotations:\n    kubernetes.io/service-account.name: console-sa\ntype: kubernetes.io/service-account-token\nEOF\nkubectl -n minio-operator get secret console-sa-secret -o jsonpath=\"{.data.token}\" | base64 --decode\n\n2. Get the Operator Console URL by running these commands:\n  kubectl --namespace minio-operator port-forward svc/console 9090:9090\n  echo \"Visit the Operator Console at http://127.0.0.1:9090\"\n[root@master1 ~]# kubectl get all -n minio-operator\nNAME                                  READY   STATUS    RESTARTS   AGE\nconsole-658c74c776-mjdq7              1/1     Running   0          3m\nminio-operator-5fb5486696-b494r       1/1     Running   0          3m\nminio-operator-5fb5486696-txds7       1/1     Running   0          3m\n\nNAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\nservice/console    ClusterIP   10.98.101.3     <none>        9090/TCP,9443/TCP   6s\nservice/operator   ClusterIP   10.100.70.152   <none>        4221/TCP            6s\nservice/sts        ClusterIP   10.109.22.187   <none>        4223/TCP            6s\n\nNAME                             READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/console          1/1     1            1           39m\ndeployment.apps/minio-operator   2/2     2            2           39m\n\nNAME                                        DESIRED   CURRENT   READY   AGE\nreplicaset.apps/console-59cbf8fbfb          1         1         1       6s\nreplicaset.apps/minio-operator-6868bf476d   2         2         2       6s\n```\n\n<h2 id=\"4a9f317f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制台</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源，以traefik为例</font>\n\n```plain\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: minio-console\n  namespace: minio-operator\nspec:\n  entryPoints:\n  - web\n  routes:\n  - match: Host(`minio.local.com`) # 域名\n    kind: Rule\n    services:\n      - name: console  # 与svc的name一致\n        port: 9090      # 与svc的port一致\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">获取token</font>\n\n```plain\n[root@tiaoban minio]# kubectl get secret/console-sa-secret -n minio-operator -o json | jq -r \".data.token\" | base64 -d\neyJhbGciOiJSUzI1NiIsImtpZCI6IkJqajJ5XzA1LTdjWmhWWTJhUWdtNW5pMHJsejI4Z0d5MjlsWHg1YjF3NG8ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJtaW5pby1vcGVyYXRvciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjb25zb2xlLXNhLXNlY3JldCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJjb25zb2xlLXNhIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZTA2NmRjOTQtMmI5NS00ODllLTk1MzQtNDdjNTY5MzI0YjQxIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Om1pbmlvLW9wZXJhdG9yOmNvbnNvbGUtc2EifQ.0828UMXxhkESZtTo6xUtJRDqHf8ksVNGUVOZas7dIMCPeF9Z2nLZDySMFXBc4qYUb-qGEw5YT0JYxhz_B82Cy-Lg05RaawCmFWlf4Q5O57xdOZ66sUJffRNprqd4uzLejvirtwgzpD6ddiIg4HVN107VIy--S-A-OTbvbrSWtO95GIu4eNG5pM0YALrYAXPuDbBzRsQ9DHjH9dEoXsJW_yhwmlMoIm4Qi4RR4SSRBuVVRvU38DGvg2eZjveSDDJiozOLuGvw3HTPHuamdneEpdfQzCysMEkUm0eZa_uG-5aoSINd7peB9CBPkSx91tM3aX4E1lyN6Q5SVmr3v7o31w\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">浏览器访问minio</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811639483-67b3a890-3f91-4c28-9417-156359fc770f.jpeg)\n\n<h2 id=\"18531cb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm创建租户</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">拉取helm包</font>\n\n```plain\n[root@master1 ~]# helm pull minio-operator/tenant --untar \n[root@master1 ~]# cd tenant/\n[root@master1 tenant]# ls\nChart.yaml  README.md  templates  values.yaml\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改values.yaml</font>\n\n```plain\n39 tenant:\n44   name: k8s-minio\n\n68   image:\n69     repository: harbor.local.com/minio\n70     tag: RELEASE.2024-03-21T23-13-43Z\n\n91   pools:\n96     - servers: 4            # 服务器数\n102      volumesPerServer: 1   # 每个服务器节点数\n105      size: 10Gi            # 每个节点大小\n112      storageClassName: local-storage\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm</font>\n\n```plain\n[root@master1 tenant]# helm install tenant . -f values.yaml -n minio\nNAME: tenant\nLAST DEPLOYED: Sun Mar 24 23:12:11 2024\nNAMESPACE: minio\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nTo connect to the k8s-minio tenant if it doesn't have a service exposed, you can port-forward to it by running:\n\n  kubectl --namespace minio port-forward svc/k8s-minio-console 9443:9443\n\n  Then visit the MinIO Console at https://127.0.0.1:9443\n```\n\n<h2 id=\"63da7cbb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web页面创建租户</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811692573-08170951-d860-4858-8885-f4f759e1b31b.jpeg)\n\n<h1 id=\"0e6b9bf9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus Operator添加监控</font></h1>\n---\n\n<h2 id=\"23493e2c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问metrics接口验证</font></h2>\n---\n\n```plain\n[root@master1 minio]# kubectl get svc -n minio \nNAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE\nminio            ClusterIP   10.103.75.63   <none>        9000/TCP,9001/TCP   71m\nminio-headless   ClusterIP   None           <none>        9000/TCP,9001/TCP   71m\n[root@rocky /]# curl http://10.103.75.63:9000/minio/v2/metrics/cluster\n# HELP minio_audit_failed_messages Total number of messages that failed to send since start\n# TYPE minio_audit_failed_messages counter\nminio_audit_failed_messages{server=\"minio-0.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_failed_messages{server=\"minio-1.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_failed_messages{server=\"minio-2.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_failed_messages{server=\"minio-3.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\n# HELP minio_audit_target_queue_length Number of unsent messages in queue for target\n# TYPE minio_audit_target_queue_length gauge\nminio_audit_target_queue_length{server=\"minio-0.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_target_queue_length{server=\"minio-1.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_target_queue_length{server=\"minio-2.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\nminio_audit_target_queue_length{server=\"minio-3.minio-headless.minio.svc.cluster.local:9000\",target_id=\"sys_console_0\"} 0\n…………\n```\n\n<h2 id=\"4954f1e7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增svc标签</font></h2>\n---\n\n```plain\n[root@master1 minio]# kubectl edit svc -n minio minio\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    meta.helm.sh/release-name: minio\n    meta.helm.sh/release-namespace: minio\n  creationTimestamp: \"2024-03-24T07:52:49Z\"\n  labels:\n    app: minio # 新增labels标签\n```\n\n<h2 id=\"7c5a5aba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ServiceMonitor</font></h2>\n---\n\n```plain\n[root@master1 minio]# cat ServiceMonitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: minio-exporter  # ServiceMonitor名称\n  namespace: monitoring # ServiceMonitor所在名称空间\nspec:\n  jobLabel: minio # job名称\n  endpoints:  # prometheus所采集Metrics地址配置，endpoints为一个数组，可以创建多个，但是每个endpoints包含三个字段interval、path、port\n    - interval: 30s # prometheus采集数据的周期，单位为秒\n      path: /minio/v2/metrics/cluster # prometheus采集数据的路径\n      port: minio-api # prometheus采集数据的端口，这里为port的name，主要是通过spec.selector中选择对应的svc，在选中的svc中匹配该端口\n      scheme: http # 协议\n  namespaceSelector: # 需要发现svc的范围\n    matchNames:\n    - minio\n  selector:\n    matchLabels:  # 选择svc的标签\n      app: minio\n```\n\n<h2 id=\"13a63e45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus targets验证</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811750733-0d85b71e-0041-4bba-9fdf-8db6370c296f.jpeg)\n\n<h1 id=\"ed9e439c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">minIO使用</font></h1>\n---\n\n<h2 id=\"8f89c55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建bucket</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811763767-c3ad368b-263f-46ce-90c4-40cbe4ccdad8.jpeg)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811768940-3e2cd95f-1090-4378-bde4-a539b48f56b8.jpeg)\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811774668-16a9ae87-385a-4bbb-b853-6c4288d3b60c.jpeg)\n\n<h2 id=\"812ce170\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Access Keys</font></h2>\n---\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811794794-53fd8172-ad1f-42ab-8671-ef20cc41f499.jpeg)\n\n<h2 id=\"4abae06c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建访问控制权限</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Minio 的存储桶默认是不跟任何 Acess Key 关联的，不过由于 Minio 支持标准的 S3 协议，我们可以给 Access Key 授予某个 Bucket 存储桶的访问权限，实现 Key 和 Bucket 的绑定。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建policy</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811834692-a48aece0-9058-4cf9-becc-5961c28613b4.jpeg)\n\n```plain\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListAllMyBuckets\",\n                \"s3:ListBucket\",\n                \"s3:GetBucketLocation\",\n                \"s3:GetObject\",\n                \"s3:PutObject\",\n                \"s3:DeleteObject\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::es-backup/*\"\n            ]\n        }\n    ]\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">创建user</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">这里 Access Key 是用户名，Access Secret 是对应的口令。设置时关联上刚才创建的 Policy 即可。</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811879724-66f317e4-e8b0-48fa-ba59-f4664e59f4fd.jpeg)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">我们就创建了一个新的存储桶，并且给这个存储桶设置了一个用户，同时授权了用户对存储桶的访问，包括列表、上传、下载这几个基本权限。</font>\n\n<h1 id=\"522d049b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端使用</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO Client (mc)为ls，cat，cp，mirror，diff，find等UNIX命令提供了一种替代方案。它支持文件系统和兼容Amazon S3的云存储服务（AWS Signature v2和v4）。</font>\n\n<h2 id=\"e9f10274\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（Linux二进制文件）</font></h2>\n---\n\n```plain\n[root@k8s-master minio]# curl https://dl.min.io/client/mc/release/linux-amd64/mc --create-dirs -o /usr/local/minio-binaries/mc\n[root@k8s-master local]# cd /usr/local/minio-binaries\n[root@k8s-master minio-binaries]# ls\nmc\n[root@k8s-master minio-binaries]# chmod +x mc \n[root@k8s-master minio-binaries]# ./mc --help\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc\nNAME:                                                                              \n  mc - MinIO Client for object storage and filesystems.                            \n                                                                                   \nUSAGE:                                                                             \n  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]\n# 添加环境变量\n[root@k8s-master minio-binaries]# cat /etc/profile\nexport PATH=\"$PATH:/usr/local/minio-binaries\"\n[root@k8s-master minio-binaries]# source /etc/profile\n[root@k8s-master minio-binaries]# mc --help\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc\n  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]\n```\n\n<h2 id=\"2183de63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（docker）</font></h2>\n---\n\n```plain\n[root@tiaoban ~]# docker run -it --rm minio/mc ls play\nmc: Configuration written to `/root/.mc/config.json`. Please update your access credentials.\nmc: Successfully created `/root/.mc/share`.\nmc: Initialized share uploads `/root/.mc/share/uploads.json` file.\nmc: Initialized share downloads `/root/.mc/share/downloads.json` file.\n[2023-04-13 01:39:27 UTC]     0B 64375d4bed2b146c15d5383f-files/\n[2023-03-15 11:55:17 UTC]     0B abc/\n[2023-03-31 18:46:54 UTC]     0B awdkenny/\n```\n\n<h2 id=\"e2e248e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端常用命令</font></h2>\n---\n\n| **<font style=\"background-color:rgba(255, 255, 255, 0);\">命令</font>** | **<font style=\"background-color:rgba(255, 255, 255, 0);\">功能</font>** |\n| --- | --- |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">ls</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">列出文件和文件夹。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">mb</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">创建一个存储桶或一个文件夹。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">cat</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">显示文件和对象内容。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">pipe</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">将一个STDIN重定向到一个对象或者文件或者STDOUT。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">share</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">生成用于共享的URL。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">cp</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝文件和对象。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">mirror</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">给存储桶和文件夹做镜像。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">find</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">基于参数查找文件。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">diff</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">对两个文件夹或者存储桶比较差异。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">rm</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">删除文件和对象。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">events</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">管理对象通知。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">watch</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">监视文件和对象的事件。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">policy</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">管理访问策略。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">config</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">管理mc配置文件。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">update</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">检查软件更新。</font> |\n| <font style=\"background-color:rgba(255, 255, 255, 0);\">version</font> | <font style=\"background-color:rgba(255, 255, 255, 0);\">输出版本信息。</font> |\n\n\n<h2 id=\"d34f7a7e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc连接minIO服务</font></h2>\n---\n\n```plain\n# 添加对象存储服务\n[root@k8s-master minio-binaries]# mc alias set k8s-minio http://10.102.223.132:9000 minioadmin minioadmin\nAdded `k8s-minio` successfully.\n[root@k8s-master minio-binaries]# mc admin info k8s-minio\n●  10.102.223.132:9000\n   Uptime: 41 minutes \n   Version: 2023-04-07T05:28:58Z\n   Network: 1/1 OK \n   Drives: 1/1 OK \n   Pool: 1\n\nPools:\n   1st, Erasure sets: 1, Drives per erasure set: 1\n\n12 MiB Used, 1 Bucket, 2 Objects\n1 drive online, 0 drives offline\n```\n\n<h2 id=\"e67e6265\"><font style=\"background-color:rgba(255, 255, 255, 0);\">bucket操作</font></h2>\n---\n\n```plain\n# 创建bucket\n[root@k8s-master ~]# mc mb k8s-minio/test\nBucket created successfully `k8s-minio/test`.\n# 查看bucket\n[root@k8s-master ~]# mc ls k8s-minio\n[2023-04-13 10:02:02 CST]     0B test/\n\n# 删除没有文件的bucket\n[root@k8s-master ~]# mc rb k8s-minio/demo\n# 删除有文件的bucket\n[root@k8s-master ~]# mc rb k8s-minio/test --force\n```\n\n<h2 id=\"46cb4abb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传下载操作</font></h2>\n---\n\n```plain\n# 上传文件到bucket\n[root@k8s-master ~]# mc cp /etc/hosts k8s-minio/test\n/etc/hosts:                   2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.07 KiB/s 0s[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test\n# 上传目录到bucket\n[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test --recursive\n...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.99 KiB/s 0s\n\n# 下载bucket文件到本地\n[root@k8s-master ~]# mkdir /tmp/download\n[root@k8s-master ~]# mc cp k8s-minio/test/hosts /tmp/download/\n...2.223.132:9000/test/hosts: 2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.18 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/\nhosts\n[root@k8s-master ~]# cat /tmp/download/hosts \n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n# 下载bucket目录到本地\n[root@k8s-master ~]# mc cp k8s-minio/test/yum.repos.d /tmp/download/ --recursive\n...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.10 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/yum.repos.d/\ndocker-ce.repo     epel-testing-modular.repo  Rocky-AppStream.repo\n```\n\n<h2 id=\"52cefcb2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件操作</font></h2>\n---\n\n```plain\n# 查看bucket文件列表\n[root@k8s-master ~]# mc ls k8s-minio/test\n[2023-04-13 10:04:59 CST] 2.1KiB STANDARD hosts\n[2023-04-13 10:10:42 CST]     0B yum.repos.d/\n# 查看bucket目录内容\n[root@k8s-master ~]# mc ls k8s-minio/test/yum.repos.d\n[2023-04-13 10:05:34 CST]   710B STANDARD Rocky-AppStream.repo\n[2023-04-13 10:05:34 CST]   695B STANDARD Rocky-BaseOS.repo\n[2023-04-13 10:05:34 CST] 1.7KiB STANDARD Rocky-Debuginfo.repo\n[2023-04-13 10:05:34 CST]   360B STANDARD Rocky-Devel.repo\n# 查看bucket文件内容\n[root@k8s-master ~]# mc cat k8s-minio/test/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n\n# 删除文件\n[root@k8s-master ~]# mc rm k8s-minio/test/hosts\nRemoved `k8s-minio/test/hosts`.\n# 删除目录\n[root@k8s-master ~]# mc rm k8s-minio/test/yum.repos.d --recursive --force\nRemoved `k8s-minio/test/yum.repos.d/Rocky-AppStream.repo`.\nRemoved `k8s-minio/test/yum.repos.d/Rocky-BaseOS.repo`.\nRemoved `k8s-minio/test/yum.repos.d/Rocky-Debuginfo.repo`.\nRemoved `k8s-minio/test/yum.repos.d/Rocky-Devel.repo`.\n```\n\n<h1 id=\"6506b326\"><font style=\"background-color:rgba(255, 255, 255, 0);\">curl客户端使用</font></h1>\n---\n\n<h2 id=\"a6fc9e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件脚本，按实际情况修改host、s3_key、s3_secret，其中192.168.10.10替换为客户端ip.</font>\n\n```plain\n[root@tiaoban ~]# cat push.sh \n#!/bin/bash\nexport PATH=$PATH:/bin:/usr/bin:/usr/local/bin\nif [ $# != 2 ] ; then \necho \"Usage: `basename $0` my-bucket my-file.zip\" >&2\nexit 1\nfi\nbucket=$1\nfile=$2\nhost=minio-api.test.com\ns3_key=GfuHooI5byVpGf2RGwl3\ns3_secret=YpYqXKKhI4bNUmWWULa3qf5n5WPq3TDedb1uzREc\nresource=\"/${bucket}/${file}\"\ncontent_type=\"application/zstd\"\ndate=`date -R`\n_signature=\"PUT\\n\\n${content_type}\\n${date}\\n${resource}\"\nsignature=`echo -en ${_signature} | openssl sha1 -hmac ${s3_secret} -binary | base64`\n\ncurl -v -X PUT -T \"${file}\" \\\n          -H \"Host: ${host}\" \\\n          -x \"192.168.10.10:80\" \\\n          -H \"Date: ${date}\" \\\n          -H \"Content-Type: ${content_type}\" \\\n          -H \"Authorization: AWS ${s3_key}:${signature}\" \\\n          http://${host}${resource}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font>\n\n```plain\n[root@tiaoban ~]# ls\nanaconda-ks.cfg  cfssl  defaults.ini  es  go  push.sh\n[root@tiaoban ~]# ./push.sh test defaults.ini \n*   Trying 192.168.10.10...\n* TCP_NODELAY set\n* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)\n> PUT http://minio-api.test.com/test/defaults.ini HTTP/1.1\n> Host: minio-api.test.com\n> User-Agent: curl/7.61.1\n> Accept: */*\n> Proxy-Connection: Keep-Alive\n> Date: Sat, 06 May 2023 10:10:07 +0800\n> Content-Type: application/zstd\n> Authorization: AWS bhUsp7nwc6XNPzoI:w2ddmcsQWOijC2BZJSGE4u7DgFc=\n> Content-Length: 55875\n> Expect: 100-continue\n> \n< HTTP/1.1 100 Continue\n* We are completely uploaded and fine\n< HTTP/1.1 200 OK\n< Accept-Ranges: bytes\n< Content-Length: 0\n< Content-Security-Policy: block-all-mixed-content\n< Date: Sat, 06 May 2023 02:10:07 GMT\n< Etag: \"1b0bdd8f4c5f31ef5661380efcaefce5\"\n< Server: MinIO\n< Strict-Transport-Security: max-age=31536000; includeSubDomains\n< Vary: Origin\n< Vary: Accept-Encoding\n< X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n< X-Amz-Request-Id: 175C6BE8ACF79B53\n< X-Content-Type-Options: nosniff\n< X-Xss-Protection: 1; mode=block\n< \n* Connection #0 to host 192.168.10.10 left intact\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看bucket文件</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737812117578-8097118f-4fd4-4847-b9c3-98f82d4e4579.jpeg)\n\n<h2 id=\"5dfd5a78\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font></h2>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件脚本</font>\n\n```plain\n#!/usr/bin/env sh\nif [ $# != 3 ] ; then \necho \"Usage: `basename $0` my-bucket minio-filename localfile\" >&2\necho \"Usage: `basename $0` test-bucket 1.log /tmp/1.log\" >&2\nexit 1\nfi\n# User Minio Vars\nhost=minio-api.test.com\ns3_key=bhUsp7nwc6XNPzoI\ns3_secret=w3KBPxMZ5Nw4apRGZY3uAHON7bkkKprP\nBUCKET=$1\nMINIO_PATH=\"/${BUCKET}/$2\"\nOUT_FILE=$3\n# Static Vars\nDATE=$(date -R)\nCONTENT_TYPE='application/zstd'\nSIG_STRING=\"GET\\n\\n${CONTENT_TYPE}\\n${DATE}\\n${MINIO_PATH}\"\nSIGNATURE=`echo -en ${SIG_STRING} | openssl sha1 -hmac ${s3_secret} -binary | base64`\n\ncurl -v -o \"${OUT_FILE}\" \\\n    -x \"192.168.10.10:80\" \\\n    -H \"Host: $host\" \\\n    -H \"Date: ${DATE}\" \\\n    -H \"Content-Type: ${CONTENT_TYPE}\" \\\n    -H \"Authorization: AWS ${s3_key}:${SIGNATURE}\" \\\n    http://$URL${MINIO_PATH}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font>\n\n```plain\n[root@tiaoban ~]# ./pull.sh test defaults.ini /tmp/defaults.ini\n*   Trying 192.168.10.10...\n* TCP_NODELAY set\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)\n> GET http://minio-api.test.com/test/defaults.ini HTTP/1.1\n> Host: minio-api.test.com\n> User-Agent: curl/7.61.1\n> Accept: */*\n> Proxy-Connection: Keep-Alive\n> Date: Sat, 06 May 2023 10:17:18 +0800\n> Content-Type: application/zstd\n> Authorization: AWS bhUsp7nwc6XNPzoI:sl8feCFiJC4MpaKSKrGU9HlDMLw=\n> \n< HTTP/1.1 200 OK\n< Accept-Ranges: bytes\n< Content-Length: 55875\n< Content-Security-Policy: block-all-mixed-content\n< Content-Type: application/zstd\n< Date: Sat, 06 May 2023 02:17:18 GMT\n< Etag: \"1b0bdd8f4c5f31ef5661380efcaefce5\"\n< Last-Modified: Sat, 06 May 2023 02:10:07 GMT\n< Server: MinIO\n< Strict-Transport-Security: max-age=31536000; includeSubDomains\n< Vary: Origin\n< Vary: Accept-Encoding\n< X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n< X-Amz-Request-Id: 175C6C4CF3EB56C4\n< X-Content-Type-Options: nosniff\n< X-Xss-Protection: 1; mode=block\n< \n{ [3529 bytes data]\n100 55875  100 55875    0     0  1474k      0 --:--:-- --:--:-- --:--:-- 1515k\n* Connection #0 to host 192.168.10.10 left intact\n[root@tiaoban ~]# ls -lh /tmp/defaults.ini \n-rw-r--r-- 1 root root 55K 5月   6 10:17 /tmp/defaults.ini\n```\n\n","slug":"5.部署minIO对象存储 副本","published":1,"updated":"2025-03-30T13:13:11.609Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjls000qtsv1e2bm96jk","content":"<h1 id=\"25b8808d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点部署</font></h1>\n---\n\n<h2 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h2>\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes</font>](http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes)\n\n<hr>\n<h2 id=\"8913c985\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat &gt; minio.yaml &lt;&lt; EOF</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pvc</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio</span><br><span class=\"line\">  name: minio</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: minio</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: minio</span><br><span class=\"line\">        image: quay.io/minio/minio:latest</span><br><span class=\"line\">        command:</span><br><span class=\"line\">        - /bin/bash</span><br><span class=\"line\">        - -c</span><br><span class=\"line\">        args: </span><br><span class=\"line\">        - minio server /data --console-address :9090</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - mountPath: /data</span><br><span class=\"line\">          name: data</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 9090</span><br><span class=\"line\">          name: console</span><br><span class=\"line\">        - containerPort: 9000</span><br><span class=\"line\">          name: api</span><br><span class=\"line\">        env:</span><br><span class=\"line\">        - name: MINIO_ROOT_USER # 指定用户名</span><br><span class=\"line\">          value: &quot;admin&quot; </span><br><span class=\"line\">        - name: MINIO_ROOT_PASSWORD # 指定密码，最少8位置</span><br><span class=\"line\">          value: &quot;minioadmin&quot;</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: data</span><br><span class=\"line\">        persistentVolumeClaim:</span><br><span class=\"line\">          claimName: minio-pvc</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-service</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">    type: NodePort </span><br><span class=\"line\">    selector:     </span><br><span class=\"line\">      app: minio</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - name: console</span><br><span class=\"line\">      port: 9090</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 9090</span><br><span class=\"line\">      nodePort: 30300</span><br><span class=\"line\">    - name: api</span><br><span class=\"line\">      port: 9000</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 9000</span><br><span class=\"line\">      nodePort: 30200</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f minio.yaml </span><br><span class=\"line\">deployment.apps/minio created</span><br><span class=\"line\">service/minio-service created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用NodePort方式访问web页面</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# kubectl get pod -n minio </span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">minio-86577f8755-l65mf   1/1     Running   0          11m</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get svc -n minio </span><br><span class=\"line\">NAME            TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE</span><br><span class=\"line\">minio-service   NodePort   10.102.223.132   &lt;none&gt;        9090:30300/TCP,9000:30200/TCP   10m</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问k8s节点ip:30300，默认用户名密码都是**</font><font style=\"background-color:rgba(255, 255, 255, 0);\">admin</font><font style=\"background-color:rgba(255, 255, 255, 0);\">**</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811336392-f240e346-f3cc-41d9-8b16-5c003a092099.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用ingress方式访问</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat minio-ingress.yaml</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-console</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio.test.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio-service  # 与svc的name一致</span><br><span class=\"line\">        port: 9090           # 与svc的port一致</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-api</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio-api.test.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio-service  # 与svc的name一致</span><br><span class=\"line\">        port: 9000           # 与svc的port一致</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f minio-ingress.yaml </span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-console created</span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-api created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts记录</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;192.168.10.10 minio.test.com&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">访问域名即可</font></p>\n<h1 id=\"7f042bda\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">minIO集群方式部署使用operator或者helm均可。如果是一套 k8s 集群部署一套 minio 推荐 shiyonghelm 方式部署，operator 更适合多套 minio 集群多租户场景使用。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO参考文档：</font><a href=\"https://artifacthub.io/packages/helm/bitnami/minio\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://artifacthub.io/packages/helm/bitnami/minio</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">。</font></p>\n<h2 id=\"afac90af\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群角色规划</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用分布式方式部署高可用的minIO集群时，驱动器总数至少是4 个，以保证纠删码。我们可以在k8s-work1和k8s-work2上的data1和data2路径存放minIO数据，使用local pv方式持久化数据。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建数据存放路径</span><br><span class=\"line\">[root@k8s-work1 ~]# mkdir -p /data1/minio</span><br><span class=\"line\">[root@k8s-work1 ~]# mkdir -p /data2/minio</span><br><span class=\"line\">[root@k8s-work2 ~]# mkdir -p /data1/minio</span><br><span class=\"line\">[root@k8s-work2 ~]# mkdir -p /data2/minio</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"73285e10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载helm包</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class=\"line\">[root@k8s-master ~]# helm search repo minio</span><br><span class=\"line\">NAME                            CHART VERSION   APP VERSION     DESCRIPTION                                       </span><br><span class=\"line\">bitnami/minio                   14.1.4          2024.3.30       MinIO(R) is an object storage server, compatibl...</span><br><span class=\"line\">[root@k8s-master ~]# helm pull bitnami/minio --untar </span><br><span class=\"line\">[root@k8s-master ~]# cd minio</span><br><span class=\"line\">[root@k8s-master minio]# ls</span><br><span class=\"line\">Chart.lock  charts  Chart.yaml  README.md  templates  values.yaml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"b19846a6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建sc</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat &gt; storageClass.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: storage.k8s.io/v1</span><br><span class=\"line\">kind: StorageClass</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: local-storage</span><br><span class=\"line\">provisioner: kubernetes.io/no-provisioner</span><br><span class=\"line\">volumeBindingMode: WaitForFirstConsumer</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f storageClass.yaml </span><br><span class=\"line\">storageclass.storage.k8s.io/local-storage created</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get storageclass</span><br><span class=\"line\">NAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span><br><span class=\"line\">local-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font>\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">pvc名称</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data1&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data2&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv3</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data1&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv4</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-3</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data2&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n</tbody></table>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat &gt; pv.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv1</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-0</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data1/minio # 本地存储路径</span><br><span class=\"line\">  nodeAffinity: # 调度至work1节点</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv2</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-1</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data2/minio</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv3</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-2</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data1/minio</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work2</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv4</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-3</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data2/minio</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work2</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master1 minio]# kubectl apply -f pv.yaml </span><br><span class=\"line\">persistentvolume/minio-pv1 created</span><br><span class=\"line\">persistentvolume/minio-pv2 created</span><br><span class=\"line\">persistentvolume/minio-pv3 created</span><br><span class=\"line\">persistentvolume/minio-pv4 created</span><br><span class=\"line\">[root@master1 minio]# kubectl get pv | grep minio</span><br><span class=\"line\">minio-pv1                                  10Gi       RWO            Delete           Bound    minio/data-minio-1                              local-storage            9s</span><br><span class=\"line\">minio-pv2                                  10Gi       RWO            Delete           Bound    minio/data-minio-2                              local-storage            9s</span><br><span class=\"line\">minio-pv3                                  10Gi       RWO            Delete           Bound    minio/data-minio-3                              local-storage            9s</span><br><span class=\"line\">minio-pv4                                  10Gi       RWO            Delete           Bound    minio/data-minio-0                              local-storage            9s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 &#x3D; volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# cat &gt; pvc.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-0</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-0</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-1</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-2</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-2</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-3</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-3</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban minio]# kubectl create ns minio</span><br><span class=\"line\">namespace/minio created</span><br><span class=\"line\">[root@tiaoban minio]# kubectl apply -f pvc.yaml </span><br><span class=\"line\">persistentvolumeclaim/data-minio-0 created</span><br><span class=\"line\">persistentvolumeclaim/data-minio-1 created</span><br><span class=\"line\">persistentvolumeclaim/data-minio-2 created</span><br><span class=\"line\">persistentvolumeclaim/data-minio-3 created</span><br><span class=\"line\">[root@tiaoban minio]# kubectl get pvc -n minio</span><br><span class=\"line\">NAME           STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    AGE</span><br><span class=\"line\">data-minio-0   Pending                                      local-storage   13s</span><br><span class=\"line\">data-minio-1   Pending                                      local-storage   13s</span><br><span class=\"line\">data-minio-2   Pending                                      local-storage   13s</span><br><span class=\"line\">data-minio-3   Pending                                      local-storage   13s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置values.yaml</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">68 image:</span><br><span class=\"line\">69   registry: docker.io</span><br><span class=\"line\">70   repository: bitnami/minio</span><br><span class=\"line\">71   tag: 2024.3.30-debian-12-r0</span><br><span class=\"line\">  </span><br><span class=\"line\">104 mode: distributed # 集群模式，单节点为standalone，分布式集群为distributed</span><br><span class=\"line\"></span><br><span class=\"line\">197 statefulset:</span><br><span class=\"line\">215  replicaCount: 2 # 节点数</span><br><span class=\"line\">218   zones: 1 # 区域数，1个即可</span><br><span class=\"line\">221   drivesPerNode: 2 # 每个节点数据目录数.2节点×2目录组成4节点的mimio集群</span><br><span class=\"line\"></span><br><span class=\"line\">558 #podAnnotations: &#123;&#125; # 导出Prometheus指标</span><br><span class=\"line\">559 podAnnotations:</span><br><span class=\"line\">560   prometheus.io/scrape: &quot;true&quot;</span><br><span class=\"line\">561   prometheus.io/path: &quot;/minio/v2/metrics/cluster&quot;</span><br><span class=\"line\">562   prometheus.io/port: &quot;9000&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">1049 persistence:</span><br><span class=\"line\">1052   enabled: true</span><br><span class=\"line\">1060   storageClass: &quot;local-storage&quot;</span><br><span class=\"line\">1063   mountPath: /bitnami/minio/data</span><br><span class=\"line\">1066   accessModes:</span><br><span class=\"line\">1067     - ReadWriteOnce</span><br><span class=\"line\">1070   size: 10Gi</span><br><span class=\"line\">1073   annotations: &#123;&#125;</span><br><span class=\"line\">1076   existingClaim: &quot;&quot;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"oFNWc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# kubectl create ns minio</span><br><span class=\"line\">[root@k8s-master minio]# helm install minio . -f values.yaml -n minio</span><br><span class=\"line\">NAME: minio</span><br><span class=\"line\">LAST DEPLOYED: Tue Apr  2 22:28:03 2024</span><br><span class=\"line\">NAMESPACE: minio</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">CHART NAME: minio</span><br><span class=\"line\">CHART VERSION: 14.1.4</span><br><span class=\"line\">APP VERSION: 2024.3.30</span><br><span class=\"line\"></span><br><span class=\"line\">** Please be patient while the chart is being deployed **</span><br><span class=\"line\"></span><br><span class=\"line\">MinIO&amp;reg; can be accessed via port  on the following DNS name from within your cluster:</span><br><span class=\"line\"></span><br><span class=\"line\">   minio.minio.svc.cluster.local</span><br><span class=\"line\"></span><br><span class=\"line\">To get your credentials run:</span><br><span class=\"line\"></span><br><span class=\"line\">   export ROOT_USER=$(kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-user&#125;&quot; | base64 -d)</span><br><span class=\"line\">   export ROOT_PASSWORD=$(kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-password&#125;&quot; | base64 -d)</span><br><span class=\"line\"></span><br><span class=\"line\">To connect to your MinIO&amp;reg; server using a client:</span><br><span class=\"line\"></span><br><span class=\"line\">- Run a MinIO&amp;reg; Client pod and append the desired command (e.g. &#x27;admin info&#x27;):</span><br><span class=\"line\"></span><br><span class=\"line\">   kubectl run --namespace minio minio-client \\</span><br><span class=\"line\">     --rm --tty -i --restart=&#x27;Never&#x27; \\</span><br><span class=\"line\">     --env MINIO_SERVER_ROOT_USER=$ROOT_USER \\</span><br><span class=\"line\">     --env MINIO_SERVER_ROOT_PASSWORD=$ROOT_PASSWORD \\</span><br><span class=\"line\">     --env MINIO_SERVER_HOST=minio \\</span><br><span class=\"line\">     --image docker.io/bitnami/minio-client:2024.3.30-debian-12-r0 -- admin info minio</span><br><span class=\"line\"></span><br><span class=\"line\">To access the MinIO&amp;reg; web UI:</span><br><span class=\"line\"></span><br><span class=\"line\">- Get the MinIO&amp;reg; URL:</span><br><span class=\"line\"></span><br><span class=\"line\">   echo &quot;MinIO&amp;reg; web URL: http://127.0.0.1:9001/minio&quot;</span><br><span class=\"line\">   kubectl port-forward --namespace minio svc/minio 9001:9001</span><br><span class=\"line\"></span><br><span class=\"line\">WARNING: There are &quot;resources&quot; sections in the chart not set. Using &quot;resourcesPreset&quot; is not recommended for production. For production installations, please set the following values according to your workload needs:</span><br><span class=\"line\">  - resources</span><br><span class=\"line\">+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# kubectl get all -n minio </span><br><span class=\"line\">NAME          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">pod/minio-0   1/1     Running   0          15s</span><br><span class=\"line\">pod/minio-1   1/1     Running   0          15s</span><br><span class=\"line\">pod/minio-2   1/1     Running   0          15s</span><br><span class=\"line\">pod/minio-3   1/1     Running   0          14s</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">service/minio            ClusterIP   10.106.74.147   &lt;none&gt;        9000/TCP,9001/TCP   15s</span><br><span class=\"line\">service/minio-headless   ClusterIP   None            &lt;none&gt;        9000/TCP,9001/TCP   15s</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                     READY   AGE</span><br><span class=\"line\">statefulset.apps/minio   4/4     15s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以ingrss-nginx为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cat &gt; ingress.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-ingreess</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: minio.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: minio</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 9001</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat ingress.yaml </span><br><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-console</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio  # 与svc的name一致</span><br><span class=\"line\">        port: 9001      # 与svc的port一致</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-api</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio-api.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio  # 与svc的name一致</span><br><span class=\"line\">        port: 9000      # 与svc的port一致</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f ingress.yaml </span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-console created</span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-api created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"94d6e340\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户名密码</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 获取用户名和密码</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-user&#125;&quot; | base64 -d</span><br><span class=\"line\">admin</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-password&#125;&quot; | base64 -d</span><br><span class=\"line\">HWLLGMhgkp</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"218f27d6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811583730-920d29c1-0cb8-4123-9787-99a2b32fdade.jpeg)\n\n<h1 id=\"c34d22c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署minIO</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font><a href=\"https://min.io/docs/minio/kubernetes/upstream/operations/installation.html\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://min.io/docs/minio/kubernetes/upstream/operations/installation.html</font></a></p>\n<h2 id=\"5ef4b236\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装operator</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# helm repo add minio-operator https://operator.min.io</span><br><span class=\"line\">&quot;minio-operator&quot; has been added to your repositories</span><br><span class=\"line\">[root@master1 ~]# helm search repo minio-operator</span><br><span class=\"line\">NAME                            CHART VERSION   APP VERSION     DESCRIPTION                    </span><br><span class=\"line\">minio-operator/minio-operator   4.3.7           v4.3.7          A Helm chart for MinIO Operator</span><br><span class=\"line\">minio-operator/operator         5.0.14          v5.0.14         A Helm chart for MinIO Operator</span><br><span class=\"line\">minio-operator/tenant           5.0.14          v5.0.14         A Helm chart for MinIO Operator</span><br><span class=\"line\">[root@master1 ~]# helm install \\</span><br><span class=\"line\">--namespace minio-operator \\</span><br><span class=\"line\">--create-namespace \\</span><br><span class=\"line\">operator minio-operator/operator</span><br><span class=\"line\">NAME: operator</span><br><span class=\"line\">LAST DEPLOYED: Sun Mar 24 21:47:05 2024</span><br><span class=\"line\">NAMESPACE: minio-operator</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Get the JWT for logging in to the console:</span><br><span class=\"line\">kubectl apply -f - &lt;&lt;EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: console-sa-secret</span><br><span class=\"line\">  namespace: minio-operator</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    kubernetes.io/service-account.name: console-sa</span><br><span class=\"line\">type: kubernetes.io/service-account-token</span><br><span class=\"line\">EOF</span><br><span class=\"line\">kubectl -n minio-operator get secret console-sa-secret -o jsonpath=&quot;&#123;.data.token&#125;&quot; | base64 --decode</span><br><span class=\"line\"></span><br><span class=\"line\">2. Get the Operator Console URL by running these commands:</span><br><span class=\"line\">  kubectl --namespace minio-operator port-forward svc/console 9090:9090</span><br><span class=\"line\">  echo &quot;Visit the Operator Console at http://127.0.0.1:9090&quot;</span><br><span class=\"line\">[root@master1 ~]# kubectl get all -n minio-operator</span><br><span class=\"line\">NAME                                  READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">console-658c74c776-mjdq7              1/1     Running   0          3m</span><br><span class=\"line\">minio-operator-5fb5486696-b494r       1/1     Running   0          3m</span><br><span class=\"line\">minio-operator-5fb5486696-txds7       1/1     Running   0          3m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">service/console    ClusterIP   10.98.101.3     &lt;none&gt;        9090/TCP,9443/TCP   6s</span><br><span class=\"line\">service/operator   ClusterIP   10.100.70.152   &lt;none&gt;        4221/TCP            6s</span><br><span class=\"line\">service/sts        ClusterIP   10.109.22.187   &lt;none&gt;        4223/TCP            6s</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                             READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class=\"line\">deployment.apps/console          1/1     1            1           39m</span><br><span class=\"line\">deployment.apps/minio-operator   2/2     2            2           39m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                        DESIRED   CURRENT   READY   AGE</span><br><span class=\"line\">replicaset.apps/console-59cbf8fbfb          1         1         1       6s</span><br><span class=\"line\">replicaset.apps/minio-operator-6868bf476d   2         2         2       6s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4a9f317f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制台</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源，以traefik为例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-console</span><br><span class=\"line\">  namespace: minio-operator</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: console  # 与svc的name一致</span><br><span class=\"line\">        port: 9090      # 与svc的port一致</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取token</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban minio]# kubectl get secret/console-sa-secret -n minio-operator -o json | jq -r &quot;.data.token&quot; | base64 -d</span><br><span class=\"line\">eyJhbGciOiJSUzI1NiIsImtpZCI6IkJqajJ5XzA1LTdjWmhWWTJhUWdtNW5pMHJsejI4Z0d5MjlsWHg1YjF3NG8ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJtaW5pby1vcGVyYXRvciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjb25zb2xlLXNhLXNlY3JldCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJjb25zb2xlLXNhIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZTA2NmRjOTQtMmI5NS00ODllLTk1MzQtNDdjNTY5MzI0YjQxIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Om1pbmlvLW9wZXJhdG9yOmNvbnNvbGUtc2EifQ.0828UMXxhkESZtTo6xUtJRDqHf8ksVNGUVOZas7dIMCPeF9Z2nLZDySMFXBc4qYUb-qGEw5YT0JYxhz_B82Cy-Lg05RaawCmFWlf4Q5O57xdOZ66sUJffRNprqd4uzLejvirtwgzpD6ddiIg4HVN107VIy--S-A-OTbvbrSWtO95GIu4eNG5pM0YALrYAXPuDbBzRsQ9DHjH9dEoXsJW_yhwmlMoIm4Qi4RR4SSRBuVVRvU38DGvg2eZjveSDDJiozOLuGvw3HTPHuamdneEpdfQzCysMEkUm0eZa_uG-5aoSINd7peB9CBPkSx91tM3aX4E1lyN6Q5SVmr3v7o31w</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">浏览器访问minio</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811639483-67b3a890-3f91-4c28-9417-156359fc770f.jpeg\"></p>\n<h2 id=\"18531cb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm创建租户</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取helm包</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# helm pull minio-operator/tenant --untar </span><br><span class=\"line\">[root@master1 ~]# cd tenant/</span><br><span class=\"line\">[root@master1 tenant]# ls</span><br><span class=\"line\">Chart.yaml  README.md  templates  values.yaml</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改values.yaml</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">39 tenant:</span><br><span class=\"line\">44   name: k8s-minio</span><br><span class=\"line\"></span><br><span class=\"line\">68   image:</span><br><span class=\"line\">69     repository: harbor.local.com/minio</span><br><span class=\"line\">70     tag: RELEASE.2024-03-21T23-13-43Z</span><br><span class=\"line\"></span><br><span class=\"line\">91   pools:</span><br><span class=\"line\">96     - servers: 4            # 服务器数</span><br><span class=\"line\">102      volumesPerServer: 1   # 每个服务器节点数</span><br><span class=\"line\">105      size: 10Gi            # 每个节点大小</span><br><span class=\"line\">112      storageClassName: local-storage</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 tenant]# helm install tenant . -f values.yaml -n minio</span><br><span class=\"line\">NAME: tenant</span><br><span class=\"line\">LAST DEPLOYED: Sun Mar 24 23:12:11 2024</span><br><span class=\"line\">NAMESPACE: minio</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">To connect to the k8s-minio tenant if it doesn&#x27;t have a service exposed, you can port-forward to it by running:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubectl --namespace minio port-forward svc/k8s-minio-console 9443:9443</span><br><span class=\"line\"></span><br><span class=\"line\">  Then visit the MinIO Console at https://127.0.0.1:9443</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"63da7cbb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web页面创建租户</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811692573-08170951-d860-4858-8885-f4f759e1b31b.jpeg)\n\n<h1 id=\"0e6b9bf9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus Operator添加监控</font></h1>\n---\n\n<h2 id=\"23493e2c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问metrics接口验证</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# kubectl get svc -n minio </span><br><span class=\"line\">NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">minio            ClusterIP   10.103.75.63   &lt;none&gt;        9000/TCP,9001/TCP   71m</span><br><span class=\"line\">minio-headless   ClusterIP   None           &lt;none&gt;        9000/TCP,9001/TCP   71m</span><br><span class=\"line\">[root@rocky /]# curl http://10.103.75.63:9000/minio/v2/metrics/cluster</span><br><span class=\"line\"># HELP minio_audit_failed_messages Total number of messages that failed to send since start</span><br><span class=\"line\"># TYPE minio_audit_failed_messages counter</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-0.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-1.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-2.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-3.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\"># HELP minio_audit_target_queue_length Number of unsent messages in queue for target</span><br><span class=\"line\"># TYPE minio_audit_target_queue_length gauge</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-0.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-1.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-2.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-3.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">…………</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4954f1e7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增svc标签</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# kubectl edit svc -n minio minio</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    meta.helm.sh/release-name: minio</span><br><span class=\"line\">    meta.helm.sh/release-namespace: minio</span><br><span class=\"line\">  creationTimestamp: &quot;2024-03-24T07:52:49Z&quot;</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio # 新增labels标签</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7c5a5aba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ServiceMonitor</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# cat ServiceMonitor.yaml</span><br><span class=\"line\">apiVersion: monitoring.coreos.com/v1</span><br><span class=\"line\">kind: ServiceMonitor</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-exporter  # ServiceMonitor名称</span><br><span class=\"line\">  namespace: monitoring # ServiceMonitor所在名称空间</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  jobLabel: minio # job名称</span><br><span class=\"line\">  endpoints:  # prometheus所采集Metrics地址配置，endpoints为一个数组，可以创建多个，但是每个endpoints包含三个字段interval、path、port</span><br><span class=\"line\">    - interval: 30s # prometheus采集数据的周期，单位为秒</span><br><span class=\"line\">      path: /minio/v2/metrics/cluster # prometheus采集数据的路径</span><br><span class=\"line\">      port: minio-api # prometheus采集数据的端口，这里为port的name，主要是通过spec.selector中选择对应的svc，在选中的svc中匹配该端口</span><br><span class=\"line\">      scheme: http # 协议</span><br><span class=\"line\">  namespaceSelector: # 需要发现svc的范围</span><br><span class=\"line\">    matchNames:</span><br><span class=\"line\">    - minio</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:  # 选择svc的标签</span><br><span class=\"line\">      app: minio</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"13a63e45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus targets验证</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811750733-0d85b71e-0041-4bba-9fdf-8db6370c296f.jpeg\"></p>\n<h1 id=\"ed9e439c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">minIO使用</font></h1>\n---\n\n<h2 id=\"8f89c55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建bucket</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811763767-c3ad368b-263f-46ce-90c4-40cbe4ccdad8.jpeg)\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811768940-3e2cd95f-1090-4378-bde4-a539b48f56b8.jpeg\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811774668-16a9ae87-385a-4bbb-b853-6c4288d3b60c.jpeg\"></p>\n<h2 id=\"812ce170\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Access Keys</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811794794-53fd8172-ad1f-42ab-8671-ef20cc41f499.jpeg\"></p>\n<h2 id=\"4abae06c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建访问控制权限</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Minio 的存储桶默认是不跟任何 Acess Key 关联的，不过由于 Minio 支持标准的 S3 协议，我们可以给 Access Key 授予某个 Bucket 存储桶的访问权限，实现 Key 和 Bucket 的绑定。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建policy</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811834692-a48aece0-9058-4cf9-becc-5961c28613b4.jpeg\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class=\"line\">    &quot;Statement&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class=\"line\">            &quot;Action&quot;: [</span><br><span class=\"line\">                &quot;s3:ListAllMyBuckets&quot;,</span><br><span class=\"line\">                &quot;s3:ListBucket&quot;,</span><br><span class=\"line\">                &quot;s3:GetBucketLocation&quot;,</span><br><span class=\"line\">                &quot;s3:GetObject&quot;,</span><br><span class=\"line\">                &quot;s3:PutObject&quot;,</span><br><span class=\"line\">                &quot;s3:DeleteObject&quot;</span><br><span class=\"line\">            ],</span><br><span class=\"line\">            &quot;Resource&quot;: [</span><br><span class=\"line\">                &quot;arn:aws:s3:::es-backup/*&quot;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建user</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这里 Access Key 是用户名，Access Secret 是对应的口令。设置时关联上刚才创建的 Policy 即可。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811879724-66f317e4-e8b0-48fa-ba59-f4664e59f4fd.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们就创建了一个新的存储桶，并且给这个存储桶设置了一个用户，同时授权了用户对存储桶的访问，包括列表、上传、下载这几个基本权限。</font></p>\n<h1 id=\"522d049b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端使用</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO Client (mc)为ls，cat，cp，mirror，diff，find等UNIX命令提供了一种替代方案。它支持文件系统和兼容Amazon S3的云存储服务（AWS Signature v2和v4）。</font></p>\n<h2 id=\"e9f10274\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（Linux二进制文件）</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# curl https://dl.min.io/client/mc/release/linux-amd64/mc --create-dirs -o /usr/local/minio-binaries/mc</span><br><span class=\"line\">[root@k8s-master local]# cd /usr/local/minio-binaries</span><br><span class=\"line\">[root@k8s-master minio-binaries]# ls</span><br><span class=\"line\">mc</span><br><span class=\"line\">[root@k8s-master minio-binaries]# chmod +x mc </span><br><span class=\"line\">[root@k8s-master minio-binaries]# ./mc --help</span><br><span class=\"line\">──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc</span><br><span class=\"line\">NAME:                                                                              </span><br><span class=\"line\">  mc - MinIO Client for object storage and filesystems.                            </span><br><span class=\"line\">                                                                                   </span><br><span class=\"line\">USAGE:                                                                             </span><br><span class=\"line\">  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]</span><br><span class=\"line\"># 添加环境变量</span><br><span class=\"line\">[root@k8s-master minio-binaries]# cat /etc/profile</span><br><span class=\"line\">export PATH=&quot;$PATH:/usr/local/minio-binaries&quot;</span><br><span class=\"line\">[root@k8s-master minio-binaries]# source /etc/profile</span><br><span class=\"line\">[root@k8s-master minio-binaries]# mc --help</span><br><span class=\"line\">──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc</span><br><span class=\"line\">  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2183de63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（docker）</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# docker run -it --rm minio/mc ls play</span><br><span class=\"line\">mc: Configuration written to `/root/.mc/config.json`. Please update your access credentials.</span><br><span class=\"line\">mc: Successfully created `/root/.mc/share`.</span><br><span class=\"line\">mc: Initialized share uploads `/root/.mc/share/uploads.json` file.</span><br><span class=\"line\">mc: Initialized share downloads `/root/.mc/share/downloads.json` file.</span><br><span class=\"line\">[2023-04-13 01:39:27 UTC]     0B 64375d4bed2b146c15d5383f-files/</span><br><span class=\"line\">[2023-03-15 11:55:17 UTC]     0B abc/</span><br><span class=\"line\">[2023-03-31 18:46:54 UTC]     0B awdkenny/</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e2e248e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端常用命令</font></h2>\n---\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">命令</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">ls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">列出文件和文件夹。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">mb</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">创建一个存储桶或一个文件夹。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">cat</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">显示文件和对象内容。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">pipe</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">将一个STDIN重定向到一个对象或者文件或者STDOUT。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">share</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">生成用于共享的URL。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">cp</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝文件和对象。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">mirror</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">给存储桶和文件夹做镜像。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">find</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于参数查找文件。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">diff</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对两个文件夹或者存储桶比较差异。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">rm</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除文件和对象。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">events</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">管理对象通知。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">watch</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">监视文件和对象的事件。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">policy</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">管理访问策略。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">config</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">管理mc配置文件。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">update</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">检查软件更新。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">version</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">输出版本信息。</font></td>\n</tr>\n</tbody></table>\n<h2 id=\"d34f7a7e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc连接minIO服务</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加对象存储服务</span><br><span class=\"line\">[root@k8s-master minio-binaries]# mc alias set k8s-minio http://10.102.223.132:9000 minioadmin minioadmin</span><br><span class=\"line\">Added `k8s-minio` successfully.</span><br><span class=\"line\">[root@k8s-master minio-binaries]# mc admin info k8s-minio</span><br><span class=\"line\">●  10.102.223.132:9000</span><br><span class=\"line\">   Uptime: 41 minutes </span><br><span class=\"line\">   Version: 2023-04-07T05:28:58Z</span><br><span class=\"line\">   Network: 1/1 OK </span><br><span class=\"line\">   Drives: 1/1 OK </span><br><span class=\"line\">   Pool: 1</span><br><span class=\"line\"></span><br><span class=\"line\">Pools:</span><br><span class=\"line\">   1st, Erasure sets: 1, Drives per erasure set: 1</span><br><span class=\"line\"></span><br><span class=\"line\">12 MiB Used, 1 Bucket, 2 Objects</span><br><span class=\"line\">1 drive online, 0 drives offline</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e67e6265\"><font style=\"background-color:rgba(255, 255, 255, 0);\">bucket操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc mb k8s-minio/test</span><br><span class=\"line\">Bucket created successfully `k8s-minio/test`.</span><br><span class=\"line\"># 查看bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc ls k8s-minio</span><br><span class=\"line\">[2023-04-13 10:02:02 CST]     0B test/</span><br><span class=\"line\"></span><br><span class=\"line\"># 删除没有文件的bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc rb k8s-minio/demo</span><br><span class=\"line\"># 删除有文件的bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc rb k8s-minio/test --force</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"46cb4abb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传下载操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 上传文件到bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc cp /etc/hosts k8s-minio/test</span><br><span class=\"line\">/etc/hosts:                   2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.07 KiB/s 0s[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test</span><br><span class=\"line\"># 上传目录到bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test --recursive</span><br><span class=\"line\">...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.99 KiB/s 0s</span><br><span class=\"line\"></span><br><span class=\"line\"># 下载bucket文件到本地</span><br><span class=\"line\">[root@k8s-master ~]# mkdir /tmp/download</span><br><span class=\"line\">[root@k8s-master ~]# mc cp k8s-minio/test/hosts /tmp/download/</span><br><span class=\"line\">...2.223.132:9000/test/hosts: 2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.18 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/</span><br><span class=\"line\">hosts</span><br><span class=\"line\">[root@k8s-master ~]# cat /tmp/download/hosts </span><br><span class=\"line\">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class=\"line\">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class=\"line\"># 下载bucket目录到本地</span><br><span class=\"line\">[root@k8s-master ~]# mc cp k8s-minio/test/yum.repos.d /tmp/download/ --recursive</span><br><span class=\"line\">...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.10 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/yum.repos.d/</span><br><span class=\"line\">docker-ce.repo     epel-testing-modular.repo  Rocky-AppStream.repo</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"52cefcb2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看bucket文件列表</span><br><span class=\"line\">[root@k8s-master ~]# mc ls k8s-minio/test</span><br><span class=\"line\">[2023-04-13 10:04:59 CST] 2.1KiB STANDARD hosts</span><br><span class=\"line\">[2023-04-13 10:10:42 CST]     0B yum.repos.d/</span><br><span class=\"line\"># 查看bucket目录内容</span><br><span class=\"line\">[root@k8s-master ~]# mc ls k8s-minio/test/yum.repos.d</span><br><span class=\"line\">[2023-04-13 10:05:34 CST]   710B STANDARD Rocky-AppStream.repo</span><br><span class=\"line\">[2023-04-13 10:05:34 CST]   695B STANDARD Rocky-BaseOS.repo</span><br><span class=\"line\">[2023-04-13 10:05:34 CST] 1.7KiB STANDARD Rocky-Debuginfo.repo</span><br><span class=\"line\">[2023-04-13 10:05:34 CST]   360B STANDARD Rocky-Devel.repo</span><br><span class=\"line\"># 查看bucket文件内容</span><br><span class=\"line\">[root@k8s-master ~]# mc cat k8s-minio/test/hosts</span><br><span class=\"line\">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class=\"line\">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class=\"line\"></span><br><span class=\"line\"># 删除文件</span><br><span class=\"line\">[root@k8s-master ~]# mc rm k8s-minio/test/hosts</span><br><span class=\"line\">Removed `k8s-minio/test/hosts`.</span><br><span class=\"line\"># 删除目录</span><br><span class=\"line\">[root@k8s-master ~]# mc rm k8s-minio/test/yum.repos.d --recursive --force</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-AppStream.repo`.</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-BaseOS.repo`.</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-Debuginfo.repo`.</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-Devel.repo`.</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6506b326\"><font style=\"background-color:rgba(255, 255, 255, 0);\">curl客户端使用</font></h1>\n---\n\n<h2 id=\"a6fc9e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件脚本，按实际情况修改host、s3_key、s3_secret，其中192.168.10.10替换为客户端ip.</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat push.sh </span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">export PATH=$PATH:/bin:/usr/bin:/usr/local/bin</span><br><span class=\"line\">if [ $# != 2 ] ; then </span><br><span class=\"line\">echo &quot;Usage: `basename $0` my-bucket my-file.zip&quot; &gt;&amp;2</span><br><span class=\"line\">exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\">bucket=$1</span><br><span class=\"line\">file=$2</span><br><span class=\"line\">host=minio-api.test.com</span><br><span class=\"line\">s3_key=GfuHooI5byVpGf2RGwl3</span><br><span class=\"line\">s3_secret=YpYqXKKhI4bNUmWWULa3qf5n5WPq3TDedb1uzREc</span><br><span class=\"line\">resource=&quot;/$&#123;bucket&#125;/$&#123;file&#125;&quot;</span><br><span class=\"line\">content_type=&quot;application/zstd&quot;</span><br><span class=\"line\">date=`date -R`</span><br><span class=\"line\">_signature=&quot;PUT\\n\\n$&#123;content_type&#125;\\n$&#123;date&#125;\\n$&#123;resource&#125;&quot;</span><br><span class=\"line\">signature=`echo -en $&#123;_signature&#125; | openssl sha1 -hmac $&#123;s3_secret&#125; -binary | base64`</span><br><span class=\"line\"></span><br><span class=\"line\">curl -v -X PUT -T &quot;$&#123;file&#125;&quot; \\</span><br><span class=\"line\">          -H &quot;Host: $&#123;host&#125;&quot; \\</span><br><span class=\"line\">          -x &quot;192.168.10.10:80&quot; \\</span><br><span class=\"line\">          -H &quot;Date: $&#123;date&#125;&quot; \\</span><br><span class=\"line\">          -H &quot;Content-Type: $&#123;content_type&#125;&quot; \\</span><br><span class=\"line\">          -H &quot;Authorization: AWS $&#123;s3_key&#125;:$&#123;signature&#125;&quot; \\</span><br><span class=\"line\">          http://$&#123;host&#125;$&#123;resource&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# ls</span><br><span class=\"line\">anaconda-ks.cfg  cfssl  defaults.ini  es  go  push.sh</span><br><span class=\"line\">[root@tiaoban ~]# ./push.sh test defaults.ini </span><br><span class=\"line\">*   Trying 192.168.10.10...</span><br><span class=\"line\">* TCP_NODELAY set</span><br><span class=\"line\">* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)</span><br><span class=\"line\">&gt; PUT http://minio-api.test.com/test/defaults.ini HTTP/1.1</span><br><span class=\"line\">&gt; Host: minio-api.test.com</span><br><span class=\"line\">&gt; User-Agent: curl/7.61.1</span><br><span class=\"line\">&gt; Accept: */*</span><br><span class=\"line\">&gt; Proxy-Connection: Keep-Alive</span><br><span class=\"line\">&gt; Date: Sat, 06 May 2023 10:10:07 +0800</span><br><span class=\"line\">&gt; Content-Type: application/zstd</span><br><span class=\"line\">&gt; Authorization: AWS bhUsp7nwc6XNPzoI:w2ddmcsQWOijC2BZJSGE4u7DgFc=</span><br><span class=\"line\">&gt; Content-Length: 55875</span><br><span class=\"line\">&gt; Expect: 100-continue</span><br><span class=\"line\">&gt; </span><br><span class=\"line\">&lt; HTTP/1.1 100 Continue</span><br><span class=\"line\">* We are completely uploaded and fine</span><br><span class=\"line\">&lt; HTTP/1.1 200 OK</span><br><span class=\"line\">&lt; Accept-Ranges: bytes</span><br><span class=\"line\">&lt; Content-Length: 0</span><br><span class=\"line\">&lt; Content-Security-Policy: block-all-mixed-content</span><br><span class=\"line\">&lt; Date: Sat, 06 May 2023 02:10:07 GMT</span><br><span class=\"line\">&lt; Etag: &quot;1b0bdd8f4c5f31ef5661380efcaefce5&quot;</span><br><span class=\"line\">&lt; Server: MinIO</span><br><span class=\"line\">&lt; Strict-Transport-Security: max-age=31536000; includeSubDomains</span><br><span class=\"line\">&lt; Vary: Origin</span><br><span class=\"line\">&lt; Vary: Accept-Encoding</span><br><span class=\"line\">&lt; X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855</span><br><span class=\"line\">&lt; X-Amz-Request-Id: 175C6BE8ACF79B53</span><br><span class=\"line\">&lt; X-Content-Type-Options: nosniff</span><br><span class=\"line\">&lt; X-Xss-Protection: 1; mode=block</span><br><span class=\"line\">&lt; </span><br><span class=\"line\">* Connection #0 to host 192.168.10.10 left intact</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看bucket文件</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737812117578-8097118f-4fd4-4847-b9c3-98f82d4e4579.jpeg\"></p>\n<h2 id=\"5dfd5a78\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/usr/bin/env sh</span><br><span class=\"line\">if [ $# != 3 ] ; then </span><br><span class=\"line\">echo &quot;Usage: `basename $0` my-bucket minio-filename localfile&quot; &gt;&amp;2</span><br><span class=\"line\">echo &quot;Usage: `basename $0` test-bucket 1.log /tmp/1.log&quot; &gt;&amp;2</span><br><span class=\"line\">exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\"># User Minio Vars</span><br><span class=\"line\">host=minio-api.test.com</span><br><span class=\"line\">s3_key=bhUsp7nwc6XNPzoI</span><br><span class=\"line\">s3_secret=w3KBPxMZ5Nw4apRGZY3uAHON7bkkKprP</span><br><span class=\"line\">BUCKET=$1</span><br><span class=\"line\">MINIO_PATH=&quot;/$&#123;BUCKET&#125;/$2&quot;</span><br><span class=\"line\">OUT_FILE=$3</span><br><span class=\"line\"># Static Vars</span><br><span class=\"line\">DATE=$(date -R)</span><br><span class=\"line\">CONTENT_TYPE=&#x27;application/zstd&#x27;</span><br><span class=\"line\">SIG_STRING=&quot;GET\\n\\n$&#123;CONTENT_TYPE&#125;\\n$&#123;DATE&#125;\\n$&#123;MINIO_PATH&#125;&quot;</span><br><span class=\"line\">SIGNATURE=`echo -en $&#123;SIG_STRING&#125; | openssl sha1 -hmac $&#123;s3_secret&#125; -binary | base64`</span><br><span class=\"line\"></span><br><span class=\"line\">curl -v -o &quot;$&#123;OUT_FILE&#125;&quot; \\</span><br><span class=\"line\">    -x &quot;192.168.10.10:80&quot; \\</span><br><span class=\"line\">    -H &quot;Host: $host&quot; \\</span><br><span class=\"line\">    -H &quot;Date: $&#123;DATE&#125;&quot; \\</span><br><span class=\"line\">    -H &quot;Content-Type: $&#123;CONTENT_TYPE&#125;&quot; \\</span><br><span class=\"line\">    -H &quot;Authorization: AWS $&#123;s3_key&#125;:$&#123;SIGNATURE&#125;&quot; \\</span><br><span class=\"line\">    http://$URL$&#123;MINIO_PATH&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# ./pull.sh test defaults.ini /tmp/defaults.ini</span><br><span class=\"line\">*   Trying 192.168.10.10...</span><br><span class=\"line\">* TCP_NODELAY set</span><br><span class=\"line\">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class=\"line\">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class=\"line\">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)</span><br><span class=\"line\">&gt; GET http://minio-api.test.com/test/defaults.ini HTTP/1.1</span><br><span class=\"line\">&gt; Host: minio-api.test.com</span><br><span class=\"line\">&gt; User-Agent: curl/7.61.1</span><br><span class=\"line\">&gt; Accept: */*</span><br><span class=\"line\">&gt; Proxy-Connection: Keep-Alive</span><br><span class=\"line\">&gt; Date: Sat, 06 May 2023 10:17:18 +0800</span><br><span class=\"line\">&gt; Content-Type: application/zstd</span><br><span class=\"line\">&gt; Authorization: AWS bhUsp7nwc6XNPzoI:sl8feCFiJC4MpaKSKrGU9HlDMLw=</span><br><span class=\"line\">&gt; </span><br><span class=\"line\">&lt; HTTP/1.1 200 OK</span><br><span class=\"line\">&lt; Accept-Ranges: bytes</span><br><span class=\"line\">&lt; Content-Length: 55875</span><br><span class=\"line\">&lt; Content-Security-Policy: block-all-mixed-content</span><br><span class=\"line\">&lt; Content-Type: application/zstd</span><br><span class=\"line\">&lt; Date: Sat, 06 May 2023 02:17:18 GMT</span><br><span class=\"line\">&lt; Etag: &quot;1b0bdd8f4c5f31ef5661380efcaefce5&quot;</span><br><span class=\"line\">&lt; Last-Modified: Sat, 06 May 2023 02:10:07 GMT</span><br><span class=\"line\">&lt; Server: MinIO</span><br><span class=\"line\">&lt; Strict-Transport-Security: max-age=31536000; includeSubDomains</span><br><span class=\"line\">&lt; Vary: Origin</span><br><span class=\"line\">&lt; Vary: Accept-Encoding</span><br><span class=\"line\">&lt; X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855</span><br><span class=\"line\">&lt; X-Amz-Request-Id: 175C6C4CF3EB56C4</span><br><span class=\"line\">&lt; X-Content-Type-Options: nosniff</span><br><span class=\"line\">&lt; X-Xss-Protection: 1; mode=block</span><br><span class=\"line\">&lt; </span><br><span class=\"line\">&#123; [3529 bytes data]</span><br><span class=\"line\">100 55875  100 55875    0     0  1474k      0 --:--:-- --:--:-- --:--:-- 1515k</span><br><span class=\"line\">* Connection #0 to host 192.168.10.10 left intact</span><br><span class=\"line\">[root@tiaoban ~]# ls -lh /tmp/defaults.ini </span><br><span class=\"line\">-rw-r--r-- 1 root root 55K 5月   6 10:17 /tmp/defaults.ini</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<h1 id=\"25b8808d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点部署</font></h1>\n---\n\n<h2 id=\"d1f972b3\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档</font></h2>\n[<font style=\"background-color:rgba(255, 255, 255, 0);\">http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes</font>](http://www.minio.org.cn/docs/minio/kubernetes/upstream/#quickstart-minio-for-kubernetes)\n\n<hr>\n<h2 id=\"8913c985\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建资源</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat &gt; minio.yaml &lt;&lt; EOF</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pvc</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  storageClassName: nfs-client</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">    - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 50Gi</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: Deployment</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio</span><br><span class=\"line\">  name: minio</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        app: minio</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: minio</span><br><span class=\"line\">        image: quay.io/minio/minio:latest</span><br><span class=\"line\">        command:</span><br><span class=\"line\">        - /bin/bash</span><br><span class=\"line\">        - -c</span><br><span class=\"line\">        args: </span><br><span class=\"line\">        - minio server /data --console-address :9090</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - mountPath: /data</span><br><span class=\"line\">          name: data</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">        - containerPort: 9090</span><br><span class=\"line\">          name: console</span><br><span class=\"line\">        - containerPort: 9000</span><br><span class=\"line\">          name: api</span><br><span class=\"line\">        env:</span><br><span class=\"line\">        - name: MINIO_ROOT_USER # 指定用户名</span><br><span class=\"line\">          value: &quot;admin&quot; </span><br><span class=\"line\">        - name: MINIO_ROOT_PASSWORD # 指定密码，最少8位置</span><br><span class=\"line\">          value: &quot;minioadmin&quot;</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: data</span><br><span class=\"line\">        persistentVolumeClaim:</span><br><span class=\"line\">          claimName: minio-pvc</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-service</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">    type: NodePort </span><br><span class=\"line\">    selector:     </span><br><span class=\"line\">      app: minio</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - name: console</span><br><span class=\"line\">      port: 9090</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 9090</span><br><span class=\"line\">      nodePort: 30300</span><br><span class=\"line\">    - name: api</span><br><span class=\"line\">      port: 9000</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 9000</span><br><span class=\"line\">      nodePort: 30200</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f minio.yaml </span><br><span class=\"line\">deployment.apps/minio created</span><br><span class=\"line\">service/minio-service created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用NodePort方式访问web页面</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# kubectl get pod -n minio </span><br><span class=\"line\">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">minio-86577f8755-l65mf   1/1     Running   0          11m</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get svc -n minio </span><br><span class=\"line\">NAME            TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE</span><br><span class=\"line\">minio-service   NodePort   10.102.223.132   &lt;none&gt;        9090:30300/TCP,9000:30200/TCP   10m</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">访问k8s节点ip:30300，默认用户名密码都是**</font><font style=\"background-color:rgba(255, 255, 255, 0);\">admin</font><font style=\"background-color:rgba(255, 255, 255, 0);\">**</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811336392-f240e346-f3cc-41d9-8b16-5c003a092099.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用ingress方式访问</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat minio-ingress.yaml</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-console</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio.test.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio-service  # 与svc的name一致</span><br><span class=\"line\">        port: 9090           # 与svc的port一致</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.io/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-api</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio-api.test.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio-service  # 与svc的name一致</span><br><span class=\"line\">        port: 9000           # 与svc的port一致</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f minio-ingress.yaml </span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-console created</span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-api created</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">添加hosts记录</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;192.168.10.10 minio.test.com&lt;/font&gt;</code><font style=\"background-color:rgba(255, 255, 255, 0);\">访问域名即可</font></p>\n<h1 id=\"7f042bda\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO集群</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">minIO集群方式部署使用operator或者helm均可。如果是一套 k8s 集群部署一套 minio 推荐 shiyonghelm 方式部署，operator 更适合多套 minio 集群多租户场景使用。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">helm部署minIO参考文档：</font><a href=\"https://artifacthub.io/packages/helm/bitnami/minio\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://artifacthub.io/packages/helm/bitnami/minio</font></a><font style=\"background-color:rgba(255, 255, 255, 0);\">。</font></p>\n<h2 id=\"afac90af\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群角色规划</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">使用分布式方式部署高可用的minIO集群时，驱动器总数至少是4 个，以保证纠删码。我们可以在k8s-work1和k8s-work2上的data1和data2路径存放minIO数据，使用local pv方式持久化数据。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建数据存放路径</span><br><span class=\"line\">[root@k8s-work1 ~]# mkdir -p /data1/minio</span><br><span class=\"line\">[root@k8s-work1 ~]# mkdir -p /data2/minio</span><br><span class=\"line\">[root@k8s-work2 ~]# mkdir -p /data1/minio</span><br><span class=\"line\">[root@k8s-work2 ~]# mkdir -p /data2/minio</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"73285e10\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载helm包</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class=\"line\">[root@k8s-master ~]# helm search repo minio</span><br><span class=\"line\">NAME                            CHART VERSION   APP VERSION     DESCRIPTION                                       </span><br><span class=\"line\">bitnami/minio                   14.1.4          2024.3.30       MinIO(R) is an object storage server, compatibl...</span><br><span class=\"line\">[root@k8s-master ~]# helm pull bitnami/minio --untar </span><br><span class=\"line\">[root@k8s-master ~]# cd minio</span><br><span class=\"line\">[root@k8s-master minio]# ls</span><br><span class=\"line\">Chart.lock  charts  Chart.yaml  README.md  templates  values.yaml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"b19846a6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建sc</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">provisioner 字段定义为 no-provisioner，这是因为 Local Persistent Volume 目前尚不支持 Dynamic Provisioning 动态生成 PV，所以我们需要提前手动创建 PV。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">volumeBindingMode 字段定义为 WaitForFirstConsumer，它是 Local Persistent Volume 里一个非常重要的特性，即：延迟绑定。延迟绑定就是在我们提交 PVC 文件时，StorageClass 为我们延迟绑定 PV 与 PVC 的对应关系。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat &gt; storageClass.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: storage.k8s.io/v1</span><br><span class=\"line\">kind: StorageClass</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: local-storage</span><br><span class=\"line\">provisioner: kubernetes.io/no-provisioner</span><br><span class=\"line\">volumeBindingMode: WaitForFirstConsumer</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f storageClass.yaml </span><br><span class=\"line\">storageclass.storage.k8s.io/local-storage created</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get storageclass</span><br><span class=\"line\">NAME                  PROVISIONER                                         RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span><br><span class=\"line\">local-storage         kubernetes.io/no-provisioner                        Delete          WaitForFirstConsumer   false                  19s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"33e882bc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pv</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">pv资源分布如下：</font>\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">pv名称</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">pvc名称</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">主机</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">路径</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">容量</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-0</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data1&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work1</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data2&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv3</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data1&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">minio-pv4</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">data-minio-3</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">work2</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">&#x2F;data2&#x2F;minio</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">10G</font></td>\n</tr>\n</tbody></table>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat &gt; pv.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv1</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-0</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage # storageClass名称，与前面创建的storageClass保持一致</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data1/minio # 本地存储路径</span><br><span class=\"line\">  nodeAffinity: # 调度至work1节点</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv2</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-1</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data2/minio</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv3</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-2</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data1/minio</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work2</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolume</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-pv4</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio-3</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  capacity:</span><br><span class=\"line\">    storage: 10Gi</span><br><span class=\"line\">  volumeMode: Filesystem</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  local:</span><br><span class=\"line\">    path: /data2/minio</span><br><span class=\"line\">  nodeAffinity:</span><br><span class=\"line\">    required:</span><br><span class=\"line\">      nodeSelectorTerms:</span><br><span class=\"line\">      - matchExpressions:</span><br><span class=\"line\">        - key: kubernetes.io/hostname</span><br><span class=\"line\">          operator: In</span><br><span class=\"line\">          values:</span><br><span class=\"line\">          - work2</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@master1 minio]# kubectl apply -f pv.yaml </span><br><span class=\"line\">persistentvolume/minio-pv1 created</span><br><span class=\"line\">persistentvolume/minio-pv2 created</span><br><span class=\"line\">persistentvolume/minio-pv3 created</span><br><span class=\"line\">persistentvolume/minio-pv4 created</span><br><span class=\"line\">[root@master1 minio]# kubectl get pv | grep minio</span><br><span class=\"line\">minio-pv1                                  10Gi       RWO            Delete           Bound    minio/data-minio-1                              local-storage            9s</span><br><span class=\"line\">minio-pv2                                  10Gi       RWO            Delete           Bound    minio/data-minio-2                              local-storage            9s</span><br><span class=\"line\">minio-pv3                                  10Gi       RWO            Delete           Bound    minio/data-minio-3                              local-storage            9s</span><br><span class=\"line\">minio-pv4                                  10Gi       RWO            Delete           Bound    minio/data-minio-0                              local-storage            9s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"892d3960\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建pvc</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建的时候注意pvc的名字的构成：pvc的名字 &#x3D; volume_name-statefulset_name-序号，然后通过selector标签选择，强制将pvc与pv绑定。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# cat &gt; pvc.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-0</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-0</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-1</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-1</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-2</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-2</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: PersistentVolumeClaim</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: data-minio-3</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  accessModes:</span><br><span class=\"line\">  - ReadWriteOnce</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">    requests:</span><br><span class=\"line\">      storage: 10Gi</span><br><span class=\"line\">  storageClassName: local-storage</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      app: minio-3</span><br><span class=\"line\">EOF</span><br><span class=\"line\">[root@tiaoban minio]# kubectl create ns minio</span><br><span class=\"line\">namespace/minio created</span><br><span class=\"line\">[root@tiaoban minio]# kubectl apply -f pvc.yaml </span><br><span class=\"line\">persistentvolumeclaim/data-minio-0 created</span><br><span class=\"line\">persistentvolumeclaim/data-minio-1 created</span><br><span class=\"line\">persistentvolumeclaim/data-minio-2 created</span><br><span class=\"line\">persistentvolumeclaim/data-minio-3 created</span><br><span class=\"line\">[root@tiaoban minio]# kubectl get pvc -n minio</span><br><span class=\"line\">NAME           STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS    AGE</span><br><span class=\"line\">data-minio-0   Pending                                      local-storage   13s</span><br><span class=\"line\">data-minio-1   Pending                                      local-storage   13s</span><br><span class=\"line\">data-minio-2   Pending                                      local-storage   13s</span><br><span class=\"line\">data-minio-3   Pending                                      local-storage   13s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2e4b9b00\"><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置values.yaml</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">68 image:</span><br><span class=\"line\">69   registry: docker.io</span><br><span class=\"line\">70   repository: bitnami/minio</span><br><span class=\"line\">71   tag: 2024.3.30-debian-12-r0</span><br><span class=\"line\">  </span><br><span class=\"line\">104 mode: distributed # 集群模式，单节点为standalone，分布式集群为distributed</span><br><span class=\"line\"></span><br><span class=\"line\">197 statefulset:</span><br><span class=\"line\">215  replicaCount: 2 # 节点数</span><br><span class=\"line\">218   zones: 1 # 区域数，1个即可</span><br><span class=\"line\">221   drivesPerNode: 2 # 每个节点数据目录数.2节点×2目录组成4节点的mimio集群</span><br><span class=\"line\"></span><br><span class=\"line\">558 #podAnnotations: &#123;&#125; # 导出Prometheus指标</span><br><span class=\"line\">559 podAnnotations:</span><br><span class=\"line\">560   prometheus.io/scrape: &quot;true&quot;</span><br><span class=\"line\">561   prometheus.io/path: &quot;/minio/v2/metrics/cluster&quot;</span><br><span class=\"line\">562   prometheus.io/port: &quot;9000&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">1049 persistence:</span><br><span class=\"line\">1052   enabled: true</span><br><span class=\"line\">1060   storageClass: &quot;local-storage&quot;</span><br><span class=\"line\">1063   mountPath: /bitnami/minio/data</span><br><span class=\"line\">1066   accessModes:</span><br><span class=\"line\">1067     - ReadWriteOnce</span><br><span class=\"line\">1070   size: 10Gi</span><br><span class=\"line\">1073   annotations: &#123;&#125;</span><br><span class=\"line\">1076   existingClaim: &quot;&quot;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"oFNWc\"><font style=\"background-color:rgba(255, 255, 255, 0);\">部署minIO</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# kubectl create ns minio</span><br><span class=\"line\">[root@k8s-master minio]# helm install minio . -f values.yaml -n minio</span><br><span class=\"line\">NAME: minio</span><br><span class=\"line\">LAST DEPLOYED: Tue Apr  2 22:28:03 2024</span><br><span class=\"line\">NAMESPACE: minio</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">CHART NAME: minio</span><br><span class=\"line\">CHART VERSION: 14.1.4</span><br><span class=\"line\">APP VERSION: 2024.3.30</span><br><span class=\"line\"></span><br><span class=\"line\">** Please be patient while the chart is being deployed **</span><br><span class=\"line\"></span><br><span class=\"line\">MinIO&amp;reg; can be accessed via port  on the following DNS name from within your cluster:</span><br><span class=\"line\"></span><br><span class=\"line\">   minio.minio.svc.cluster.local</span><br><span class=\"line\"></span><br><span class=\"line\">To get your credentials run:</span><br><span class=\"line\"></span><br><span class=\"line\">   export ROOT_USER=$(kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-user&#125;&quot; | base64 -d)</span><br><span class=\"line\">   export ROOT_PASSWORD=$(kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-password&#125;&quot; | base64 -d)</span><br><span class=\"line\"></span><br><span class=\"line\">To connect to your MinIO&amp;reg; server using a client:</span><br><span class=\"line\"></span><br><span class=\"line\">- Run a MinIO&amp;reg; Client pod and append the desired command (e.g. &#x27;admin info&#x27;):</span><br><span class=\"line\"></span><br><span class=\"line\">   kubectl run --namespace minio minio-client \\</span><br><span class=\"line\">     --rm --tty -i --restart=&#x27;Never&#x27; \\</span><br><span class=\"line\">     --env MINIO_SERVER_ROOT_USER=$ROOT_USER \\</span><br><span class=\"line\">     --env MINIO_SERVER_ROOT_PASSWORD=$ROOT_PASSWORD \\</span><br><span class=\"line\">     --env MINIO_SERVER_HOST=minio \\</span><br><span class=\"line\">     --image docker.io/bitnami/minio-client:2024.3.30-debian-12-r0 -- admin info minio</span><br><span class=\"line\"></span><br><span class=\"line\">To access the MinIO&amp;reg; web UI:</span><br><span class=\"line\"></span><br><span class=\"line\">- Get the MinIO&amp;reg; URL:</span><br><span class=\"line\"></span><br><span class=\"line\">   echo &quot;MinIO&amp;reg; web URL: http://127.0.0.1:9001/minio&quot;</span><br><span class=\"line\">   kubectl port-forward --namespace minio svc/minio 9001:9001</span><br><span class=\"line\"></span><br><span class=\"line\">WARNING: There are &quot;resources&quot; sections in the chart not set. Using &quot;resourcesPreset&quot; is not recommended for production. For production installations, please set the following values according to your workload needs:</span><br><span class=\"line\">  - resources</span><br><span class=\"line\">+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e71d7ced\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看资源信息</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# kubectl get all -n minio </span><br><span class=\"line\">NAME          READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">pod/minio-0   1/1     Running   0          15s</span><br><span class=\"line\">pod/minio-1   1/1     Running   0          15s</span><br><span class=\"line\">pod/minio-2   1/1     Running   0          15s</span><br><span class=\"line\">pod/minio-3   1/1     Running   0          14s</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">service/minio            ClusterIP   10.106.74.147   &lt;none&gt;        9000/TCP,9001/TCP   15s</span><br><span class=\"line\">service/minio-headless   ClusterIP   None            &lt;none&gt;        9000/TCP,9001/TCP   15s</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                     READY   AGE</span><br><span class=\"line\">statefulset.apps/minio   4/4     15s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3dcf82cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以ingrss-nginx为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># cat &gt; ingress.yaml &lt;&lt; EOF</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-ingreess</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: minio.local.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: minio</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 9001</span><br><span class=\"line\">EOF</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以traefik为例：</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# cat ingress.yaml </span><br><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-console</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio  # 与svc的name一致</span><br><span class=\"line\">        port: 9001      # 与svc的port一致</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-api</span><br><span class=\"line\">  namespace: minio</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio-api.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: minio  # 与svc的name一致</span><br><span class=\"line\">        port: 9000      # 与svc的port一致</span><br><span class=\"line\">[root@k8s-master minio]# kubectl apply -f ingress.yaml </span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-console created</span><br><span class=\"line\">ingressroute.traefik.containo.us/minio-api created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"94d6e340\"><font style=\"background-color:rgba(255, 255, 255, 0);\">获取用户名密码</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 获取用户名和密码</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-user&#125;&quot; | base64 -d</span><br><span class=\"line\">admin</span><br><span class=\"line\">[root@k8s-master minio]# kubectl get secret --namespace minio minio -o jsonpath=&quot;&#123;.data.root-password&#125;&quot; | base64 -d</span><br><span class=\"line\">HWLLGMhgkp</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"218f27d6\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问web管理页</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811583730-920d29c1-0cb8-4123-9787-99a2b32fdade.jpeg)\n\n<h1 id=\"c34d22c4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">operator部署minIO</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font><a href=\"https://min.io/docs/minio/kubernetes/upstream/operations/installation.html\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://min.io/docs/minio/kubernetes/upstream/operations/installation.html</font></a></p>\n<h2 id=\"5ef4b236\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装operator</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# helm repo add minio-operator https://operator.min.io</span><br><span class=\"line\">&quot;minio-operator&quot; has been added to your repositories</span><br><span class=\"line\">[root@master1 ~]# helm search repo minio-operator</span><br><span class=\"line\">NAME                            CHART VERSION   APP VERSION     DESCRIPTION                    </span><br><span class=\"line\">minio-operator/minio-operator   4.3.7           v4.3.7          A Helm chart for MinIO Operator</span><br><span class=\"line\">minio-operator/operator         5.0.14          v5.0.14         A Helm chart for MinIO Operator</span><br><span class=\"line\">minio-operator/tenant           5.0.14          v5.0.14         A Helm chart for MinIO Operator</span><br><span class=\"line\">[root@master1 ~]# helm install \\</span><br><span class=\"line\">--namespace minio-operator \\</span><br><span class=\"line\">--create-namespace \\</span><br><span class=\"line\">operator minio-operator/operator</span><br><span class=\"line\">NAME: operator</span><br><span class=\"line\">LAST DEPLOYED: Sun Mar 24 21:47:05 2024</span><br><span class=\"line\">NAMESPACE: minio-operator</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">1. Get the JWT for logging in to the console:</span><br><span class=\"line\">kubectl apply -f - &lt;&lt;EOF</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Secret</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: console-sa-secret</span><br><span class=\"line\">  namespace: minio-operator</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    kubernetes.io/service-account.name: console-sa</span><br><span class=\"line\">type: kubernetes.io/service-account-token</span><br><span class=\"line\">EOF</span><br><span class=\"line\">kubectl -n minio-operator get secret console-sa-secret -o jsonpath=&quot;&#123;.data.token&#125;&quot; | base64 --decode</span><br><span class=\"line\"></span><br><span class=\"line\">2. Get the Operator Console URL by running these commands:</span><br><span class=\"line\">  kubectl --namespace minio-operator port-forward svc/console 9090:9090</span><br><span class=\"line\">  echo &quot;Visit the Operator Console at http://127.0.0.1:9090&quot;</span><br><span class=\"line\">[root@master1 ~]# kubectl get all -n minio-operator</span><br><span class=\"line\">NAME                                  READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">console-658c74c776-mjdq7              1/1     Running   0          3m</span><br><span class=\"line\">minio-operator-5fb5486696-b494r       1/1     Running   0          3m</span><br><span class=\"line\">minio-operator-5fb5486696-txds7       1/1     Running   0          3m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">service/console    ClusterIP   10.98.101.3     &lt;none&gt;        9090/TCP,9443/TCP   6s</span><br><span class=\"line\">service/operator   ClusterIP   10.100.70.152   &lt;none&gt;        4221/TCP            6s</span><br><span class=\"line\">service/sts        ClusterIP   10.109.22.187   &lt;none&gt;        4223/TCP            6s</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                             READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class=\"line\">deployment.apps/console          1/1     1            1           39m</span><br><span class=\"line\">deployment.apps/minio-operator   2/2     2            2           39m</span><br><span class=\"line\"></span><br><span class=\"line\">NAME                                        DESIRED   CURRENT   READY   AGE</span><br><span class=\"line\">replicaset.apps/console-59cbf8fbfb          1         1         1       6s</span><br><span class=\"line\">replicaset.apps/minio-operator-6868bf476d   2         2         2       6s</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4a9f317f\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制台</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建ingress资源，以traefik为例</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: traefik.containo.us/v1alpha1</span><br><span class=\"line\">kind: IngressRoute</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-console</span><br><span class=\"line\">  namespace: minio-operator</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  entryPoints:</span><br><span class=\"line\">  - web</span><br><span class=\"line\">  routes:</span><br><span class=\"line\">  - match: Host(`minio.local.com`) # 域名</span><br><span class=\"line\">    kind: Rule</span><br><span class=\"line\">    services:</span><br><span class=\"line\">      - name: console  # 与svc的name一致</span><br><span class=\"line\">        port: 9090      # 与svc的port一致</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">获取token</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban minio]# kubectl get secret/console-sa-secret -n minio-operator -o json | jq -r &quot;.data.token&quot; | base64 -d</span><br><span class=\"line\">eyJhbGciOiJSUzI1NiIsImtpZCI6IkJqajJ5XzA1LTdjWmhWWTJhUWdtNW5pMHJsejI4Z0d5MjlsWHg1YjF3NG8ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJtaW5pby1vcGVyYXRvciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjb25zb2xlLXNhLXNlY3JldCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJjb25zb2xlLXNhIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiZTA2NmRjOTQtMmI5NS00ODllLTk1MzQtNDdjNTY5MzI0YjQxIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Om1pbmlvLW9wZXJhdG9yOmNvbnNvbGUtc2EifQ.0828UMXxhkESZtTo6xUtJRDqHf8ksVNGUVOZas7dIMCPeF9Z2nLZDySMFXBc4qYUb-qGEw5YT0JYxhz_B82Cy-Lg05RaawCmFWlf4Q5O57xdOZ66sUJffRNprqd4uzLejvirtwgzpD6ddiIg4HVN107VIy--S-A-OTbvbrSWtO95GIu4eNG5pM0YALrYAXPuDbBzRsQ9DHjH9dEoXsJW_yhwmlMoIm4Qi4RR4SSRBuVVRvU38DGvg2eZjveSDDJiozOLuGvw3HTPHuamdneEpdfQzCysMEkUm0eZa_uG-5aoSINd7peB9CBPkSx91tM3aX4E1lyN6Q5SVmr3v7o31w</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">浏览器访问minio</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811639483-67b3a890-3f91-4c28-9417-156359fc770f.jpeg\"></p>\n<h2 id=\"18531cb0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">helm创建租户</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">拉取helm包</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 ~]# helm pull minio-operator/tenant --untar </span><br><span class=\"line\">[root@master1 ~]# cd tenant/</span><br><span class=\"line\">[root@master1 tenant]# ls</span><br><span class=\"line\">Chart.yaml  README.md  templates  values.yaml</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">修改values.yaml</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">39 tenant:</span><br><span class=\"line\">44   name: k8s-minio</span><br><span class=\"line\"></span><br><span class=\"line\">68   image:</span><br><span class=\"line\">69     repository: harbor.local.com/minio</span><br><span class=\"line\">70     tag: RELEASE.2024-03-21T23-13-43Z</span><br><span class=\"line\"></span><br><span class=\"line\">91   pools:</span><br><span class=\"line\">96     - servers: 4            # 服务器数</span><br><span class=\"line\">102      volumesPerServer: 1   # 每个服务器节点数</span><br><span class=\"line\">105      size: 10Gi            # 每个节点大小</span><br><span class=\"line\">112      storageClassName: local-storage</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">安装helm</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 tenant]# helm install tenant . -f values.yaml -n minio</span><br><span class=\"line\">NAME: tenant</span><br><span class=\"line\">LAST DEPLOYED: Sun Mar 24 23:12:11 2024</span><br><span class=\"line\">NAMESPACE: minio</span><br><span class=\"line\">STATUS: deployed</span><br><span class=\"line\">REVISION: 1</span><br><span class=\"line\">TEST SUITE: None</span><br><span class=\"line\">NOTES:</span><br><span class=\"line\">To connect to the k8s-minio tenant if it doesn&#x27;t have a service exposed, you can port-forward to it by running:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubectl --namespace minio port-forward svc/k8s-minio-console 9443:9443</span><br><span class=\"line\"></span><br><span class=\"line\">  Then visit the MinIO Console at https://127.0.0.1:9443</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"63da7cbb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web页面创建租户</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811692573-08170951-d860-4858-8885-f4f759e1b31b.jpeg)\n\n<h1 id=\"0e6b9bf9\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus Operator添加监控</font></h1>\n---\n\n<h2 id=\"23493e2c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问metrics接口验证</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# kubectl get svc -n minio </span><br><span class=\"line\">NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">minio            ClusterIP   10.103.75.63   &lt;none&gt;        9000/TCP,9001/TCP   71m</span><br><span class=\"line\">minio-headless   ClusterIP   None           &lt;none&gt;        9000/TCP,9001/TCP   71m</span><br><span class=\"line\">[root@rocky /]# curl http://10.103.75.63:9000/minio/v2/metrics/cluster</span><br><span class=\"line\"># HELP minio_audit_failed_messages Total number of messages that failed to send since start</span><br><span class=\"line\"># TYPE minio_audit_failed_messages counter</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-0.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-1.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-2.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_failed_messages&#123;server=&quot;minio-3.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\"># HELP minio_audit_target_queue_length Number of unsent messages in queue for target</span><br><span class=\"line\"># TYPE minio_audit_target_queue_length gauge</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-0.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-1.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-2.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">minio_audit_target_queue_length&#123;server=&quot;minio-3.minio-headless.minio.svc.cluster.local:9000&quot;,target_id=&quot;sys_console_0&quot;&#125; 0</span><br><span class=\"line\">…………</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4954f1e7\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增svc标签</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# kubectl edit svc -n minio minio</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Service</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    meta.helm.sh/release-name: minio</span><br><span class=\"line\">    meta.helm.sh/release-namespace: minio</span><br><span class=\"line\">  creationTimestamp: &quot;2024-03-24T07:52:49Z&quot;</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: minio # 新增labels标签</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"7c5a5aba\"><font style=\"background-color:rgba(255, 255, 255, 0);\">新增ServiceMonitor</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master1 minio]# cat ServiceMonitor.yaml</span><br><span class=\"line\">apiVersion: monitoring.coreos.com/v1</span><br><span class=\"line\">kind: ServiceMonitor</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: minio-exporter  # ServiceMonitor名称</span><br><span class=\"line\">  namespace: monitoring # ServiceMonitor所在名称空间</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  jobLabel: minio # job名称</span><br><span class=\"line\">  endpoints:  # prometheus所采集Metrics地址配置，endpoints为一个数组，可以创建多个，但是每个endpoints包含三个字段interval、path、port</span><br><span class=\"line\">    - interval: 30s # prometheus采集数据的周期，单位为秒</span><br><span class=\"line\">      path: /minio/v2/metrics/cluster # prometheus采集数据的路径</span><br><span class=\"line\">      port: minio-api # prometheus采集数据的端口，这里为port的name，主要是通过spec.selector中选择对应的svc，在选中的svc中匹配该端口</span><br><span class=\"line\">      scheme: http # 协议</span><br><span class=\"line\">  namespaceSelector: # 需要发现svc的范围</span><br><span class=\"line\">    matchNames:</span><br><span class=\"line\">    - minio</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:  # 选择svc的标签</span><br><span class=\"line\">      app: minio</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"13a63e45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Prometheus targets验证</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811750733-0d85b71e-0041-4bba-9fdf-8db6370c296f.jpeg\"></p>\n<h1 id=\"ed9e439c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">minIO使用</font></h1>\n---\n\n<h2 id=\"8f89c55c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建bucket</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811763767-c3ad368b-263f-46ce-90c4-40cbe4ccdad8.jpeg)\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811768940-3e2cd95f-1090-4378-bde4-a539b48f56b8.jpeg\"></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811774668-16a9ae87-385a-4bbb-b853-6c4288d3b60c.jpeg\"></p>\n<h2 id=\"812ce170\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建Access Keys</font></h2>\n---\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811794794-53fd8172-ad1f-42ab-8671-ef20cc41f499.jpeg\"></p>\n<h2 id=\"4abae06c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">创建访问控制权限</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">Minio 的存储桶默认是不跟任何 Acess Key 关联的，不过由于 Minio 支持标准的 S3 协议，我们可以给 Access Key 授予某个 Bucket 存储桶的访问权限，实现 Key 和 Bucket 的绑定。</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建policy</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811834692-a48aece0-9058-4cf9-becc-5961c28613b4.jpeg\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;Version&quot;: &quot;2012-10-17&quot;,</span><br><span class=\"line\">    &quot;Statement&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;Effect&quot;: &quot;Allow&quot;,</span><br><span class=\"line\">            &quot;Action&quot;: [</span><br><span class=\"line\">                &quot;s3:ListAllMyBuckets&quot;,</span><br><span class=\"line\">                &quot;s3:ListBucket&quot;,</span><br><span class=\"line\">                &quot;s3:GetBucketLocation&quot;,</span><br><span class=\"line\">                &quot;s3:GetObject&quot;,</span><br><span class=\"line\">                &quot;s3:PutObject&quot;,</span><br><span class=\"line\">                &quot;s3:DeleteObject&quot;</span><br><span class=\"line\">            ],</span><br><span class=\"line\">            &quot;Resource&quot;: [</span><br><span class=\"line\">                &quot;arn:aws:s3:::es-backup/*&quot;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">创建user</font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">这里 Access Key 是用户名，Access Secret 是对应的口令。设置时关联上刚才创建的 Policy 即可。</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737811879724-66f317e4-e8b0-48fa-ba59-f4664e59f4fd.jpeg\"></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">我们就创建了一个新的存储桶，并且给这个存储桶设置了一个用户，同时授权了用户对存储桶的访问，包括列表、上传、下载这几个基本权限。</font></p>\n<h1 id=\"522d049b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端使用</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">MinIO Client (mc)为ls，cat，cp，mirror，diff，find等UNIX命令提供了一种替代方案。它支持文件系统和兼容Amazon S3的云存储服务（AWS Signature v2和v4）。</font></p>\n<h2 id=\"e9f10274\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（Linux二进制文件）</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master minio]# curl https://dl.min.io/client/mc/release/linux-amd64/mc --create-dirs -o /usr/local/minio-binaries/mc</span><br><span class=\"line\">[root@k8s-master local]# cd /usr/local/minio-binaries</span><br><span class=\"line\">[root@k8s-master minio-binaries]# ls</span><br><span class=\"line\">mc</span><br><span class=\"line\">[root@k8s-master minio-binaries]# chmod +x mc </span><br><span class=\"line\">[root@k8s-master minio-binaries]# ./mc --help</span><br><span class=\"line\">──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc</span><br><span class=\"line\">NAME:                                                                              </span><br><span class=\"line\">  mc - MinIO Client for object storage and filesystems.                            </span><br><span class=\"line\">                                                                                   </span><br><span class=\"line\">USAGE:                                                                             </span><br><span class=\"line\">  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]</span><br><span class=\"line\"># 添加环境变量</span><br><span class=\"line\">[root@k8s-master minio-binaries]# cat /etc/profile</span><br><span class=\"line\">export PATH=&quot;$PATH:/usr/local/minio-binaries&quot;</span><br><span class=\"line\">[root@k8s-master minio-binaries]# source /etc/profile</span><br><span class=\"line\">[root@k8s-master minio-binaries]# mc --help</span><br><span class=\"line\">──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── (q)uit/esc</span><br><span class=\"line\">  mc [FLAGS] COMMAND [COMMAND FLAGS | -h] [ARGUMENTS...]</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2183de63\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装mc客户端（docker）</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# docker run -it --rm minio/mc ls play</span><br><span class=\"line\">mc: Configuration written to `/root/.mc/config.json`. Please update your access credentials.</span><br><span class=\"line\">mc: Successfully created `/root/.mc/share`.</span><br><span class=\"line\">mc: Initialized share uploads `/root/.mc/share/uploads.json` file.</span><br><span class=\"line\">mc: Initialized share downloads `/root/.mc/share/downloads.json` file.</span><br><span class=\"line\">[2023-04-13 01:39:27 UTC]     0B 64375d4bed2b146c15d5383f-files/</span><br><span class=\"line\">[2023-03-15 11:55:17 UTC]     0B abc/</span><br><span class=\"line\">[2023-03-31 18:46:54 UTC]     0B awdkenny/</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e2e248e4\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc客户端常用命令</font></h2>\n---\n\n<table>\n<thead>\n<tr>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">命令</font></strong></th>\n<th><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">功能</font></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">ls</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">列出文件和文件夹。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">mb</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">创建一个存储桶或一个文件夹。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">cat</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">显示文件和对象内容。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">pipe</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">将一个STDIN重定向到一个对象或者文件或者STDOUT。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">share</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">生成用于共享的URL。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">cp</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">拷贝文件和对象。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">mirror</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">给存储桶和文件夹做镜像。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">find</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">基于参数查找文件。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">diff</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">对两个文件夹或者存储桶比较差异。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">rm</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">删除文件和对象。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">events</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">管理对象通知。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">watch</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">监视文件和对象的事件。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">policy</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">管理访问策略。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">config</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">管理mc配置文件。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">update</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">检查软件更新。</font></td>\n</tr>\n<tr>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">version</font></td>\n<td><font style=\"background-color:rgba(255, 255, 255, 0);\">输出版本信息。</font></td>\n</tr>\n</tbody></table>\n<h2 id=\"d34f7a7e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">mc连接minIO服务</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 添加对象存储服务</span><br><span class=\"line\">[root@k8s-master minio-binaries]# mc alias set k8s-minio http://10.102.223.132:9000 minioadmin minioadmin</span><br><span class=\"line\">Added `k8s-minio` successfully.</span><br><span class=\"line\">[root@k8s-master minio-binaries]# mc admin info k8s-minio</span><br><span class=\"line\">●  10.102.223.132:9000</span><br><span class=\"line\">   Uptime: 41 minutes </span><br><span class=\"line\">   Version: 2023-04-07T05:28:58Z</span><br><span class=\"line\">   Network: 1/1 OK </span><br><span class=\"line\">   Drives: 1/1 OK </span><br><span class=\"line\">   Pool: 1</span><br><span class=\"line\"></span><br><span class=\"line\">Pools:</span><br><span class=\"line\">   1st, Erasure sets: 1, Drives per erasure set: 1</span><br><span class=\"line\"></span><br><span class=\"line\">12 MiB Used, 1 Bucket, 2 Objects</span><br><span class=\"line\">1 drive online, 0 drives offline</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"e67e6265\"><font style=\"background-color:rgba(255, 255, 255, 0);\">bucket操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 创建bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc mb k8s-minio/test</span><br><span class=\"line\">Bucket created successfully `k8s-minio/test`.</span><br><span class=\"line\"># 查看bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc ls k8s-minio</span><br><span class=\"line\">[2023-04-13 10:02:02 CST]     0B test/</span><br><span class=\"line\"></span><br><span class=\"line\"># 删除没有文件的bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc rb k8s-minio/demo</span><br><span class=\"line\"># 删除有文件的bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc rb k8s-minio/test --force</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"46cb4abb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传下载操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 上传文件到bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc cp /etc/hosts k8s-minio/test</span><br><span class=\"line\">/etc/hosts:                   2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.07 KiB/s 0s[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test</span><br><span class=\"line\"># 上传目录到bucket</span><br><span class=\"line\">[root@k8s-master ~]# mc cp /etc/yum.repos.d k8s-minio/test --recursive</span><br><span class=\"line\">...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.99 KiB/s 0s</span><br><span class=\"line\"></span><br><span class=\"line\"># 下载bucket文件到本地</span><br><span class=\"line\">[root@k8s-master ~]# mkdir /tmp/download</span><br><span class=\"line\">[root@k8s-master ~]# mc cp k8s-minio/test/hosts /tmp/download/</span><br><span class=\"line\">...2.223.132:9000/test/hosts: 2.09 KiB / 2.09 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.18 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/</span><br><span class=\"line\">hosts</span><br><span class=\"line\">[root@k8s-master ~]# cat /tmp/download/hosts </span><br><span class=\"line\">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class=\"line\">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class=\"line\"># 下载bucket目录到本地</span><br><span class=\"line\">[root@k8s-master ~]# mc cp k8s-minio/test/yum.repos.d /tmp/download/ --recursive</span><br><span class=\"line\">...m.repos.d/kubernetes.repo: 19.46 KiB / 19.46 KiB ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.10 KiB/s 0s[root@k8s-master ~]# ls /tmp/download/yum.repos.d/</span><br><span class=\"line\">docker-ce.repo     epel-testing-modular.repo  Rocky-AppStream.repo</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"52cefcb2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">文件操作</font></h2>\n---\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看bucket文件列表</span><br><span class=\"line\">[root@k8s-master ~]# mc ls k8s-minio/test</span><br><span class=\"line\">[2023-04-13 10:04:59 CST] 2.1KiB STANDARD hosts</span><br><span class=\"line\">[2023-04-13 10:10:42 CST]     0B yum.repos.d/</span><br><span class=\"line\"># 查看bucket目录内容</span><br><span class=\"line\">[root@k8s-master ~]# mc ls k8s-minio/test/yum.repos.d</span><br><span class=\"line\">[2023-04-13 10:05:34 CST]   710B STANDARD Rocky-AppStream.repo</span><br><span class=\"line\">[2023-04-13 10:05:34 CST]   695B STANDARD Rocky-BaseOS.repo</span><br><span class=\"line\">[2023-04-13 10:05:34 CST] 1.7KiB STANDARD Rocky-Debuginfo.repo</span><br><span class=\"line\">[2023-04-13 10:05:34 CST]   360B STANDARD Rocky-Devel.repo</span><br><span class=\"line\"># 查看bucket文件内容</span><br><span class=\"line\">[root@k8s-master ~]# mc cat k8s-minio/test/hosts</span><br><span class=\"line\">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class=\"line\">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class=\"line\"></span><br><span class=\"line\"># 删除文件</span><br><span class=\"line\">[root@k8s-master ~]# mc rm k8s-minio/test/hosts</span><br><span class=\"line\">Removed `k8s-minio/test/hosts`.</span><br><span class=\"line\"># 删除目录</span><br><span class=\"line\">[root@k8s-master ~]# mc rm k8s-minio/test/yum.repos.d --recursive --force</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-AppStream.repo`.</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-BaseOS.repo`.</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-Debuginfo.repo`.</span><br><span class=\"line\">Removed `k8s-minio/test/yum.repos.d/Rocky-Devel.repo`.</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"6506b326\"><font style=\"background-color:rgba(255, 255, 255, 0);\">curl客户端使用</font></h1>\n---\n\n<h2 id=\"a6fc9e3a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件脚本，按实际情况修改host、s3_key、s3_secret，其中192.168.10.10替换为客户端ip.</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat push.sh </span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">export PATH=$PATH:/bin:/usr/bin:/usr/local/bin</span><br><span class=\"line\">if [ $# != 2 ] ; then </span><br><span class=\"line\">echo &quot;Usage: `basename $0` my-bucket my-file.zip&quot; &gt;&amp;2</span><br><span class=\"line\">exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\">bucket=$1</span><br><span class=\"line\">file=$2</span><br><span class=\"line\">host=minio-api.test.com</span><br><span class=\"line\">s3_key=GfuHooI5byVpGf2RGwl3</span><br><span class=\"line\">s3_secret=YpYqXKKhI4bNUmWWULa3qf5n5WPq3TDedb1uzREc</span><br><span class=\"line\">resource=&quot;/$&#123;bucket&#125;/$&#123;file&#125;&quot;</span><br><span class=\"line\">content_type=&quot;application/zstd&quot;</span><br><span class=\"line\">date=`date -R`</span><br><span class=\"line\">_signature=&quot;PUT\\n\\n$&#123;content_type&#125;\\n$&#123;date&#125;\\n$&#123;resource&#125;&quot;</span><br><span class=\"line\">signature=`echo -en $&#123;_signature&#125; | openssl sha1 -hmac $&#123;s3_secret&#125; -binary | base64`</span><br><span class=\"line\"></span><br><span class=\"line\">curl -v -X PUT -T &quot;$&#123;file&#125;&quot; \\</span><br><span class=\"line\">          -H &quot;Host: $&#123;host&#125;&quot; \\</span><br><span class=\"line\">          -x &quot;192.168.10.10:80&quot; \\</span><br><span class=\"line\">          -H &quot;Date: $&#123;date&#125;&quot; \\</span><br><span class=\"line\">          -H &quot;Content-Type: $&#123;content_type&#125;&quot; \\</span><br><span class=\"line\">          -H &quot;Authorization: AWS $&#123;s3_key&#125;:$&#123;signature&#125;&quot; \\</span><br><span class=\"line\">          http://$&#123;host&#125;$&#123;resource&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">上传文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# ls</span><br><span class=\"line\">anaconda-ks.cfg  cfssl  defaults.ini  es  go  push.sh</span><br><span class=\"line\">[root@tiaoban ~]# ./push.sh test defaults.ini </span><br><span class=\"line\">*   Trying 192.168.10.10...</span><br><span class=\"line\">* TCP_NODELAY set</span><br><span class=\"line\">* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)</span><br><span class=\"line\">&gt; PUT http://minio-api.test.com/test/defaults.ini HTTP/1.1</span><br><span class=\"line\">&gt; Host: minio-api.test.com</span><br><span class=\"line\">&gt; User-Agent: curl/7.61.1</span><br><span class=\"line\">&gt; Accept: */*</span><br><span class=\"line\">&gt; Proxy-Connection: Keep-Alive</span><br><span class=\"line\">&gt; Date: Sat, 06 May 2023 10:10:07 +0800</span><br><span class=\"line\">&gt; Content-Type: application/zstd</span><br><span class=\"line\">&gt; Authorization: AWS bhUsp7nwc6XNPzoI:w2ddmcsQWOijC2BZJSGE4u7DgFc=</span><br><span class=\"line\">&gt; Content-Length: 55875</span><br><span class=\"line\">&gt; Expect: 100-continue</span><br><span class=\"line\">&gt; </span><br><span class=\"line\">&lt; HTTP/1.1 100 Continue</span><br><span class=\"line\">* We are completely uploaded and fine</span><br><span class=\"line\">&lt; HTTP/1.1 200 OK</span><br><span class=\"line\">&lt; Accept-Ranges: bytes</span><br><span class=\"line\">&lt; Content-Length: 0</span><br><span class=\"line\">&lt; Content-Security-Policy: block-all-mixed-content</span><br><span class=\"line\">&lt; Date: Sat, 06 May 2023 02:10:07 GMT</span><br><span class=\"line\">&lt; Etag: &quot;1b0bdd8f4c5f31ef5661380efcaefce5&quot;</span><br><span class=\"line\">&lt; Server: MinIO</span><br><span class=\"line\">&lt; Strict-Transport-Security: max-age=31536000; includeSubDomains</span><br><span class=\"line\">&lt; Vary: Origin</span><br><span class=\"line\">&lt; Vary: Accept-Encoding</span><br><span class=\"line\">&lt; X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855</span><br><span class=\"line\">&lt; X-Amz-Request-Id: 175C6BE8ACF79B53</span><br><span class=\"line\">&lt; X-Content-Type-Options: nosniff</span><br><span class=\"line\">&lt; X-Xss-Protection: 1; mode=block</span><br><span class=\"line\">&lt; </span><br><span class=\"line\">* Connection #0 to host 192.168.10.10 left intact</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看bucket文件</font></p>\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1737812117578-8097118f-4fd4-4847-b9c3-98f82d4e4579.jpeg\"></p>\n<h2 id=\"5dfd5a78\"><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font></h2>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/usr/bin/env sh</span><br><span class=\"line\">if [ $# != 3 ] ; then </span><br><span class=\"line\">echo &quot;Usage: `basename $0` my-bucket minio-filename localfile&quot; &gt;&amp;2</span><br><span class=\"line\">echo &quot;Usage: `basename $0` test-bucket 1.log /tmp/1.log&quot; &gt;&amp;2</span><br><span class=\"line\">exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\"># User Minio Vars</span><br><span class=\"line\">host=minio-api.test.com</span><br><span class=\"line\">s3_key=bhUsp7nwc6XNPzoI</span><br><span class=\"line\">s3_secret=w3KBPxMZ5Nw4apRGZY3uAHON7bkkKprP</span><br><span class=\"line\">BUCKET=$1</span><br><span class=\"line\">MINIO_PATH=&quot;/$&#123;BUCKET&#125;/$2&quot;</span><br><span class=\"line\">OUT_FILE=$3</span><br><span class=\"line\"># Static Vars</span><br><span class=\"line\">DATE=$(date -R)</span><br><span class=\"line\">CONTENT_TYPE=&#x27;application/zstd&#x27;</span><br><span class=\"line\">SIG_STRING=&quot;GET\\n\\n$&#123;CONTENT_TYPE&#125;\\n$&#123;DATE&#125;\\n$&#123;MINIO_PATH&#125;&quot;</span><br><span class=\"line\">SIGNATURE=`echo -en $&#123;SIG_STRING&#125; | openssl sha1 -hmac $&#123;s3_secret&#125; -binary | base64`</span><br><span class=\"line\"></span><br><span class=\"line\">curl -v -o &quot;$&#123;OUT_FILE&#125;&quot; \\</span><br><span class=\"line\">    -x &quot;192.168.10.10:80&quot; \\</span><br><span class=\"line\">    -H &quot;Host: $host&quot; \\</span><br><span class=\"line\">    -H &quot;Date: $&#123;DATE&#125;&quot; \\</span><br><span class=\"line\">    -H &quot;Content-Type: $&#123;CONTENT_TYPE&#125;&quot; \\</span><br><span class=\"line\">    -H &quot;Authorization: AWS $&#123;s3_key&#125;:$&#123;SIGNATURE&#125;&quot; \\</span><br><span class=\"line\">    http://$URL$&#123;MINIO_PATH&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">下载文件</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# ./pull.sh test defaults.ini /tmp/defaults.ini</span><br><span class=\"line\">*   Trying 192.168.10.10...</span><br><span class=\"line\">* TCP_NODELAY set</span><br><span class=\"line\">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class=\"line\">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class=\"line\">  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to 192.168.10.10 (192.168.10.10) port 80 (#0)</span><br><span class=\"line\">&gt; GET http://minio-api.test.com/test/defaults.ini HTTP/1.1</span><br><span class=\"line\">&gt; Host: minio-api.test.com</span><br><span class=\"line\">&gt; User-Agent: curl/7.61.1</span><br><span class=\"line\">&gt; Accept: */*</span><br><span class=\"line\">&gt; Proxy-Connection: Keep-Alive</span><br><span class=\"line\">&gt; Date: Sat, 06 May 2023 10:17:18 +0800</span><br><span class=\"line\">&gt; Content-Type: application/zstd</span><br><span class=\"line\">&gt; Authorization: AWS bhUsp7nwc6XNPzoI:sl8feCFiJC4MpaKSKrGU9HlDMLw=</span><br><span class=\"line\">&gt; </span><br><span class=\"line\">&lt; HTTP/1.1 200 OK</span><br><span class=\"line\">&lt; Accept-Ranges: bytes</span><br><span class=\"line\">&lt; Content-Length: 55875</span><br><span class=\"line\">&lt; Content-Security-Policy: block-all-mixed-content</span><br><span class=\"line\">&lt; Content-Type: application/zstd</span><br><span class=\"line\">&lt; Date: Sat, 06 May 2023 02:17:18 GMT</span><br><span class=\"line\">&lt; Etag: &quot;1b0bdd8f4c5f31ef5661380efcaefce5&quot;</span><br><span class=\"line\">&lt; Last-Modified: Sat, 06 May 2023 02:10:07 GMT</span><br><span class=\"line\">&lt; Server: MinIO</span><br><span class=\"line\">&lt; Strict-Transport-Security: max-age=31536000; includeSubDomains</span><br><span class=\"line\">&lt; Vary: Origin</span><br><span class=\"line\">&lt; Vary: Accept-Encoding</span><br><span class=\"line\">&lt; X-Amz-Id-2: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855</span><br><span class=\"line\">&lt; X-Amz-Request-Id: 175C6C4CF3EB56C4</span><br><span class=\"line\">&lt; X-Content-Type-Options: nosniff</span><br><span class=\"line\">&lt; X-Xss-Protection: 1; mode=block</span><br><span class=\"line\">&lt; </span><br><span class=\"line\">&#123; [3529 bytes data]</span><br><span class=\"line\">100 55875  100 55875    0     0  1474k      0 --:--:-- --:--:-- --:--:-- 1515k</span><br><span class=\"line\">* Connection #0 to host 192.168.10.10 left intact</span><br><span class=\"line\">[root@tiaoban ~]# ls -lh /tmp/defaults.ini </span><br><span class=\"line\">-rw-r--r-- 1 root root 55K 5月   6 10:17 /tmp/defaults.ini</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2025-03-30T10:39:36.452Z","updated":"2025-03-30T10:38:14.437Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjls000rtsv11nha88ur","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"Istio--安装部署","date":"2025-03-08T11:08:06.000Z","_content":"<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font>\n\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif)\n\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font>\n\n```bash\n$ curl -L https://istio.io/downloadIstio | sh -\n# 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3\n\n$ cd istio-1.7.3/\n# 输出环境变量, 以便直接使用\n$ export PATH=$PWD/bin:$PATH\n# 添加自动补全功能(需要子命令时按下TAB键激活)\n$ cp ./tools/istioctl.bash ~ && source ~/istioctl.bash\n# 安装demo配置\n$ istioctl manifest install --set profile=demo\n# 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：\n$ kubectl get svc -n istio-system\n# 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running\n$ kubectl get pods -n istio-system\n\n# 卸载\n$ istioctl manifest generate --set profile=demo | kubectl delete -f -\n```\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n","source":"_posts/Istio.md","raw":"---\ntitle: Istio--安装部署\ndate: 2025-03-08 19:08:06\n---\n<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font>\n\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n![](https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif)\n\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font>\n\n```bash\n$ curl -L https://istio.io/downloadIstio | sh -\n# 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3\n\n$ cd istio-1.7.3/\n# 输出环境变量, 以便直接使用\n$ export PATH=$PWD/bin:$PATH\n# 添加自动补全功能(需要子命令时按下TAB键激活)\n$ cp ./tools/istioctl.bash ~ && source ~/istioctl.bash\n# 安装demo配置\n$ istioctl manifest install --set profile=demo\n# 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：\n$ kubectl get svc -n istio-system\n# 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running\n$ kubectl get pods -n istio-system\n\n# 卸载\n$ istioctl manifest generate --set profile=demo | kubectl delete -f -\n```\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n","slug":"Istio","published":1,"updated":"2025-03-30T13:19:41.870Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlt000stsv11len65bc","content":"<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font></li>\n</ul>\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif\"></p>\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -L https://istio.io/downloadIstio | sh -</span><br><span class=\"line\"><span class=\"comment\"># 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> istio-1.7.3/</span><br><span class=\"line\"><span class=\"comment\"># 输出环境变量, 以便直接使用</span></span><br><span class=\"line\">$ <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PWD</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"comment\"># 添加自动补全功能(需要子命令时按下TAB键激活)</span></span><br><span class=\"line\">$ <span class=\"built_in\">cp</span> ./tools/istioctl.bash ~ &amp;&amp; <span class=\"built_in\">source</span> ~/istioctl.bash</span><br><span class=\"line\"><span class=\"comment\"># 安装demo配置</span></span><br><span class=\"line\">$ istioctl manifest install --<span class=\"built_in\">set</span> profile=demo</span><br><span class=\"line\"><span class=\"comment\"># 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：</span></span><br><span class=\"line\">$ kubectl get svc -n istio-system</span><br><span class=\"line\"><span class=\"comment\"># 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running</span></span><br><span class=\"line\">$ kubectl get pods -n istio-system</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 卸载</span></span><br><span class=\"line\">$ istioctl manifest generate --<span class=\"built_in\">set</span> profile=demo | kubectl delete -f -</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><a href=\"https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font></a></p>\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n","excerpt":"","more":"<h2 id=\"istio-简介\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 简介</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Connect, secure, control, and observe services.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">连接、安全加固、控制和观察服务的开放平台。</font></p>\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配；</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</font></li>\n</ul>\n<h2 id=\"service-mesh\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font></h2>\n`<font style=\"background-color:rgba(255, 255, 255, 0);\">Service Mesh</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">(服务网格)可以简单理解为</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">\"分布式代理\"</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">.</font>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/gif/43141749/1741444376203-46e720d6-3fb5-4672-b8ad-01e6eedd677f.gif\"></p>\n<h2 id=\"istio-架构\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 架构</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/svg/43141749/1741444377049-daa84c0b-0834-4f07-9510-5202b4a8617a.svg)\n\n<h2 id=\"istio-安装部署\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 安装部署</font></h2>\n<h3 id=\"使用istioctl安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">官方详细中文安装文档:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/install/istioctl/</font>](https://istio.io/latest/zh/docs/setup/install/istioctl/)\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下只记录相关命令:</font></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -L https://istio.io/downloadIstio | sh -</span><br><span class=\"line\"><span class=\"comment\"># 也可以从官方github仓库进行获取release包, https://github.com/istio/istio/releases/tag/1.7.3</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> istio-1.7.3/</span><br><span class=\"line\"><span class=\"comment\"># 输出环境变量, 以便直接使用</span></span><br><span class=\"line\">$ <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PWD</span>/bin:<span class=\"variable\">$PATH</span></span><br><span class=\"line\"><span class=\"comment\"># 添加自动补全功能(需要子命令时按下TAB键激活)</span></span><br><span class=\"line\">$ <span class=\"built_in\">cp</span> ./tools/istioctl.bash ~ &amp;&amp; <span class=\"built_in\">source</span> ~/istioctl.bash</span><br><span class=\"line\"><span class=\"comment\"># 安装demo配置</span></span><br><span class=\"line\">$ istioctl manifest install --<span class=\"built_in\">set</span> profile=demo</span><br><span class=\"line\"><span class=\"comment\"># 为了验证是否安装成功，需要先确保以下 Kubernetes 服务正确部署，然后验证除 jaeger-agent 服务外的其他服务，是否均有正确的 CLUSTER-IP：</span></span><br><span class=\"line\">$ kubectl get svc -n istio-system</span><br><span class=\"line\"><span class=\"comment\"># 请确保关联的 Kubernetes pod 已经部署，并且 STATUS 为 Running</span></span><br><span class=\"line\">$ kubectl get pods -n istio-system</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 卸载</span></span><br><span class=\"line\">$ istioctl manifest generate --<span class=\"built_in\">set</span> profile=demo | kubectl delete -f -</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"使用helm-chart安装\"><font style=\"background-color:rgba(255, 255, 255, 0);\">使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">helm chart</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装</font></h3>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">已被启用, 推荐使用</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">istioctl</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">安装.</font>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">部分内容筛选自:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font><a href=\"https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font></a></p>\n<h2 id=\"参考链接\"><font style=\"background-color:rgba(255, 255, 255, 0);\">参考链接</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Documentation:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/</font>](https://istio.io/latest/docs/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Arch:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/docs/ops/deployment/architecture/</font>](https://istio.io/latest/docs/ops/deployment/architecture/)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 入门:</font><font style=\"background-color:rgba(255, 255, 255, 0);\"> </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">Istio 是啥?一文带你彻底了解</font>](https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS8MgskBbNKMg1jd_UAgBBtBgbuW-CnWsI1qXa8Fplpd9M2HsHPtL_uGFwcB-LoRjg8V_MfAw8Wg3k70j_V31ZLuJMytP8qR2YRnycg--9VFPkkNS1gPt1QyTqAvLDpSkyT_ezw95tL17tyKO1qlVHvGS8DMVBk6NX30KCpE-80kRTqGhvjHCpURaK6ytIf8OgoTKJs_5u3vtMjWlhLQ8AEgCYioxHkzTmA..&type=2&query=istio&token=empty&k=91&h=L)\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Istio Installation: </font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://istio.io/latest/zh/docs/setup/getting-started/</font>](https://istio.io/latest/zh/docs/setup/getting-started/)\n\n"},{"title":"consul 入门服务注册中心","date":"2025-03-08T11:08:06.000Z","_content":"\n<h1 id=\"8519e085\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础概念</font></h1>\n---\n\n<h2 id=\"5e372583\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是注册中心</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着微服务理论发展的成熟，越来越多互联网公司采用微服务架构来支持业务发展。各个微服务之间都需要通过注册中心来实现自动化的注册和发现。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841329-403a2378-9696-4410-a98b-791e28e3ccf0.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">注册中心主要有三种角色：</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">服务提供者（RPC Server）</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 注册自身服务，并向 Registry 定期发送心跳汇报存活状态。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">服务消费者（RPC Client）</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 订阅服务，把 Registry 返回的服务节点列表缓存在本地内存中，并与 RPC Sever 建立连接。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册中心（Registry）</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：用于保存 RPC Server 的注册信息，当 RPC Server 节点发生变更时，Registry 会同步变更，RPC Client 感知后会刷新本地 内存中缓存的服务节点列表。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">最后，RPC Client 从本地缓存的服务节点列表中，基于负载均衡算法选择一台 RPC Sever 发起调用。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">目前常见的注册中心有Consul、ETCD、Zookeeper、Eureka、Nacos等。</font>\n\n<h2 id=\"9cfc6012\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是Consul</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul是HashiCorp公司推出的开源工具，Consul由Go语言开发，部署起来非常容易，只需要极少的可执行程序和配置文件，具有绿色、轻量级的特点。Consul是分布式的、高可用的、 可横向扩展的用于实现分布式系统的服务发现与配置。</font>\n\n<h2 id=\"22750ec8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现（Service Discovery）：Consul提供了通过DNS或者HTTP接口的方式来注册服务和发现服务。一些外部的服务通过Consul很容易的找到它所依赖的服务。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查（Health Checking）：Consul的Client可以提供任意数量的健康检查，既可以与给定的服务相关联(“webserver是否返回200 OK”)，也可以与本地节点相关联(“内存利用率是否低于90%”)。操作员可以使用这些信息来监视集群的健康状况，服务发现组件可以使用这些信息将流量从不健康的主机路由出去。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Key/Value存储：应用程序可以根据自己的需要使用Consul提供的Key/Value存储。 Consul提供了简单易用的HTTP接口，结合其他工具可以实现动态配置、功能标记、领袖选举等等功能。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全服务通信：Consul可以为服务生成和分发TLS证书，以建立相互的TLS连接。意图可用于定义允许哪些服务通信。服务分割可以很容易地进行管理，其目的是可以实时更改的，而不是使用复杂的网络拓扑和静态防火墙规则。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多数据中心：Consul支持开箱即用的多数据中心. 这意味着用户不需要担心需要建立额外的抽象层让业务扩展到多个区域。</font>\n\n<h2 id=\"73539e88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">consul组件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Agent：是在 Consul 集群的每个成员上长期运行的守护进程，通过命令 consul agent 启动运行。由于所有节点都必须运行一个 Agent，因此 Agent 可以分为 client 或 Server。所有的 Agent 都可以运行DNS或HTTP接口，并负责运行监测和保持服务同步</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Client：是将所有RPC转发到 Server 的 Agent。Client 是相对无状态的，Client 唯一执行的后台活动是加入 LAN gossip 池。这只有最小的资源开销，且只消耗少量的网络带宽</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Server：是一个有一组扩展功能的 Agent，这些功能包括参与 Raft 选举、维护集群状态、响应RPC查询、与其他数据中心交互 WAN gossip 和转发查询给 leader 或远程的数据中心</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Datacenter：是一个私有的、低延迟和高带宽的网络环境。这不包括通过公网的通信，但就目的而言，单个 EC2 中的多个可用区域被视为数据中心的一部分</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Consensus：一致性。Consul 使用 Consensus 协议（具体由 Raft 算法实现）来提供一致性（由 CAP 定义），表明 leader 选举和事务的顺序达成一致</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Gossip：Consul 使用 Gossip 协议来管理成员资格并向集群广播消息。Serf 提供了完整的 Gossip 协议，可用于多种目的，而 Consul 建立在 Serf 之上。Gossip 涉及节点到节点的随机通信，主要是通过UDP。Gossip 协议也被称为 Epidemic 协议（流行病协议）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">LAN Gossip：指包含所有位于同一局域网或数据中心的节点的 LAN gossip 池</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">WAN Gossip：指仅包含 Server 的 WAN gossip 池。这些 Server 主要分布在不同的数据中心，通常通过Internet或者广域网进行通信</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">RPC：远程过程调用。一种 请求/响应 机制，允许 Client 向 Server 发起请求</font>\n\n<h2 id=\"641185e8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 架构图</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841304-0599a640-bce7-44a1-8834-3b42cbe90ad9.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">每个为Consul提供服务的节点都会运行一个Consul Agent进程。运行代理不需要发现其他服务或获取/设置密钥/值数据。Agent负责对节点上的服务以及节点本身进行健康检查。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul Agent 分为两种模式， Server 和 Client模式，一般部署模型是 Server + Client的模式（当然也可以纯Server）, Server 具有Client的全部功能， 但是由于Server负责存储数据，并且强一致性模型的缘故， Server数是有限的（3-5个Server节点，Client可以无限扩展的）。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent与一个或多个Consul Server对话。Consul Server是</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">存储</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">和</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">复制数据</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">的地方。Server本身会选出一个Leader。虽然Consul可以用一台Server来运作，但建议使用3到5台，以避免故障情况导致数据丢失。建议每个数据中心采用Consul服务器集群。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Server Agent维护着一个目录（Catalog），这个目录（Catalog）是由Agent提交的信息汇总形成的。目录维护着集群的高层视图，包括哪些服务可用，哪些节点运行这些服务，健康信息等。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">需要发现其他服务或节点的基础结构组件可以查询任何Consul Server或任何Consul Agent。Agent将查询自动转发到Server。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent会自动将查询转发给Server Agent。 每个数据中心都运行一个Consul Server集群。当有跨数据中心的服务发现或配置请求时，本地Consul Server将请求转发到远程数据中心并返回结果。</font>\n\n<h2 id=\"236bb442\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的使用场景</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的应用场景包括服务发现、服务隔离、服务配置：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现场景中consul作为注册中心，服务地址被注册到consul中以后，可以使用consul提供的dns、http接口查询，consul支持health check。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务隔离场景中consul支持以服务为单位设置访问策略，能同时支持经典的平台和新兴的平台，支持tls证书分发，service-to-service加密。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务配置场景中consul提供key-value数据存储功能，并且能将变动迅速地通知出去，借助Consul可以实现配置共享，需要读取配置的服务可以从Consul中读取到准确的配置信息。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Consul可以帮助系统管理者更清晰的了解复杂系统内部的系统架构，运维人员可以将Consul看成一种监控软件，也可以看成一种资产（资源）管理系统。</font>\n\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/downloads?host=www.consul.io</font>](https://developer.hashicorp.com/consul/downloads?host=www.consul.io)\n\n<h2 id=\"62a5d2da\"><font style=\"background-color:rgba(255, 255, 255, 0);\">yum部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font>\n\n```plain\n[root@tiaoban ~]# yum install -y yum-utils\n[root@tiaoban ~]# yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo\n[root@tiaoban ~]# yum -y install consul\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font>\n\n```plain\n[root@tiaoban ~]# systemctl start consul\n[root@tiaoban ~]# systemctl enable consul\n```\n\n<h2 id=\"4443f491\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载</font>\n\n```plain\n[root@tiaoban ~]# mkdir consul\n[root@tiaoban ~]# cd consul/\n[root@tiaoban consul]# wget https://releases.hashicorp.com/consul/1.13.2/consul_1.13.2_linux_amd64.zip\n[root@tiaoban consul]# ls\nconsul_1.13.2_darwin_amd64.zip\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">解压安装</font>\n\n```plain\n[root@tiaoban consul]# unzip consul_1.13.2_linux_amd64.zip \nArchive:  consul_1.13.2_linux_amd64.zip\n  inflating: consul                  \n[root@tiaoban consul]# ls\nconsul  consul_1.13.2_linux_amd64.zip\n[root@tiaoban consul]# mv consul /usr/local/bin/\n[root@tiaoban consul]# consul version\nConsul v1.13.2\nRevision 0e046bbb\nBuild Date 2022-09-20T20:30:07Z\nProtocol 2 spoken by default, understands 2 to 3 (agent will automatically use protocol >2 when speaking to compatible agents)\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务测试  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">使用单节点模式启动测试</font>\n\n```plain\n[root@tiaoban consul]# consul agent -dev -ui -client 0.0.0.0\n```\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841427-2c5517e2-2c9f-4ae3-9048-de5811f58ea6.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">添加启动脚本</font>\n\n```plain\n[root@tiaoban ~]# cat /usr/lib/systemd/system/consul.service \n[Unit]\nDescription=consul\nAfter=network.target\n    \n[Service]\nExecStart=/usr/local/consul/start.sh\nKillSignal=SIGTERM\n    \n[Install]\nWantedBy=multi-user.target\n[root@tiaoban ~]# mkdir -p /usr/local/consul/\n[root@tiaoban ~]# cat /usr/local/consul/start.sh\n#!/bin/bash\n/usr/local/bin/consul agent -dev -ui -client 0.0.0.0\n[root@tiaoban ~]# chmod u+x /usr/local/consul/start.sh\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font>\n\n```plain\n[root@tiaoban ~]# systemctl daemon-reload \n[root@tiaoban ~]# systemctl start consul\n[root@tiaoban ~]# systemctl enable consul\n```\n\n<h1 id=\"b19ba4ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务启动</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作以yum方式安装consul配置为例，配置文件路径</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">/etc/consul.d/consul.hcl</font>`\n\n<h2 id=\"8c7054cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n```plain\n# 指明数据中心的名字\ndatacenter = \"my-dc-1\"\n# 存储状态的数据目录\ndata_dir = \"/opt/consul\"\n# web ui\nui_config{\n  enabled = true\n}\n# 节点是个Server\nserver = true\n# 绑定的一个地址，用于节点之间通信的地址\nbind_addr = \"192.168.10.100\"\n# 期望提供的Server节点数目\nbootstrap_expect=1\n# Client接口绑定到的地址\nclient_addr = \"0.0.0.0\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务，查看集群成员</font>\n\n```plain\n[root@tiaoban consul.d]# systemctl start consul\n[root@tiaoban consul.d]# consul members \nNode     Address              Status  Type    Build   Protocol  DC       Partition  Segment\ntiaoban  192.168.10.100:8301  alive   server  1.13.2  2         my-dc-1  default    <all>\n```\n\n<h2 id=\"6955953a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主机规划</font>\n\n| **主机名** | **IP** | **角色** |\n| --- | --- | --- |\n| k8s-master | 192.168.10.10 | server |\n| k8s-work1 | 192.168.10.11 | server |\n| k8s-work2 | 192.168.10.12 | server |\n| tiaoban | 192.168.10.100 | clinet |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">server端配置</font>\n\n```plain\n# 指明数据中心的名字\ndatacenter = \"my-dc-1\"\n# 存储状态的数据目录\ndata_dir = \"/opt/consul\"\n# web ui\nui_config{\n  enabled = true\n}\n# 节点是个Server\nserver = true\n# 绑定的一个地址，用于节点之间通信的地址。此处以192.168.10.10为例，其他两个更换ip即可。\nbind_addr = \"192.168.10.10\"\n# 期望提供的Server节点数目\nbootstrap_expect=3\n# Client接口绑定到的地址\nclient_addr = \"0.0.0.0\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font>\n\n```plain\n# 指明数据中心的名字\ndatacenter = \"my-dc-1\"\n# 存储状态的数据目录\ndata_dir = \"/opt/consul\"\n# web ui\nui_config{\n  enabled = true\n}\n# 节点是个Server\nserver = false\n# 绑定的一个地址，用于节点之间通信的地址\nbind_addr = \"192.168.10.100\"\n# Client接口绑定到的地址\nclient_addr = \"0.0.0.0\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并加入集群</font>\n\n```plain\n# 所有机器执行\n[root@k8s-master consul.d]# systemctl restart consul\n# 除了k8s-master以外的其他机器执行\n[root@k8s-tiaoban consul.d]# consul join 192.168.10.10\nSuccessfully joined cluster by contacting 1 nodes.\n```\n\n<h1 id=\"4b194b09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 常用CLI</font></h1>\n---\n\n<h2 id=\"eb75b9f5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font></h2>\n```plain\n[root@k8s-master ~]# consul catalog services\nconsul\ntraefik\ntraefik-tcp\n```\n\n<h2 id=\"75acbd2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注销服务</font></h2>\n```plain\nconsul services deregister -id=:service-id\n// :service-id 为用户服务Id\n```\n\n<h2 id=\"1b4e985d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点成员</font></h2>\n```plain\n[root@k8s-master ~]# consul members\nNode        Address              Status  Type    Build   Protocol  DC       Partition  Segment\nk8s-master  192.168.10.10:8301   alive   server  1.13.3  2         my-dc-1  default    <all>\nk8s-work1   192.168.10.11:8301   alive   server  1.13.3  2         my-dc-1  default    <all>\nk8s-work2   192.168.10.12:8301   alive   server  1.13.3  2         my-dc-1  default    <all>\ntiaoban     192.168.10.100:8301  alive   client  1.13.2  2         my-dc-1  default    <default>\n```\n\n<h2 id=\"1459fae8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看server节点信息</font></h2>\n```plain\n[root@k8s-master ~]# consul operator raft list-peers\nNode        ID                                    Address             State     Voter  RaftProtocol\nk8s-work1   322a522a-dcf5-3727-052e-0f2d65406f8d  192.168.10.11:8300  follower  true   3\nk8s-master  5db3c09a-f94d-b53f-6c9f-694beb64c1aa  192.168.10.10:8300  leader    true   3\nk8s-work2   d0e4a609-f029-cd91-1d61-63c3403b82b3  192.168.10.12:8300  follower  false  3\n```\n\n<h2 id=\"81ea3784\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul常用HTTP API</font></h2>\n<h2 id=\"3b842616\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/services：该端点返回在本地代理程序中注册的所有服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/{service_id}：返回在本地代理上注册的单个服务实例的完整服务定义；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/name/{service_name} ：通过名称检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/id/{service_id}：通过id检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/health/service/{service_name}?passing：通过健康检查的服务(包含未设置check的service)</font>\n\n<h2 id=\"f3bad82b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/register：注册服务；</font>\n\n<h2 id=\"18616023\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务删除</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/deregister/{service_id}：注销服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/maintenance/{service_id}：该端点将给定的服务置于“维护模式”，在维护模式下，该服务将被标记为不可用，并且不会出现在DNS或API查询中；</font>\n\n<h1 id=\"f3bad82b-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h1>\n---\n\n<h2 id=\"15c64aa0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">新增json配置文件</font>\n\n```plain\n[root@k8s-master consul.d]# cat /etc/consul.d/kube-apiserver.json \n{\n    \"service\": {\n        \"name\": \"traefik-tcp\",\n        \"tags\": [\n            \"k8s\",\"traefik\"\n        ],\n        \"address\": \"192.168.10.10\",\n        \"port\": 9100\n    }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重启服务</font>\n\n```plain\n[root@k8s-master consul.d]# systemctl restart consul\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841445-ed3d6655-6fda-49ac-88cb-19c119d5de0f.jpeg)\n\n<h2 id=\"http-api\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注册一个name为traefik的服务</font>\n\n```plain\n[root@k8s-master consul.d]# curl -X PUT -d '{\"name\": \"traefik\",\"address\": \"192.168.10.10\",\"port\": 80,\"tags\": [\"k8s\"]}' http://192.168.10.10:8500/v1/agent/service/register\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注册带健康检查的服务</font>\n\n```plain\ncurl -X PUT -d '{\"name\": \"traefik-metrics\",\"address\": \"192.168.10.10\",\"port\": 80,\"tags\": [\"k8s\"],\"checks\":[{\"http\":\"http://192.168.10.10:9100/metrics\",\"interval\":\"5s\"}]}' http://192.168.10.10:8500/v1/agent/service/register\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打开管理页面查看已注册的服务  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841454-78a08404-76de-44b8-8f10-689d9517273f.jpeg)\n\n<h2 id=\"sdk\"><font style=\"background-color:rgba(255, 255, 255, 0);\">SDK</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">除了采用配置文件或者HTTP API方式注册服务外，consul也支持使用sdk包注册查询服务，目前主流的开发语法均已支持，详情参考文档：  \n</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks</font>](https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks)\n\n<h1 id=\"3b842616-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h1>\n---\n\n<h2 id=\"http-api-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font>\n\n```plain\n[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/services | jq\n{\n  \"consul\": [],\n  \"traefik\": [\n    \"k8s\"\n  ],\n  \"traefik-tcp\": [\n    \"k8s\",\n    \"traefik\"\n  ]\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务详细信息</font>\n\n```plain\n[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/service/traefik | jq\n[\n  {\n    \"ID\": \"eda0ef7f-ca12-bbca-c84e-f88cc3664cd1\",\n    \"Node\": \"tiaoban\",\n    \"Address\": \"192.168.10.100\",\n    \"Datacenter\": \"my-dc-1\",\n    \"TaggedAddresses\": {\n      \"lan\": \"192.168.10.100\",\n      \"lan_ipv4\": \"192.168.10.100\",\n      \"wan\": \"192.168.10.100\",\n      \"wan_ipv4\": \"192.168.10.100\"\n    },\n    \"NodeMeta\": {\n      \"consul-network-segment\": \"\"\n    },\n    \"ServiceKind\": \"\",\n    \"ServiceID\": \"traefik\",\n    \"ServiceName\": \"traefik\",\n    \"ServiceTags\": [\n      \"k8s\"\n    ],\n    \"ServiceAddress\": \"192.168.10.10\",\n    \"ServiceTaggedAddresses\": {\n      \"lan_ipv4\": {\n        \"Address\": \"192.168.10.10\",\n        \"Port\": 80\n      },\n      \"wan_ipv4\": {\n        \"Address\": \"192.168.10.10\",\n        \"Port\": 80\n      }\n    },\n    \"ServiceWeights\": {\n      \"Passing\": 1,\n      \"Warning\": 1\n    },\n    \"ServiceMeta\": {},\n    \"ServicePort\": 80,\n    \"ServiceSocketPath\": \"\",\n    \"ServiceEnableTagOverride\": false,\n    \"ServiceProxy\": {\n      \"Mode\": \"\",\n      \"MeshGateway\": {},\n      \"Expose\": {}\n    },\n    \"ServiceConnect\": {},\n    \"CreateIndex\": 12,\n    \"ModifyIndex\": 12\n  }\n]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查</font>\n\n```plain\n[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/health/service/traefik?passing | jq\n[\n  {\n    \"Node\": {\n      \"ID\": \"eda0ef7f-ca12-bbca-c84e-f88cc3664cd1\",\n      \"Node\": \"tiaoban\",\n      \"Address\": \"192.168.10.100\",\n      \"Datacenter\": \"my-dc-1\",\n      \"TaggedAddresses\": {\n        \"lan\": \"192.168.10.100\",\n        \"lan_ipv4\": \"192.168.10.100\",\n        \"wan\": \"192.168.10.100\",\n        \"wan_ipv4\": \"192.168.10.100\"\n      },\n      \"Meta\": {\n        \"consul-network-segment\": \"\"\n      },\n      \"CreateIndex\": 9,\n      \"ModifyIndex\": 11\n    },\n    \"Service\": {\n      \"ID\": \"traefik\",\n      \"Service\": \"traefik\",\n      \"Tags\": [\n        \"k8s\"\n      ],\n      \"Address\": \"192.168.10.10\",\n      \"TaggedAddresses\": {\n        \"lan_ipv4\": {\n          \"Address\": \"192.168.10.10\",\n          \"Port\": 80\n        },\n        \"wan_ipv4\": {\n          \"Address\": \"192.168.10.10\",\n          \"Port\": 80\n        }\n      },\n      \"Meta\": null,\n      \"Port\": 80,\n      \"Weights\": {\n        \"Passing\": 1,\n        \"Warning\": 1\n      },\n      \"EnableTagOverride\": false,\n      \"Proxy\": {\n        \"Mode\": \"\",\n        \"MeshGateway\": {},\n        \"Expose\": {}\n      },\n      \"Connect\": {},\n      \"PeerName\": \"\",\n      \"CreateIndex\": 12,\n      \"ModifyIndex\": 12\n    },\n    \"Checks\": [\n      {\n        \"Node\": \"tiaoban\",\n        \"CheckID\": \"serfHealth\",\n        \"Name\": \"Serf Health Status\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Agent alive and reachable\",\n        \"ServiceID\": \"\",\n        \"ServiceName\": \"\",\n        \"ServiceTags\": [],\n        \"Type\": \"\",\n        \"Interval\": \"\",\n        \"Timeout\": \"\",\n        \"ExposedPort\": 0,\n        \"Definition\": {},\n        \"CreateIndex\": 9,\n        \"ModifyIndex\": 9\n      }\n    ]\n  }\n]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除注册的服务</font>\n\n```plain\n[root@k8s-master consul.d]# curl -X PUT http://192.168.10.10:8500/v1/agent/service/deregister/traefik\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h2 id=\"74c3df45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">DNS解析</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">DNS接口是Consul中主要的查询接口之一，另一个是HTTP接口， HTTP接口查询请查阅,Consul默认在8600端口监听DNS查询。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/docs/discovery/dns</font>](https://developer.hashicorp.com/consul/docs/discovery/dns)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">要使用DNS接口， 有几种方法可以实现：  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">一是使用指定的DNS解析库， 然后指向Consul；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">二是把Consul设置为节点的DNS服务器, 并且提供recursors配置项， 这样非Consul的查询也能被解析；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">最后一种方法是从已有的DNS服务器上把所有consul.为域名的请求转发到consul agent上。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">节点查找</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查找节点的地址信息，查找格式：<node>.node[.datacenter].<domain>。如果datacenter不指定，默认为当前集群查询。</font>\n\n```plain\n[root@k8s-master ~]# dig @192.168.10.10 -p 8600 tiaoban.node.consul ANY\n\n; <<>> DiG 9.11.26-RedHat-9.11.26-6.el8 <<>> @192.168.10.10 -p 8600 tiaoban.node.consul ANY\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 25684\n;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;tiaoban.node.consul.           IN      ANY\n\n;; ANSWER SECTION:\ntiaoban.node.consul.    0       IN      A       192.168.10.100\ntiaoban.node.consul.    0       IN      TXT     \"consul-network-segment=\"\n\n;; Query time: 14 msec\n;; SERVER: 192.168.10.10#8600(192.168.10.10)\n;; WHEN: 一 10月 31 10:51:10 CST 2022\n;; MSG SIZE  rcvd: 100\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">服务查找</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查询服务提供者。服务查询支持两种查找方法：标准和严格RFC 2782。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">标准查找格式：[tag.]<service>.service[.datacenter].<domain>。Tag是可选的，而且与节点查找一样，数据中心也是可选。如果没有提供Tag，就不会有过滤，如果没有数据中心，就会选择默认的数据中心。</font>\n\n```plain\n[root@k8s-master ~]# dig @192.168.10.10 -p 8600 traefik.service.consul SRV\n\n; <<>> DiG 9.11.26-RedHat-9.11.26-6.el8 <<>> @192.168.10.10 -p 8600 traefik.service.consul SRV\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 28200\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;traefik.service.consul.                IN      SRV\n\n;; ANSWER SECTION:\ntraefik.service.consul. 0       IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.\n\n;; ADDITIONAL SECTION:\nc0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10\ntiaoban.node.my-dc-1.consul. 0  IN      TXT     \"consul-network-segment=\"\n\n;; Query time: 13 msec\n;; SERVER: 192.168.10.10#8600(192.168.10.10)\n;; WHEN: 一 10月 31 10:53:30 CST 2022\n;; MSG SIZE  rcvd: 164\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">RFC2782 查找 格式：</font>_<font style=\"background-color:rgba(255, 255, 255, 0);\"><service>.</font>_<font style=\"background-color:rgba(255, 255, 255, 0);\"><protocol>.service[.datacenter][.domain]根据RFC 2782， SRV请求都应该在service和protocol前使用(_)作为前缀。避免发生DNS冲突。Protocol可以是service任何一个tag，如果service没有tag，使用tcp作为protocol。如果一旦设置了tcp，那么查询时将不会执行任何标签过滤。</font>\n\n```plain\n# 查询tag为k8s的注册服务traefik信息。\n[root@k8s-master ~]# dig @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV\n\n; <<>> DiG 9.11.26-RedHat-9.11.26-6.el8 <<>> @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 43270\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;_traefik._k8s.service.consul.  IN      SRV\n\n;; ANSWER SECTION:\n_traefik._k8s.service.consul. 0 IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.\n\n;; ADDITIONAL SECTION:\nc0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10\ntiaoban.node.my-dc-1.consul. 0  IN      TXT     \"consul-network-segment=\"\n\n;; Query time: 1 msec\n;; SERVER: 192.168.10.10#8600(192.168.10.10)\n;; WHEN: 一 10月 31 10:57:05 CST 2022\n;; MSG SIZE  rcvd: 170\n```\n\n<h1 id=\"bf9a8ea1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置kv</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 是consul的核心功能，并随consul agent一起安装。consul kv允许用户存储索引对象，尽管其主要用途是存储配置参数和元数据。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 数据存储在server上，可以由任何agent（client或server）访问。consul允许在所有server之间自动复制数据，如果发生故障，拥有一定数量的server将减少数据丢失的风险。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储位于server上的数据目录中，为确保在完全中断的情况下不会丢失数据，可以使用 consul snapshot 命令备份数据。还可以通过 consul kv 子命令、HTTP API 和 Consul UI 访问kv存储。</font>\n\n<h2 id=\"dbb0d3bb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建kv</font>\n\n```plain\n[root@k8s-master consul.d]# consul kv put key1 value1\nSuccess! Data written to: key1\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看kv</font>\n\n```plain\n# 查看所有key value数据\n[root@k8s-master consul.d]# consul kv get --recurse \nkey1:value1\nkey2:value2\n# 查看指定key value数据\n[root@k8s-master consul.d]# consul kv get key2\nvalue2\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">更新kv</font>\n\n```plain\n[root@k8s-master consul.d]# consul kv put key2 v2\nSuccess! Data written to: key2\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除kv</font>\n\n```plain\n[root@k8s-master consul.d]# consul kv delete key2\nSuccess! Deleted key: key2\n```\n\n<h2 id=\"web\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web界面创建kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841944-ff641b3f-de5b-4382-b961-1c30bf857d1b.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842227-005c67d9-9bd2-4a02-9f36-e4e9aa288c32.jpeg)\n\n<h2 id=\"http-api-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n```plain\n# 设置kv\n[root@k8s-master consul.d]# curl -X PUT -d 'value3' http://192.168.10.10:8500/v1/kv/key3\ntrue\n# 查看kv\n[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 | jq\n[\n  {\n    \"LockIndex\": 0,\n    \"Key\": \"key3\",\n    \"Flags\": 0,\n    \"Value\": \"dmFsdWUz\",\n    \"CreateIndex\": 611,\n    \"ModifyIndex\": 611\n  }\n]\n# base64解码查看内容\n[root@k8s-master consul.d]# echo \"dmFsdWUz\" | base64 -d\nvalue3\n# 删除kv\n[root@k8s-master consul.d]# curl -X DELETE http://192.168.10.10:8500/v1/kv/key3\n```\n\n<h1 id=\"f58e1c18\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过ACLS 来确保安全的访问 UI, API, CLI, servie 通信，Agent通信。如果想要确保数据中心安全，就需要配置ACLS。ACL核心原理是，将规则分组为策略， 然后一个或多个策略于令牌关联。</font>\n\n<h2 id=\"8facd89c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用ACL</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改consul配置文件，新增如下内容</font>\n\n```plain\n# acl访问控制\nacl = {\n  enabled = true\n  default_policy = \"deny\" # 默认拒绝所有操作\n  enable_token_persistence = true # 持久化到磁盘，重启时重新加载\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重启consul服务</font>\n\n```plain\n[root@k8s-master consul.d]# systemctl restart consul\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">生成token</font>\n\n```plain\n[root@k8s-master consul.d]# consul acl bootstrap\nAccessorID:       16a37577-f243-94fb-8770-35489870025c\nSecretID:         54a3e3fd-ea07-85a8-67e3-33107a958977\nDescription:      Bootstrap Token (Global Management)\nLocal:            false\nCreate Time:      2022-10-27 22:56:07.654230262 +0800 CST\nPolicies:\n   00000000-0000-0000-0000-000000000001 - global-management\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web页面访问验证  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842237-eb42da7b-f34d-499d-9861-dd3bb7290224.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">api接口访问验证</font>\n\n```plain\n# 直接获取kv提示权限拒绝\n[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 \nrpc error making call: Permission denied: token with AccessorID '00000000-0000-0000-0000-000000000002' lacks permission 'key:read' on \"key3\"[root@k8s-master consul.d]# \n# 请求头添加token访问\n[root@k8s-master consul.d]# curl -s -H \"X-Consul-Token:54a3e3fd-ea07-85a8-67e3-33107a958977\" http://192.168.10.10:8500/v1/kv/key3 | jq\n[\n  {\n    \"LockIndex\": 0,\n    \"Key\": \"key3\",\n    \"Flags\": 0,\n    \"Value\": \"dmFsdWUz\",\n    \"CreateIndex\": 611,\n    \"ModifyIndex\": 611\n  }\n]\n```\n\n","source":"_posts/入门服务注册中心——consul 副本.md","raw":"---\ntitle: consul 入门服务注册中心\ndate: 2025-03-08 19:08:06\n---\n\n<h1 id=\"8519e085\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础概念</font></h1>\n---\n\n<h2 id=\"5e372583\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是注册中心</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着微服务理论发展的成熟，越来越多互联网公司采用微服务架构来支持业务发展。各个微服务之间都需要通过注册中心来实现自动化的注册和发现。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841329-403a2378-9696-4410-a98b-791e28e3ccf0.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">注册中心主要有三种角色：</font>\n\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">服务提供者（RPC Server）</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 注册自身服务，并向 Registry 定期发送心跳汇报存活状态。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">服务消费者（RPC Client）</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 订阅服务，把 Registry 返回的服务节点列表缓存在本地内存中，并与 RPC Sever 建立连接。</font>\n+ **<font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册中心（Registry）</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">：用于保存 RPC Server 的注册信息，当 RPC Server 节点发生变更时，Registry 会同步变更，RPC Client 感知后会刷新本地 内存中缓存的服务节点列表。</font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">最后，RPC Client 从本地缓存的服务节点列表中，基于负载均衡算法选择一台 RPC Sever 发起调用。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">目前常见的注册中心有Consul、ETCD、Zookeeper、Eureka、Nacos等。</font>\n\n<h2 id=\"9cfc6012\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是Consul</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul是HashiCorp公司推出的开源工具，Consul由Go语言开发，部署起来非常容易，只需要极少的可执行程序和配置文件，具有绿色、轻量级的特点。Consul是分布式的、高可用的、 可横向扩展的用于实现分布式系统的服务发现与配置。</font>\n\n<h2 id=\"22750ec8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现（Service Discovery）：Consul提供了通过DNS或者HTTP接口的方式来注册服务和发现服务。一些外部的服务通过Consul很容易的找到它所依赖的服务。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查（Health Checking）：Consul的Client可以提供任意数量的健康检查，既可以与给定的服务相关联(“webserver是否返回200 OK”)，也可以与本地节点相关联(“内存利用率是否低于90%”)。操作员可以使用这些信息来监视集群的健康状况，服务发现组件可以使用这些信息将流量从不健康的主机路由出去。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Key/Value存储：应用程序可以根据自己的需要使用Consul提供的Key/Value存储。 Consul提供了简单易用的HTTP接口，结合其他工具可以实现动态配置、功能标记、领袖选举等等功能。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全服务通信：Consul可以为服务生成和分发TLS证书，以建立相互的TLS连接。意图可用于定义允许哪些服务通信。服务分割可以很容易地进行管理，其目的是可以实时更改的，而不是使用复杂的网络拓扑和静态防火墙规则。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多数据中心：Consul支持开箱即用的多数据中心. 这意味着用户不需要担心需要建立额外的抽象层让业务扩展到多个区域。</font>\n\n<h2 id=\"73539e88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">consul组件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Agent：是在 Consul 集群的每个成员上长期运行的守护进程，通过命令 consul agent 启动运行。由于所有节点都必须运行一个 Agent，因此 Agent 可以分为 client 或 Server。所有的 Agent 都可以运行DNS或HTTP接口，并负责运行监测和保持服务同步</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Client：是将所有RPC转发到 Server 的 Agent。Client 是相对无状态的，Client 唯一执行的后台活动是加入 LAN gossip 池。这只有最小的资源开销，且只消耗少量的网络带宽</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Server：是一个有一组扩展功能的 Agent，这些功能包括参与 Raft 选举、维护集群状态、响应RPC查询、与其他数据中心交互 WAN gossip 和转发查询给 leader 或远程的数据中心</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Datacenter：是一个私有的、低延迟和高带宽的网络环境。这不包括通过公网的通信，但就目的而言，单个 EC2 中的多个可用区域被视为数据中心的一部分</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Consensus：一致性。Consul 使用 Consensus 协议（具体由 Raft 算法实现）来提供一致性（由 CAP 定义），表明 leader 选举和事务的顺序达成一致</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Gossip：Consul 使用 Gossip 协议来管理成员资格并向集群广播消息。Serf 提供了完整的 Gossip 协议，可用于多种目的，而 Consul 建立在 Serf 之上。Gossip 涉及节点到节点的随机通信，主要是通过UDP。Gossip 协议也被称为 Epidemic 协议（流行病协议）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">LAN Gossip：指包含所有位于同一局域网或数据中心的节点的 LAN gossip 池</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">WAN Gossip：指仅包含 Server 的 WAN gossip 池。这些 Server 主要分布在不同的数据中心，通常通过Internet或者广域网进行通信</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">RPC：远程过程调用。一种 请求/响应 机制，允许 Client 向 Server 发起请求</font>\n\n<h2 id=\"641185e8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 架构图</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841304-0599a640-bce7-44a1-8834-3b42cbe90ad9.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">每个为Consul提供服务的节点都会运行一个Consul Agent进程。运行代理不需要发现其他服务或获取/设置密钥/值数据。Agent负责对节点上的服务以及节点本身进行健康检查。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul Agent 分为两种模式， Server 和 Client模式，一般部署模型是 Server + Client的模式（当然也可以纯Server）, Server 具有Client的全部功能， 但是由于Server负责存储数据，并且强一致性模型的缘故， Server数是有限的（3-5个Server节点，Client可以无限扩展的）。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent与一个或多个Consul Server对话。Consul Server是</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">存储</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">和</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">复制数据</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">的地方。Server本身会选出一个Leader。虽然Consul可以用一台Server来运作，但建议使用3到5台，以避免故障情况导致数据丢失。建议每个数据中心采用Consul服务器集群。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Server Agent维护着一个目录（Catalog），这个目录（Catalog）是由Agent提交的信息汇总形成的。目录维护着集群的高层视图，包括哪些服务可用，哪些节点运行这些服务，健康信息等。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">需要发现其他服务或节点的基础结构组件可以查询任何Consul Server或任何Consul Agent。Agent将查询自动转发到Server。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent会自动将查询转发给Server Agent。 每个数据中心都运行一个Consul Server集群。当有跨数据中心的服务发现或配置请求时，本地Consul Server将请求转发到远程数据中心并返回结果。</font>\n\n<h2 id=\"236bb442\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的使用场景</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的应用场景包括服务发现、服务隔离、服务配置：</font>\n\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现场景中consul作为注册中心，服务地址被注册到consul中以后，可以使用consul提供的dns、http接口查询，consul支持health check。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务隔离场景中consul支持以服务为单位设置访问策略，能同时支持经典的平台和新兴的平台，支持tls证书分发，service-to-service加密。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务配置场景中consul提供key-value数据存储功能，并且能将变动迅速地通知出去，借助Consul可以实现配置共享，需要读取配置的服务可以从Consul中读取到准确的配置信息。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Consul可以帮助系统管理者更清晰的了解复杂系统内部的系统架构，运维人员可以将Consul看成一种监控软件，也可以看成一种资产（资源）管理系统。</font>\n\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/downloads?host=www.consul.io</font>](https://developer.hashicorp.com/consul/downloads?host=www.consul.io)\n\n<h2 id=\"62a5d2da\"><font style=\"background-color:rgba(255, 255, 255, 0);\">yum部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font>\n\n```plain\n[root@tiaoban ~]# yum install -y yum-utils\n[root@tiaoban ~]# yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo\n[root@tiaoban ~]# yum -y install consul\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font>\n\n```plain\n[root@tiaoban ~]# systemctl start consul\n[root@tiaoban ~]# systemctl enable consul\n```\n\n<h2 id=\"4443f491\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载</font>\n\n```plain\n[root@tiaoban ~]# mkdir consul\n[root@tiaoban ~]# cd consul/\n[root@tiaoban consul]# wget https://releases.hashicorp.com/consul/1.13.2/consul_1.13.2_linux_amd64.zip\n[root@tiaoban consul]# ls\nconsul_1.13.2_darwin_amd64.zip\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">解压安装</font>\n\n```plain\n[root@tiaoban consul]# unzip consul_1.13.2_linux_amd64.zip \nArchive:  consul_1.13.2_linux_amd64.zip\n  inflating: consul                  \n[root@tiaoban consul]# ls\nconsul  consul_1.13.2_linux_amd64.zip\n[root@tiaoban consul]# mv consul /usr/local/bin/\n[root@tiaoban consul]# consul version\nConsul v1.13.2\nRevision 0e046bbb\nBuild Date 2022-09-20T20:30:07Z\nProtocol 2 spoken by default, understands 2 to 3 (agent will automatically use protocol >2 when speaking to compatible agents)\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务测试  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">使用单节点模式启动测试</font>\n\n```plain\n[root@tiaoban consul]# consul agent -dev -ui -client 0.0.0.0\n```\n\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841427-2c5517e2-2c9f-4ae3-9048-de5811f58ea6.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">添加启动脚本</font>\n\n```plain\n[root@tiaoban ~]# cat /usr/lib/systemd/system/consul.service \n[Unit]\nDescription=consul\nAfter=network.target\n    \n[Service]\nExecStart=/usr/local/consul/start.sh\nKillSignal=SIGTERM\n    \n[Install]\nWantedBy=multi-user.target\n[root@tiaoban ~]# mkdir -p /usr/local/consul/\n[root@tiaoban ~]# cat /usr/local/consul/start.sh\n#!/bin/bash\n/usr/local/bin/consul agent -dev -ui -client 0.0.0.0\n[root@tiaoban ~]# chmod u+x /usr/local/consul/start.sh\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font>\n\n```plain\n[root@tiaoban ~]# systemctl daemon-reload \n[root@tiaoban ~]# systemctl start consul\n[root@tiaoban ~]# systemctl enable consul\n```\n\n<h1 id=\"b19ba4ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务启动</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作以yum方式安装consul配置为例，配置文件路径</font>`<font style=\"background-color:rgba(255, 255, 255, 0);\">/etc/consul.d/consul.hcl</font>`\n\n<h2 id=\"8c7054cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n```plain\n# 指明数据中心的名字\ndatacenter = \"my-dc-1\"\n# 存储状态的数据目录\ndata_dir = \"/opt/consul\"\n# web ui\nui_config{\n  enabled = true\n}\n# 节点是个Server\nserver = true\n# 绑定的一个地址，用于节点之间通信的地址\nbind_addr = \"192.168.10.100\"\n# 期望提供的Server节点数目\nbootstrap_expect=1\n# Client接口绑定到的地址\nclient_addr = \"0.0.0.0\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务，查看集群成员</font>\n\n```plain\n[root@tiaoban consul.d]# systemctl start consul\n[root@tiaoban consul.d]# consul members \nNode     Address              Status  Type    Build   Protocol  DC       Partition  Segment\ntiaoban  192.168.10.100:8301  alive   server  1.13.2  2         my-dc-1  default    <all>\n```\n\n<h2 id=\"6955953a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主机规划</font>\n\n| **主机名** | **IP** | **角色** |\n| --- | --- | --- |\n| k8s-master | 192.168.10.10 | server |\n| k8s-work1 | 192.168.10.11 | server |\n| k8s-work2 | 192.168.10.12 | server |\n| tiaoban | 192.168.10.100 | clinet |\n\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">server端配置</font>\n\n```plain\n# 指明数据中心的名字\ndatacenter = \"my-dc-1\"\n# 存储状态的数据目录\ndata_dir = \"/opt/consul\"\n# web ui\nui_config{\n  enabled = true\n}\n# 节点是个Server\nserver = true\n# 绑定的一个地址，用于节点之间通信的地址。此处以192.168.10.10为例，其他两个更换ip即可。\nbind_addr = \"192.168.10.10\"\n# 期望提供的Server节点数目\nbootstrap_expect=3\n# Client接口绑定到的地址\nclient_addr = \"0.0.0.0\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font>\n\n```plain\n# 指明数据中心的名字\ndatacenter = \"my-dc-1\"\n# 存储状态的数据目录\ndata_dir = \"/opt/consul\"\n# web ui\nui_config{\n  enabled = true\n}\n# 节点是个Server\nserver = false\n# 绑定的一个地址，用于节点之间通信的地址\nbind_addr = \"192.168.10.100\"\n# Client接口绑定到的地址\nclient_addr = \"0.0.0.0\"\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并加入集群</font>\n\n```plain\n# 所有机器执行\n[root@k8s-master consul.d]# systemctl restart consul\n# 除了k8s-master以外的其他机器执行\n[root@k8s-tiaoban consul.d]# consul join 192.168.10.10\nSuccessfully joined cluster by contacting 1 nodes.\n```\n\n<h1 id=\"4b194b09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 常用CLI</font></h1>\n---\n\n<h2 id=\"eb75b9f5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font></h2>\n```plain\n[root@k8s-master ~]# consul catalog services\nconsul\ntraefik\ntraefik-tcp\n```\n\n<h2 id=\"75acbd2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注销服务</font></h2>\n```plain\nconsul services deregister -id=:service-id\n// :service-id 为用户服务Id\n```\n\n<h2 id=\"1b4e985d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点成员</font></h2>\n```plain\n[root@k8s-master ~]# consul members\nNode        Address              Status  Type    Build   Protocol  DC       Partition  Segment\nk8s-master  192.168.10.10:8301   alive   server  1.13.3  2         my-dc-1  default    <all>\nk8s-work1   192.168.10.11:8301   alive   server  1.13.3  2         my-dc-1  default    <all>\nk8s-work2   192.168.10.12:8301   alive   server  1.13.3  2         my-dc-1  default    <all>\ntiaoban     192.168.10.100:8301  alive   client  1.13.2  2         my-dc-1  default    <default>\n```\n\n<h2 id=\"1459fae8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看server节点信息</font></h2>\n```plain\n[root@k8s-master ~]# consul operator raft list-peers\nNode        ID                                    Address             State     Voter  RaftProtocol\nk8s-work1   322a522a-dcf5-3727-052e-0f2d65406f8d  192.168.10.11:8300  follower  true   3\nk8s-master  5db3c09a-f94d-b53f-6c9f-694beb64c1aa  192.168.10.10:8300  leader    true   3\nk8s-work2   d0e4a609-f029-cd91-1d61-63c3403b82b3  192.168.10.12:8300  follower  false  3\n```\n\n<h2 id=\"81ea3784\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul常用HTTP API</font></h2>\n<h2 id=\"3b842616\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/services：该端点返回在本地代理程序中注册的所有服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/{service_id}：返回在本地代理上注册的单个服务实例的完整服务定义；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/name/{service_name} ：通过名称检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/id/{service_id}：通过id检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/health/service/{service_name}?passing：通过健康检查的服务(包含未设置check的service)</font>\n\n<h2 id=\"f3bad82b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/register：注册服务；</font>\n\n<h2 id=\"18616023\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务删除</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/deregister/{service_id}：注销服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/maintenance/{service_id}：该端点将给定的服务置于“维护模式”，在维护模式下，该服务将被标记为不可用，并且不会出现在DNS或API查询中；</font>\n\n<h1 id=\"f3bad82b-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h1>\n---\n\n<h2 id=\"15c64aa0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">新增json配置文件</font>\n\n```plain\n[root@k8s-master consul.d]# cat /etc/consul.d/kube-apiserver.json \n{\n    \"service\": {\n        \"name\": \"traefik-tcp\",\n        \"tags\": [\n            \"k8s\",\"traefik\"\n        ],\n        \"address\": \"192.168.10.10\",\n        \"port\": 9100\n    }\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重启服务</font>\n\n```plain\n[root@k8s-master consul.d]# systemctl restart consul\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841445-ed3d6655-6fda-49ac-88cb-19c119d5de0f.jpeg)\n\n<h2 id=\"http-api\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注册一个name为traefik的服务</font>\n\n```plain\n[root@k8s-master consul.d]# curl -X PUT -d '{\"name\": \"traefik\",\"address\": \"192.168.10.10\",\"port\": 80,\"tags\": [\"k8s\"]}' http://192.168.10.10:8500/v1/agent/service/register\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注册带健康检查的服务</font>\n\n```plain\ncurl -X PUT -d '{\"name\": \"traefik-metrics\",\"address\": \"192.168.10.10\",\"port\": 80,\"tags\": [\"k8s\"],\"checks\":[{\"http\":\"http://192.168.10.10:9100/metrics\",\"interval\":\"5s\"}]}' http://192.168.10.10:8500/v1/agent/service/register\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">打开管理页面查看已注册的服务  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841454-78a08404-76de-44b8-8f10-689d9517273f.jpeg)\n\n<h2 id=\"sdk\"><font style=\"background-color:rgba(255, 255, 255, 0);\">SDK</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">除了采用配置文件或者HTTP API方式注册服务外，consul也支持使用sdk包注册查询服务，目前主流的开发语法均已支持，详情参考文档：  \n</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks</font>](https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks)\n\n<h1 id=\"3b842616-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h1>\n---\n\n<h2 id=\"http-api-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font>\n\n```plain\n[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/services | jq\n{\n  \"consul\": [],\n  \"traefik\": [\n    \"k8s\"\n  ],\n  \"traefik-tcp\": [\n    \"k8s\",\n    \"traefik\"\n  ]\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务详细信息</font>\n\n```plain\n[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/service/traefik | jq\n[\n  {\n    \"ID\": \"eda0ef7f-ca12-bbca-c84e-f88cc3664cd1\",\n    \"Node\": \"tiaoban\",\n    \"Address\": \"192.168.10.100\",\n    \"Datacenter\": \"my-dc-1\",\n    \"TaggedAddresses\": {\n      \"lan\": \"192.168.10.100\",\n      \"lan_ipv4\": \"192.168.10.100\",\n      \"wan\": \"192.168.10.100\",\n      \"wan_ipv4\": \"192.168.10.100\"\n    },\n    \"NodeMeta\": {\n      \"consul-network-segment\": \"\"\n    },\n    \"ServiceKind\": \"\",\n    \"ServiceID\": \"traefik\",\n    \"ServiceName\": \"traefik\",\n    \"ServiceTags\": [\n      \"k8s\"\n    ],\n    \"ServiceAddress\": \"192.168.10.10\",\n    \"ServiceTaggedAddresses\": {\n      \"lan_ipv4\": {\n        \"Address\": \"192.168.10.10\",\n        \"Port\": 80\n      },\n      \"wan_ipv4\": {\n        \"Address\": \"192.168.10.10\",\n        \"Port\": 80\n      }\n    },\n    \"ServiceWeights\": {\n      \"Passing\": 1,\n      \"Warning\": 1\n    },\n    \"ServiceMeta\": {},\n    \"ServicePort\": 80,\n    \"ServiceSocketPath\": \"\",\n    \"ServiceEnableTagOverride\": false,\n    \"ServiceProxy\": {\n      \"Mode\": \"\",\n      \"MeshGateway\": {},\n      \"Expose\": {}\n    },\n    \"ServiceConnect\": {},\n    \"CreateIndex\": 12,\n    \"ModifyIndex\": 12\n  }\n]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查</font>\n\n```plain\n[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/health/service/traefik?passing | jq\n[\n  {\n    \"Node\": {\n      \"ID\": \"eda0ef7f-ca12-bbca-c84e-f88cc3664cd1\",\n      \"Node\": \"tiaoban\",\n      \"Address\": \"192.168.10.100\",\n      \"Datacenter\": \"my-dc-1\",\n      \"TaggedAddresses\": {\n        \"lan\": \"192.168.10.100\",\n        \"lan_ipv4\": \"192.168.10.100\",\n        \"wan\": \"192.168.10.100\",\n        \"wan_ipv4\": \"192.168.10.100\"\n      },\n      \"Meta\": {\n        \"consul-network-segment\": \"\"\n      },\n      \"CreateIndex\": 9,\n      \"ModifyIndex\": 11\n    },\n    \"Service\": {\n      \"ID\": \"traefik\",\n      \"Service\": \"traefik\",\n      \"Tags\": [\n        \"k8s\"\n      ],\n      \"Address\": \"192.168.10.10\",\n      \"TaggedAddresses\": {\n        \"lan_ipv4\": {\n          \"Address\": \"192.168.10.10\",\n          \"Port\": 80\n        },\n        \"wan_ipv4\": {\n          \"Address\": \"192.168.10.10\",\n          \"Port\": 80\n        }\n      },\n      \"Meta\": null,\n      \"Port\": 80,\n      \"Weights\": {\n        \"Passing\": 1,\n        \"Warning\": 1\n      },\n      \"EnableTagOverride\": false,\n      \"Proxy\": {\n        \"Mode\": \"\",\n        \"MeshGateway\": {},\n        \"Expose\": {}\n      },\n      \"Connect\": {},\n      \"PeerName\": \"\",\n      \"CreateIndex\": 12,\n      \"ModifyIndex\": 12\n    },\n    \"Checks\": [\n      {\n        \"Node\": \"tiaoban\",\n        \"CheckID\": \"serfHealth\",\n        \"Name\": \"Serf Health Status\",\n        \"Status\": \"passing\",\n        \"Notes\": \"\",\n        \"Output\": \"Agent alive and reachable\",\n        \"ServiceID\": \"\",\n        \"ServiceName\": \"\",\n        \"ServiceTags\": [],\n        \"Type\": \"\",\n        \"Interval\": \"\",\n        \"Timeout\": \"\",\n        \"ExposedPort\": 0,\n        \"Definition\": {},\n        \"CreateIndex\": 9,\n        \"ModifyIndex\": 9\n      }\n    ]\n  }\n]\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除注册的服务</font>\n\n```plain\n[root@k8s-master consul.d]# curl -X PUT http://192.168.10.10:8500/v1/agent/service/deregister/traefik\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<h2 id=\"74c3df45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">DNS解析</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">DNS接口是Consul中主要的查询接口之一，另一个是HTTP接口， HTTP接口查询请查阅,Consul默认在8600端口监听DNS查询。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/docs/discovery/dns</font>](https://developer.hashicorp.com/consul/docs/discovery/dns)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">要使用DNS接口， 有几种方法可以实现：  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">一是使用指定的DNS解析库， 然后指向Consul；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">二是把Consul设置为节点的DNS服务器, 并且提供recursors配置项， 这样非Consul的查询也能被解析；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">最后一种方法是从已有的DNS服务器上把所有consul.为域名的请求转发到consul agent上。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">节点查找</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查找节点的地址信息，查找格式：<node>.node[.datacenter].<domain>。如果datacenter不指定，默认为当前集群查询。</font>\n\n```plain\n[root@k8s-master ~]# dig @192.168.10.10 -p 8600 tiaoban.node.consul ANY\n\n; <<>> DiG 9.11.26-RedHat-9.11.26-6.el8 <<>> @192.168.10.10 -p 8600 tiaoban.node.consul ANY\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 25684\n;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;tiaoban.node.consul.           IN      ANY\n\n;; ANSWER SECTION:\ntiaoban.node.consul.    0       IN      A       192.168.10.100\ntiaoban.node.consul.    0       IN      TXT     \"consul-network-segment=\"\n\n;; Query time: 14 msec\n;; SERVER: 192.168.10.10#8600(192.168.10.10)\n;; WHEN: 一 10月 31 10:51:10 CST 2022\n;; MSG SIZE  rcvd: 100\n```\n\n**<font style=\"background-color:rgba(255, 255, 255, 0);\">服务查找</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查询服务提供者。服务查询支持两种查找方法：标准和严格RFC 2782。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">标准查找格式：[tag.]<service>.service[.datacenter].<domain>。Tag是可选的，而且与节点查找一样，数据中心也是可选。如果没有提供Tag，就不会有过滤，如果没有数据中心，就会选择默认的数据中心。</font>\n\n```plain\n[root@k8s-master ~]# dig @192.168.10.10 -p 8600 traefik.service.consul SRV\n\n; <<>> DiG 9.11.26-RedHat-9.11.26-6.el8 <<>> @192.168.10.10 -p 8600 traefik.service.consul SRV\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 28200\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;traefik.service.consul.                IN      SRV\n\n;; ANSWER SECTION:\ntraefik.service.consul. 0       IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.\n\n;; ADDITIONAL SECTION:\nc0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10\ntiaoban.node.my-dc-1.consul. 0  IN      TXT     \"consul-network-segment=\"\n\n;; Query time: 13 msec\n;; SERVER: 192.168.10.10#8600(192.168.10.10)\n;; WHEN: 一 10月 31 10:53:30 CST 2022\n;; MSG SIZE  rcvd: 164\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">RFC2782 查找 格式：</font>_<font style=\"background-color:rgba(255, 255, 255, 0);\"><service>.</font>_<font style=\"background-color:rgba(255, 255, 255, 0);\"><protocol>.service[.datacenter][.domain]根据RFC 2782， SRV请求都应该在service和protocol前使用(_)作为前缀。避免发生DNS冲突。Protocol可以是service任何一个tag，如果service没有tag，使用tcp作为protocol。如果一旦设置了tcp，那么查询时将不会执行任何标签过滤。</font>\n\n```plain\n# 查询tag为k8s的注册服务traefik信息。\n[root@k8s-master ~]# dig @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV\n\n; <<>> DiG 9.11.26-RedHat-9.11.26-6.el8 <<>> @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV\n; (1 server found)\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 43270\n;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3\n;; WARNING: recursion requested but not available\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;_traefik._k8s.service.consul.  IN      SRV\n\n;; ANSWER SECTION:\n_traefik._k8s.service.consul. 0 IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.\n\n;; ADDITIONAL SECTION:\nc0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10\ntiaoban.node.my-dc-1.consul. 0  IN      TXT     \"consul-network-segment=\"\n\n;; Query time: 1 msec\n;; SERVER: 192.168.10.10#8600(192.168.10.10)\n;; WHEN: 一 10月 31 10:57:05 CST 2022\n;; MSG SIZE  rcvd: 170\n```\n\n<h1 id=\"bf9a8ea1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置kv</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 是consul的核心功能，并随consul agent一起安装。consul kv允许用户存储索引对象，尽管其主要用途是存储配置参数和元数据。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 数据存储在server上，可以由任何agent（client或server）访问。consul允许在所有server之间自动复制数据，如果发生故障，拥有一定数量的server将减少数据丢失的风险。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储位于server上的数据目录中，为确保在完全中断的情况下不会丢失数据，可以使用 consul snapshot 命令备份数据。还可以通过 consul kv 子命令、HTTP API 和 Consul UI 访问kv存储。</font>\n\n<h2 id=\"dbb0d3bb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建kv</font>\n\n```plain\n[root@k8s-master consul.d]# consul kv put key1 value1\nSuccess! Data written to: key1\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看kv</font>\n\n```plain\n# 查看所有key value数据\n[root@k8s-master consul.d]# consul kv get --recurse \nkey1:value1\nkey2:value2\n# 查看指定key value数据\n[root@k8s-master consul.d]# consul kv get key2\nvalue2\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">更新kv</font>\n\n```plain\n[root@k8s-master consul.d]# consul kv put key2 v2\nSuccess! Data written to: key2\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">删除kv</font>\n\n```plain\n[root@k8s-master consul.d]# consul kv delete key2\nSuccess! Deleted key: key2\n```\n\n<h2 id=\"web\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web界面创建kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841944-ff641b3f-de5b-4382-b961-1c30bf857d1b.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842227-005c67d9-9bd2-4a02-9f36-e4e9aa288c32.jpeg)\n\n<h2 id=\"http-api-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n```plain\n# 设置kv\n[root@k8s-master consul.d]# curl -X PUT -d 'value3' http://192.168.10.10:8500/v1/kv/key3\ntrue\n# 查看kv\n[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 | jq\n[\n  {\n    \"LockIndex\": 0,\n    \"Key\": \"key3\",\n    \"Flags\": 0,\n    \"Value\": \"dmFsdWUz\",\n    \"CreateIndex\": 611,\n    \"ModifyIndex\": 611\n  }\n]\n# base64解码查看内容\n[root@k8s-master consul.d]# echo \"dmFsdWUz\" | base64 -d\nvalue3\n# 删除kv\n[root@k8s-master consul.d]# curl -X DELETE http://192.168.10.10:8500/v1/kv/key3\n```\n\n<h1 id=\"f58e1c18\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制</font></h1>\n---\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">通过ACLS 来确保安全的访问 UI, API, CLI, servie 通信，Agent通信。如果想要确保数据中心安全，就需要配置ACLS。ACL核心原理是，将规则分组为策略， 然后一个或多个策略于令牌关联。</font>\n\n<h2 id=\"8facd89c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用ACL</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改consul配置文件，新增如下内容</font>\n\n```plain\n# acl访问控制\nacl = {\n  enabled = true\n  default_policy = \"deny\" # 默认拒绝所有操作\n  enable_token_persistence = true # 持久化到磁盘，重启时重新加载\n}\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">重启consul服务</font>\n\n```plain\n[root@k8s-master consul.d]# systemctl restart consul\n```\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\"></font>\n\n<font style=\"background-color:rgba(255, 255, 255, 0);\">生成token</font>\n\n```plain\n[root@k8s-master consul.d]# consul acl bootstrap\nAccessorID:       16a37577-f243-94fb-8770-35489870025c\nSecretID:         54a3e3fd-ea07-85a8-67e3-33107a958977\nDescription:      Bootstrap Token (Global Management)\nLocal:            false\nCreate Time:      2022-10-27 22:56:07.654230262 +0800 CST\nPolicies:\n   00000000-0000-0000-0000-000000000001 - global-management\n```\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web页面访问验证  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842237-eb42da7b-f34d-499d-9861-dd3bb7290224.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">api接口访问验证</font>\n\n```plain\n# 直接获取kv提示权限拒绝\n[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 \nrpc error making call: Permission denied: token with AccessorID '00000000-0000-0000-0000-000000000002' lacks permission 'key:read' on \"key3\"[root@k8s-master consul.d]# \n# 请求头添加token访问\n[root@k8s-master consul.d]# curl -s -H \"X-Consul-Token:54a3e3fd-ea07-85a8-67e3-33107a958977\" http://192.168.10.10:8500/v1/kv/key3 | jq\n[\n  {\n    \"LockIndex\": 0,\n    \"Key\": \"key3\",\n    \"Flags\": 0,\n    \"Value\": \"dmFsdWUz\",\n    \"CreateIndex\": 611,\n    \"ModifyIndex\": 611\n  }\n]\n```\n\n","slug":"入门服务注册中心——consul 副本","published":1,"updated":"2025-03-30T13:07:37.647Z","comments":1,"layout":"post","photos":[],"_id":"cm8vqsjlt000ttsv1ashd9xpg","content":"<h1 id=\"8519e085\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础概念</font></h1>\n---\n\n<h2 id=\"5e372583\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是注册中心</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着微服务理论发展的成熟，越来越多互联网公司采用微服务架构来支持业务发展。各个微服务之间都需要通过注册中心来实现自动化的注册和发现。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841329-403a2378-9696-4410-a98b-791e28e3ccf0.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">注册中心主要有三种角色：</font>\n\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务提供者（RPC Server）</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 注册自身服务，并向 Registry 定期发送心跳汇报存活状态。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务消费者（RPC Client）</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 订阅服务，把 Registry 返回的服务节点列表缓存在本地内存中，并与 RPC Sever 建立连接。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册中心（Registry）</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：用于保存 RPC Server 的注册信息，当 RPC Server 节点发生变更时，Registry 会同步变更，RPC Client 感知后会刷新本地 内存中缓存的服务节点列表。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">最后，RPC Client 从本地缓存的服务节点列表中，基于负载均衡算法选择一台 RPC Sever 发起调用。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">目前常见的注册中心有Consul、ETCD、Zookeeper、Eureka、Nacos等。</font></p>\n<h2 id=\"9cfc6012\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是Consul</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul是HashiCorp公司推出的开源工具，Consul由Go语言开发，部署起来非常容易，只需要极少的可执行程序和配置文件，具有绿色、轻量级的特点。Consul是分布式的、高可用的、 可横向扩展的用于实现分布式系统的服务发现与配置。</font>\n\n<h2 id=\"22750ec8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现（Service Discovery）：Consul提供了通过DNS或者HTTP接口的方式来注册服务和发现服务。一些外部的服务通过Consul很容易的找到它所依赖的服务。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查（Health Checking）：Consul的Client可以提供任意数量的健康检查，既可以与给定的服务相关联(“webserver是否返回200 OK”)，也可以与本地节点相关联(“内存利用率是否低于90%”)。操作员可以使用这些信息来监视集群的健康状况，服务发现组件可以使用这些信息将流量从不健康的主机路由出去。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Key/Value存储：应用程序可以根据自己的需要使用Consul提供的Key/Value存储。 Consul提供了简单易用的HTTP接口，结合其他工具可以实现动态配置、功能标记、领袖选举等等功能。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全服务通信：Consul可以为服务生成和分发TLS证书，以建立相互的TLS连接。意图可用于定义允许哪些服务通信。服务分割可以很容易地进行管理，其目的是可以实时更改的，而不是使用复杂的网络拓扑和静态防火墙规则。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多数据中心：Consul支持开箱即用的多数据中心. 这意味着用户不需要担心需要建立额外的抽象层让业务扩展到多个区域。</font>\n\n<h2 id=\"73539e88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">consul组件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Agent：是在 Consul 集群的每个成员上长期运行的守护进程，通过命令 consul agent 启动运行。由于所有节点都必须运行一个 Agent，因此 Agent 可以分为 client 或 Server。所有的 Agent 都可以运行DNS或HTTP接口，并负责运行监测和保持服务同步</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Client：是将所有RPC转发到 Server 的 Agent。Client 是相对无状态的，Client 唯一执行的后台活动是加入 LAN gossip 池。这只有最小的资源开销，且只消耗少量的网络带宽</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Server：是一个有一组扩展功能的 Agent，这些功能包括参与 Raft 选举、维护集群状态、响应RPC查询、与其他数据中心交互 WAN gossip 和转发查询给 leader 或远程的数据中心</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Datacenter：是一个私有的、低延迟和高带宽的网络环境。这不包括通过公网的通信，但就目的而言，单个 EC2 中的多个可用区域被视为数据中心的一部分</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Consensus：一致性。Consul 使用 Consensus 协议（具体由 Raft 算法实现）来提供一致性（由 CAP 定义），表明 leader 选举和事务的顺序达成一致</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Gossip：Consul 使用 Gossip 协议来管理成员资格并向集群广播消息。Serf 提供了完整的 Gossip 协议，可用于多种目的，而 Consul 建立在 Serf 之上。Gossip 涉及节点到节点的随机通信，主要是通过UDP。Gossip 协议也被称为 Epidemic 协议（流行病协议）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">LAN Gossip：指包含所有位于同一局域网或数据中心的节点的 LAN gossip 池</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">WAN Gossip：指仅包含 Server 的 WAN gossip 池。这些 Server 主要分布在不同的数据中心，通常通过Internet或者广域网进行通信</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">RPC：远程过程调用。一种 请求/响应 机制，允许 Client 向 Server 发起请求</font>\n\n<h2 id=\"641185e8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 架构图</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841304-0599a640-bce7-44a1-8834-3b42cbe90ad9.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">每个为Consul提供服务的节点都会运行一个Consul Agent进程。运行代理不需要发现其他服务或获取/设置密钥/值数据。Agent负责对节点上的服务以及节点本身进行健康检查。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul Agent 分为两种模式， Server 和 Client模式，一般部署模型是 Server + Client的模式（当然也可以纯Server）, Server 具有Client的全部功能， 但是由于Server负责存储数据，并且强一致性模型的缘故， Server数是有限的（3-5个Server节点，Client可以无限扩展的）。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent与一个或多个Consul Server对话。Consul Server是</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">存储</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">和</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">复制数据</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">的地方。Server本身会选出一个Leader。虽然Consul可以用一台Server来运作，但建议使用3到5台，以避免故障情况导致数据丢失。建议每个数据中心采用Consul服务器集群。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Server Agent维护着一个目录（Catalog），这个目录（Catalog）是由Agent提交的信息汇总形成的。目录维护着集群的高层视图，包括哪些服务可用，哪些节点运行这些服务，健康信息等。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">需要发现其他服务或节点的基础结构组件可以查询任何Consul Server或任何Consul Agent。Agent将查询自动转发到Server。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent会自动将查询转发给Server Agent。 每个数据中心都运行一个Consul Server集群。当有跨数据中心的服务发现或配置请求时，本地Consul Server将请求转发到远程数据中心并返回结果。</font>\n\n<h2 id=\"236bb442\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的使用场景</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的应用场景包括服务发现、服务隔离、服务配置：</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现场景中consul作为注册中心，服务地址被注册到consul中以后，可以使用consul提供的dns、http接口查询，consul支持health check。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">服务隔离场景中consul支持以服务为单位设置访问策略，能同时支持经典的平台和新兴的平台，支持tls证书分发，service-to-service加密。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">服务配置场景中consul提供key-value数据存储功能，并且能将变动迅速地通知出去，借助Consul可以实现配置共享，需要读取配置的服务可以从Consul中读取到准确的配置信息。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul可以帮助系统管理者更清晰的了解复杂系统内部的系统架构，运维人员可以将Consul看成一种监控软件，也可以看成一种资产（资源）管理系统。</font></li>\n</ul>\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font><a href=\"https://developer.hashicorp.com/consul/downloads?host=www.consul.io\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/downloads?host=www.consul.io</font></a></p>\n<h2 id=\"62a5d2da\"><font style=\"background-color:rgba(255, 255, 255, 0);\">yum部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# yum install -y yum-utils</span><br><span class=\"line\">[root@tiaoban ~]# yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo</span><br><span class=\"line\">[root@tiaoban ~]# yum -y install consul</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# systemctl start consul</span><br><span class=\"line\">[root@tiaoban ~]# systemctl enable consul</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4443f491\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# mkdir consul</span><br><span class=\"line\">[root@tiaoban ~]# cd consul/</span><br><span class=\"line\">[root@tiaoban consul]# wget https://releases.hashicorp.com/consul/1.13.2/consul_1.13.2_linux_amd64.zip</span><br><span class=\"line\">[root@tiaoban consul]# ls</span><br><span class=\"line\">consul_1.13.2_darwin_amd64.zip</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">解压安装</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban consul]# unzip consul_1.13.2_linux_amd64.zip </span><br><span class=\"line\">Archive:  consul_1.13.2_linux_amd64.zip</span><br><span class=\"line\">  inflating: consul                  </span><br><span class=\"line\">[root@tiaoban consul]# ls</span><br><span class=\"line\">consul  consul_1.13.2_linux_amd64.zip</span><br><span class=\"line\">[root@tiaoban consul]# mv consul /usr/local/bin/</span><br><span class=\"line\">[root@tiaoban consul]# consul version</span><br><span class=\"line\">Consul v1.13.2</span><br><span class=\"line\">Revision 0e046bbb</span><br><span class=\"line\">Build Date 2022-09-20T20:30:07Z</span><br><span class=\"line\">Protocol 2 spoken by default, understands 2 to 3 (agent will automatically use protocol &gt;2 when speaking to compatible agents)</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务测试<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">使用单节点模式启动测试</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban consul]# consul agent -dev -ui -client 0.0.0.0</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841427-2c5517e2-2c9f-4ae3-9048-de5811f58ea6.jpeg\"><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">添加启动脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat /usr/lib/systemd/system/consul.service </span><br><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=consul</span><br><span class=\"line\">After=network.target</span><br><span class=\"line\">    </span><br><span class=\"line\">[Service]</span><br><span class=\"line\">ExecStart=/usr/local/consul/start.sh</span><br><span class=\"line\">KillSignal=SIGTERM</span><br><span class=\"line\">    </span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br><span class=\"line\">[root@tiaoban ~]# mkdir -p /usr/local/consul/</span><br><span class=\"line\">[root@tiaoban ~]# cat /usr/local/consul/start.sh</span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">/usr/local/bin/consul agent -dev -ui -client 0.0.0.0</span><br><span class=\"line\">[root@tiaoban ~]# chmod u+x /usr/local/consul/start.sh</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# systemctl daemon-reload </span><br><span class=\"line\">[root@tiaoban ~]# systemctl start consul</span><br><span class=\"line\">[root@tiaoban ~]# systemctl enable consul</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"b19ba4ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务启动</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作以yum方式安装consul配置为例，配置文件路径</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;/etc/consul.d/consul.hcl&lt;/font&gt;</code></p>\n<h2 id=\"8c7054cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指明数据中心的名字</span><br><span class=\"line\">datacenter = &quot;my-dc-1&quot;</span><br><span class=\"line\"># 存储状态的数据目录</span><br><span class=\"line\">data_dir = &quot;/opt/consul&quot;</span><br><span class=\"line\"># web ui</span><br><span class=\"line\">ui_config&#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"># 节点是个Server</span><br><span class=\"line\">server = true</span><br><span class=\"line\"># 绑定的一个地址，用于节点之间通信的地址</span><br><span class=\"line\">bind_addr = &quot;192.168.10.100&quot;</span><br><span class=\"line\"># 期望提供的Server节点数目</span><br><span class=\"line\">bootstrap_expect=1</span><br><span class=\"line\"># Client接口绑定到的地址</span><br><span class=\"line\">client_addr = &quot;0.0.0.0&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务，查看集群成员</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban consul.d]# systemctl start consul</span><br><span class=\"line\">[root@tiaoban consul.d]# consul members </span><br><span class=\"line\">Node     Address              Status  Type    Build   Protocol  DC       Partition  Segment</span><br><span class=\"line\">tiaoban  192.168.10.100:8301  alive   server  1.13.2  2         my-dc-1  default    &lt;all&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6955953a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主机规划</font>\n\n<table>\n<thead>\n<tr>\n<th><strong>主机名</strong></th>\n<th><strong>IP</strong></th>\n<th><strong>角色</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>k8s-master</td>\n<td>192.168.10.10</td>\n<td>server</td>\n</tr>\n<tr>\n<td>k8s-work1</td>\n<td>192.168.10.11</td>\n<td>server</td>\n</tr>\n<tr>\n<td>k8s-work2</td>\n<td>192.168.10.12</td>\n<td>server</td>\n</tr>\n<tr>\n<td>tiaoban</td>\n<td>192.168.10.100</td>\n<td>clinet</td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">server端配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指明数据中心的名字</span><br><span class=\"line\">datacenter = &quot;my-dc-1&quot;</span><br><span class=\"line\"># 存储状态的数据目录</span><br><span class=\"line\">data_dir = &quot;/opt/consul&quot;</span><br><span class=\"line\"># web ui</span><br><span class=\"line\">ui_config&#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"># 节点是个Server</span><br><span class=\"line\">server = true</span><br><span class=\"line\"># 绑定的一个地址，用于节点之间通信的地址。此处以192.168.10.10为例，其他两个更换ip即可。</span><br><span class=\"line\">bind_addr = &quot;192.168.10.10&quot;</span><br><span class=\"line\"># 期望提供的Server节点数目</span><br><span class=\"line\">bootstrap_expect=3</span><br><span class=\"line\"># Client接口绑定到的地址</span><br><span class=\"line\">client_addr = &quot;0.0.0.0&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指明数据中心的名字</span><br><span class=\"line\">datacenter = &quot;my-dc-1&quot;</span><br><span class=\"line\"># 存储状态的数据目录</span><br><span class=\"line\">data_dir = &quot;/opt/consul&quot;</span><br><span class=\"line\"># web ui</span><br><span class=\"line\">ui_config&#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"># 节点是个Server</span><br><span class=\"line\">server = false</span><br><span class=\"line\"># 绑定的一个地址，用于节点之间通信的地址</span><br><span class=\"line\">bind_addr = &quot;192.168.10.100&quot;</span><br><span class=\"line\"># Client接口绑定到的地址</span><br><span class=\"line\">client_addr = &quot;0.0.0.0&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并加入集群</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 所有机器执行</span><br><span class=\"line\">[root@k8s-master consul.d]# systemctl restart consul</span><br><span class=\"line\"># 除了k8s-master以外的其他机器执行</span><br><span class=\"line\">[root@k8s-tiaoban consul.d]# consul join 192.168.10.10</span><br><span class=\"line\">Successfully joined cluster by contacting 1 nodes.</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"4b194b09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 常用CLI</font></h1>\n---\n\n<h2 id=\"eb75b9f5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# consul catalog services</span><br><span class=\"line\">consul</span><br><span class=\"line\">traefik</span><br><span class=\"line\">traefik-tcp</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"75acbd2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注销服务</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">consul services deregister -id=:service-id</span><br><span class=\"line\">// :service-id 为用户服务Id</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1b4e985d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点成员</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# consul members</span><br><span class=\"line\">Node        Address              Status  Type    Build   Protocol  DC       Partition  Segment</span><br><span class=\"line\">k8s-master  192.168.10.10:8301   alive   server  1.13.3  2         my-dc-1  default    &lt;all&gt;</span><br><span class=\"line\">k8s-work1   192.168.10.11:8301   alive   server  1.13.3  2         my-dc-1  default    &lt;all&gt;</span><br><span class=\"line\">k8s-work2   192.168.10.12:8301   alive   server  1.13.3  2         my-dc-1  default    &lt;all&gt;</span><br><span class=\"line\">tiaoban     192.168.10.100:8301  alive   client  1.13.2  2         my-dc-1  default    &lt;default&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1459fae8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看server节点信息</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# consul operator raft list-peers</span><br><span class=\"line\">Node        ID                                    Address             State     Voter  RaftProtocol</span><br><span class=\"line\">k8s-work1   322a522a-dcf5-3727-052e-0f2d65406f8d  192.168.10.11:8300  follower  true   3</span><br><span class=\"line\">k8s-master  5db3c09a-f94d-b53f-6c9f-694beb64c1aa  192.168.10.10:8300  leader    true   3</span><br><span class=\"line\">k8s-work2   d0e4a609-f029-cd91-1d61-63c3403b82b3  192.168.10.12:8300  follower  false  3</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"81ea3784\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul常用HTTP API</font></h2>\n<h2 id=\"3b842616\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/services：该端点返回在本地代理程序中注册的所有服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/{service_id}：返回在本地代理上注册的单个服务实例的完整服务定义；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/name/{service_name} ：通过名称检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/id/{service_id}：通过id检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/health/service/{service_name}?passing：通过健康检查的服务(包含未设置check的service)</font>\n\n<h2 id=\"f3bad82b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/register：注册服务；</font>\n\n<h2 id=\"18616023\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务删除</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/deregister/{service_id}：注销服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/maintenance/{service_id}：该端点将给定的服务置于“维护模式”，在维护模式下，该服务将被标记为不可用，并且不会出现在DNS或API查询中；</font>\n\n<h1 id=\"f3bad82b-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h1>\n---\n\n<h2 id=\"15c64aa0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">新增json配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# cat /etc/consul.d/kube-apiserver.json </span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;service&quot;: &#123;</span><br><span class=\"line\">        &quot;name&quot;: &quot;traefik-tcp&quot;,</span><br><span class=\"line\">        &quot;tags&quot;: [</span><br><span class=\"line\">            &quot;k8s&quot;,&quot;traefik&quot;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">        &quot;port&quot;: 9100</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重启服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# systemctl restart consul</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看<br></font><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841445-ed3d6655-6fda-49ac-88cb-19c119d5de0f.jpeg\"></p>\n<h2 id=\"http-api\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注册一个name为traefik的服务</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# curl -X PUT -d &#x27;&#123;&quot;name&quot;: &quot;traefik&quot;,&quot;address&quot;: &quot;192.168.10.10&quot;,&quot;port&quot;: 80,&quot;tags&quot;: [&quot;k8s&quot;]&#125;&#x27; http://192.168.10.10:8500/v1/agent/service/register</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">注册带健康检查的服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -X PUT -d &#x27;&#123;&quot;name&quot;: &quot;traefik-metrics&quot;,&quot;address&quot;: &quot;192.168.10.10&quot;,&quot;port&quot;: 80,&quot;tags&quot;: [&quot;k8s&quot;],&quot;checks&quot;:[&#123;&quot;http&quot;:&quot;http://192.168.10.10:9100/metrics&quot;,&quot;interval&quot;:&quot;5s&quot;&#125;]&#125;&#x27; http://192.168.10.10:8500/v1/agent/service/register</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打开管理页面查看已注册的服务<br></font><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841454-78a08404-76de-44b8-8f10-689d9517273f.jpeg\"></p>\n<h2 id=\"sdk\"><font style=\"background-color:rgba(255, 255, 255, 0);\">SDK</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">除了采用配置文件或者HTTP API方式注册服务外，consul也支持使用sdk包注册查询服务，目前主流的开发语法均已支持，详情参考文档：  \n</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks</font>](https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks)\n\n<h1 id=\"3b842616-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h1>\n---\n\n<h2 id=\"http-api-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/services | jq</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;consul&quot;: [],</span><br><span class=\"line\">  &quot;traefik&quot;: [</span><br><span class=\"line\">    &quot;k8s&quot;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  &quot;traefik-tcp&quot;: [</span><br><span class=\"line\">    &quot;k8s&quot;,</span><br><span class=\"line\">    &quot;traefik&quot;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务详细信息</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/service/traefik | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;ID&quot;: &quot;eda0ef7f-ca12-bbca-c84e-f88cc3664cd1&quot;,</span><br><span class=\"line\">    &quot;Node&quot;: &quot;tiaoban&quot;,</span><br><span class=\"line\">    &quot;Address&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">    &quot;Datacenter&quot;: &quot;my-dc-1&quot;,</span><br><span class=\"line\">    &quot;TaggedAddresses&quot;: &#123;</span><br><span class=\"line\">      &quot;lan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;lan_ipv4&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;wan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;wan_ipv4&quot;: &quot;192.168.10.100&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;NodeMeta&quot;: &#123;</span><br><span class=\"line\">      &quot;consul-network-segment&quot;: &quot;&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceKind&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;ServiceID&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">    &quot;ServiceName&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">    &quot;ServiceTags&quot;: [</span><br><span class=\"line\">      &quot;k8s&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;ServiceAddress&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">    &quot;ServiceTaggedAddresses&quot;: &#123;</span><br><span class=\"line\">      &quot;lan_ipv4&quot;: &#123;</span><br><span class=\"line\">        &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">        &quot;Port&quot;: 80</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;wan_ipv4&quot;: &#123;</span><br><span class=\"line\">        &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">        &quot;Port&quot;: 80</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceWeights&quot;: &#123;</span><br><span class=\"line\">      &quot;Passing&quot;: 1,</span><br><span class=\"line\">      &quot;Warning&quot;: 1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceMeta&quot;: &#123;&#125;,</span><br><span class=\"line\">    &quot;ServicePort&quot;: 80,</span><br><span class=\"line\">    &quot;ServiceSocketPath&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;ServiceEnableTagOverride&quot;: false,</span><br><span class=\"line\">    &quot;ServiceProxy&quot;: &#123;</span><br><span class=\"line\">      &quot;Mode&quot;: &quot;&quot;,</span><br><span class=\"line\">      &quot;MeshGateway&quot;: &#123;&#125;,</span><br><span class=\"line\">      &quot;Expose&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceConnect&quot;: &#123;&#125;,</span><br><span class=\"line\">    &quot;CreateIndex&quot;: 12,</span><br><span class=\"line\">    &quot;ModifyIndex&quot;: 12</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/health/service/traefik?passing | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;Node&quot;: &#123;</span><br><span class=\"line\">      &quot;ID&quot;: &quot;eda0ef7f-ca12-bbca-c84e-f88cc3664cd1&quot;,</span><br><span class=\"line\">      &quot;Node&quot;: &quot;tiaoban&quot;,</span><br><span class=\"line\">      &quot;Address&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;Datacenter&quot;: &quot;my-dc-1&quot;,</span><br><span class=\"line\">      &quot;TaggedAddresses&quot;: &#123;</span><br><span class=\"line\">        &quot;lan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;lan_ipv4&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;wan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;wan_ipv4&quot;: &quot;192.168.10.100&quot;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;Meta&quot;: &#123;</span><br><span class=\"line\">        &quot;consul-network-segment&quot;: &quot;&quot;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;CreateIndex&quot;: 9,</span><br><span class=\"line\">      &quot;ModifyIndex&quot;: 11</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;Service&quot;: &#123;</span><br><span class=\"line\">      &quot;ID&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">      &quot;Service&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">      &quot;Tags&quot;: [</span><br><span class=\"line\">        &quot;k8s&quot;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">      &quot;TaggedAddresses&quot;: &#123;</span><br><span class=\"line\">        &quot;lan_ipv4&quot;: &#123;</span><br><span class=\"line\">          &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">          &quot;Port&quot;: 80</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;wan_ipv4&quot;: &#123;</span><br><span class=\"line\">          &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">          &quot;Port&quot;: 80</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;Meta&quot;: null,</span><br><span class=\"line\">      &quot;Port&quot;: 80,</span><br><span class=\"line\">      &quot;Weights&quot;: &#123;</span><br><span class=\"line\">        &quot;Passing&quot;: 1,</span><br><span class=\"line\">        &quot;Warning&quot;: 1</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;EnableTagOverride&quot;: false,</span><br><span class=\"line\">      &quot;Proxy&quot;: &#123;</span><br><span class=\"line\">        &quot;Mode&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;MeshGateway&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;Expose&quot;: &#123;&#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;Connect&quot;: &#123;&#125;,</span><br><span class=\"line\">      &quot;PeerName&quot;: &quot;&quot;,</span><br><span class=\"line\">      &quot;CreateIndex&quot;: 12,</span><br><span class=\"line\">      &quot;ModifyIndex&quot;: 12</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;Checks&quot;: [</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        &quot;Node&quot;: &quot;tiaoban&quot;,</span><br><span class=\"line\">        &quot;CheckID&quot;: &quot;serfHealth&quot;,</span><br><span class=\"line\">        &quot;Name&quot;: &quot;Serf Health Status&quot;,</span><br><span class=\"line\">        &quot;Status&quot;: &quot;passing&quot;,</span><br><span class=\"line\">        &quot;Notes&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Output&quot;: &quot;Agent alive and reachable&quot;,</span><br><span class=\"line\">        &quot;ServiceID&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;ServiceName&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;ServiceTags&quot;: [],</span><br><span class=\"line\">        &quot;Type&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Interval&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Timeout&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;ExposedPort&quot;: 0,</span><br><span class=\"line\">        &quot;Definition&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;CreateIndex&quot;: 9,</span><br><span class=\"line\">        &quot;ModifyIndex&quot;: 9</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除注册的服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# curl -X PUT http://192.168.10.10:8500/v1/agent/service/deregister/traefik</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h2 id=\"74c3df45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">DNS解析</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">DNS接口是Consul中主要的查询接口之一，另一个是HTTP接口， HTTP接口查询请查阅,Consul默认在8600端口监听DNS查询。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/docs/discovery/dns</font>](https://developer.hashicorp.com/consul/docs/discovery/dns)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">要使用DNS接口， 有几种方法可以实现：  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">一是使用指定的DNS解析库， 然后指向Consul；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">二是把Consul设置为节点的DNS服务器, 并且提供recursors配置项， 这样非Consul的查询也能被解析；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">最后一种方法是从已有的DNS服务器上把所有consul.为域名的请求转发到consul agent上。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">节点查找</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查找节点的地址信息，查找格式：<node>.node[.datacenter].<domain>。如果datacenter不指定，默认为当前集群查询。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# dig @192.168.10.10 -p 8600 tiaoban.node.consul ANY</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; @192.168.10.10 -p 8600 tiaoban.node.consul ANY</span><br><span class=\"line\">; (1 server found)</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">;; Got answer:</span><br><span class=\"line\">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 25684</span><br><span class=\"line\">;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1</span><br><span class=\"line\">;; WARNING: recursion requested but not available</span><br><span class=\"line\"></span><br><span class=\"line\">;; OPT PSEUDOSECTION:</span><br><span class=\"line\">; EDNS: version: 0, flags:; udp: 4096</span><br><span class=\"line\">;; QUESTION SECTION:</span><br><span class=\"line\">;tiaoban.node.consul.           IN      ANY</span><br><span class=\"line\"></span><br><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">tiaoban.node.consul.    0       IN      A       192.168.10.100</span><br><span class=\"line\">tiaoban.node.consul.    0       IN      TXT     &quot;consul-network-segment=&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">;; Query time: 14 msec</span><br><span class=\"line\">;; SERVER: 192.168.10.10#8600(192.168.10.10)</span><br><span class=\"line\">;; WHEN: 一 10月 31 10:51:10 CST 2022</span><br><span class=\"line\">;; MSG SIZE  rcvd: 100</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查找</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">查询服务提供者。服务查询支持两种查找方法：标准和严格RFC 2782。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">标准查找格式：[tag.]<service>.service[.datacenter].<domain>。Tag是可选的，而且与节点查找一样，数据中心也是可选。如果没有提供Tag，就不会有过滤，如果没有数据中心，就会选择默认的数据中心。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# dig @192.168.10.10 -p 8600 traefik.service.consul SRV</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; @192.168.10.10 -p 8600 traefik.service.consul SRV</span><br><span class=\"line\">; (1 server found)</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">;; Got answer:</span><br><span class=\"line\">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 28200</span><br><span class=\"line\">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3</span><br><span class=\"line\">;; WARNING: recursion requested but not available</span><br><span class=\"line\"></span><br><span class=\"line\">;; OPT PSEUDOSECTION:</span><br><span class=\"line\">; EDNS: version: 0, flags:; udp: 4096</span><br><span class=\"line\">;; QUESTION SECTION:</span><br><span class=\"line\">;traefik.service.consul.                IN      SRV</span><br><span class=\"line\"></span><br><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">traefik.service.consul. 0       IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.</span><br><span class=\"line\"></span><br><span class=\"line\">;; ADDITIONAL SECTION:</span><br><span class=\"line\">c0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10</span><br><span class=\"line\">tiaoban.node.my-dc-1.consul. 0  IN      TXT     &quot;consul-network-segment=&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">;; Query time: 13 msec</span><br><span class=\"line\">;; SERVER: 192.168.10.10#8600(192.168.10.10)</span><br><span class=\"line\">;; WHEN: 一 10月 31 10:53:30 CST 2022</span><br><span class=\"line\">;; MSG SIZE  rcvd: 164</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">RFC2782 查找 格式：</font><em><font style=\"background-color:rgba(255, 255, 255, 0);\"><service>.</font></em><font style=\"background-color:rgba(255, 255, 255, 0);\"><protocol>.service[.datacenter][.domain]根据RFC 2782， SRV请求都应该在service和protocol前使用(_)作为前缀。避免发生DNS冲突。Protocol可以是service任何一个tag，如果service没有tag，使用tcp作为protocol。如果一旦设置了tcp，那么查询时将不会执行任何标签过滤。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查询tag为k8s的注册服务traefik信息。</span><br><span class=\"line\">[root@k8s-master ~]# dig @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV</span><br><span class=\"line\">; (1 server found)</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">;; Got answer:</span><br><span class=\"line\">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43270</span><br><span class=\"line\">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3</span><br><span class=\"line\">;; WARNING: recursion requested but not available</span><br><span class=\"line\"></span><br><span class=\"line\">;; OPT PSEUDOSECTION:</span><br><span class=\"line\">; EDNS: version: 0, flags:; udp: 4096</span><br><span class=\"line\">;; QUESTION SECTION:</span><br><span class=\"line\">;_traefik._k8s.service.consul.  IN      SRV</span><br><span class=\"line\"></span><br><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">_traefik._k8s.service.consul. 0 IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.</span><br><span class=\"line\"></span><br><span class=\"line\">;; ADDITIONAL SECTION:</span><br><span class=\"line\">c0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10</span><br><span class=\"line\">tiaoban.node.my-dc-1.consul. 0  IN      TXT     &quot;consul-network-segment=&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">;; Query time: 1 msec</span><br><span class=\"line\">;; SERVER: 192.168.10.10#8600(192.168.10.10)</span><br><span class=\"line\">;; WHEN: 一 10月 31 10:57:05 CST 2022</span><br><span class=\"line\">;; MSG SIZE  rcvd: 170</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"bf9a8ea1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置kv</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 是consul的核心功能，并随consul agent一起安装。consul kv允许用户存储索引对象，尽管其主要用途是存储配置参数和元数据。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 数据存储在server上，可以由任何agent（client或server）访问。consul允许在所有server之间自动复制数据，如果发生故障，拥有一定数量的server将减少数据丢失的风险。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储位于server上的数据目录中，为确保在完全中断的情况下不会丢失数据，可以使用 consul snapshot 命令备份数据。还可以通过 consul kv 子命令、HTTP API 和 Consul UI 访问kv存储。</font></p>\n<h2 id=\"dbb0d3bb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建kv</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul kv put key1 value1</span><br><span class=\"line\">Success! Data written to: key1</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看kv</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看所有key value数据</span><br><span class=\"line\">[root@k8s-master consul.d]# consul kv get --recurse </span><br><span class=\"line\">key1:value1</span><br><span class=\"line\">key2:value2</span><br><span class=\"line\"># 查看指定key value数据</span><br><span class=\"line\">[root@k8s-master consul.d]# consul kv get key2</span><br><span class=\"line\">value2</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">更新kv</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul kv put key2 v2</span><br><span class=\"line\">Success! Data written to: key2</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除kv</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul kv delete key2</span><br><span class=\"line\">Success! Deleted key: key2</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"web\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web界面创建kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841944-ff641b3f-de5b-4382-b961-1c30bf857d1b.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842227-005c67d9-9bd2-4a02-9f36-e4e9aa288c32.jpeg)\n\n<h2 id=\"http-api-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置kv</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -X PUT -d &#x27;value3&#x27; http://192.168.10.10:8500/v1/kv/key3</span><br><span class=\"line\">true</span><br><span class=\"line\"># 查看kv</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;LockIndex&quot;: 0,</span><br><span class=\"line\">    &quot;Key&quot;: &quot;key3&quot;,</span><br><span class=\"line\">    &quot;Flags&quot;: 0,</span><br><span class=\"line\">    &quot;Value&quot;: &quot;dmFsdWUz&quot;,</span><br><span class=\"line\">    &quot;CreateIndex&quot;: 611,</span><br><span class=\"line\">    &quot;ModifyIndex&quot;: 611</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br><span class=\"line\"># base64解码查看内容</span><br><span class=\"line\">[root@k8s-master consul.d]# echo &quot;dmFsdWUz&quot; | base64 -d</span><br><span class=\"line\">value3</span><br><span class=\"line\"># 删除kv</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -X DELETE http://192.168.10.10:8500/v1/kv/key3</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"f58e1c18\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">通过ACLS 来确保安全的访问 UI, API, CLI, servie 通信，Agent通信。如果想要确保数据中心安全，就需要配置ACLS。ACL核心原理是，将规则分组为策略， 然后一个或多个策略于令牌关联。</font></p>\n<h2 id=\"8facd89c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用ACL</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改consul配置文件，新增如下内容</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># acl访问控制</span><br><span class=\"line\">acl = &#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">  default_policy = &quot;deny&quot; # 默认拒绝所有操作</span><br><span class=\"line\">  enable_token_persistence = true # 持久化到磁盘，重启时重新加载</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重启consul服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# systemctl restart consul</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">生成token</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul acl bootstrap</span><br><span class=\"line\">AccessorID:       16a37577-f243-94fb-8770-35489870025c</span><br><span class=\"line\">SecretID:         54a3e3fd-ea07-85a8-67e3-33107a958977</span><br><span class=\"line\">Description:      Bootstrap Token (Global Management)</span><br><span class=\"line\">Local:            false</span><br><span class=\"line\">Create Time:      2022-10-27 22:56:07.654230262 +0800 CST</span><br><span class=\"line\">Policies:</span><br><span class=\"line\">   00000000-0000-0000-0000-000000000001 - global-management</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web页面访问验证  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842237-eb42da7b-f34d-499d-9861-dd3bb7290224.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">api接口访问验证</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 直接获取kv提示权限拒绝</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 </span><br><span class=\"line\">rpc error making call: Permission denied: token with AccessorID &#x27;00000000-0000-0000-0000-000000000002&#x27; lacks permission &#x27;key:read&#x27; on &quot;key3&quot;[root@k8s-master consul.d]# </span><br><span class=\"line\"># 请求头添加token访问</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -s -H &quot;X-Consul-Token:54a3e3fd-ea07-85a8-67e3-33107a958977&quot; http://192.168.10.10:8500/v1/kv/key3 | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;LockIndex&quot;: 0,</span><br><span class=\"line\">    &quot;Key&quot;: &quot;key3&quot;,</span><br><span class=\"line\">    &quot;Flags&quot;: 0,</span><br><span class=\"line\">    &quot;Value&quot;: &quot;dmFsdWUz&quot;,</span><br><span class=\"line\">    &quot;CreateIndex&quot;: 611,</span><br><span class=\"line\">    &quot;ModifyIndex&quot;: 611</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n","excerpt":"","more":"<h1 id=\"8519e085\"><font style=\"background-color:rgba(255, 255, 255, 0);\">基础概念</font></h1>\n---\n\n<h2 id=\"5e372583\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是注册中心</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">随着微服务理论发展的成熟，越来越多互联网公司采用微服务架构来支持业务发展。各个微服务之间都需要通过注册中心来实现自动化的注册和发现。  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841329-403a2378-9696-4410-a98b-791e28e3ccf0.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">注册中心主要有三种角色：</font>\n\n<ul>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务提供者（RPC Server）</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 注册自身服务，并向 Registry 定期发送心跳汇报存活状态。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务消费者（RPC Client）</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：在启动时，向 Registry 订阅服务，把 Registry 返回的服务节点列表缓存在本地内存中，并与 RPC Sever 建立连接。</font></li>\n<li><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册中心（Registry）</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\">：用于保存 RPC Server 的注册信息，当 RPC Server 节点发生变更时，Registry 会同步变更，RPC Client 感知后会刷新本地 内存中缓存的服务节点列表。</font></li>\n</ul>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">最后，RPC Client 从本地缓存的服务节点列表中，基于负载均衡算法选择一台 RPC Sever 发起调用。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">目前常见的注册中心有Consul、ETCD、Zookeeper、Eureka、Nacos等。</font></p>\n<h2 id=\"9cfc6012\"><font style=\"background-color:rgba(255, 255, 255, 0);\">什么是Consul</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul是HashiCorp公司推出的开源工具，Consul由Go语言开发，部署起来非常容易，只需要极少的可执行程序和配置文件，具有绿色、轻量级的特点。Consul是分布式的、高可用的、 可横向扩展的用于实现分布式系统的服务发现与配置。</font>\n\n<h2 id=\"22750ec8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul特点</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现（Service Discovery）：Consul提供了通过DNS或者HTTP接口的方式来注册服务和发现服务。一些外部的服务通过Consul很容易的找到它所依赖的服务。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查（Health Checking）：Consul的Client可以提供任意数量的健康检查，既可以与给定的服务相关联(“webserver是否返回200 OK”)，也可以与本地节点相关联(“内存利用率是否低于90%”)。操作员可以使用这些信息来监视集群的健康状况，服务发现组件可以使用这些信息将流量从不健康的主机路由出去。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Key/Value存储：应用程序可以根据自己的需要使用Consul提供的Key/Value存储。 Consul提供了简单易用的HTTP接口，结合其他工具可以实现动态配置、功能标记、领袖选举等等功能。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">安全服务通信：Consul可以为服务生成和分发TLS证书，以建立相互的TLS连接。意图可用于定义允许哪些服务通信。服务分割可以很容易地进行管理，其目的是可以实时更改的，而不是使用复杂的网络拓扑和静态防火墙规则。</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">多数据中心：Consul支持开箱即用的多数据中心. 这意味着用户不需要担心需要建立额外的抽象层让业务扩展到多个区域。</font>\n\n<h2 id=\"73539e88\"><font style=\"background-color:rgba(255, 255, 255, 0);\">consul组件</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Agent：是在 Consul 集群的每个成员上长期运行的守护进程，通过命令 consul agent 启动运行。由于所有节点都必须运行一个 Agent，因此 Agent 可以分为 client 或 Server。所有的 Agent 都可以运行DNS或HTTP接口，并负责运行监测和保持服务同步</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Client：是将所有RPC转发到 Server 的 Agent。Client 是相对无状态的，Client 唯一执行的后台活动是加入 LAN gossip 池。这只有最小的资源开销，且只消耗少量的网络带宽</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Server：是一个有一组扩展功能的 Agent，这些功能包括参与 Raft 选举、维护集群状态、响应RPC查询、与其他数据中心交互 WAN gossip 和转发查询给 leader 或远程的数据中心</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Datacenter：是一个私有的、低延迟和高带宽的网络环境。这不包括通过公网的通信，但就目的而言，单个 EC2 中的多个可用区域被视为数据中心的一部分</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Consensus：一致性。Consul 使用 Consensus 协议（具体由 Raft 算法实现）来提供一致性（由 CAP 定义），表明 leader 选举和事务的顺序达成一致</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">Gossip：Consul 使用 Gossip 协议来管理成员资格并向集群广播消息。Serf 提供了完整的 Gossip 协议，可用于多种目的，而 Consul 建立在 Serf 之上。Gossip 涉及节点到节点的随机通信，主要是通过UDP。Gossip 协议也被称为 Epidemic 协议（流行病协议）</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">LAN Gossip：指包含所有位于同一局域网或数据中心的节点的 LAN gossip 池</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">WAN Gossip：指仅包含 Server 的 WAN gossip 池。这些 Server 主要分布在不同的数据中心，通常通过Internet或者广域网进行通信</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">RPC：远程过程调用。一种 请求/响应 机制，允许 Client 向 Server 发起请求</font>\n\n<h2 id=\"641185e8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 架构图</font></h2>\n![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841304-0599a640-bce7-44a1-8834-3b42cbe90ad9.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">每个为Consul提供服务的节点都会运行一个Consul Agent进程。运行代理不需要发现其他服务或获取/设置密钥/值数据。Agent负责对节点上的服务以及节点本身进行健康检查。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul Agent 分为两种模式， Server 和 Client模式，一般部署模型是 Server + Client的模式（当然也可以纯Server）, Server 具有Client的全部功能， 但是由于Server负责存储数据，并且强一致性模型的缘故， Server数是有限的（3-5个Server节点，Client可以无限扩展的）。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent与一个或多个Consul Server对话。Consul Server是</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">存储</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">和</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">复制数据</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">的地方。Server本身会选出一个Leader。虽然Consul可以用一台Server来运作，但建议使用3到5台，以避免故障情况导致数据丢失。建议每个数据中心采用Consul服务器集群。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Server Agent维护着一个目录（Catalog），这个目录（Catalog）是由Agent提交的信息汇总形成的。目录维护着集群的高层视图，包括哪些服务可用，哪些节点运行这些服务，健康信息等。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">需要发现其他服务或节点的基础结构组件可以查询任何Consul Server或任何Consul Agent。Agent将查询自动转发到Server。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">Agent会自动将查询转发给Server Agent。 每个数据中心都运行一个Consul Server集群。当有跨数据中心的服务发现或配置请求时，本地Consul Server将请求转发到远程数据中心并返回结果。</font>\n\n<h2 id=\"236bb442\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的使用场景</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">Consul的应用场景包括服务发现、服务隔离、服务配置：</font>\n\n<ul>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">服务发现场景中consul作为注册中心，服务地址被注册到consul中以后，可以使用consul提供的dns、http接口查询，consul支持health check。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">服务隔离场景中consul支持以服务为单位设置访问策略，能同时支持经典的平台和新兴的平台，支持tls证书分发，service-to-service加密。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">服务配置场景中consul提供key-value数据存储功能，并且能将变动迅速地通知出去，借助Consul可以实现配置共享，需要读取配置的服务可以从Consul中读取到准确的配置信息。</font></li>\n<li><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul可以帮助系统管理者更清晰的了解复杂系统内部的系统架构，运维人员可以将Consul看成一种监控软件，也可以看成一种资产（资源）管理系统。</font></li>\n</ul>\n<h1 id=\"039d392c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">安装部署</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font><a href=\"https://developer.hashicorp.com/consul/downloads?host=www.consul.io\"><font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/downloads?host=www.consul.io</font></a></p>\n<h2 id=\"62a5d2da\"><font style=\"background-color:rgba(255, 255, 255, 0);\">yum部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">安装软件包</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# yum install -y yum-utils</span><br><span class=\"line\">[root@tiaoban ~]# yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo</span><br><span class=\"line\">[root@tiaoban ~]# yum -y install consul</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# systemctl start consul</span><br><span class=\"line\">[root@tiaoban ~]# systemctl enable consul</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"4443f491\"><font style=\"background-color:rgba(255, 255, 255, 0);\">二进制部署</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">下载</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# mkdir consul</span><br><span class=\"line\">[root@tiaoban ~]# cd consul/</span><br><span class=\"line\">[root@tiaoban consul]# wget https://releases.hashicorp.com/consul/1.13.2/consul_1.13.2_linux_amd64.zip</span><br><span class=\"line\">[root@tiaoban consul]# ls</span><br><span class=\"line\">consul_1.13.2_darwin_amd64.zip</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">解压安装</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban consul]# unzip consul_1.13.2_linux_amd64.zip </span><br><span class=\"line\">Archive:  consul_1.13.2_linux_amd64.zip</span><br><span class=\"line\">  inflating: consul                  </span><br><span class=\"line\">[root@tiaoban consul]# ls</span><br><span class=\"line\">consul  consul_1.13.2_linux_amd64.zip</span><br><span class=\"line\">[root@tiaoban consul]# mv consul /usr/local/bin/</span><br><span class=\"line\">[root@tiaoban consul]# consul version</span><br><span class=\"line\">Consul v1.13.2</span><br><span class=\"line\">Revision 0e046bbb</span><br><span class=\"line\">Build Date 2022-09-20T20:30:07Z</span><br><span class=\"line\">Protocol 2 spoken by default, understands 2 to 3 (agent will automatically use protocol &gt;2 when speaking to compatible agents)</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务测试<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">使用单节点模式启动测试</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban consul]# consul agent -dev -ui -client 0.0.0.0</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841427-2c5517e2-2c9f-4ae3-9048-de5811f58ea6.jpeg\"><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">添加启动脚本</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# cat /usr/lib/systemd/system/consul.service </span><br><span class=\"line\">[Unit]</span><br><span class=\"line\">Description=consul</span><br><span class=\"line\">After=network.target</span><br><span class=\"line\">    </span><br><span class=\"line\">[Service]</span><br><span class=\"line\">ExecStart=/usr/local/consul/start.sh</span><br><span class=\"line\">KillSignal=SIGTERM</span><br><span class=\"line\">    </span><br><span class=\"line\">[Install]</span><br><span class=\"line\">WantedBy=multi-user.target</span><br><span class=\"line\">[root@tiaoban ~]# mkdir -p /usr/local/consul/</span><br><span class=\"line\">[root@tiaoban ~]# cat /usr/local/consul/start.sh</span><br><span class=\"line\">#!/bin/bash</span><br><span class=\"line\">/usr/local/bin/consul agent -dev -ui -client 0.0.0.0</span><br><span class=\"line\">[root@tiaoban ~]# chmod u+x /usr/local/consul/start.sh</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban ~]# systemctl daemon-reload </span><br><span class=\"line\">[root@tiaoban ~]# systemctl start consul</span><br><span class=\"line\">[root@tiaoban ~]# systemctl enable consul</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"b19ba4ef\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务启动</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">以下操作以yum方式安装consul配置为例，配置文件路径</font><code>&lt;font style=&quot;background-color:rgba(255, 255, 255, 0);&quot;&gt;/etc/consul.d/consul.hcl&lt;/font&gt;</code></p>\n<h2 id=\"8c7054cf\"><font style=\"background-color:rgba(255, 255, 255, 0);\">单节点模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指明数据中心的名字</span><br><span class=\"line\">datacenter = &quot;my-dc-1&quot;</span><br><span class=\"line\"># 存储状态的数据目录</span><br><span class=\"line\">data_dir = &quot;/opt/consul&quot;</span><br><span class=\"line\"># web ui</span><br><span class=\"line\">ui_config&#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"># 节点是个Server</span><br><span class=\"line\">server = true</span><br><span class=\"line\"># 绑定的一个地址，用于节点之间通信的地址</span><br><span class=\"line\">bind_addr = &quot;192.168.10.100&quot;</span><br><span class=\"line\"># 期望提供的Server节点数目</span><br><span class=\"line\">bootstrap_expect=1</span><br><span class=\"line\"># Client接口绑定到的地址</span><br><span class=\"line\">client_addr = &quot;0.0.0.0&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务，查看集群成员</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@tiaoban consul.d]# systemctl start consul</span><br><span class=\"line\">[root@tiaoban consul.d]# consul members </span><br><span class=\"line\">Node     Address              Status  Type    Build   Protocol  DC       Partition  Segment</span><br><span class=\"line\">tiaoban  192.168.10.100:8301  alive   server  1.13.2  2         my-dc-1  default    &lt;all&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"6955953a\"><font style=\"background-color:rgba(255, 255, 255, 0);\">集群模式</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">主机规划</font>\n\n<table>\n<thead>\n<tr>\n<th><strong>主机名</strong></th>\n<th><strong>IP</strong></th>\n<th><strong>角色</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>k8s-master</td>\n<td>192.168.10.10</td>\n<td>server</td>\n</tr>\n<tr>\n<td>k8s-work1</td>\n<td>192.168.10.11</td>\n<td>server</td>\n</tr>\n<tr>\n<td>k8s-work2</td>\n<td>192.168.10.12</td>\n<td>server</td>\n</tr>\n<tr>\n<td>tiaoban</td>\n<td>192.168.10.100</td>\n<td>clinet</td>\n</tr>\n</tbody></table>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">server端配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指明数据中心的名字</span><br><span class=\"line\">datacenter = &quot;my-dc-1&quot;</span><br><span class=\"line\"># 存储状态的数据目录</span><br><span class=\"line\">data_dir = &quot;/opt/consul&quot;</span><br><span class=\"line\"># web ui</span><br><span class=\"line\">ui_config&#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"># 节点是个Server</span><br><span class=\"line\">server = true</span><br><span class=\"line\"># 绑定的一个地址，用于节点之间通信的地址。此处以192.168.10.10为例，其他两个更换ip即可。</span><br><span class=\"line\">bind_addr = &quot;192.168.10.10&quot;</span><br><span class=\"line\"># 期望提供的Server节点数目</span><br><span class=\"line\">bootstrap_expect=3</span><br><span class=\"line\"># Client接口绑定到的地址</span><br><span class=\"line\">client_addr = &quot;0.0.0.0&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">client配置</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 指明数据中心的名字</span><br><span class=\"line\">datacenter = &quot;my-dc-1&quot;</span><br><span class=\"line\"># 存储状态的数据目录</span><br><span class=\"line\">data_dir = &quot;/opt/consul&quot;</span><br><span class=\"line\"># web ui</span><br><span class=\"line\">ui_config&#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"># 节点是个Server</span><br><span class=\"line\">server = false</span><br><span class=\"line\"># 绑定的一个地址，用于节点之间通信的地址</span><br><span class=\"line\">bind_addr = &quot;192.168.10.100&quot;</span><br><span class=\"line\"># Client接口绑定到的地址</span><br><span class=\"line\">client_addr = &quot;0.0.0.0&quot;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">启动服务并加入集群</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 所有机器执行</span><br><span class=\"line\">[root@k8s-master consul.d]# systemctl restart consul</span><br><span class=\"line\"># 除了k8s-master以外的其他机器执行</span><br><span class=\"line\">[root@k8s-tiaoban consul.d]# consul join 192.168.10.10</span><br><span class=\"line\">Successfully joined cluster by contacting 1 nodes.</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"4b194b09\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul 常用CLI</font></h1>\n---\n\n<h2 id=\"eb75b9f5\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# consul catalog services</span><br><span class=\"line\">consul</span><br><span class=\"line\">traefik</span><br><span class=\"line\">traefik-tcp</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"75acbd2e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">注销服务</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">consul services deregister -id=:service-id</span><br><span class=\"line\">// :service-id 为用户服务Id</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1b4e985d\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看节点成员</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# consul members</span><br><span class=\"line\">Node        Address              Status  Type    Build   Protocol  DC       Partition  Segment</span><br><span class=\"line\">k8s-master  192.168.10.10:8301   alive   server  1.13.3  2         my-dc-1  default    &lt;all&gt;</span><br><span class=\"line\">k8s-work1   192.168.10.11:8301   alive   server  1.13.3  2         my-dc-1  default    &lt;all&gt;</span><br><span class=\"line\">k8s-work2   192.168.10.12:8301   alive   server  1.13.3  2         my-dc-1  default    &lt;all&gt;</span><br><span class=\"line\">tiaoban     192.168.10.100:8301  alive   client  1.13.2  2         my-dc-1  default    &lt;default&gt;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1459fae8\"><font style=\"background-color:rgba(255, 255, 255, 0);\">查看server节点信息</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# consul operator raft list-peers</span><br><span class=\"line\">Node        ID                                    Address             State     Voter  RaftProtocol</span><br><span class=\"line\">k8s-work1   322a522a-dcf5-3727-052e-0f2d65406f8d  192.168.10.11:8300  follower  true   3</span><br><span class=\"line\">k8s-master  5db3c09a-f94d-b53f-6c9f-694beb64c1aa  192.168.10.10:8300  leader    true   3</span><br><span class=\"line\">k8s-work2   d0e4a609-f029-cd91-1d61-63c3403b82b3  192.168.10.12:8300  follower  false  3</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"81ea3784\"><font style=\"background-color:rgba(255, 255, 255, 0);\">Consul常用HTTP API</font></h2>\n<h2 id=\"3b842616\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/services：该端点返回在本地代理程序中注册的所有服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/{service_id}：返回在本地代理上注册的单个服务实例的完整服务定义；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/name/{service_name} ：通过名称检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/health/service/id/{service_id}：通过id检索注册的服务状态（设置了健康检查的服务）；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/health/service/{service_name}?passing：通过健康检查的服务(包含未设置check的service)</font>\n\n<h2 id=\"f3bad82b\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/register：注册服务；</font>\n\n<h2 id=\"18616023\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务删除</font></h2>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/deregister/{service_id}：注销服务；</font>\n+ <font style=\"background-color:rgba(255, 255, 255, 0);\">/agent/service/maintenance/{service_id}：该端点将给定的服务置于“维护模式”，在维护模式下，该服务将被标记为不可用，并且不会出现在DNS或API查询中；</font>\n\n<h1 id=\"f3bad82b-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务注册</font></h1>\n---\n\n<h2 id=\"15c64aa0\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置文件</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">新增json配置文件</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# cat /etc/consul.d/kube-apiserver.json </span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;service&quot;: &#123;</span><br><span class=\"line\">        &quot;name&quot;: &quot;traefik-tcp&quot;,</span><br><span class=\"line\">        &quot;tags&quot;: [</span><br><span class=\"line\">            &quot;k8s&quot;,&quot;traefik&quot;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">        &quot;port&quot;: 9100</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重启服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# systemctl restart consul</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看<br></font><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841445-ed3d6655-6fda-49ac-88cb-19c119d5de0f.jpeg\"></p>\n<h2 id=\"http-api\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">注册一个name为traefik的服务</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# curl -X PUT -d &#x27;&#123;&quot;name&quot;: &quot;traefik&quot;,&quot;address&quot;: &quot;192.168.10.10&quot;,&quot;port&quot;: 80,&quot;tags&quot;: [&quot;k8s&quot;]&#125;&#x27; http://192.168.10.10:8500/v1/agent/service/register</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">注册带健康检查的服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -X PUT -d &#x27;&#123;&quot;name&quot;: &quot;traefik-metrics&quot;,&quot;address&quot;: &quot;192.168.10.10&quot;,&quot;port&quot;: 80,&quot;tags&quot;: [&quot;k8s&quot;],&quot;checks&quot;:[&#123;&quot;http&quot;:&quot;http://192.168.10.10:9100/metrics&quot;,&quot;interval&quot;:&quot;5s&quot;&#125;]&#125;&#x27; http://192.168.10.10:8500/v1/agent/service/register</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">打开管理页面查看已注册的服务<br></font><img src=\"https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841454-78a08404-76de-44b8-8f10-689d9517273f.jpeg\"></p>\n<h2 id=\"sdk\"><font style=\"background-color:rgba(255, 255, 255, 0);\">SDK</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">除了采用配置文件或者HTTP API方式注册服务外，consul也支持使用sdk包注册查询服务，目前主流的开发语法均已支持，详情参考文档：  \n</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks</font>](https://developer.hashicorp.com/consul/api-docs/libraries-and-sdks)\n\n<h1 id=\"3b842616-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查询</font></h1>\n---\n\n<h2 id=\"http-api-1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务列表</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/services | jq</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;consul&quot;: [],</span><br><span class=\"line\">  &quot;traefik&quot;: [</span><br><span class=\"line\">    &quot;k8s&quot;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  &quot;traefik-tcp&quot;: [</span><br><span class=\"line\">    &quot;k8s&quot;,</span><br><span class=\"line\">    &quot;traefik&quot;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看服务详细信息</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/catalog/service/traefik | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;ID&quot;: &quot;eda0ef7f-ca12-bbca-c84e-f88cc3664cd1&quot;,</span><br><span class=\"line\">    &quot;Node&quot;: &quot;tiaoban&quot;,</span><br><span class=\"line\">    &quot;Address&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">    &quot;Datacenter&quot;: &quot;my-dc-1&quot;,</span><br><span class=\"line\">    &quot;TaggedAddresses&quot;: &#123;</span><br><span class=\"line\">      &quot;lan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;lan_ipv4&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;wan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;wan_ipv4&quot;: &quot;192.168.10.100&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;NodeMeta&quot;: &#123;</span><br><span class=\"line\">      &quot;consul-network-segment&quot;: &quot;&quot;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceKind&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;ServiceID&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">    &quot;ServiceName&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">    &quot;ServiceTags&quot;: [</span><br><span class=\"line\">      &quot;k8s&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;ServiceAddress&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">    &quot;ServiceTaggedAddresses&quot;: &#123;</span><br><span class=\"line\">      &quot;lan_ipv4&quot;: &#123;</span><br><span class=\"line\">        &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">        &quot;Port&quot;: 80</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;wan_ipv4&quot;: &#123;</span><br><span class=\"line\">        &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">        &quot;Port&quot;: 80</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceWeights&quot;: &#123;</span><br><span class=\"line\">      &quot;Passing&quot;: 1,</span><br><span class=\"line\">      &quot;Warning&quot;: 1</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceMeta&quot;: &#123;&#125;,</span><br><span class=\"line\">    &quot;ServicePort&quot;: 80,</span><br><span class=\"line\">    &quot;ServiceSocketPath&quot;: &quot;&quot;,</span><br><span class=\"line\">    &quot;ServiceEnableTagOverride&quot;: false,</span><br><span class=\"line\">    &quot;ServiceProxy&quot;: &#123;</span><br><span class=\"line\">      &quot;Mode&quot;: &quot;&quot;,</span><br><span class=\"line\">      &quot;MeshGateway&quot;: &#123;&#125;,</span><br><span class=\"line\">      &quot;Expose&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;ServiceConnect&quot;: &#123;&#125;,</span><br><span class=\"line\">    &quot;CreateIndex&quot;: 12,</span><br><span class=\"line\">    &quot;ModifyIndex&quot;: 12</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">健康检查</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# curl -s http://192.168.10.10:8500/v1/health/service/traefik?passing | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;Node&quot;: &#123;</span><br><span class=\"line\">      &quot;ID&quot;: &quot;eda0ef7f-ca12-bbca-c84e-f88cc3664cd1&quot;,</span><br><span class=\"line\">      &quot;Node&quot;: &quot;tiaoban&quot;,</span><br><span class=\"line\">      &quot;Address&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">      &quot;Datacenter&quot;: &quot;my-dc-1&quot;,</span><br><span class=\"line\">      &quot;TaggedAddresses&quot;: &#123;</span><br><span class=\"line\">        &quot;lan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;lan_ipv4&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;wan&quot;: &quot;192.168.10.100&quot;,</span><br><span class=\"line\">        &quot;wan_ipv4&quot;: &quot;192.168.10.100&quot;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;Meta&quot;: &#123;</span><br><span class=\"line\">        &quot;consul-network-segment&quot;: &quot;&quot;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;CreateIndex&quot;: 9,</span><br><span class=\"line\">      &quot;ModifyIndex&quot;: 11</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;Service&quot;: &#123;</span><br><span class=\"line\">      &quot;ID&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">      &quot;Service&quot;: &quot;traefik&quot;,</span><br><span class=\"line\">      &quot;Tags&quot;: [</span><br><span class=\"line\">        &quot;k8s&quot;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">      &quot;TaggedAddresses&quot;: &#123;</span><br><span class=\"line\">        &quot;lan_ipv4&quot;: &#123;</span><br><span class=\"line\">          &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">          &quot;Port&quot;: 80</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;wan_ipv4&quot;: &#123;</span><br><span class=\"line\">          &quot;Address&quot;: &quot;192.168.10.10&quot;,</span><br><span class=\"line\">          &quot;Port&quot;: 80</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;Meta&quot;: null,</span><br><span class=\"line\">      &quot;Port&quot;: 80,</span><br><span class=\"line\">      &quot;Weights&quot;: &#123;</span><br><span class=\"line\">        &quot;Passing&quot;: 1,</span><br><span class=\"line\">        &quot;Warning&quot;: 1</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;EnableTagOverride&quot;: false,</span><br><span class=\"line\">      &quot;Proxy&quot;: &#123;</span><br><span class=\"line\">        &quot;Mode&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;MeshGateway&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;Expose&quot;: &#123;&#125;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;Connect&quot;: &#123;&#125;,</span><br><span class=\"line\">      &quot;PeerName&quot;: &quot;&quot;,</span><br><span class=\"line\">      &quot;CreateIndex&quot;: 12,</span><br><span class=\"line\">      &quot;ModifyIndex&quot;: 12</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;Checks&quot;: [</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">        &quot;Node&quot;: &quot;tiaoban&quot;,</span><br><span class=\"line\">        &quot;CheckID&quot;: &quot;serfHealth&quot;,</span><br><span class=\"line\">        &quot;Name&quot;: &quot;Serf Health Status&quot;,</span><br><span class=\"line\">        &quot;Status&quot;: &quot;passing&quot;,</span><br><span class=\"line\">        &quot;Notes&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Output&quot;: &quot;Agent alive and reachable&quot;,</span><br><span class=\"line\">        &quot;ServiceID&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;ServiceName&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;ServiceTags&quot;: [],</span><br><span class=\"line\">        &quot;Type&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Interval&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Timeout&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;ExposedPort&quot;: 0,</span><br><span class=\"line\">        &quot;Definition&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;CreateIndex&quot;: 9,</span><br><span class=\"line\">        &quot;ModifyIndex&quot;: 9</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除注册的服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# curl -X PUT http://192.168.10.10:8500/v1/agent/service/deregister/traefik</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<h2 id=\"74c3df45\"><font style=\"background-color:rgba(255, 255, 255, 0);\">DNS解析</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">DNS接口是Consul中主要的查询接口之一，另一个是HTTP接口， HTTP接口查询请查阅,Consul默认在8600端口监听DNS查询。  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">参考文档：</font>[<font style=\"background-color:rgba(255, 255, 255, 0);\">https://developer.hashicorp.com/consul/docs/discovery/dns</font>](https://developer.hashicorp.com/consul/docs/discovery/dns)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">要使用DNS接口， 有几种方法可以实现：  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">一是使用指定的DNS解析库， 然后指向Consul；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">二是把Consul设置为节点的DNS服务器, 并且提供recursors配置项， 这样非Consul的查询也能被解析；  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">最后一种方法是从已有的DNS服务器上把所有consul.为域名的请求转发到consul agent上。  \n</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">节点查找</font>**<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">查找节点的地址信息，查找格式：<node>.node[.datacenter].<domain>。如果datacenter不指定，默认为当前集群查询。</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# dig @192.168.10.10 -p 8600 tiaoban.node.consul ANY</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; @192.168.10.10 -p 8600 tiaoban.node.consul ANY</span><br><span class=\"line\">; (1 server found)</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">;; Got answer:</span><br><span class=\"line\">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 25684</span><br><span class=\"line\">;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1</span><br><span class=\"line\">;; WARNING: recursion requested but not available</span><br><span class=\"line\"></span><br><span class=\"line\">;; OPT PSEUDOSECTION:</span><br><span class=\"line\">; EDNS: version: 0, flags:; udp: 4096</span><br><span class=\"line\">;; QUESTION SECTION:</span><br><span class=\"line\">;tiaoban.node.consul.           IN      ANY</span><br><span class=\"line\"></span><br><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">tiaoban.node.consul.    0       IN      A       192.168.10.100</span><br><span class=\"line\">tiaoban.node.consul.    0       IN      TXT     &quot;consul-network-segment=&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">;; Query time: 14 msec</span><br><span class=\"line\">;; SERVER: 192.168.10.10#8600(192.168.10.10)</span><br><span class=\"line\">;; WHEN: 一 10月 31 10:51:10 CST 2022</span><br><span class=\"line\">;; MSG SIZE  rcvd: 100</span><br></pre></td></tr></table></figure>\n\n<p><strong><font style=\"background-color:rgba(255, 255, 255, 0);\">服务查找</font></strong><font style=\"background-color:rgba(255, 255, 255, 0);\"><br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">查询服务提供者。服务查询支持两种查找方法：标准和严格RFC 2782。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">标准查找格式：[tag.]<service>.service[.datacenter].<domain>。Tag是可选的，而且与节点查找一样，数据中心也是可选。如果没有提供Tag，就不会有过滤，如果没有数据中心，就会选择默认的数据中心。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master ~]# dig @192.168.10.10 -p 8600 traefik.service.consul SRV</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; @192.168.10.10 -p 8600 traefik.service.consul SRV</span><br><span class=\"line\">; (1 server found)</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">;; Got answer:</span><br><span class=\"line\">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 28200</span><br><span class=\"line\">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3</span><br><span class=\"line\">;; WARNING: recursion requested but not available</span><br><span class=\"line\"></span><br><span class=\"line\">;; OPT PSEUDOSECTION:</span><br><span class=\"line\">; EDNS: version: 0, flags:; udp: 4096</span><br><span class=\"line\">;; QUESTION SECTION:</span><br><span class=\"line\">;traefik.service.consul.                IN      SRV</span><br><span class=\"line\"></span><br><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">traefik.service.consul. 0       IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.</span><br><span class=\"line\"></span><br><span class=\"line\">;; ADDITIONAL SECTION:</span><br><span class=\"line\">c0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10</span><br><span class=\"line\">tiaoban.node.my-dc-1.consul. 0  IN      TXT     &quot;consul-network-segment=&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">;; Query time: 13 msec</span><br><span class=\"line\">;; SERVER: 192.168.10.10#8600(192.168.10.10)</span><br><span class=\"line\">;; WHEN: 一 10月 31 10:53:30 CST 2022</span><br><span class=\"line\">;; MSG SIZE  rcvd: 164</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">RFC2782 查找 格式：</font><em><font style=\"background-color:rgba(255, 255, 255, 0);\"><service>.</font></em><font style=\"background-color:rgba(255, 255, 255, 0);\"><protocol>.service[.datacenter][.domain]根据RFC 2782， SRV请求都应该在service和protocol前使用(_)作为前缀。避免发生DNS冲突。Protocol可以是service任何一个tag，如果service没有tag，使用tcp作为protocol。如果一旦设置了tcp，那么查询时将不会执行任何标签过滤。</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查询tag为k8s的注册服务traefik信息。</span><br><span class=\"line\">[root@k8s-master ~]# dig @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV</span><br><span class=\"line\"></span><br><span class=\"line\">; &lt;&lt;&gt;&gt; DiG 9.11.26-RedHat-9.11.26-6.el8 &lt;&lt;&gt;&gt; @192.168.10.10 -p 8600 _traefik._k8s.service.consul SRV</span><br><span class=\"line\">; (1 server found)</span><br><span class=\"line\">;; global options: +cmd</span><br><span class=\"line\">;; Got answer:</span><br><span class=\"line\">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43270</span><br><span class=\"line\">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3</span><br><span class=\"line\">;; WARNING: recursion requested but not available</span><br><span class=\"line\"></span><br><span class=\"line\">;; OPT PSEUDOSECTION:</span><br><span class=\"line\">; EDNS: version: 0, flags:; udp: 4096</span><br><span class=\"line\">;; QUESTION SECTION:</span><br><span class=\"line\">;_traefik._k8s.service.consul.  IN      SRV</span><br><span class=\"line\"></span><br><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">_traefik._k8s.service.consul. 0 IN      SRV     1 1 80 c0a80a0a.addr.my-dc-1.consul.</span><br><span class=\"line\"></span><br><span class=\"line\">;; ADDITIONAL SECTION:</span><br><span class=\"line\">c0a80a0a.addr.my-dc-1.consul. 0 IN      A       192.168.10.10</span><br><span class=\"line\">tiaoban.node.my-dc-1.consul. 0  IN      TXT     &quot;consul-network-segment=&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">;; Query time: 1 msec</span><br><span class=\"line\">;; SERVER: 192.168.10.10#8600(192.168.10.10)</span><br><span class=\"line\">;; WHEN: 一 10月 31 10:57:05 CST 2022</span><br><span class=\"line\">;; MSG SIZE  rcvd: 170</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"bf9a8ea1\"><font style=\"background-color:rgba(255, 255, 255, 0);\">配置kv</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 是consul的核心功能，并随consul agent一起安装。consul kv允许用户存储索引对象，尽管其主要用途是存储配置参数和元数据。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">consul kv 数据存储在server上，可以由任何agent（client或server）访问。consul允许在所有server之间自动复制数据，如果发生故障，拥有一定数量的server将减少数据丢失的风险。<br></font><font style=\"background-color:rgba(255, 255, 255, 0);\">数据存储位于server上的数据目录中，为确保在完全中断的情况下不会丢失数据，可以使用 consul snapshot 命令备份数据。还可以通过 consul kv 子命令、HTTP API 和 Consul UI 访问kv存储。</font></p>\n<h2 id=\"dbb0d3bb\"><font style=\"background-color:rgba(255, 255, 255, 0);\">命令行</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">命令行创建kv</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul kv put key1 value1</span><br><span class=\"line\">Success! Data written to: key1</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">查看kv</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 查看所有key value数据</span><br><span class=\"line\">[root@k8s-master consul.d]# consul kv get --recurse </span><br><span class=\"line\">key1:value1</span><br><span class=\"line\">key2:value2</span><br><span class=\"line\"># 查看指定key value数据</span><br><span class=\"line\">[root@k8s-master consul.d]# consul kv get key2</span><br><span class=\"line\">value2</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">更新kv</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul kv put key2 v2</span><br><span class=\"line\">Success! Data written to: key2</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">删除kv</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul kv delete key2</span><br><span class=\"line\">Success! Deleted key: key2</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"web\"><font style=\"background-color:rgba(255, 255, 255, 0);\">web</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web界面创建kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900841944-ff641b3f-de5b-4382-b961-1c30bf857d1b.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">web界面查看kv  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842227-005c67d9-9bd2-4a02-9f36-e4e9aa288c32.jpeg)\n\n<h2 id=\"http-api-2\"><font style=\"background-color:rgba(255, 255, 255, 0);\">HTTP API</font></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 设置kv</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -X PUT -d &#x27;value3&#x27; http://192.168.10.10:8500/v1/kv/key3</span><br><span class=\"line\">true</span><br><span class=\"line\"># 查看kv</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;LockIndex&quot;: 0,</span><br><span class=\"line\">    &quot;Key&quot;: &quot;key3&quot;,</span><br><span class=\"line\">    &quot;Flags&quot;: 0,</span><br><span class=\"line\">    &quot;Value&quot;: &quot;dmFsdWUz&quot;,</span><br><span class=\"line\">    &quot;CreateIndex&quot;: 611,</span><br><span class=\"line\">    &quot;ModifyIndex&quot;: 611</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br><span class=\"line\"># base64解码查看内容</span><br><span class=\"line\">[root@k8s-master consul.d]# echo &quot;dmFsdWUz&quot; | base64 -d</span><br><span class=\"line\">value3</span><br><span class=\"line\"># 删除kv</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -X DELETE http://192.168.10.10:8500/v1/kv/key3</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"f58e1c18\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问控制</font></h1>\n---\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">通过ACLS 来确保安全的访问 UI, API, CLI, servie 通信，Agent通信。如果想要确保数据中心安全，就需要配置ACLS。ACL核心原理是，将规则分组为策略， 然后一个或多个策略于令牌关联。</font></p>\n<h2 id=\"8facd89c\"><font style=\"background-color:rgba(255, 255, 255, 0);\">启用ACL</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">修改consul配置文件，新增如下内容</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># acl访问控制</span><br><span class=\"line\">acl = &#123;</span><br><span class=\"line\">  enabled = true</span><br><span class=\"line\">  default_policy = &quot;deny&quot; # 默认拒绝所有操作</span><br><span class=\"line\">  enable_token_persistence = true # 持久化到磁盘，重启时重新加载</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">重启consul服务</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# systemctl restart consul</span><br></pre></td></tr></table></figure>\n\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\"></font></p>\n<p><font style=\"background-color:rgba(255, 255, 255, 0);\">生成token</font></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@k8s-master consul.d]# consul acl bootstrap</span><br><span class=\"line\">AccessorID:       16a37577-f243-94fb-8770-35489870025c</span><br><span class=\"line\">SecretID:         54a3e3fd-ea07-85a8-67e3-33107a958977</span><br><span class=\"line\">Description:      Bootstrap Token (Global Management)</span><br><span class=\"line\">Local:            false</span><br><span class=\"line\">Create Time:      2022-10-27 22:56:07.654230262 +0800 CST</span><br><span class=\"line\">Policies:</span><br><span class=\"line\">   00000000-0000-0000-0000-000000000001 - global-management</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"046e223e\"><font style=\"background-color:rgba(255, 255, 255, 0);\">访问验证</font></h2>\n<font style=\"background-color:rgba(255, 255, 255, 0);\">web页面访问验证  \n</font>![](https://cdn.nlark.com/yuque/0/2025/jpeg/43141749/1738900842237-eb42da7b-f34d-499d-9861-dd3bb7290224.jpeg)<font style=\"background-color:rgba(255, 255, 255, 0);\">  \n</font><font style=\"background-color:rgba(255, 255, 255, 0);\">api接口访问验证</font>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 直接获取kv提示权限拒绝</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -s http://192.168.10.10:8500/v1/kv/key3 </span><br><span class=\"line\">rpc error making call: Permission denied: token with AccessorID &#x27;00000000-0000-0000-0000-000000000002&#x27; lacks permission &#x27;key:read&#x27; on &quot;key3&quot;[root@k8s-master consul.d]# </span><br><span class=\"line\"># 请求头添加token访问</span><br><span class=\"line\">[root@k8s-master consul.d]# curl -s -H &quot;X-Consul-Token:54a3e3fd-ea07-85a8-67e3-33107a958977&quot; http://192.168.10.10:8500/v1/kv/key3 | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;LockIndex&quot;: 0,</span><br><span class=\"line\">    &quot;Key&quot;: &quot;key3&quot;,</span><br><span class=\"line\">    &quot;Flags&quot;: 0,</span><br><span class=\"line\">    &quot;Value&quot;: &quot;dmFsdWUz&quot;,</span><br><span class=\"line\">    &quot;CreateIndex&quot;: 611,</span><br><span class=\"line\">    &quot;ModifyIndex&quot;: 611</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}